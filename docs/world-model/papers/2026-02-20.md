# arXiv World Model Papers - 2026-02-20

**Paper Count**: 2

---

## 1. AI Gamestore: Scalable, Open-Ended Evaluation of Machine General Intelligence with Human Games / AI Gamestore：通过人类游戏对机器通用智能进行可扩展、开放式评估

**Date**: 2026-02-19 | **arXiv**: [2602.17594v1](http://arxiv.org/abs/2602.17594v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.17594v1)

**Categories**: cs.AI

<details><summary><b>Abstract / 摘要</b></summary>

Rigorously evaluating machine intelligence against the broad spectrum of human general intelligence has become increasingly important and challenging in this era of rapid technological advance. Conventional AI benchmarks typically assess only narrow capabilities in a limited range of human activity. Most are also static, quickly saturating as developers explicitly or implicitly optimize for them. We propose that a more promising way to evaluate human-like general intelligence in AI systems is through a particularly strong form of general game playing: studying how and how well they play and learn to play \textbf{all conceivable human games}, in comparison to human players with the same level of experience, time, or other resources. We define a "human game" to be a game designed by humans for humans, and argue for the evaluative suitability of this space of all such games people can imagine and enjoy -- the "Multiverse of Human Games". Taking a first step towards this vision, we introduce the AI GameStore, a scalable and open-ended platform that uses LLMs with humans-in-the-loop to synthesize new representative human games, by automatically sourcing and adapting standardized and containerized variants of game environments from popular human digital gaming platforms. As a proof of concept, we generated 100 such games based on the top charts of Apple App Store and Steam, and evaluated seven frontier vision-language models (VLMs) on short episodes of play. The best models achieved less than 10\% of the human average score on the majority of the games, and especially struggled with games that challenge world-model learning, memory and planning. We conclude with a set of next steps for building out the AI GameStore as a practical way to measure and drive progress toward human-like general intelligence in machines.

在这个技术快速进步的时代，根据广泛的人类通用智能严格评估机器智能变得越来越重要和具有挑战性。传统的人工智能基准通常仅评估有限范围的人类活动中的狭窄能力。大多数也是静态的，随着开发人员显式或隐式地优化它们，它们很快就会饱和。我们提出，评估人工智能系统中类人通用智能的一种更有前景的方法是通过一种特别强大的通用游戏玩法：与具有相同经验、时间或其他资源水平的人类玩家相比，研究它们如何玩、玩得如何以及学会玩\textbf{所有可以想象的人类游戏}。我们将“人类游戏”定义为由人类为人类设计的游戏，并论证了人们可以想象和享受的所有此类游戏空间的评估适用性——“人类游戏的多元宇宙”。为了实现这一愿景，我们迈出了第一步，我们推出了 AI GameStore，这是一个可扩展的开放式平台，它使用法学硕士和人类在环技术，通过自动从流行的人类数字游戏平台中获取和调整游戏环境的标准化和容器化变体，来合成新的代表性人类游戏。作为概念验证，我们根据 Apple App Store 和 Steam 的热门排行榜生成了 100 款此类游戏，并在短集游戏中评估了 7 个前沿视觉语言模型 (VLM)。最好的模型在大多数游戏中的得分都不到人类平均得分的 10%，尤其是在挑战世界模型学习、记忆和规划的游戏中表现不佳。最后，我们提出了一系列后续步骤，旨在构建 AI GameStore，作为衡量和推动机器类人通用智能进步的实用方法。

</details>

---

## 2. Continual learning and refinement of causal models through dynamic predicate invention / 通过动态谓词发明不断学习和完善因果模型

**Date**: 2026-02-19 | **arXiv**: [2602.17217v1](http://arxiv.org/abs/2602.17217v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.17217v1)

**Categories**: cs.AI

<details><summary><b>Abstract / 摘要</b></summary>

Efficiently navigating complex environments requires agents to internalize the underlying logic of their world, yet standard world modelling methods often struggle with sample inefficiency, lack of transparency, and poor scalability. We propose a framework for constructing symbolic causal world models entirely online by integrating continuous model learning and repair into the agent's decision loop, by leveraging the power of Meta-Interpretive Learning and predicate invention to find semantically meaningful and reusable abstractions, allowing an agent to construct a hierarchy of disentangled, high-quality concepts from its observations. We demonstrate that our lifted inference approach scales to domains with complex relational dynamics, where propositional methods suffer from combinatorial explosion, while achieving sample-efficiency orders of magnitude higher than the established PPO neural-network-based baseline.

有效地驾驭复杂的环境需要智能体将其世界的底层逻辑内化，但标准的世界建模方法常常面临样本效率低、缺乏透明度和可扩展性差的问题。我们提出了一个完全在线构建符号因果世界模型的框架，通过将连续模型学习和修复集成到代理的决策循环中，利用元解释学习和谓词发明的力量来找到语义上有意义和可重用的抽象，从而允许代理从其观察中构建一个解开的高质量概念的层次结构。我们证明，我们的提升推理方法可以扩展到具有复杂关系动态的领域，其中命题方法遭受组合爆炸，同时实现的样本效率数量级高于已建立的基于 PPO 神经网络的基线。

</details>

---

