# arXiv Video Papers - 2026-02-12

**Paper Count**: 288

---

## 1. Interpretable Vision Transformers in Monocular Depth Estimation via SVDA

**中文标题**: 通过 SVDA 进行单眼深度估计的可解释视觉变换器

**Date**: 2026-02-11 | **arXiv**: [2602.11005v1](http://arxiv.org/abs/2602.11005v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.11005v1)

<details><summary><b>Abstract</b></summary>

Monocular depth estimation is a central problem in computer vision with applications in robotics, AR, and autonomous driving, yet the self-attention mechanisms that drive modern Transformer architectures remain opaque. We introduce SVD-Inspired Attention (SVDA) into the Dense Prediction Transformer (DPT), providing the first spectrally structured formulation of attention for dense prediction tasks. SVDA decouples directional alignment from spectral modulation by embedding a learnable diagonal matrix into normalized query-key interactions, enabling attention maps that are intrinsically interpretable rather than post-hoc approximations. Experiments on KITTI and NYU-v2 show that SVDA preserves or slightly improves predictive accuracy while adding only minor computational overhead. More importantly, SVDA unlocks six spectral indicators that quantify entropy, rank, sparsity, alignment, selectivity, and robustness. These reveal consistent cross-dataset and depth-wise patterns in how attention organizes during training, insights that remain inaccessible in standard Transformers. By shifting the role of attention from opaque mechanism to quantifiable descriptor, SVDA redefines interpretability in monocular depth estimation and opens a principled avenue toward transparent dense prediction models.

</details>

<details><summary><b>中文摘要</b></summary>

单目深度估计是计算机视觉在机器人、AR 和自动驾驶领域的应用的核心问题，但驱动现代 Transformer 架构的自注意力机制仍然不透明。我们将 SVD-Inspired Attention (SVDA) 引入到密集预测变换器 (DPT) 中，为密集预测任务提供了第一个频谱结构的注意力公式。 SVDA 通过将可学习的对角矩阵嵌入到标准化的查询键交互中，将方向对齐与频谱调制解耦，从而实现本质上可解释的注意力图，而不是事后近似。 KITTI 和 NYU-v2 上的实验表明，SVDA 保留或略微提高了预测准确性，同时仅增加了少量计算开销。更重要的是，SVDA 解锁了六个光谱指标，可量化熵、秩、稀疏性、对齐、选择性和鲁棒性。这些揭示了训练过程中注意力如何组织的一致的跨数据集和深度模式，这些见解在标准 Transformer 中仍然无法获得。通过将注意力的作用从不透明机制转移到可量化描述符，SVDA 重新定义了单目深度估计的可解释性，并为透明密集预测模型开辟了一条原则性途径。

</details>

---

## 2. Interpretable Vision Transformers in Image Classification via SVDA

**中文标题**: 通过 SVDA 进行图像分类中的可解释视觉转换器

**Date**: 2026-02-11 | **arXiv**: [2602.10994v1](http://arxiv.org/abs/2602.10994v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10994v1)

<details><summary><b>Abstract</b></summary>

Vision Transformers (ViTs) have achieved state-of-the-art performance in image classification, yet their attention mechanisms often remain opaque and exhibit dense, non-structured behaviors. In this work, we adapt our previously proposed SVD-Inspired Attention (SVDA) mechanism to the ViT architecture, introducing a geometrically grounded formulation that enhances interpretability, sparsity, and spectral structure. We apply the use of interpretability indicators -- originally proposed with SVDA -- to monitor attention dynamics during training and assess structural properties of the learned representations. Experimental evaluations on four widely used benchmarks -- CIFAR-10, FashionMNIST, CIFAR-100, and ImageNet-100 -- demonstrate that SVDA consistently yields more interpretable attention patterns without sacrificing classification accuracy. While the current framework offers descriptive insights rather than prescriptive guidance, our results establish SVDA as a comprehensive and informative tool for analyzing and developing structured attention models in computer vision. This work lays the foundation for future advances in explainable AI, spectral diagnostics, and attention-based model compression.

</details>

<details><summary><b>中文摘要</b></summary>

视觉变换器 (ViT) 在图像分类方面取得了最先进的性能，但它们的注意力机制通常仍然不透明，并表现出密集的非结构化行为。在这项工作中，我们将之前提出的 SVD-Inspired Attention (SVDA) 机制应用于 ViT 架构，引入了一种基于几何的公式，增强了可解释性、稀疏性和谱结构。我们应用可解释性指标（最初由 SVDA 提出）来监控训练期间的注意力动态并评估所学习表征的结构属性。对四个广泛使用的基准（CIFAR-10、FashionMNIST、CIFAR-100 和 ImageNet-100）的实验评估表明，SVDA 在不牺牲分类准确性的情况下始终能产生更可解释的注意力模式。虽然当前的框架提供了描述性见解而不是规定性指导，但我们的结果将 SVDA 确立为一种用于分析和开发计算机视觉中结构化注意力模型的全面且信息丰富的工具。这项工作为可解释的人工智能、光谱诊断和基于注意力的模型压缩的未来发展奠定了基础。

</details>

---

## 3. DFIC: Towards a balanced facial image dataset for automatic ICAO compliance verification

**中文标题**: DFIC：建立平衡的面部图像数据集，用于自动 ICAO 合规性验证

**Date**: 2026-02-11 | **arXiv**: [2602.10985v1](http://arxiv.org/abs/2602.10985v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10985v1)

**Code**: https://github.com/visteam-isr-uc/DFIC)

<details><summary><b>Abstract</b></summary>

Ensuring compliance with ISO/IEC and ICAO standards for facial images in machine-readable travel documents (MRTDs) is essential for reliable identity verification, but current manual inspection methods are inefficient in high-demand environments. This paper introduces the DFIC dataset, a novel comprehensive facial image dataset comprising around 58,000 annotated images and 2706 videos of more than 1000 subjects, that cover a broad range of non-compliant conditions, in addition to compliant portraits. Our dataset provides a more balanced demographic distribution than the existing public datasets, with one partition that is nearly uniformly distributed, facilitating the development of automated ICAO compliance verification methods.   Using DFIC, we fine-tuned a novel method that heavily relies on spatial attention mechanisms for the automatic validation of ICAO compliance requirements, and we have compared it with the state-of-the-art aimed at ICAO compliance verification, demonstrating improved results. DFIC dataset is now made public (https://github.com/visteam-isr-uc/DFIC) for the training and validation of new models, offering an unprecedented diversity of faces, that will improve both robustness and adaptability to the intrinsically diverse combinations of faces and props that can be presented to the validation system. These results emphasize the potential of DFIC to enhance automated ICAO compliance methods but it can also be used in many other applications that aim to improve the security, privacy, and fairness of facial recognition systems.

</details>

<details><summary><b>中文摘要</b></summary>

确保机读旅行证件 (MRTD) 中的面部图像符合 ISO/IEC 和 ICAO 标准对于可靠的身份验证至关重要，但当前的手动检查方法在高要求环境中效率低下。本文介绍了 DFIC 数据集，这是一个新颖的综合面部图像数据集，包含 1000 多个主题的约 58,000 张带注释图像和 2706 个视频，除了合规肖像之外，还涵盖了广泛的不合规条件。我们的数据集提供了比现有公共数据集更平衡的人口分布，其中一个分区几乎均匀分布，有利于自动化国际民航组织合规性验证方法的开发。   使用 DFIC，我们微调了一种严重依赖空间注意机制来自动验证 ICAO 合规性要求的新颖方法，并将其与针对 ICAO 合规性验证的最先进方法进行了比较，展示了改进的结果。 DFIC 数据集现已公开 (https://github.com/visteam-isr-uc/DFIC)，用于新模型的训练和验证，提供前所未有的人脸多样性，这将提高可呈现给验证系统的人脸和道具的本质多样化组合的鲁棒性和适应性。这些结果强调了 DFIC 在增强自动化 ICAO 合规方法方面的潜力，但它也可用于许多其他旨在提高面部识别系统的安全性、隐私性和公平性的应用。

</details>

---

## 4. Towards Learning a Generalizable 3D Scene Representation from 2D Observations

**中文标题**: 从 2D 观察中学习可概括的 3D 场景表示

**Date**: 2026-02-11 | **arXiv**: [2602.10943v1](http://arxiv.org/abs/2602.10943v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10943v1)

<details><summary><b>Abstract</b></summary>

We introduce a Generalizable Neural Radiance Field approach for predicting 3D workspace occupancy from egocentric robot observations. Unlike prior methods operating in camera-centric coordinates, our model constructs occupancy representations in a global workspace frame, making it directly applicable to robotic manipulation. The model integrates flexible source views and generalizes to unseen object arrangements without scene-specific finetuning. We demonstrate the approach on a humanoid robot and evaluate predicted geometry against 3D sensor ground truth. Trained on 40 real scenes, our model achieves 26mm reconstruction error, including occluded regions, validating its ability to infer complete 3D occupancy beyond traditional stereo vision methods.

</details>

<details><summary><b>中文摘要</b></summary>

我们引入了一种通用神经辐射场方法，用于根据以自我为中心的机器人观察来预测 3D 工作空间占用情况。与之前在以相机为中心的坐标中操作的方法不同，我们的模型在全局工作空间框架中构建占用表示，使其直接适用于机器人操作。该模型集成了灵活的源视图，并可推广到看不见的对象排列，而无需针对特定场景进行微调。我们在人形机器人上演示了该方法，并根据 3D 传感器地面实况评估预测的几何形状。经过 40 个真实场景的训练，我们的模型实现了 26mm 的重建误差（包括遮挡区域），验证了其超越传统立体视觉方法推断完整 3D 占用的能力。

</details>

---

## 5. ResWorld: Temporal Residual World Model for End-to-End Autonomous Driving

**中文标题**: ResWorld：端到端自动驾驶的时间残差世界模型

**Date**: 2026-02-11 | **arXiv**: [2602.10884v1](http://arxiv.org/abs/2602.10884v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10884v1)

**Code**: https://github.com/mengtan00/ResWorld.git.

<details><summary><b>Abstract</b></summary>

The comprehensive understanding capabilities of world models for driving scenarios have significantly improved the planning accuracy of end-to-end autonomous driving frameworks. However, the redundant modeling of static regions and the lack of deep interaction with trajectories hinder world models from exerting their full effectiveness. In this paper, we propose Temporal Residual World Model (TR-World), which focuses on dynamic object modeling. By calculating the temporal residuals of scene representations, the information of dynamic objects can be extracted without relying on detection and tracking. TR-World takes only temporal residuals as input, thus predicting the future spatial distribution of dynamic objects more precisely. By combining the prediction with the static object information contained in the current BEV features, accurate future BEV features can be obtained. Furthermore, we propose Future-Guided Trajectory Refinement (FGTR) module, which conducts interaction between prior trajectories (predicted from the current scene representation) and the future BEV features. This module can not only utilize future road conditions to refine trajectories, but also provides sparse spatial-temporal supervision on future BEV features to prevent world model collapse. Comprehensive experiments conducted on the nuScenes and NAVSIM datasets demonstrate that our method, namely ResWorld, achieves state-of-the-art planning performance. The code is available at https://github.com/mengtan00/ResWorld.git.

</details>

<details><summary><b>中文摘要</b></summary>

世界模型对驾驶场景的全面理解能力，显着提高了端到端自动驾驶框架的规划精度。然而，静态区域的冗余建模以及缺乏与轨迹的深度交互阻碍了世界模型发挥其全部有效性。在本文中，我们提出了时间残差世界模型（TR-World），它专注于动态对象建模。通过计算场景表示的时间残差，可以在不依赖检测和跟踪的情况下提取动态对象的信息。 TR-World仅将时间残差作为输入，从而更准确地预测动态对象的未来空间分布。通过将预测与当前BEV特征中包含的静态物体信息相结合，可以获得准确的未来BEV特征。此外，我们提出了未来引导轨迹细化（FGTR）模块，该模块在先前轨迹（根据当前场景表示预测）和未来 BEV 特征之间进行交互。该模块不仅可以利用未来的路况来细化轨迹，还可以对未来的 BEV 特征提供稀疏时空监督，​​以防止世界模型崩溃。在 nuScenes 和 NAVSIM 数据集上进行的综合实验表明，我们的方法（即 ResWorld）实现了最先进的规划性能。代码可在 https://github.com/mengtan00/ResWorld.git 获取。

</details>

---

## 6. Chart Specification: Structural Representations for Incentivizing VLM Reasoning in Chart-to-Code Generation

**中文标题**: 图表规范：在图表到代码生成中激励 VLM 推理的结构表示

**Date**: 2026-02-11 | **arXiv**: [2602.10880v1](http://arxiv.org/abs/2602.10880v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10880v1)

**Code**: https://github.com/Mighten/chart-specification-paper

<details><summary><b>Abstract</b></summary>

Vision-Language Models (VLMs) have shown promise in generating plotting code from chart images, yet achieving structural fidelity remains challenging. Existing approaches largely rely on supervised fine-tuning, encouraging surface-level token imitation rather than faithful modeling of underlying chart structure, which often leads to hallucinated or semantically inconsistent outputs. We propose Chart Specification, a structured intermediate representation that shifts training from text imitation to semantically grounded supervision. Chart Specification filters syntactic noise to construct a structurally balanced training set and supports a Spec-Align Reward that provides fine-grained, verifiable feedback on structural correctness, enabling reinforcement learning to enforce consistent plotting logic. Experiments on three public benchmarks show that our method consistently outperforms prior approaches. With only 3K training samples, we achieve strong data efficiency, surpassing leading baselines by up to 61.7% on complex benchmarks, and scaling to 4K samples establishes new state-of-the-art results across all evaluated metrics. Overall, our results demonstrate that precise structural supervision offers an efficient pathway to high-fidelity chart-to-code generation. Code and dataset are available at: https://github.com/Mighten/chart-specification-paper

</details>

<details><summary><b>中文摘要</b></summary>

视觉语言模型 (VLM) 在从图表图像生成绘图代码方面显示出了前景，但实现结构保真度仍然具有挑战性。现有的方法在很大程度上依赖于监督微调，鼓励表面级别的令牌模仿，而不是对底层图表结构的忠实建模，这通常会导致幻觉或语义不一致的输出。我们提出了图表规范，一种结构化的中间表示，将训练从文本模仿转变为基于语义的监督。图表规范过滤语法噪音以构建结构平衡的训练集，并支持规范对齐奖励，该奖励提供有关结构正确性的细粒度、可验证的反馈，使强化学习能够强制执行一致的绘图逻辑。对三个公共基准的实验表明，我们的方法始终优于先前的方法。仅通过 3K 训练样本，我们就实现了强大的数据效率，在复杂的基准测试中超出了领先基线高达 61.7%，并且扩展到 4K 样本在所有评估指标中建立了新的最先进的结果。总的来说，我们的结果表明，精确的结构监督为高保真图表到代码生成提供了一条有效的途径。代码和数据集可在以下位置获取：https://github.com/Mighten/chart-specification-paper

</details>

---

## 7. Stride-Net: Fairness-Aware Disentangled Representation Learning for Chest X-Ray Diagnosis

**中文标题**: Stride-Net：用于胸部 X 射线诊断的公平意识解缠表示学习

**Date**: 2026-02-11 | **arXiv**: [2602.10875v1](http://arxiv.org/abs/2602.10875v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10875v1)

**Code**: https://github.com/Daraksh/Fairness_StrideNet.

<details><summary><b>Abstract</b></summary>

Deep neural networks for chest X-ray classification achieve strong average performance, yet often underperform for specific demographic subgroups, raising critical concerns about clinical safety and equity. Existing debiasing methods frequently yield inconsistent improvements across datasets or attain fairness by degrading overall diagnostic utility, treating fairness as a post hoc constraint rather than a property of the learned representation. In this work, we propose Stride-Net (Sensitive Attribute Resilient Learning via Disentanglement and Learnable Masking with Embedding Alignment), a fairness-aware framework that learns disease-discriminative yet demographically invariant representations for chest X-ray analysis. Stride-Net operates at the patch level, using a learnable stride-based mask to select label-aligned image regions while suppressing sensitive attribute information through adversarial confusion loss. To anchor representations in clinical semantics and discourage shortcut learning, we further enforce semantic alignment between image features and BioBERT-based disease label embeddings via Group Optimal Transport. We evaluate Stride-Net on the MIMIC-CXR and CheXpert benchmarks across race and intersectional race-gender subgroups. Across architectures including ResNet and Vision Transformers, Stride-Net consistently improves fairness metrics while matching or exceeding baseline accuracy, achieving a more favorable accuracy-fairness trade-off than prior debiasing approaches. Our code is available at https://github.com/Daraksh/Fairness_StrideNet.

</details>

<details><summary><b>中文摘要</b></summary>

用于胸部 X 射线分类的深度神经网络实现了强劲的平均性能，但对于特定的人口亚组通常表现不佳，引发了对临床安全性和公平性的严重担忧。现有的去偏差方法经常会在数据集中产生不一致的改进，或者通过降低整体诊断效用来实现公平性，将公平性视为事后约束而不是学习表示的属性。在这项工作中，我们提出了 Stride-Net（通过解缠结和可学习掩码与嵌入对齐进行敏感属性弹性学习），这是一种公平意识框架，可以学习用于胸部 X 射线分析的疾病区分性但人口统计不变的表示。 Stride-Net 在补丁级别运行，使用可学习的基于步幅的掩模来选择标签对齐的图像区域，同时通过对抗性混淆损失抑制敏感属性信息。为了锚定临床语义中的表示并阻止快捷学习，我们通过组最优传输进一步加强图像特征和基于 BioBERT 的疾病标签嵌入之间的语义对齐。我们在 MIMIC-CXR 和 CheXpert 基准上评估跨种族和交叉种族性别子组的 Stride-Net。在包括 ResNet 和 Vision Transformers 在内的架构中，Stride-Net 持续改进公平性指标，同时匹配或超过基线准确度，实现比之前的去偏方法更有利的准确度与公平性权衡。我们的代码可在 https://github.com/Daraksh/Fairness_StrideNet 上获取。

</details>

---

## 8. Hyperspectral Smoke Segmentation via Mixture of Prototypes

**中文标题**: 通过混合原型进行高光谱烟雾分割

**Date**: 2026-02-11 | **arXiv**: [2602.10858v1](http://arxiv.org/abs/2602.10858v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10858v1)

<details><summary><b>Abstract</b></summary>

Smoke segmentation is critical for wildfire management and industrial safety applications. Traditional visible-light-based methods face limitations due to insufficient spectral information, particularly struggling with cloud interference and semi-transparent smoke regions. To address these challenges, we introduce hyperspectral imaging for smoke segmentation and present the first hyperspectral smoke segmentation dataset (HSSDataset) with carefully annotated samples collected from over 18,000 frames across 20 real-world scenarios using a Many-to-One annotations protocol. However, different spectral bands exhibit varying discriminative capabilities across spatial regions, necessitating adaptive band weighting strategies. We decompose this into three technical challenges: spectral interaction contamination, limited spectral pattern modeling, and complex weighting router problems. We propose a mixture of prototypes (MoP) network with: (1) Band split for spectral isolation, (2) Prototype-based spectral representation for diverse patterns, and (3) Dual-level router for adaptive spatial-aware band weighting. We further construct a multispectral dataset (MSSDataset) with RGB-infrared images. Extensive experiments validate superior performance across both hyperspectral and multispectral modalities, establishing a new paradigm for spectral-based smoke segmentation.

</details>

<details><summary><b>中文摘要</b></summary>

烟雾分割对于野火管理和工业安全应用至关重要。传统的基于可见光的方法由于光谱信息不足而面临局限性，特别是在云干扰和半透明烟雾区域方面遇到困难。为了应对这些挑战，我们引入了用于烟雾分割的高光谱成像，并提出了第一个高光谱烟雾分割数据集 (HSSDataset)，其中使用多对一注释协议从 20 个真实场景的 18,000 多个帧中收集了仔细注释的样本。然而，不同的光谱带在空间区域上表现出不同的辨别能力，因此需要自适应频带加权策略。我们将其分解为三个技术挑战：光谱相互作用污染、有限的光谱模式建模和复杂的加权路由器问题。我们提出了一种混合原型（MoP）网络：（1）用于光谱隔离的频带分割，（2）用于不同模式的基于原型的光谱表示，以及（3）用于自适应空间感知频带加权的双层路由器。我们进一步用 RGB 红外图像构建了多光谱数据集 (MSSDataset)。大量的实验验证了高光谱和多光谱模式的卓越性能，为基于光谱的烟雾分割建立了新的范例。

</details>

---

## 9. Flow caching for autoregressive video generation

**中文标题**: 用于自回归视频生成的流缓存

**Date**: 2026-02-11 | **arXiv**: [2602.10825v1](http://arxiv.org/abs/2602.10825v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10825v1)

**Code**: https://github.com/mikeallen39/FlowCache.

<details><summary><b>Abstract</b></summary>

Autoregressive models, often built on Transformer architectures, represent a powerful paradigm for generating ultra-long videos by synthesizing content in sequential chunks. However, this sequential generation process is notoriously slow. While caching strategies have proven effective for accelerating traditional video diffusion models, existing methods assume uniform denoising across all frames-an assumption that breaks down in autoregressive models where different video chunks exhibit varying similarity patterns at identical timesteps. In this paper, we present FlowCache, the first caching framework specifically designed for autoregressive video generation. Our key insight is that each video chunk should maintain independent caching policies, allowing fine-grained control over which chunks require recomputation at each timestep. We introduce a chunkwise caching strategy that dynamically adapts to the unique denoising characteristics of each chunk, complemented by a joint importance-redundancy optimized KV cache compression mechanism that maintains fixed memory bounds while preserving generation quality. Our method achieves remarkable speedups of 2.38 times on MAGI-1 and 6.7 times on SkyReels-V2, with negligible quality degradation (VBench: 0.87 increase and 0.79 decrease respectively). These results demonstrate that FlowCache successfully unlocks the potential of autoregressive models for real-time, ultra-long video generation-establishing a new benchmark for efficient video synthesis at scale. The code is available at https://github.com/mikeallen39/FlowCache.

</details>

<details><summary><b>中文摘要</b></summary>

自回归模型通常建立在 Transformer 架构之上，代表了通过合成连续块中的内容来生成超长视频的强大范例。然而，这种顺序生成过程是出了名的慢。虽然缓存策略已被证明对于加速传统视频扩散模型是有效的，但现有方法假设所有帧都采用统一的去噪——这种假设在自回归模型中被打破，其中不同的视频块在相同的时间步长表现出不同的相似性模式。在本文中，我们介绍了 FlowCache，这是第一个专为自回归视频生成而设计的缓存框架。我们的主要见解是每个视频块应该维护独立的缓存策略，从而可以对每个时间步需要重新计算的块进行细粒度控制。我们引入了一种分块缓存策略，该策略动态适应每个块的独特去噪特性，并辅以联合重要性冗余优化的 KV 缓存压缩机制，该机制在保持固定内存边界的同时保持生成质量。我们的方法在 MAGI-1 上实现了 2.38 倍的显着加速，在 SkyReels-V2 上实现了 6.7 倍的显着加速，而质量下降可以忽略不计（VBench：分别增加 0.87 倍和减少 0.79 倍）。这些结果表明，FlowCache 成功释放了自回归模型在实时、超长视频生成方面的潜力，为大规模高效视频合成建立了新基准。该代码可从 https://github.com/mikeallen39/FlowCache 获取。

</details>

---

## 10. Resource-Efficient RGB-Only Action Recognition for Edge Deployment

**中文标题**: 适用于边缘部署的资源高效型纯 RGB 动作识别

**Date**: 2026-02-11 | **arXiv**: [2602.10818v1](http://arxiv.org/abs/2602.10818v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10818v1)

<details><summary><b>Abstract</b></summary>

Action recognition on edge devices poses stringent constraints on latency, memory, storage, and power consumption. While auxiliary modalities such as skeleton and depth information can enhance recognition performance, they often require additional sensors or computationally expensive pose-estimation pipelines, limiting practicality for edge use. In this work, we propose a compact RGB-only network tailored for efficient on-device inference. Our approach builds upon an X3D-style backbone augmented with Temporal Shift, and further introduces selective temporal adaptation and parameter-free attention. Extensive experiments on the NTU RGB+D 60 and 120 benchmarks demonstrate a strong accuracy-efficiency balance. Moreover, deployment-level profiling on the Jetson Orin Nano verifies a smaller on-device footprint and practical resource utilization compared to existing RGB-based action recognition techniques.

</details>

<details><summary><b>中文摘要</b></summary>

边缘设备上的动作识别对延迟、内存、存储和功耗提出了严格的限制。虽然骨架和深度信息等辅助模态可以增强识别性能，但它们通常需要额外的传感器或计算成本高昂的姿态估计管道，从而限制了边缘使用的实用性。在这项工作中，我们提出了一个紧凑的纯 RGB 网络，专为高效的设备上推理而定制。我们的方法建立在 X3D 风格的主干上，并通过时间移位进行增强，并进一步引入了选择性时间适应和无参数注意力。 NTU RGB+D 60 和 120 基准的大量实验证明了强大的准确性与效率平衡。此外，与现有基于 RGB 的动作识别技术相比，Jetson Orin Nano 上的部署级分析验证了更小的设备占用空间和实际资源利用率。

</details>

---

## 11. Why Does RL Generalize Better Than SFT? A Data-Centric Perspective on VLM Post-Training

**中文标题**: 为什么 RL 的泛化能力比 SFT 更好？以数据为中心的 VLM 训练后视角

**Date**: 2026-02-11 | **arXiv**: [2602.10815v1](http://arxiv.org/abs/2602.10815v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10815v1)

**Code**: https://github.com/byyx666/DC-SFT.

<details><summary><b>Abstract</b></summary>

The adaptation of large-scale Vision-Language Models (VLMs) through post-training reveals a pronounced generalization gap: models fine-tuned with Reinforcement Learning (RL) consistently achieve superior out-of-distribution (OOD) performance compared to those trained with Supervised Fine-Tuning (SFT). This paper posits a data-centric explanation for this phenomenon, contending that RL's generalization advantage arises from an implicit data filtering mechanism that inherently prioritizes medium-difficulty training samples. To test this hypothesis, we systematically evaluate the OOD generalization of SFT models across training datasets of varying difficulty levels. Our results confirm that data difficulty is a critical factor, revealing that training on hard samples significantly degrades OOD performance. Motivated by this finding, we introduce Difficulty-Curated SFT (DC-SFT), a straightforward method that explicitly filters the training set based on sample difficulty. Experiments show that DC-SFT not only substantially enhances OOD generalization over standard SFT, but also surpasses the performance of RL-based training, all while providing greater stability and computational efficiency. This work offers a data-centric account of the OOD generalization gap in VLMs and establishes a more efficient pathway to achieving robust generalization. Code is available at https://github.com/byyx666/DC-SFT.

</details>

<details><summary><b>中文摘要</b></summary>

通过后期训练对大规模视觉语言模型 (VLM) 进行的调整揭示了明显的泛化差距：与使用监督微调 (SFT) 训练的模型相比，使用强化学习 (RL) 微调的模型始终能够实现卓越的分布外 (OOD) 性能。本文对这种现象提出了以数据为中心的解释，认为强化学习的泛化优势源于隐式数据过滤机制，该机制本质上优先考虑中等难度的训练样本。为了检验这一假设，我们系统地评估了 SFT 模型在不同难度级别的训练数据集上的 OOD 泛化能力。我们的结果证实，数据难度是一个关键因素，表明对硬样本进行训练会显着降低 OOD 性能。受这一发现的启发，我们引入了难度策划 SFT (DC-SFT)，这是一种根据样本难度显式过滤训练集的简单方法。实验表明，DC-SFT 不仅比标准 SFT 显着增强了 OOD 泛化能力，而且超越了基于 RL 的训练性能，同时提供了更高的稳定性和计算效率。这项工作提供了以数据为中心的 VLM 中 OOD 泛化差距的解释，并建立了一条更有效的途径来实现稳健的泛化。代码可在 https://github.com/byyx666/DC-SFT 获取。

</details>

---

## 12. DeepImageSearch: Benchmarking Multimodal Agents for Context-Aware Image Retrieval in Visual Histories

**中文标题**: DeepImageSearch：视觉历史中上下文感知图像检索的多模态代理基准测试

**Date**: 2026-02-11 | **arXiv**: [2602.10809v1](http://arxiv.org/abs/2602.10809v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10809v1)

<details><summary><b>Abstract</b></summary>

Existing multimodal retrieval systems excel at semantic matching but implicitly assume that query-image relevance can be measured in isolation. This paradigm overlooks the rich dependencies inherent in realistic visual streams, where information is distributed across temporal sequences rather than confined to single snapshots. To bridge this gap, we introduce DeepImageSearch, a novel agentic paradigm that reformulates image retrieval as an autonomous exploration task. Models must plan and perform multi-step reasoning over raw visual histories to locate targets based on implicit contextual cues. We construct DISBench, a challenging benchmark built on interconnected visual data. To address the scalability challenge of creating context-dependent queries, we propose a human-model collaborative pipeline that employs vision-language models to mine latent spatiotemporal associations, effectively offloading intensive context discovery before human verification. Furthermore, we build a robust baseline using a modular agent framework equipped with fine-grained tools and a dual-memory system for long-horizon navigation. Extensive experiments demonstrate that DISBench poses significant challenges to state-of-the-art models, highlighting the necessity of incorporating agentic reasoning into next-generation retrieval systems.

</details>

<details><summary><b>中文摘要</b></summary>

现有的多模态检索系统擅长语义匹配，但隐含地假设查询图像相关性可以单独测量。这种范例忽略了现实视觉流中固有的丰富依赖关系，其中信息分布在时间序列上，而不是局限于单个快照。为了弥补这一差距，我们引入了 DeepImageSearch，这是一种新颖的代理范式，它将图像检索重新定义为一项自主探索任务。模型必须对原始视觉历史进行规划和执行多步骤推理，以根据隐式上下文线索定位目标。我们构建了 DISBench，这是一个基于互连视觉数据的具有挑战性的基准。为了解决创建上下文相关查询的可扩展性挑战，我们提出了一种人类模型协作管道，该管道采用视觉语言模型来挖掘潜在的时空关联，从而在人类验证之前有效地卸载密集的上下文发现。此外，我们使用配备细粒度工具的模块化代理框架和用于长视野导航的双内存系统构建了强大的基线。大量实验表明 DISBench 对最先进的模型提出了重大挑战，凸显了将代理推理纳入下一代检索系统的必要性。

</details>

---

## 13. DMP-3DAD: Cross-Category 3D Anomaly Detection via Realistic Depth Map Projection with Few Normal Samples

**中文标题**: DMP-3DAD：通过真实深度图投影与少量正常样本进行跨类别 3D 异常检测

**Date**: 2026-02-11 | **arXiv**: [2602.10806v1](http://arxiv.org/abs/2602.10806v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10806v1)

<details><summary><b>Abstract</b></summary>

Cross-category anomaly detection for 3D point clouds aims to determine whether an unseen object belongs to a target category using only a few normal examples. Most existing methods rely on category-specific training, which limits their flexibility in few-shot scenarios. In this paper, we propose DMP-3DAD, a training-free framework for cross-category 3D anomaly detection based on multi-view realistic depth map projection. Specifically, by converting point clouds into a fixed set of realistic depth images, our method leverages a frozen CLIP visual encoder to extract multi-view representations and performs anomaly detection via weighted feature similarity, which does not require any fine-tuning or category-dependent adaptation. Extensive experiments on the ShapeNetPart dataset demonstrate that DMP-3DAD achieves state-of-the-art performance under few-shot setting. The results show that the proposed approach provides a simple yet effective solution for practical cross-category 3D anomaly detection.

</details>

<details><summary><b>中文摘要</b></summary>

3D 点云的跨类别异常检测旨在仅使用几个正常示例来确定未见过的对象是否属于目标类别。大多数现有方法依赖于特定类别的训练，这限制了它们在少数场景中的灵活性。在本文中，我们提出了 DMP-3DAD，这是一种基于多视图真实深度图投影的跨类别 3D 异常检测的免训练框架。具体来说，通过将点云转换为一组固定的真实深度图像，我们的方法利用冻结的 CLIP 视觉编码器来提取多视图表示，并通过加权特征相似性执行异常检测，这不需要任何微调或依赖于类别的适应。在 ShapeNetPart 数据集上进行的大量实验表明，DMP-3DAD 在少量镜头设置下实现了最先进的性能。结果表明，所提出的方法为实际的跨类别 3D 异常检测提供了一种简单而有效的解决方案。

</details>

---

## 14. RSHallu: Dual-Mode Hallucination Evaluation for Remote-Sensing Multimodal Large Language Models with Domain-Tailored Mitigation

**中文标题**: RSHallu：具有领域定制缓解功能的遥感多模态大语言模型的双模幻觉评估

**Date**: 2026-02-11 | **arXiv**: [2602.10799v1](http://arxiv.org/abs/2602.10799v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10799v1)

<details><summary><b>Abstract</b></summary>

Multimodal large language models (MLLMs) are increasingly adopted in remote sensing (RS) and have shown strong performance on tasks such as RS visual grounding (RSVG), RS visual question answering (RSVQA), and multimodal dialogue. However, hallucinations, which are responses inconsistent with the input RS images, severely hinder their deployment in high-stakes scenarios (e.g., emergency management and agricultural monitoring) and remain under-explored in RS. In this work, we present RSHallu, a systematic study with three deliverables: (1) we formalize RS hallucinations with an RS-oriented taxonomy and introduce image-level hallucination to capture RS-specific inconsistencies beyond object-centric errors (e.g., modality, resolution, and scene-level semantics); (2) we build a hallucination benchmark RSHalluEval (2,023 QA pairs) and enable dual-mode checking, supporting high-precision cloud auditing and low-cost reproducible local checking via a compact checker fine-tuned on RSHalluCheck dataset (15,396 QA pairs); and (3) we introduce a domain-tailored dataset RSHalluShield (30k QA pairs) for training-friendly mitigation and further propose training-free plug-and-play strategies, including decoding-time logit correction and RS-aware prompting. Across representative RS-MLLMs, our mitigation improves the hallucination-free rate by up to 21.63 percentage points under a unified protocol, while maintaining competitive performance on downstream RS tasks (RSVQA/RSVG). Code and datasets will be released.

</details>

<details><summary><b>中文摘要</b></summary>

多模态大语言模型 (MLLM) 在遥感 (RS) 中越来越多地采用，并且在 RS 视觉接地 (RSVG)、RS 视觉问答 (RSVQA) 和多模态对话等任务上表现出强大的性能。然而，幻觉是与输入的遥感图像不一致的响应，严重阻碍了它们在高风险场景（例如应急管理和农业监测）中的部署，并且在遥感方面仍未得到充分探索。在这项工作中，我们提出了RSHallu，这是一项具有三个可交付成果的系统性研究：（1）我们用面向RS的分类法将RS幻觉形式化，并引入图像级幻觉来捕获以对象为中心的错误之外的RS特定的不一致（例如模态、分辨率和场景级语义）； （2）我们建立了幻觉基准RSHalluEval（2,023个QA对）并启用双模式检查，通过在RSHalluCheck数据集（15,396个QA对）上微调的紧凑检查器支持高精度云审计和低成本可重复的本地检查； (3)我们引入了一个领域定制的数据集RSHalluShield（30k QA对）用于训练友好的缓解，并进一步提出了免训练的即插即用策略，包括解码时logit校正和RS感知提示。在代表性的 RS-MLLM 中，我们的缓解措施在统一协议下将无幻觉率提高了高达 21.63 个百分点，同时保持了下游 RS 任务 (RSVQA/RSVG) 的竞争性能。代码和数据集将被发布。

</details>

---

## 15. From Steering to Pedalling: Do Autonomous Driving VLMs Generalize to Cyclist-Assistive Spatial Perception and Planning?

**中文标题**: 从转向到踏板：自动驾驶 VLM 是否可以推广到骑车人辅助空间感知和规划？

**Date**: 2026-02-11 | **arXiv**: [2602.10771v1](http://arxiv.org/abs/2602.10771v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10771v1)

<details><summary><b>Abstract</b></summary>

Cyclists often encounter safety-critical situations in urban traffic, highlighting the need for assistive systems that support safe and informed decision-making. Recently, vision-language models (VLMs) have demonstrated strong performance on autonomous driving benchmarks, suggesting their potential for general traffic understanding and navigation-related reasoning. However, existing evaluations are predominantly vehicle-centric and fail to assess perception and reasoning from a cyclist-centric viewpoint. To address this gap, we introduce CyclingVQA, a diagnostic benchmark designed to probe perception, spatio-temporal understanding, and traffic-rule-to-lane reasoning from a cyclist's perspective. Evaluating 31+ recent VLMs spanning general-purpose, spatially enhanced, and autonomous-driving-specialized models, we find that current models demonstrate encouraging capabilities, while also revealing clear areas for improvement in cyclist-centric perception and reasoning, particularly in interpreting cyclist-specific traffic cues and associating signs with the correct navigational lanes. Notably, several driving-specialized models underperform strong generalist VLMs, indicating limited transfer from vehicle-centric training to cyclist-assistive scenarios. Finally, through systematic error analysis, we identify recurring failure modes to guide the development of more effective cyclist-assistive intelligent systems.

</details>

<details><summary><b>中文摘要</b></summary>

骑自行车的人经常在城市交通中遇到安全危急的情况，这突出表明需要辅助系统来支持安全和明智的决策。最近，视觉语言模型（VLM）在自动驾驶基准测试中表现出强大的性能，表明它们在一般交通理解和导航相关推理方面的潜力。然而，现有的评估主要以车辆为中心，未能从以骑车人为中心的角度评估感知和推理。为了解决这一差距，我们引入了 CyclingVQA，这是一个诊断基准，旨在从骑车人的角度探讨感知、时空理解以及交通规则到车道推理。通过评估超过 31 个最新的 VLM，涵盖通用、空间增强和自动驾驶专用模型，我们发现当前模型表现出了令人鼓舞的能力，同时也揭示了以骑车人为中心的感知和推理方面有待改进的明确领域，特别是在解释骑车人特定的交通线索以及将标志与正确的导航车道相关联方面。值得注意的是，一些驾驶专用模型的表现不如强大的通用 VLM，这表明从以车辆为中心的训练到骑车人辅助场景的转移有限。最后，通过系统误差分析，我们识别重复出现的故障模式，以指导开发更有效的骑行者辅助智能系统。

</details>

---

## 16. Dual-End Consistency Model

**中文标题**: 双端一致性模型

**Date**: 2026-02-11 | **arXiv**: [2602.10764v1](http://arxiv.org/abs/2602.10764v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10764v1)

<details><summary><b>Abstract</b></summary>

The slow iterative sampling nature remains a major bottleneck for the practical deployment of diffusion and flow-based generative models. While consistency models (CMs) represent a state-of-the-art distillation-based approach for efficient generation, their large-scale application is still limited by two key issues: training instability and inflexible sampling. Existing methods seek to mitigate these problems through architectural adjustments or regularized objectives, yet overlook the critical reliance on trajectory selection. In this work, we first conduct an analysis on these two limitations: training instability originates from loss divergence induced by unstable self-supervised term, whereas sampling inflexibility arises from error accumulation. Based on these insights and analysis, we propose the Dual-End Consistency Model (DE-CM) that selects vital sub-trajectory clusters to achieve stable and effective training. DE-CM decomposes the PF-ODE trajectory and selects three critical sub-trajectories as optimization targets. Specifically, our approach leverages continuous-time CMs objectives to achieve few-step distillation and utilizes flow matching as a boundary regularizer to stabilize the training process. Furthermore, we propose a novel noise-to-noisy (N2N) mapping that can map noise to any point, thereby alleviating the error accumulation in the first step. Extensive experimental results show the effectiveness of our method: it achieves a state-of-the-art FID score of 1.70 in one-step generation on the ImageNet 256x256 dataset, outperforming existing CM-based one-step approaches.

</details>

<details><summary><b>中文摘要</b></summary>

缓慢的迭代采样性质仍然是扩散和基于流的生成模型的实际部署的主要瓶颈。虽然一致性模型（CM）代表了一种最先进的基于蒸馏的高效生成方法，但其大规模应用仍然受到两个关键问题的限制：训练不稳定和采样不灵活。现有方法试图通过架构调整或规范化目标来缓解这些问题，但忽视了对轨迹选择的关键依赖。在这项工作中，我们首先对这两个局限性进行了分析：训练的不稳定性源于不稳定的自监督项引起的损失发散，而采样的不灵活性则源于误差累积。基于这些见解和分析，我们提出了双端一致性模型（DE-CM），该模型选择重要的子轨迹簇来实现稳定有效的训练。 DE-CM分解PF-ODE轨迹并选择三个关键子轨迹作为优化目标。具体来说，我们的方法利用连续时间 CM 目标来实现几步蒸馏，并利用流匹配作为边界正则化器来稳定训练过程。此外，我们提出了一种新颖的噪声到噪声（N2N）映射，可以将噪声映射到任何点，从而减轻第一步中的误差累积。大量的实验结果表明了我们方法的有效性：它在 ImageNet 256x256 数据集上的一步生成中达到了 1.70 的最先进的 FID 分数，优于现有的基于 CM 的一步方法。

</details>

---

## 17. Text-to-Vector Conversion for Residential Plan Design

**中文标题**: 住宅规划设计的文本到矢量转换

**Date**: 2026-02-11 | **arXiv**: [2602.10757v1](http://arxiv.org/abs/2602.10757v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10757v1)

<details><summary><b>Abstract</b></summary>

Computer graphics, comprising both raster and vector components, is a fundamental part of modern science, industry, and digital communication. While raster graphics offer ease of use, its pixel-based structure limits scalability. Vector graphics, defined by mathematical primitives, provides scalability without quality loss, however, it is more complex to produce. For design and architecture, the versatility of vector graphics is paramount, despite its computational demands. This paper introduces a novel method for generating vector residential plans from textual descriptions. Our approach surpasses existing solutions by approximately 5% in CLIPScore-based visual quality, benefiting from its inherent handling of right angles and flexible settings. Additionally, we present a new algorithm for vectorizing raster plans into structured vector images. Such images have a better CLIPscore compared to others by about 4%.

</details>

<details><summary><b>中文摘要</b></summary>

计算机图形学由光栅和矢量组成，是现代科学、工业和数字通信的基本组成部分。虽然光栅图形易于使用，但其基于像素的结构限制了可扩展性。由数学基元定义的矢量图形提供了可扩展性而不会造成质量损失，但其生成更为复杂。对于设计和建筑来说，矢量图形的多功能性至关重要，尽管它具有计算需求。本文介绍了一种根据文本描述生成矢量住宅规划的新方法。我们的方法在基于 CLIPScore 的视觉质量方面比现有解决方案高出约 5%，这得益于其固有的直角处理和灵活的设置。此外，我们提出了一种将光栅计划矢量化为结构化矢量图像的新算法。与其他图像相比，此类图像的 CLIPscore 高出约 4%。

</details>

---

## 18. Self-Supervised Image Super-Resolution Quality Assessment based on Content-Free Multi-Model Oriented Representation Learning

**中文标题**: 基于内容无关的面向多模型表示学习的自监督图像超分辨率质量评估

**Date**: 2026-02-11 | **arXiv**: [2602.10744v1](http://arxiv.org/abs/2602.10744v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10744v1)

<details><summary><b>Abstract</b></summary>

Super-resolution (SR) applied to real-world low-resolution (LR) images often results in complex, irregular degradations that stem from the inherent complexity of natural scene acquisition. In contrast to SR artifacts arising from synthetic LR images created under well-defined scenarios, those distortions are highly unpredictable and vary significantly across different real-life contexts. Consequently, assessing the quality of SR images (SR-IQA) obtained from realistic LR, remains a challenging and underexplored problem. In this work, we introduce a no-reference SR-IQA approach tailored for such highly ill-posed realistic settings. The proposed method enables domain-adaptive IQA for real-world SR applications, particularly in data-scarce domains. We hypothesize that degradations in super-resolved images are strongly dependent on the underlying SR algorithms, rather than being solely determined by image content. To this end, we introduce a self-supervised learning (SSL) strategy that first pretrains multiple SR model oriented representations in a pretext stage. Our contrastive learning framework forms positive pairs from images produced by the same SR model and negative pairs from those generated by different methods, independent of image content. The proposed approach S3 RIQA, further incorporates targeted preprocessing to extract complementary quality information and an auxiliary task to better handle the various degradation profiles associated with different SR scaling factors. To this end, we constructed a new dataset, SRMORSS, to support unsupervised pretext training; it includes a wide range of SR algorithms applied to numerous real LR images, which addresses a gap in existing datasets. Experiments on real SR-IQA benchmarks demonstrate that S3 RIQA consistently outperforms most state-of-the-art relevant metrics.

</details>

<details><summary><b>中文摘要</b></summary>

将超分辨率 (SR) 应用于现实世界的低分辨率 (LR) 图像通常会导致复杂的、不规则的降级，这是由于自然场景采集的固有复杂性造成的。与在明确场景下创建的合成 LR 图像产生的 SR 伪像相比，这些失真是高度不可预测的，并且在不同的现实生活环境中存在显着差异。因此，评估从现实 LR 获得的 SR 图像 (SR-IQA) 的质量仍然是一个具有挑战性且尚未得到充分探索的问题。在这项工作中，我们引入了一种针对这种高度不适定的现实环境量身定制的无参考 SR-IQA 方法。所提出的方法能够为现实世界的 SR 应用提供域自适应 IQA，特别是在数据稀缺领域。我们假设超分辨率图像的退化很大程度上取决于底层的 SR 算法，而不是仅仅由图像内容决定。为此，我们引入了一种自监督学习（SSL）策略，该策略首先在借口阶段预训练多个面向 SR 模型的表示。我们的对比学习框架从相同 SR 模型生成的图像中形成正对，从不同方法生成的图像中形成负对，与图像内容无关。所提出的方法 S3 RIQA 进一步结合了有针对性的预处理以提取补充质量信息和辅助任务以更好地处理与不同 SR 缩放因子相关的各种退化概况。为此，我们构建了一个新的数据集SRMORSS，以支持无监督借口训练；它包括应用于大量真实 LR 图像的广泛 SR 算法，弥补了现有数据集的空白。对真实 SR-IQA 基准测试的实验表明，S3 RIQA 始终优于大多数最先进的相关指标。

</details>

---

## 19. OccFace: Unified Occlusion-Aware Facial Landmark Detection with Per-Point Visibility

**中文标题**: OccFace：具有每点可见性的统一遮挡感知面部标志检测

**Date**: 2026-02-11 | **arXiv**: [2602.10728v1](http://arxiv.org/abs/2602.10728v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10728v1)

<details><summary><b>Abstract</b></summary>

Accurate facial landmark detection under occlusion remains challenging, especially for human-like faces with large appearance variation and rotation-driven self-occlusion. Existing detectors typically localize landmarks while handling occlusion implicitly, without predicting per-point visibility that downstream applications can benefits. We present OccFace, an occlusion-aware framework for universal human-like faces, including humans, stylized characters, and other non-human designs. OccFace adopts a unified dense 100-point layout and a heatmap-based backbone, and adds an occlusion module that jointly predicts landmark coordinates and per-point visibility by combining local evidence with cross-landmark context. Visibility supervision mixes manual labels with landmark-aware masking that derives pseudo visibility from mask-heatmap overlap. We also create an occlusion-aware evaluation suite reporting NME on visible vs. occluded landmarks and benchmarking visibility with Occ AP, F1@0.5, and ROC-AUC, together with a dataset annotated with 100-point landmarks and per-point visibility. Experiments show improved robustness under external occlusion and large head rotations, especially on occluded regions, while preserving accuracy on visible landmarks.

</details>

<details><summary><b>中文摘要</b></summary>

遮挡下准确的面部标志检测仍然具有挑战性，特别是对于具有较大外观变化和旋转驱动的自遮挡的类人面部。现有的检测器通常会在隐式处理遮挡的同时定位地标，而不会预测下游应用程序可以受益的每点可见性。我们推出了 OccFace，这是一种遮挡感知框架，适用于通用的类人面孔，包括人类、风格化角色和其他非人类设计。 OccFace采用统一的密集100点布局和基于热图的主干网，并添加了遮挡模块，通过结合局部证据和跨地标上下文来联合预测地标坐标和每点可见性。可见性监督将手动标签与地标感知掩蔽相结合，从掩码热图重叠中得出伪可见性。我们还创建了一个遮挡感知评估套件，报告可见与遮挡地标的 NME 以及使用 Occ AP、F1@0.5 和 ROC-AUC 的基准可见性，以及用 100 点地标和每点可见性注释的数据集。实验表明，在外部遮挡和大的头部旋转下，尤其是在遮挡区域，鲁棒性得到了提高，同时保持了可见地标的准确性。

</details>

---

## 20. From Representational Complementarity to Dual Systems: Synergizing VLM and Vision-Only Backbones for End-to-End Driving

**中文标题**: 从代表性互补到双系统：协同 VLM 和纯视觉骨干网实现端到端驾驶

**Date**: 2026-02-11 | **arXiv**: [2602.10719v1](http://arxiv.org/abs/2602.10719v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10719v1)

<details><summary><b>Abstract</b></summary>

Vision-Language-Action (VLA) driving augments end-to-end (E2E) planning with language-enabled backbones, yet it remains unclear what changes beyond the usual accuracy--cost trade-off. We revisit this question with 3--RQ analysis in RecogDrive by instantiating the system with a full VLM and vision-only backbones, all under an identical diffusion Transformer planner. RQ1: At the backbone level, the VLM can introduce additional subspaces upon the vision-only backbones. RQ2: This unique subspace leads to a different behavioral in some long-tail scenario: the VLM tends to be more aggressive whereas ViT is more conservative, and each decisively wins on about 2--3% of test scenarios; With an oracle that selects, per scenario, the better trajectory between the VLM and ViT branches, we obtain an upper bound of 93.58 PDMS. RQ3: To fully harness this observation, we propose HybridDriveVLA, which runs both ViT and VLM branches and selects between their endpoint trajectories using a learned scorer, improving PDMS to 92.10. Finally, DualDriveVLA implements a practical fast--slow policy: it runs ViT by default and invokes the VLM only when the scorer's confidence falls below a threshold; calling the VLM on 15% of scenarios achieves 91.00 PDMS while improving throughput by 3.2x. Code will be released.

</details>

<details><summary><b>中文摘要</b></summary>

视觉-语言-行动 (VLA) 驱动通过支持语言的主干增强了端到端 (E2E) 规划，但目前尚不清楚除了通常的准确性和成本权衡之外还有哪些变化。我们通过 RecogDrive 中的 3--RQ 分析重新审视这个问题，通过使用完整的 VLM 和仅视觉主干来实例化系统，所有这些都在相同的扩散 Transformer 规划器下进行。 RQ1：在主干层，VLM 可以在仅视觉主干上引入额外的子空间。 RQ2：这个独特的子空间导致在某些长尾场景中出现不同的行为：VLM 往往更激进，而 ViT 更保守，并且每个都在大约 2--3% 的测试场景中决定性地获胜；通过根据场景选择 VLM 和 ViT 分支之间更好的轨迹的预言机，我们获得了 93.58 PDMS 的上限。 RQ3：为了充分利用这一观察结果，我们提出了 HybridDriveVLA，它运行 ViT 和 VLM 分支，并使用学习评分器在它们的端点轨迹之间进行选择，将 PDMS 提高到 92.10。最后，DualDriveVLA 实现了实用的快-慢策略：它默认运行 ViT，仅当评分者的置信度低于阈值时才调用 VLM；在 15% 的场景中调用 VLM 可实现 91.00 PDMS，同时将吞吐量提高 3.2 倍。代码将被发布。

</details>

---

## 21. FGAA-FPN: Foreground-Guided Angle-Aware Feature Pyramid Network for Oriented Object Detection

**中文标题**: FGAA-FPN：用于定向物体检测的前景引导角度感知特征金字塔网络

**Date**: 2026-02-11 | **arXiv**: [2602.10710v1](http://arxiv.org/abs/2602.10710v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10710v1)

<details><summary><b>Abstract</b></summary>

With the increasing availability of high-resolution remote sensing and aerial imagery, oriented object detection has become a key capability for geographic information updating, maritime surveillance, and disaster response. However, it remains challenging due to cluttered backgrounds, severe scale variation, and large orientation changes. Existing approaches largely improve performance through multi-scale feature fusion with feature pyramid networks or contextual modeling with attention, but they often lack explicit foreground modeling and do not leverage geometric orientation priors, which limits feature discriminability. To overcome these limitations, we propose FGAA-FPN, a Foreground-Guided Angle-Aware Feature Pyramid Network for oriented object detection. FGAA-FPN is built on a hierarchical functional decomposition that accounts for the distinct spatial resolution and semantic abstraction across pyramid levels, thereby strengthening multi-scale representations. Concretely, a Foreground-Guided Feature Modulation module learns foreground saliency under weak supervision to enhance object regions and suppress background interference in low-level features. In parallel, an Angle-Aware Multi-Head Attention module encodes relative orientation relationships to guide global interactions among high-level semantic features. Extensive experiments on DOTA v1.0 and DOTA v1.5 demonstrate that FGAA-FPN achieves state-of-the-art results, reaching 75.5% and 68.3% mAP, respectively.

</details>

<details><summary><b>中文摘要</b></summary>

随着高分辨率遥感和航空图像的日益普及，定向目标检测已成为地理信息更新、海上监视和灾害响应的关键能力。然而，由于杂乱的背景、严重的尺度变化和大的方向变化，它仍然具有挑战性。现有方法通过特征金字塔网络的多尺度特征融合或带有注意力的上下文建模在很大程度上提高了性能，但它们通常缺乏明确的前景建模并且不利用几何方向先验，这限制了特征的可辨别性。为了克服这些限制，我们提出了 FGAA-FPN，一种用于定向对象检测的前景引导角度感知特征金字塔网络。 FGAA-FPN 建立在分层功能分解的基础上，该分解考虑了跨金字塔级别的不同空间分辨率和语义抽象，从而加强了多尺度表示。具体来说，前景引导特征调制模块在弱监督下学习前景显着性，以增强对象区域并抑制低级特征中的背景干扰。同时，角度感知多头注意力模块对相对方向关系进行编码，以指导高级语义特征之间的全局交互。在 DOTA v1.0 和 DOTA v1.5 上进行的大量实验表明，FGAA-FPN 取得了最先进的结果，分别达到 75.5% 和 68.3% mAP。

</details>

---

## 22. AugVLA-3D: Depth-Driven Feature Augmentation for Vision-Language-Action Models

**中文标题**: AugVLA-3D：视觉-语言-动作模型的深度驱动特征增强

**Date**: 2026-02-11 | **arXiv**: [2602.10698v1](http://arxiv.org/abs/2602.10698v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10698v1)

<details><summary><b>Abstract</b></summary>

Vision-Language-Action (VLA) models have recently achieved remarkable progress in robotic perception and control, yet most existing approaches primarily rely on VLM trained using 2D images, which limits their spatial understanding and action grounding in complex 3D environments. To address this limitation, we propose a novel framework that integrates depth estimation into VLA models to enrich 3D feature representations. Specifically, we employ a depth estimation baseline called VGGT to extract geometry-aware 3D cues from standard RGB inputs, enabling efficient utilization of existing large-scale 2D datasets while implicitly recovering 3D structural information. To further enhance the reliability of these depth-derived features, we introduce a new module called action assistant, which constrains the learned 3D representations with action priors and ensures their consistency with downstream control tasks. By fusing the enhanced 3D features with conventional 2D visual tokens, our approach significantly improves the generalization ability and robustness of VLA models. Experimental results demonstrate that the proposed method not only strengthens perception in geometrically ambiguous scenarios but also leads to superior action prediction accuracy. This work highlights the potential of depth-driven data augmentation and auxiliary expert supervision for bridging the gap between 2D observations and 3D-aware decision-making in robotic systems.

</details>

<details><summary><b>中文摘要</b></summary>

视觉-语言-动作 (VLA) 模型最近在机器人感知和控制方面取得了显着进展，但大多数现有方法主要依赖于使用 2D 图像训练的 VLM，这限制了它们在复杂 3D 环境中的空间理解和动作基础。为了解决这个限制，我们提出了一种新颖的框架，将深度估计集成到 VLA 模型中以丰富 3D 特征表示。具体来说，我们采用称为 VGGT 的深度估计基线从标准 RGB 输入中提取几何感知的 3D 线索，从而能够有效利用现有的大规模 2D 数据集，同时隐式恢复 3D 结构信息。为了进一步增强这些深度衍生特征的可靠性，我们引入了一个名为动作助手的新模块，它用动作先验来约束学习到的 3D 表示，并确保它们与下游控制任务的一致性。通过将增强的 3D 特征与传统的 2D 视觉标记融合，我们的方法显着提高了 VLA 模型的泛化能力和鲁棒性。实验结果表明，所提出的方法不仅增强了几何模糊场景中的感知，而且还带来了卓越的动作预测精度。这项工作强调了深度驱动的数据增强和辅助专家监督在缩小机器人系统中 2D 观察和 3D 感知决策之间差距的潜力。

</details>

---

## 23. OmniVL-Guard: Towards Unified Vision-Language Forgery Detection and Grounding via Balanced RL

**中文标题**: OmniVL-Guard：通过平衡 RL 实现统一视觉语言伪造检测和接地

**Date**: 2026-02-11 | **arXiv**: [2602.10687v1](http://arxiv.org/abs/2602.10687v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10687v1)

<details><summary><b>Abstract</b></summary>

Existing forgery detection methods are often limited to uni-modal or bi-modal settings, failing to handle the interleaved text, images, and videos prevalent in real-world misinformation. To bridge this gap, this paper targets to develop a unified framework for omnibus vision-language forgery detection and grounding. In this unified setting, the {interplay} between diverse modalities and the dual requirements of simultaneous detection and localization pose a critical ``difficulty bias`` problem: the simpler veracity classification task tends to dominate the gradients, leading to suboptimal performance in fine-grained grounding during multi-task optimization. To address this challenge, we propose \textbf{OmniVL-Guard}, a balanced reinforcement learning framework for omnibus vision-language forgery detection and grounding. Particularly, OmniVL-Guard comprises two core designs: Self-Evolving CoT Generatio and Adaptive Reward Scaling Policy Optimization (ARSPO). {Self-Evolving CoT Generation} synthesizes high-quality reasoning paths, effectively overcoming the cold-start challenge. Building upon this, {Adaptive Reward Scaling Policy Optimization (ARSPO)} dynamically modulates reward scales and task weights, ensuring a balanced joint optimization. Extensive experiments demonstrate that OmniVL-Guard significantly outperforms state-of-the-art methods and exhibits zero-shot robust generalization across out-of-domain scenarios.

</details>

<details><summary><b>中文摘要</b></summary>

现有的伪造检测方法通常仅限于单模态或双模态设置，无法处理现实世界错误信息中普遍存在的交错文本、图像和视频。为了弥补这一差距，本文的目标是开发一个用于综合视觉语言伪造检测和基础的统一框架。在这种统一的设置中，不同模态之间的相互作用以及同时检测和定位的双重要求提出了一个关键的“难度偏差”问题：更简单的准确性分类任务往往会主导梯度，导致多任务优化期间细粒度基础的性能不佳。为了应对这一挑战，我们提出了 \textbf{OmniVL-Guard}，这是一个用于综合视觉语言伪造检测和基础的平衡强化学习框架。特别是，OmniVL-Guard包含两个核心设计：自我进化CoT生成和自适应奖励缩放策略优化（ARSPO）。 {Self-Evolving CoT Generation}综合高质量推理路径，有效克服冷启动挑战。在此基础上，{自适应奖励缩放策略优化（ARSPO）}动态调整奖励规模和任务权重，确保平衡的联合优化。大量实验表明，OmniVL-Guard 的性能显着优于最先进的方法，并在域外场景中展现出零样本的鲁棒泛化能力。

</details>

---

## 24. TwiFF (Think With Future Frames): A Large-Scale Dataset for Dynamic Visual Reasoning

**中文标题**: TwiFF（思考未来框架）：用于动态视觉推理的大规模数据集

**Date**: 2026-02-11 | **arXiv**: [2602.10675v1](http://arxiv.org/abs/2602.10675v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10675v1)

**Code**: https://github.com/LiuJunhua02/TwiFF.

<details><summary><b>Abstract</b></summary>

Visual Chain-of-Thought (VCoT) has emerged as a promising paradigm for enhancing multimodal reasoning by integrating visual perception into intermediate reasoning steps. However, existing VCoT approaches are largely confined to static scenarios and struggle to capture the temporal dynamics essential for tasks such as instruction, prediction, and camera motion. To bridge this gap, we propose TwiFF-2.7M, the first large-scale, temporally grounded VCoT dataset derived from $2.7$ million video clips, explicitly designed for dynamic visual question and answer. Accompanying this, we introduce TwiFF-Bench, a high-quality evaluation benchmark of $1,078$ samples that assesses both the plausibility of reasoning trajectories and the correctness of final answers in open-ended dynamic settings. Building on these foundations, we propose the TwiFF model, a unified modal that synergistically leverages pre-trained video generation and image comprehension capabilities to produce temporally coherent visual reasoning cues-iteratively generating future action frames and textual reasoning. Extensive experiments demonstrate that TwiFF significantly outperforms existing VCoT methods and Textual Chain-of-Thought baselines on dynamic reasoning tasks, which fully validates the effectiveness for visual question answering in dynamic scenarios. Our code and data is available at https://github.com/LiuJunhua02/TwiFF.

</details>

<details><summary><b>中文摘要</b></summary>

视觉思维链（VCoT）已成为一种有前途的范式，通过将视觉感知集成到中间推理步骤来增强多模态推理。然而，现有的 VCoT 方法主要局限于静态场景，难以捕捉指令、预测和相机运动等任务所必需的时间动态。为了弥补这一差距，我们提出了 TwiFF-2.7M，这是第一个大规模、基于时间的 VCoT 数据集，源自价值 270 万美元的视频剪辑，专门为动态视觉问答而设计。与此同时，我们推出了 TwiFF-Bench，这是一个包含 1,078 美元样本的高质量评估基准，用于评估开放式动态设置中推理轨迹的合理性和最终答案的正确性。在此基础上，我们提出了 TwiFF 模型，这是一种统一模式，协同利用预先训练的视频生成和图像理解功能来产生时间连贯的视觉推理线索，迭代地生成未来的动作框架和文本推理。大量实验表明，TwiFF 在动态推理任务上显着优于现有的 VCoT 方法和文本思维链基线，充分验证了动态场景下视觉问答的有效性。我们的代码和数据可在 https://github.com/LiuJunhua02/TwiFF 获取。

</details>

---

## 25. Multimodal Priors-Augmented Text-Driven 3D Human-Object Interaction Generation

**中文标题**: 多模态先验增强文本驱动 3D 人机交互生成

**Date**: 2026-02-11 | **arXiv**: [2602.10659v1](http://arxiv.org/abs/2602.10659v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10659v1)

<details><summary><b>Abstract</b></summary>

We address the challenging task of text-driven 3D human-object interaction (HOI) motion generation. Existing methods primarily rely on a direct text-to-HOI mapping, which suffers from three key limitations due to the significant cross-modality gap: (Q1) sub-optimal human motion, (Q2) unnatural object motion, and (Q3) weak interaction between humans and objects. To address these challenges, we propose MP-HOI, a novel framework grounded in four core insights: (1) Multimodal Data Priors: We leverage multimodal data (text, image, pose/object) from large multimodal models as priors to guide HOI generation, which tackles Q1 and Q2 in data modeling. (2) Enhanced Object Representation: We improve existing object representations by incorporating geometric keypoints, contact features, and dynamic properties, enabling expressive object representations, which tackles Q2 in data representation. (3) Multimodal-Aware Mixture-of-Experts (MoE) Model: We propose a modality-aware MoE model for effective multimodal feature fusion paradigm, which tackles Q1 and Q2 in feature fusion. (4) Cascaded Diffusion with Interaction Supervision: We design a cascaded diffusion framework that progressively refines human-object interaction features under dedicated supervision, which tackles Q3 in interaction refinement. Comprehensive experiments demonstrate that MP-HOI outperforms existing approaches in generating high-fidelity and fine-grained HOI motions.

</details>

<details><summary><b>中文摘要</b></summary>

我们解决文本驱动的 3D 人机交互 (HOI) 运动生成这一具有挑战性的任务。现有方法主要依赖于直接文本到 HOI 的映射，由于存在显着的跨模态差距，该方法受到三个关键限制：（Q1）次优的人体运动，（Q2）不自然的物体运动，以及（Q3）人类和物体之间的弱交互。为了应对这些挑战，我们提出了 MP-HOI，这是一个基于四个核心见解的新颖框架：（1）多模态数据先验：我们利用大型多模态模型中的多模态数据（文本、图像、姿势/对象）作为先验来指导 HOI 生成，从而解决数据建模中的 Q1 和 Q2 问题。 （2）增强的对象表示：我们通过合并几何关键点、接触特征和动态属性来改进现有的对象表示，从而实现富有表现力的对象表示，从而解决了数据表示中的问题2。 （3）多模态感知混合专家（MoE）模型：我们提出了一种用于有效多模态特征融合范式的模态感知MoE模型，该模型解决了特征融合中的Q1和Q2问题。 （4）具有交互监督的级联扩散：我们设计了一个级联扩散框架，在专门的监督下逐步细化人与物体的交互特征，解决了交互细化中的问题3。综合实验表明，MP-HOI 在生成高保真和细粒度 HOI 运动方面优于现有方法。

</details>

---

## 26. VideoSTF: Stress-Testing Output Repetition in Video Large Language Models

**中文标题**: VideoSTF：视频大语言模型中的输出重复压力测试

**Date**: 2026-02-11 | **arXiv**: [2602.10639v1](http://arxiv.org/abs/2602.10639v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10639v1)

**Code**: https://github.com/yuxincao22/VideoSTF_benchmark.

<details><summary><b>Abstract</b></summary>

Video Large Language Models (VideoLLMs) have recently achieved strong performance in video understanding tasks. However, we identify a previously underexplored generation failure: severe output repetition, where models degenerate into self-reinforcing loops of repeated phrases or sentences. This failure mode is not captured by existing VideoLLM benchmarks, which focus primarily on task accuracy and factual correctness. We introduce VideoSTF, the first framework for systematically measuring and stress-testing output repetition in VideoLLMs. VideoSTF formalizes repetition using three complementary n-gram-based metrics and provides a standardized testbed of 10,000 diverse videos together with a library of controlled temporal transformations. Using VideoSTF, we conduct pervasive testing, temporal stress testing, and adversarial exploitation across 10 advanced VideoLLMs. We find that output repetition is widespread and, critically, highly sensitive to temporal perturbations of video inputs. Moreover, we show that simple temporal transformations can efficiently induce repetitive degeneration in a black-box setting, exposing output repetition as an exploitable security vulnerability. Our results reveal output repetition as a fundamental stability issue in modern VideoLLMs and motivate stability-aware evaluation for video-language systems. Our evaluation code and scripts are available at: https://github.com/yuxincao22/VideoSTF_benchmark.

</details>

<details><summary><b>中文摘要</b></summary>

视频大语言模型（VideoLLM）最近在视频理解任务中取得了强劲的性能。然而，我们发现了一个先前未被充分探索的生成失败：严重的输出重复，其中模型退化为重复短语或句子的自我强化循环。现有的 VideoLLM 基准测试未捕获此故障模式，该基准测试主要关注任务准确性和事实正确性。我们介绍 VideoSTF，这是第一个在 VideoLLM 中系统测量和压力测试输出重复的框架。 VideoSTF 使用三个互补的基于 n-gram 的指标来形式化重复，并提供包含 10,000 个不同视频的标准化测试床以及受控时间转换库。使用 VideoSTF，我们在 10 个高级 VideoLLM 中进行普遍测试、时间压力测试和对抗性利用。我们发现输出重复很普遍，而且至关重要的是，它对视频输入的时间扰动高度敏感。此外，我们表明简单的时间变换可以有效地在黑盒设置中引起重复退化，从而将输出重复暴露为可利用的安全漏洞。我们的结果表明，输出重复是现代 VideoLLM 中的一个基本稳定性问题，并激发了对视频语言系统的稳定性感知评估。我们的评估代码和脚本位于：https://github.com/yuxincao22/VideoSTF_benchmark。

</details>

---

## 27. Eliminating VAE for Fast and High-Resolution Generative Detail Restoration

**中文标题**: 消除 VAE 以实现快速、高分辨率的生成细节恢复

**Date**: 2026-02-11 | **arXiv**: [2602.10630v1](http://arxiv.org/abs/2602.10630v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10630v1)

<details><summary><b>Abstract</b></summary>

Diffusion models have attained remarkable breakthroughs in the real-world super-resolution (SR) task, albeit at slow inference and high demand on devices. To accelerate inference, recent works like GenDR adopt step distillation to minimize the step number to one. However, the memory boundary still restricts the maximum processing size, necessitating tile-by-tile restoration of high-resolution images. Through profiling the pipeline, we pinpoint that the variational auto-encoder (VAE) is the bottleneck of latency and memory. To completely solve the problem, we leverage pixel-(un)shuffle operations to eliminate the VAE, reversing the latent-based GenDR to pixel-space GenDR-Pix. However, upscale with x8 pixelshuffle may induce artifacts of repeated patterns. To alleviate the distortion, we propose a multi-stage adversarial distillation to progressively remove the encoder and decoder. Specifically, we utilize generative features from the previous stage models to guide adversarial discrimination. Moreover, we propose random padding to augment generative features and avoid discriminator collapse. We also introduce a masked Fourier space loss to penalize the outliers of amplitude. To improve inference performance, we empirically integrate a padding-based self-ensemble with classifier-free guidance to improve inference scaling. Experimental results show that GenDR-Pix performs 2.8x acceleration and 60% memory-saving compared to GenDR with negligible visual degradation, surpassing other one-step diffusion SR. Against all odds, GenDR-Pix can restore 4K image in only 1 second and 6GB.

</details>

<details><summary><b>中文摘要</b></summary>

尽管推理速度慢且对设备的要求很高，但扩散模型在现实世界的超分辨率（SR）任务中取得了显着的突破。为了加速推理，GenDR 等最近的工作采用了步骤蒸馏，将步骤数最小化为 1。然而，内存边界仍然限制最大处理大小，需要逐块恢复高分辨率图像。通过对管道进行分析，我们发现变分自动编码器（VAE）是延迟和内存的瓶颈。为了彻底解决这个问题，我们利用像素（非）洗牌操作来消除 VAE，将基于潜在的 GenDR 反转为像素空间 GenDR-Pix。然而，x8 Pixelshuffle 的高档可能会导致重复图案的伪影。为了减轻失真，我们提出了多阶段对抗性蒸馏来逐步删除编码器和解码器。具体来说，我们利用前一阶段模型的生成特征来指导对抗性歧视。此外，我们提出随机填充来增强生成特征并避免鉴别器崩溃。我们还引入了掩蔽傅立叶空间损失来惩罚幅度的异常值。为了提高推理性能，我们根据经验将基于填充的自集成与无分类器指导相结合，以提高推理规模。实验结果表明，与 GenDR 相比，GenDR-Pix 的加速速度提高了 2.8 倍，节省了 60% 的内存，视觉退化可以忽略不计，超越了其他一步扩散 SR。尽管困难重重，GenDR-Pix 仍能在 1 秒内恢复 4K 图像，容量为 6GB。

</details>

---

## 28. A Vision-Language Foundation Model for Zero-shot Clinical Collaboration and Automated Concept Discovery in Dermatology

**中文标题**: 用于皮肤科零次临床协作和自动概念发现的视觉语言基础模型

**Date**: 2026-02-11 | **arXiv**: [2602.10624v1](http://arxiv.org/abs/2602.10624v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10624v1)

<details><summary><b>Abstract</b></summary>

Medical foundation models have shown promise in controlled benchmarks, yet widespread deployment remains hindered by reliance on task-specific fine-tuning. Here, we introduce DermFM-Zero, a dermatology vision-language foundation model trained via masked latent modelling and contrastive learning on over 4 million multimodal data points. We evaluated DermFM-Zero across 20 benchmarks spanning zero-shot diagnosis and multimodal retrieval, achieving state-of-the-art performance without task-specific adaptation. We further evaluated its zero-shot capabilities in three multinational reader studies involving over 1,100 clinicians. In primary care settings, AI assistance enabled general practitioners to nearly double their differential diagnostic accuracy across 98 skin conditions. In specialist settings, the model significantly outperformed board-certified dermatologists in multimodal skin cancer assessment. In collaborative workflows, AI assistance enabled non-experts to surpass unassisted experts while improving management appropriateness. Finally, we show that DermFM-Zero's latent representations are interpretable: sparse autoencoders unsupervisedly disentangle clinically meaningful concepts that outperform predefined-vocabulary approaches and enable targeted suppression of artifact-induced biases, enhancing robustness without retraining. These findings demonstrate that a foundation model can provide effective, safe, and transparent zero-shot clinical decision support.

</details>

<details><summary><b>中文摘要</b></summary>

医学基础模型在受控基准方面显示出了希望，但广泛部署仍然因依赖特定任务的微调而受到阻碍。在这里，我们介绍 DermFM-Zero，这是一种皮肤病学视觉语言基础模型，通过对超过 400 万个多模态数据点进行掩模潜在建模和对比学习进行训练。我们通过 20 个基准评估了 DermFM-Zero，涵盖零次诊断和多模态检索，无需针对特定任务进行适应即可实现最先进的性能。我们在涉及 1,100 多名临床医生的三项跨国读者研究中进一步评估了其零样本能力。在初级保健环境中，人工智能辅助使全科医生对 98 种皮肤病的鉴别诊断准确性几乎翻了一番。在专业环境中，该模型在多模式皮肤癌评估方面显着优于经过委员会认证的皮肤科医生。在协作工作流程中，人工智能辅助使非专家能够超越无人协助的专家，同时提高管理的适当性。最后，我们证明 DermFM-Zero 的潜在表示是可解释的：稀疏自动编码器无监督地解开具有临床意义的概念，这些概念优于预定义词汇方法，并且能够有针对性地抑制伪影引起的偏差，无需重新训练即可增强鲁棒性。这些发现表明，基础模型可以提供有效、安全和透明的零样本临床决策支持。

</details>

---

## 29. Improving Medical Visual Reinforcement Fine-Tuning via Perception and Reasoning Augmentation

**中文标题**: 通过感知和推理增强改善医学视觉强化微调

**Date**: 2026-02-11 | **arXiv**: [2602.10619v1](http://arxiv.org/abs/2602.10619v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10619v1)

<details><summary><b>Abstract</b></summary>

While recent advances in Reinforcement Fine-Tuning (RFT) have shown that rule-based reward schemes can enable effective post-training for large language models, their extension to cross-modal, vision-centric domains remains largely underexplored. This limitation is especially pronounced in the medical imaging domain, where effective performance requires both robust visual perception and structured reasoning. In this work, we address this gap by proposing VRFT-Aug, a visual reinforcement fine-tuning framework tailored for the medical domain. VRFT-Aug introduces a series of training strategies designed to augment both perception and reasoning, including prior knowledge injection, perception-driven policy refinement, medically informed reward shaping, and behavioral imitation. Together, these methods aim to stabilize and improve the RFT process.   Through extensive experiments across multiple medical datasets, we show that our approaches consistently outperform both standard supervised fine-tuning and RFT baselines. Moreover, we provide empirically grounded insights and practical training heuristics that can be generalized to other medical image tasks. We hope this work contributes actionable guidance and fresh inspiration for the ongoing effort to develop reliable, reasoning-capable models for high-stakes medical applications.

</details>

<details><summary><b>中文摘要</b></summary>

虽然强化微调（RFT）的最新进展表明，基于规则的奖励方案可以为大型语言模型提供有效的后训练，但它们向跨模式、以视觉为中心的领域的扩展在很大程度上仍未得到充分探索。这种限制在医学成像领域尤其明显，其中有效的性能需要强大的视觉感知和结构化推理。在这项工作中，我们通过提出 VRFT-Aug 来解决这一差距，VRFT-Aug 是一种为医疗领域量身定制的视觉强化微调框架。 VRFT-Aug 引入了一系列旨在增强感知和推理的训练策略，包括先验知识注入、感知驱动的策略细化、医学知识奖励塑造和行为模仿。这些方法共同旨在稳定和改进 RFT 过程。   通过对多个医学数据集的广泛实验，我们表明我们的方法始终优于标准监督微调和 RFT 基线。此外，我们提供了基于经验的见解和实践训练启发法，可以推广到其他医学图像任务。我们希望这项工作能够为持续努力为高风险医疗应用开发可靠、具有推理能力的模型提供可行的指导和新的灵感。

</details>

---

## 30. Enhancing YOLOv11n for Reliable Child Detection in Noisy Surveillance Footage

**中文标题**: 增强 YOLOv11n 以在嘈杂的监控录像中实现可靠的儿童检测

**Date**: 2026-02-11 | **arXiv**: [2602.10592v1](http://arxiv.org/abs/2602.10592v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10592v1)

**Code**: https://github.com/html-ptit/Data-Augmentation-YOLOv11n-child-detection

<details><summary><b>Abstract</b></summary>

This paper presents a practical and lightweight solution for enhancing child detection in low-quality surveillance footage, a critical component in real-world missing child alert and daycare monitoring systems. Building upon the efficient YOLOv11n architecture, we propose a deployment-ready pipeline that improves detection under challenging conditions including occlusion, small object size, low resolution, motion blur, and poor lighting commonly found in existing CCTV infrastructures. Our approach introduces a domain-specific augmentation strategy that synthesizes realistic child placements using spatial perturbations such as partial visibility, truncation, and overlaps, combined with photometric degradations including lighting variation and noise. To improve recall of small and partially occluded instances, we integrate Slicing Aided Hyper Inference (SAHI) at inference time. All components are trained and evaluated on a filtered, child-only subset of the Roboflow Daycare dataset. Compared to the baseline YOLOv11n, our enhanced system achieves a mean Average Precision at 0.5 IoU (mAP@0.5) of 0.967 and a mean Average Precision averaged over IoU thresholds from 0.5 to 0.95 (mAP@0.5:0.95) of 0.783, yielding absolute improvements of 0.7 percent and 2.3 percent, respectively, without architectural changes. Importantly, the entire pipeline maintains compatibility with low-power edge devices and supports real-time performance, making it particularly well suited for low-cost or resource-constrained industrial surveillance deployments. The example augmented dataset and the source code used to generate it are available at: https://github.com/html-ptit/Data-Augmentation-YOLOv11n-child-detection

</details>

<details><summary><b>中文摘要</b></summary>

本文提出了一种实用且轻量级的解决方案，用于增强低质量监控录像中的儿童检测，这是现实世界中失踪儿童警报和日托监控系统的关键组成部分。基于高效的 YOLOv11n 架构，我们提出了一种可部署的管道，可改善现有闭路电视基础设施中常见的遮挡、小物体尺寸、低分辨率、运动模糊和光线不足等挑战性条件下的检测。我们的方法引入了一种特定于域的增强策略，该策略使用空间扰动（例如部分可见性、截断和重叠）以及光度退化（包括照明变化和噪声）来合成真实的子放置。为了提高对小型和部分遮挡实例的召回率，我们在推理时集成了切片辅助超推理（SAHI）。所有组件均在 Roboflow Daycare 数据集的经过筛选、仅限儿童的子集上进行训练和评估。与基线 YOLOv11n 相比，我们的增强系统在 0.5 IoU (mAP@0.5) 下的平均平均精度为 0.967，在 IoU 阈值从 0.5 到 0.95 (mAP@0.5:0.95) 上的平均平均精度为 0.783，在没有架构变化的情况下，绝对改进分别为 0.7% 和 2.3%。重要的是，整个管道保持与低功耗边缘设备的兼容性并支持实时性能，使其特别适合低成本或资源有限的工业监控部署。示例增强数据集和用于生成它的源代码位于：https://github.com/html-ptit/Data-Augmentation-YOLOv11n-child-detection

</details>

---

## 31. MetaphorStar: Image Metaphor Understanding and Reasoning with End-to-End Visual Reinforcement Learning

**中文标题**: MetaphorStar：通过端到端视觉强化学习进行图像隐喻理解和推理

**Date**: 2026-02-11 | **arXiv**: [2602.10575v1](http://arxiv.org/abs/2602.10575v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10575v1)

<details><summary><b>Abstract</b></summary>

Metaphorical comprehension in images remains a critical challenge for Nowadays AI systems. While Multimodal Large Language Models (MLLMs) excel at basic Visual Question Answering (VQA), they consistently struggle to grasp the nuanced cultural, emotional, and contextual implications embedded in visual content. This difficulty stems from the task's demand for sophisticated multi-hop reasoning, cultural context, and Theory of Mind (ToM) capabilities, which current models lack. To fill this gap, we propose MetaphorStar, the first end-to-end visual reinforcement learning (RL) framework for image implication tasks. Our framework includes three core components: the fine-grained dataset TFQ-Data, the visual RL method TFQ-GRPO, and the well-structured benchmark TFQ-Bench.   Our fully open-source MetaphorStar family, trained using TFQ-GRPO on TFQ-Data, significantly improves performance by an average of 82.6% on the image implication benchmarks. Compared with 20+ mainstream MLLMs, MetaphorStar-32B achieves state-of-the-art (SOTA) on Multiple-Choice Question and Open-Style Question, significantly outperforms the top closed-source model Gemini-3.0-pro on True-False Question. Crucially, our experiments reveal that learning image implication tasks improves the general understanding ability, especially the complex visual reasoning ability. We further provide a systematic analysis of model parameter scaling, training data scaling, and the impact of different model architectures and training strategies, demonstrating the broad applicability of our method. We open-sourced all model weights, datasets, and method code at https://metaphorstar.github.io.

</details>

<details><summary><b>中文摘要</b></summary>

图像中的隐喻理解仍然是当今人工智能系统的一个关键挑战。虽然多模态大型语言模型 (MLLM) 擅长基本的视觉问答 (VQA)，但它们始终难以掌握视觉内容中嵌入的微妙文化、情感和上下文含义。这一困难源于该任务对复杂的多跳推理、文化背景和心智理论 (ToM) 能力的需求，而当前模型缺乏这些能力。为了填补这一空白，我们提出了 MetaphorStar，这是第一个用于图像暗示任务的端到端视觉强化学习（RL）框架。我们的框架包括三个核心组件：细粒度数据集 TFQ-Data、视觉 RL 方法 TFQ-GRPO 和结构良好的基准 TFQ-Bench。   我们完全开源的 MetaphorStar 系列在 TFQ-Data 上使用 TFQ-GRPO 进行训练，在图像含义基准上显着提高了平均 82.6% 的性能。与20多个主流MLLM相比，MetaphorStar-32B在多项选择题和开放式题上达到了state-of-the-art（SOTA），在True-False题上显着优于顶级闭源模型Gemini-3.0-pro。至关重要的是，我们的实验表明，学习图像暗示任务可以提高一般理解能力，尤其是复杂的视觉推理能力。我们进一步对模型参数缩放、训练数据缩放以及不同模型架构和训练策略的影响进行了系统分析，证明了我们的方法的广泛适用性。我们在 https://metaphorstar.github.io 开源了所有模型权重、数据集和方法代码。

</details>

---

## 32. C^2ROPE: Causal Continuous Rotary Positional Encoding for 3D Large Multimodal-Models Reasoning

**中文标题**: C^2ROPE：用于 3D 大型多模态模型推理的因果连续旋转位置编码

**Date**: 2026-02-11 | **arXiv**: [2602.10551v1](http://arxiv.org/abs/2602.10551v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10551v1)

**Code**: https://github.com/ErikZ719/C2RoPE.

<details><summary><b>Abstract</b></summary>

Recent advances in 3D Large Multimodal Models (LMMs) built on Large Language Models (LLMs) have established the alignment of 3D visual features with LLM representations as the dominant paradigm. However, the inherited Rotary Position Embedding (RoPE) introduces limitations for multimodal processing. Specifically, applying 1D temporal positional indices disrupts the continuity of visual features along the column dimension, resulting in spatial locality loss. Moreover, RoPE follows the prior that temporally closer image tokens are more causally related, leading to long-term decay in attention allocation and causing the model to progressively neglect earlier visual tokens as the sequence length increases. To address these issues, we propose C^2RoPE, an improved RoPE that explicitly models local spatial Continuity and spatial Causal relationships for visual processing. C^2RoPE introduces a spatio-temporal continuous positional embedding mechanism for visual tokens. It first integrates 1D temporal positions with Cartesian-based spatial coordinates to construct a triplet hybrid positional index, and then employs a frequency allocation strategy to encode spatio-temporal positional information across the three index components. Additionally, we introduce Chebyshev Causal Masking, which determines causal dependencies by computing the Chebyshev distance of image tokens in 2D space. Evaluation results across various benchmarks, including 3D scene reasoning and 3D visual question answering, demonstrate C^2RoPE's effectiveness. The code is be available at https://github.com/ErikZ719/C2RoPE.

</details>

<details><summary><b>中文摘要</b></summary>

基于大型语言模型 (LLM) 的 3D 大型多模态模型 (LMM) 的最新进展已经建立了 3D 视觉特征与 LLM 表示的一致性作为主导范式。然而，继承的旋转位置嵌入（RoPE）引入了多模态处理的限制。具体来说，应用一维时间位置索引会破坏视觉特征沿列维度的连续性，导致空间局部性损失。此外，RoPE 遵循先验知识，即时间上更接近的图像标记更具有因果关系，导致注意力分配的长期衰减，并导致模型随着序列长度的增加逐渐忽略较早的视觉标记。为了解决这些问题，我们提出了 C^2RoPE，这是一种改进的 RoPE，它可以显式地模拟视觉处理的局部空间连续性和空间因果关系。 C^2RoPE 引入了视觉标记的时空连续位置嵌入机制。它首先将一维时间位置与基于笛卡尔的空间坐标相结合以构建三元组混合位置索引，然后采用频率分配策略对三个索引分量之间的时空位置信息进行编码。此外，我们引入了切比雪夫因果掩蔽，它通过计算 2D 空间中图像标记的切比雪夫距离来确定因果依赖性。包括 3D 场景推理和 3D 视觉问答在内的各种基准的评估结果证明了 C^2RoPE 的有效性。该代码可从 https://github.com/ErikZ719/C2RoPE 获取。

</details>

---

## 33. Enhancing Weakly Supervised Multimodal Video Anomaly Detection through Text Guidance

**中文标题**: 通过文本引导增强弱监督多模态视频异常检测

**Date**: 2026-02-11 | **arXiv**: [2602.10549v1](http://arxiv.org/abs/2602.10549v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10549v1)

<details><summary><b>Abstract</b></summary>

Weakly supervised multimodal video anomaly detection has gained significant attention, yet the potential of the text modality remains under-explored. Text provides explicit semantic information that can enhance anomaly characterization and reduce false alarms. However, extracting effective text features is challenging due to the inability of general-purpose language models to capture anomaly-specific nuances and the scarcity of relevant descriptions. Furthermore, multimodal fusion often suffers from redundancy and imbalance. To address these issues, we propose a novel text-guided framework. First, we introduce an in-context learning-based multi-stage text augmentation mechanism to generate high-quality anomaly text samples for fine-tuning the text feature extractor. Second, we design a multi-scale bottleneck Transformer fusion module that uses compressed bottleneck tokens to progressively integrate information across modalities, mitigating redundancy and imbalance. Experiments on UCF-Crime and XD-Violence demonstrate state-of-the-art performance.

</details>

<details><summary><b>中文摘要</b></summary>

弱监督多模态视频异常检测已引起广泛关注，但文本模态的潜力仍未得到充分开发。文本提供明确的语义信息，可以增强异常表征并减少误报。然而，由于通用语言模型无法捕获异常特定的细微差别以及相关描述的稀缺，提取有效的文本特征具有挑战性。此外，多模态融合经常遭受冗余和不平衡的困扰。为了解决这些问题，我们提出了一种新颖的文本引导框架。首先，我们引入基于上下文学习的多阶段文本增强机制来生成高质量的异常文本样本，以微调文本特征提取器。其次，我们设计了一个多尺度瓶颈 Transformer 融合模块，该模块使用压缩的瓶颈令牌逐步集成跨模态的信息，从而减轻冗余和不平衡。 UCF-Crime 和 XD-Violence 上的实验展示了最先进的性能。

</details>

---

## 34. MapVerse: A Benchmark for Geospatial Question Answering on Diverse Real-World Maps

**中文标题**: MapVerse：各种真实世界地图上的地理空间问答的基准

**Date**: 2026-02-11 | **arXiv**: [2602.10518v1](http://arxiv.org/abs/2602.10518v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10518v1)

<details><summary><b>Abstract</b></summary>

Maps are powerful carriers of structured and contextual knowledge, encompassing geography, demographics, infrastructure, and environmental patterns. Reasoning over such knowledge requires models to integrate spatial relationships, visual cues, real-world context, and domain-specific expertise-capabilities that current large language models (LLMs) and vision-language models (VLMs) still struggle to exhibit consistently. Yet, datasets used to benchmark VLMs on map-based reasoning remain narrow in scope, restricted to specific domains, and heavily reliant on artificially generated content (outputs from LLMs or pipeline-based methods), offering limited depth for evaluating genuine geospatial reasoning. To address this gap, we present MapVerse, a large-scale benchmark built on real-world maps. It comprises 11,837 human-authored question-answer pairs across 1,025 maps, spanning ten diverse map categories and multiple question categories for each. The dataset provides a rich setting for evaluating map reading, interpretation, and multimodal reasoning. We evaluate ten state-of-the-art models against our benchmark to establish baselines and quantify reasoning gaps. Beyond overall performance, we conduct fine-grained categorical analyses to assess model inference across multiple dimensions and investigate the visual factors shaping reasoning outcomes. Our findings reveal that while current VLMs perform competitively on classification-style tasks, both open- and closed-source models fall short on advanced tasks requiring complex spatial reasoning.

</details>

<details><summary><b>中文摘要</b></summary>

地图是结构化和情境知识的强大载体，涵盖地理、人口统计、基础设施和环境模式。对这些知识的推理需要模型整合空间关系、视觉线索、现实世界背景和特定领域的专业知识能力，而当前的大型语言模型 (LLM) 和视觉语言模型 (VLM) 仍然难以一致地展示这些能力。然而，用于基于地图推理对 VLM 进行基准测试的数据集范围仍然很窄，仅限于特定领域，并且严重依赖人工生成的内容（LLM 或基于管道的方法的输出），为评估真正的地理空间推理提供的深度有限。为了解决这一差距，我们推出了 MapVerse，这是一个基于真实世界地图的大型基准测试。它包含 1,025 个地图中的 11,837 个人工编写的问答对，涵盖 10 个不同的地图类别，并且每个类别都有多个问题类别。该数据集为评估地图阅读、解释和多模式推理提供了丰富的设置。我们根据我们的基准评估十个最先进的模型，以建立基线并量化推理差距。除了整体表现之外，我们还进行细粒度的分类分析，以评估多个维度的模型推理，并研究塑造推理结果的视觉因素。我们的研究结果表明，虽然当前的 VLM 在分类任务上表现得具有竞争力，但开源和闭源模型在需要复杂空间推理的高级任务上都表现不佳。

</details>

---

## 35. 3DXTalker: Unifying Identity, Lip Sync, Emotion, and Spatial Dynamics in Expressive 3D Talking Avatars

**中文标题**: 3DXTalker：在富有表现力的 3D 说话化身中统一身份、口型同步、情感和空间动态

**Date**: 2026-02-11 | **arXiv**: [2602.10516v1](http://arxiv.org/abs/2602.10516v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10516v1)

<details><summary><b>Abstract</b></summary>

Audio-driven 3D talking avatar generation is increasingly important in virtual communication, digital humans, and interactive media, where avatars must preserve identity, synchronize lip motion with speech, express emotion, and exhibit lifelike spatial dynamics, collectively defining a broader objective of expressivity. However, achieving this remains challenging due to insufficient training data with limited subject identities, narrow audio representations, and restricted explicit controllability. In this paper, we propose 3DXTalker, an expressive 3D talking avatar through data-curated identity modeling, audio-rich representations, and spatial dynamics controllability. 3DXTalker enables scalable identity modeling via 2D-to-3D data curation pipeline and disentangled representations, alleviating data scarcity and improving identity generalization. Then, we introduce frame-wise amplitude and emotional cues beyond standard speech embeddings, ensuring superior lip synchronization and nuanced expression modulation. These cues are unified by a flow-matching-based transformer for coherent facial dynamics. Moreover, 3DXTalker also enables natural head-pose motion generation while supporting stylized control via prompt-based conditioning. Extensive experiments show that 3DXTalker integrates lip synchronization, emotional expression, and head-pose dynamics within a unified framework, achieves superior performance in 3D talking avatar generation.

</details>

<details><summary><b>中文摘要</b></summary>

音频驱动的 3D 说话化身生成在虚拟通信、数字人类和交互式媒体中变得越来越重要，其中化身必须保持身份、使嘴唇运动与语音同步、表达情感并展现逼真的空间动态，共同定义更广泛的表现力目标。然而，由于训练数据不足、受试者身份有限、音频表示狭窄以及显式可控性有限，实现这一目标仍然具有挑战性。在本文中，我们提出了 3DXTalker，这是一种通过数据管理的身份建模、丰富的音频表示和空间动态可控性实现的富有表现力的 3D 说话化身。 3DXTalker 通过 2D 到 3D 数据管理管道和解开的表示实现可扩展的身份建模，从而缓解数据稀缺并提高身份泛化。然后，我们引入了标准语音嵌入之外的逐帧幅度和情感线索，确保卓越的唇形同步和细致入微的表达调制。这些线索通过基于流匹配的转换器进行统一，以实现连贯的面部动态。此外，3DXTalker 还可以生成自然的头部姿势运动，同时通过基于提示的调节支持风格化控制。大量实验表明，3DXTalker将唇形同步、情绪表达和头部姿势动态集成在一个统一的框架内，在3D说话头像生成方面取得了优异的性能。

</details>

---

## 36. 1%>100%: High-Efficiency Visual Adapter with Complex Linear Projection Optimization

**中文标题**: 1%>100%：具有复杂线性投影优化的高效视觉适配器

**Date**: 2026-02-11 | **arXiv**: [2602.10513v1](http://arxiv.org/abs/2602.10513v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10513v1)

**Code**: https://github.com/DongshuoYin/CoLin.

<details><summary><b>Abstract</b></summary>

Deploying vision foundation models typically relies on efficient adaptation strategies, whereas conventional full fine-tuning suffers from prohibitive costs and low efficiency. While delta-tuning has proven effective in boosting the performance and efficiency of LLMs during adaptation, its advantages cannot be directly transferred to the fine-tuning pipeline of vision foundation models. To push the boundaries of adaptation efficiency for vision tasks, we propose an adapter with Complex Linear Projection Optimization (CoLin). For architecture, we design a novel low-rank complex adapter that introduces only about 1% parameters to the backbone. For efficiency, we theoretically prove that low-rank composite matrices suffer from severe convergence issues during training, and address this challenge with a tailored loss. Extensive experiments on object detection, segmentation, image classification, and rotated object detection (remote sensing scenario) demonstrate that CoLin outperforms both full fine-tuning and classical delta-tuning approaches with merely 1% parameters for the first time, providing a novel and efficient solution for deployment of vision foundation models. We release the code on https://github.com/DongshuoYin/CoLin.

</details>

<details><summary><b>中文摘要</b></summary>

部署视觉基础模型通常依赖于高效的适应策略，而传统的全面微调成本高昂且效率低下。虽然 Delta-tuning 已被证明可以有效提高 LLM 在适应过程中的性能和效率，但其优势不能直接转移到视觉基础模型的微调流程中。为了突破视觉任务适应效率的界限，我们提出了一种具有复杂线性投影优化（CoLin）的适配器。对于架构，我们设计了一种新颖的低阶复杂适配器，仅向主干引入约 1% 的参数。为了提高效率，我们从理论上证明低秩复合矩阵在训练过程中会遇到严重的收敛问题，并通过定制损失来解决这一挑战。在对象检测、分割、图像分类和旋转对象检测（遥感场景）方面的大量实验表明，CoLin 首次仅用 1% 的参数就优于完全微调和经典的 delta-tuning 方法，为视觉基础模型的部署提供了一种新颖且高效的解决方案。我们在 https://github.com/DongshuoYin/CoLin 上发布了代码。

</details>

---

## 37. The Garbage Dataset (GD): A Multi-Class Image Benchmark for Automated Waste Segregation

**中文标题**: 垃圾数据集 (GD)：自动垃圾分类的多类图像基准

**Date**: 2026-02-11 | **arXiv**: [2602.10500v1](http://arxiv.org/abs/2602.10500v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10500v1)

<details><summary><b>Abstract</b></summary>

This study introduces the Garbage Dataset (GD), a publicly available image dataset designed to advance automated waste segregation through machine learning and computer vision. It's a diverse dataset covering 10 common household waste categories: metal, glass, biological, paper, battery, trash, cardboard, shoes, clothes, and plastic. The dataset comprises 13,348 labeled images collected through multiple methods, including DWaste mobile app and curated web sources. Methods included rigorous validation through checksums and outlier detection, analysis of class imbalance and visual separability via PCA/t-SNE, and assessment of background complexity using entropy and saliency measures. The dataset was benchmarked using state-of-the-art deep learning models (EfficientNetV2M, EfficientNetV2S, MobileNet, ResNet50, ResNet101) evaluated on performance metrics and operational carbon emissions. Experiment results indicate EfficientNetV2S achieved the highest performance with 96.19% accuracy and a 0.96 F1-score, though with a moderate carbon cost. Analysis revealed inherent dataset characteristics including class imbalance, a skew toward high-outlier classes (plastic, cardboard, paper), and brightness variations that require consideration. The main conclusion is that GD provides a valuable, real-world benchmark for waste classification research while highlighting important challenges such as class imbalance, background complexity, and environmental trade-offs in model selection that must be addressed for practical deployment. The dataset is publicly released to support further research in environmental sustainability applications.

</details>

<details><summary><b>中文摘要</b></summary>

这项研究引入了垃圾数据集（GD），这是一个公开的图像数据集，旨在通过机器学习和计算机视觉推进自动垃圾分类。这是一个多样化的数据集，涵盖 10 种常见的家庭废物类别：金属、玻璃、生物、纸张、电池、垃圾、纸板、鞋子、衣服和塑料。该数据集包含通过多种方法收集的 13,348 张标记图像，包括 DWaste 移动应用程序和精选的网络资源。方法包括通过校验和和异常值检测进行严格验证，通过 PCA/t-SNE 分析类不平衡和视觉可分离性，以及使用熵和显着性度量评估背景复杂性。该数据集使用最先进的深度学习模型（EfficientNetV2M、EfficientNetV2S、MobileNet、ResNet50、ResNet101）进行基准测试，并根据性能指标和运营碳排放进行评估。实验结果表明，EfficientNetV2S 实现了最高性能，准确率达到 96.19%，F1 分数为 0.96，但碳成本适中。分析揭示了固有的数据集特征，包括类别不平衡、向高异常值类别（塑料、纸板、纸张）的倾斜以及需要考虑的亮度变化。主要结论是，GD 为废物分类研究提供了一个有价值的、真实的基准，同时强调了实际部署中必须解决的重要挑战，例如类别不平衡、背景复杂性以及模型选择中的环境权衡。该数据集的公开发布是为了支持环境可持续性应用的进一步研究。

</details>

---

## 38. Towards Remote Sensing Change Detection with Neural Memory

**中文标题**: 利用神经记忆进行遥感变化检测

**Date**: 2026-02-11 | **arXiv**: [2602.10491v1](http://arxiv.org/abs/2602.10491v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10491v1)

<details><summary><b>Abstract</b></summary>

Remote sensing change detection is essential for environmental monitoring, urban planning, and related applications. However, current methods often struggle to capture long-range dependencies while maintaining computational efficiency. Although Transformers can effectively model global context, their quadratic complexity poses scalability challenges, and existing linear attention approaches frequently fail to capture intricate spatiotemporal relationships. Drawing inspiration from the recent success of Titans in language tasks, we present ChangeTitans, the Titans-based framework for remote sensing change detection. Specifically, we propose VTitans, the first Titans-based vision backbone that integrates neural memory with segmented local attention, thereby capturing long-range dependencies while mitigating computational overhead. Next, we present a hierarchical VTitans-Adapter to refine multi-scale features across different network layers. Finally, we introduce TS-CBAM, a two-stream fusion module leveraging cross-temporal attention to suppress pseudo-changes and enhance detection accuracy. Experimental evaluations on four benchmark datasets (LEVIR-CD, WHU-CD, LEVIR-CD+, and SYSU-CD) demonstrate that ChangeTitans achieves state-of-the-art results, attaining \textbf{84.36\%} IoU and \textbf{91.52\%} F1-score on LEVIR-CD, while remaining computationally competitive.

</details>

<details><summary><b>中文摘要</b></summary>

遥感变化检测对于环境监测、城市规划和相关应用至关重要。然而，当前的方法通常难以在保持计算效率的同时捕获远程依赖性。尽管 Transformer 可以有效地对全局上下文进行建模，但其二次复杂性带来了可扩展性挑战，并且现有的线性注意力方法经常无法捕获复杂的时空关系。从最近 Titans 在语言任务中取得的成功中汲取灵感，我们推出了 ChangeTitans，这是基于 Titans 的遥感变化检测框架。具体来说，我们提出了 VTitans，这是第一个基于 Titans 的视觉主干，它将神经记忆与分段局部注意力相结合，从而捕获远程依赖性，同时减少计算开销。接下来，我们提出了一个分层的 VTitans-Adapter 来细化不同网络层的多尺度特征。最后，我们介绍了 TS-CBAM，这是一种利用跨时间注意力来抑制伪变化并提高检测精度的两流融合模块。对四个基准数据集（LEVIR-CD、WHU-CD、LEVIR-CD+ 和 SYSU-CD）的实验评估表明，ChangeTitans 取得了最先进的结果，在 LEVIR-CD 上获得 \textbf{84.36\%} IoU 和 \textbf{91.52\%} F1 分数，同时保持计算竞争力。

</details>

---

## 39. HII-DPO: Eliminate Hallucination via Accurate Hallucination-Inducing Counterfactual Images

**中文标题**: HII-DPO：通过准确的诱发幻觉的反事实图像消除幻觉

**Date**: 2026-02-11 | **arXiv**: [2602.10425v1](http://arxiv.org/abs/2602.10425v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10425v1)

<details><summary><b>Abstract</b></summary>

Large Vision-Language Models (VLMs) have achieved remarkable success across diverse multimodal tasks but remain vulnerable to hallucinations rooted in inherent language bias. Despite recent progress, existing hallucination mitigation methods often overlook the underlying hallucination patterns driven by language bias. In this work, we design a novel pipeline to accurately synthesize Hallucination-Inducing Images (HIIs). Using synthesized HIIs, we reveal a consistent scene-conditioned hallucination pattern: models tend to mention objects that are highly typical of the scene even when visual evidence is removed. To quantify the susceptibility of VLMs to this hallucination pattern, we establish the Masked-Object-Hallucination (MOH) benchmark to rigorously evaluate existing state-of-the-art alignment frameworks. Finally, we leverage HIIs to construct high-quality preference datasets for fine-grained alignment. Experimental results demonstrate that our approach effectively mitigates hallucinations while preserving general model capabilities. Specifically, our method achieves up to a 38% improvement over the current state-of-the-art on standard hallucination benchmarks.

</details>

<details><summary><b>中文摘要</b></summary>

大视觉语言模型（VLM）在各种多模式任务中取得了显着的成功，但仍然容易受到源于固有语言偏见的幻觉的影响。尽管最近取得了进展，但现有的幻觉缓解方法常常忽视由语言偏见驱动的潜在幻觉模式。在这项工作中，我们设计了一种新颖的管道来准确合成幻觉诱导图像（HII）。使用合成的 HII，我们揭示了一致的场景条件幻觉模式：即使视觉证据被移除，模型也倾向于提及场景中高度典型的物体。为了量化 VLM 对这种幻觉模式的敏感性，我们建立了蒙面物体幻觉 (MOH) 基准来严格评估现有的最先进的对齐框架。最后，我们利用 HII 构建高质量的偏好数据集以进行细粒度对齐。实验结果表明，我们的方法有效地减轻了幻觉，同时保留了一般模型的能力。具体来说，我们的方法在标准幻觉基准上比当前最先进的方法提高了 38%。

</details>

---

## 40. Fine-Tuning GPT-5 for GPU Kernel Generation

**中文标题**: 针对 GPU 内核生成微调 GPT-5

**Date**: 2026-02-11 | **arXiv**: [2602.11000v1](http://arxiv.org/abs/2602.11000v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.11000v1)

<details><summary><b>Abstract</b></summary>

Developing efficient GPU kernels is essential for scaling modern AI systems, yet it remains a complex task due to intricate hardware architectures and the need for specialized optimization expertise. Although Large Language Models (LLMs) demonstrate strong capabilities in general sequential code generation, they face significant challenges in GPU code generation because of the scarcity of high-quality labeled training data, compiler biases when generating synthetic solutions, and limited generalization across hardware generations. This precludes supervised fine-tuning (SFT) as a scalable methodology for improving current LLMs. In contrast, reinforcement learning (RL) offers a data-efficient and adaptive alternative but requires access to relevant tools, careful selection of training problems, and a robust evaluation environment. We present Makora's environment and tools for reinforcement learning finetuning of frontier models and report our results from fine-tuning GPT-5 for Triton code generation. In the single-attempt setting, our fine-tuned model improves kernel correctness from 43.7% to 77.0% (+33.3 percentage points) and increases the fraction of problems outperforming TorchInductor from 14.8% to 21.8% (+7 percentage points) compared to baseline GPT-5, while exceeding prior state-of-the-art models on KernelBench. When integrated into a full coding agent, it is able to solve up to 97.4% of problems in an expanded KernelBench suite, outperforming the PyTorch TorchInductor compiler on 72.9% of problems with a geometric mean speedup of 2.12x. Our work demonstrates that targeted post-training with reinforcement learning can unlock LLM capabilities in highly specialized technical domains where traditional supervised learning is limited by data availability, opening new pathways for AI-assisted accelerator programming.

</details>

<details><summary><b>中文摘要</b></summary>

开发高效的 GPU 内核对于扩展现代人工智能系统至关重要，但由于复杂的硬件架构和对专业优化专业知识的需求，它仍然是一项复杂的任务。尽管大型语言模型 (LLM) 在通用顺序代码生成方面表现出强大的能力，但由于缺乏高质量的标记训练数据、生成综合解决方案时的编译器偏差以及跨硬件代的泛化能力有限，它们在 GPU 代码生成方面面临着重大挑战。这就排除了监督微调（SFT）作为改进当前法学硕士的可扩展方法的可能性。相比之下，强化学习（RL）提供了一种数据高效且适应性强的替代方案，但需要访问相关工具、仔细选择训练问题以及强大的评估环境。我们介绍了 Makora 用于强化学习微调前沿模型的环境和工具，并报告了微调 GPT-5 以生成 Triton 代码的结果。在单次尝试设置中，与基线 GPT-5 相比，我们的微调模型将内核正确性从 43.7% 提高到 77.0%（+33.3 个百分点），并将优于 TorchInductor 的问题比例从 14.8% 增加到 21.8%（+7 个百分点），同时超过了 KernelBench 上先前最先进的模型。当集成到完整的编码代理中时，它能够解决扩展 KernelBench 套件中高达 97.4% 的问题，在 72.9% 的问题上优于 PyTorch TorchInductor 编译器，几何平均加速率为 2.12 倍。我们的工作表明，有针对性的强化学习后培训可以在高度专业化的技术领域释放法学硕士的能力，在这些领域，传统的监督学习受到数据可用性的限制，为人工智能辅助加速器编程开辟新的途径。

</details>

---

## 41. LoRA-Squeeze: Simple and Effective Post-Tuning and In-Tuning Compression of LoRA Modules

**中文标题**: LoRA-Squeeze：LoRA 模块的简单有效的后调和调中压缩

**Date**: 2026-02-11 | **arXiv**: [2602.10993v1](http://arxiv.org/abs/2602.10993v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10993v1)

<details><summary><b>Abstract</b></summary>

Despite its huge number of variants, standard Low-Rank Adaptation (LoRA) is still a dominant technique for parameter-efficient fine-tuning (PEFT). Nonetheless, it faces persistent challenges, including the pre-selection of an optimal rank and rank-specific hyper-parameters, as well as the deployment complexity of heterogeneous-rank modules and more sophisticated LoRA derivatives. In this work, we introduce LoRA-Squeeze, a simple and efficient methodology that aims to improve standard LoRA learning by changing LoRA module ranks either post-hoc or dynamically during training}. Our approach posits that it is better to first learn an expressive, higher-rank solution and then compress it, rather than learning a constrained, low-rank solution directly. The method involves fine-tuning with a deliberately high(er) source rank, reconstructing or efficiently approximating the reconstruction of the full weight update matrix, and then using Randomized Singular Value Decomposition (RSVD) to create a new, compressed LoRA module at a lower target rank. Extensive experiments across 13 text and 10 vision-language tasks show that post-hoc compression often produces lower-rank adapters that outperform those trained directly at the target rank, especially if a small number of fine-tuning steps at the target rank is allowed. Moreover, a gradual, in-tuning rank annealing variant of LoRA-Squeeze consistently achieves the best LoRA size-performance trade-off.

</details>

<details><summary><b>中文摘要</b></summary>

尽管有大量变体，标准低秩适应 (LoRA) 仍然是参数高效微调 (PEFT) 的主导技术。尽管如此，它仍然面临着持续的挑战，包括预选择最佳等级和特定于等级的超参数，以及异构等级模块和更复杂的 LoRA 衍生品的部署复杂性。在这项工作中，我们引入了 LoRA-Squeeze，这是一种简单而高效的方法，旨在通过事后或在训练期间动态更改 LoRA 模块排名来改进标准 LoRA 学习}。我们的方法假设，最好首先学习一个富有表现力的高秩解决方案，然后对其进行压缩，而不是直接学习一个受约束的低秩解决方案。该方法涉及使用故意较高（更高）的源秩进行微调，重建或有效地近似重建全权重更新矩阵，然后使用随机奇异值分解（RSVD）以较低的目标秩创建新的压缩 LoRA 模块。跨 13 个文本和 10 个视觉语言任务的广泛实验表明，事后压缩通常会产生较低等级的适配器，其性能优于直接在目标等级上训练的适配器，特别是如果允许在目标等级上进行少量微调步骤的话。此外，LoRA-Squeeze 的渐进、调优等级退火变体始终能够实现最佳的 LoRA 尺寸与性能权衡。

</details>

---

## 42. Computational Phenomenology of Temporal Experience in Autism: Quantifying the Emotional and Narrative Characteristics of Lived Unpredictability

**中文标题**: 自闭症时间体验的计算现象学：量化生活不可预测性的情感和叙事特征

**Date**: 2026-02-11 | **arXiv**: [2602.10947v1](http://arxiv.org/abs/2602.10947v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10947v1)

<details><summary><b>Abstract</b></summary>

Disturbances in temporality, such as desynchronization with the social environment and its unpredictability, are considered core features of autism with a deep impact on relationships. However, limitations regarding research on this issue include: 1) the dominance of deficit-based medical models of autism, 2) sample size in qualitative research, and 3) the lack of phenomenological anchoring in computational research. To bridge the gap between phenomenological and computational approaches and overcome sample-size limitations, our research integrated three methodologies. Study A: structured phenomenological interviews with autistic individuals using the Transdiagnostic Assessment of Temporal Experience. Study B: computational analysis of an autobiographical corpus of autistic narratives built for this purpose. Study C: a replication of a computational study using narrative flow measures to assess the perceived phenomenological authenticity of autistic autobiographies. Interviews revealed that the most significant differences between the autistic and control groups concerned unpredictability of experience. Computational results mirrored these findings: the temporal lexicon in autistic narratives was significantly more negatively valenced - particularly the "Immediacy & Suddenness" category. Outlier analysis identified terms associated with perceived discontinuity (unpredictably, precipitously, and abruptly) as highly negative. The computational analysis of narrative flow found that the autistic narratives contained within the corpus quantifiably resemble autobiographical stories more than imaginary ones. Overall, the temporal challenges experienced by autistic individuals were shown to primarily concern lived unpredictability and stem from the contents of lived experience, and not from autistic narrative construction.

</details>

<details><summary><b>中文摘要</b></summary>

时间性紊乱，例如与社会环境的不同步及其不可预测性，被认为是自闭症的核心特征，对人际关系有深远的影响。然而，该问题研究的局限性包括：1）基于缺陷的自闭症医学模型占主导地位，2）定性研究中的样本量，以及3）计算研究中缺乏现象学锚定。为了弥合现象学方法和计算方法之间的差距并克服样本量限制，我们的研究整合了三种方法。研究A：使用时间体验跨诊断评估对自闭症患者进行结构化现象学访谈。研究 B：为此目的构建的自传体叙述语料库的计算分析。研究C：使用叙事流测量来评估自闭症自传的现象学真实性的计算研究的复制。访谈显示，自闭症组和对照组之间最显着的差异在于经历的不可预测性。计算结果反映了这些发现：自闭症叙事中的时间词汇的负价明显更高——尤其是“即时性和突然性”类别。异常值分析将与感知不连续性（不可预测的、突然的和突然的）相关的术语识别为高度负面的。对叙事流的计算分析发现，语料库中包含的自闭症叙事在数量上更类似于自传故事，而不是想象的故事。总体而言，自闭症患者经历的时间挑战主要与生活的不可预测性有关，并且源于生活经历的内容，而不是来自自闭症的叙事结构。

</details>

---

## 43. Blind Gods and Broken Screens: Architecting a Secure, Intent-Centric Mobile Agent Operating System

**中文标题**: 盲目的上帝和破碎的屏幕：构建一个安全的、以意图为中心的移动代理操作系统

**Date**: 2026-02-11 | **arXiv**: [2602.10915v1](http://arxiv.org/abs/2602.10915v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10915v1)

<details><summary><b>Abstract</b></summary>

The evolution of Large Language Models (LLMs) has shifted mobile computing from App-centric interactions to system-level autonomous agents. Current implementations predominantly rely on a "Screen-as-Interface" paradigm, which inherits structural vulnerabilities and conflicts with the mobile ecosystem's economic foundations. In this paper, we conduct a systematic security analysis of state-of-the-art mobile agents using Doubao Mobile Assistant as a representative case. We decompose the threat landscape into four dimensions - Agent Identity, External Interface, Internal Reasoning, and Action Execution - revealing critical flaws such as fake App identity, visual spoofing, indirect prompt injection, and unauthorized privilege escalation stemming from a reliance on unstructured visual data.   To address these challenges, we propose Aura, an Agent Universal Runtime Architecture for a clean-slate secure agent OS. Aura replaces brittle GUI scraping with a structured, agent-native interaction model. It adopts a Hub-and-Spoke topology where a privileged System Agent orchestrates intent, sandboxed App Agents execute domain-specific tasks, and the Agent Kernel mediates all communication. The Agent Kernel enforces four defense pillars: (i) cryptographic identity binding via a Global Agent Registry; (ii) semantic input sanitization through a multilayer Semantic Firewall; (iii) cognitive integrity via taint-aware memory and plan-trajectory alignment; and (iv) granular access control with non-deniable auditing. Evaluation on MobileSafetyBench shows that, compared to Doubao, Aura improves low-risk Task Success Rate from roughly 75% to 94.3%, reduces high-risk Attack Success Rate from roughly 40% to 4.4%, and achieves near-order-of-magnitude latency gains. These results demonstrate Aura as a viable, secure alternative to the "Screen-as-Interface" paradigm.

</details>

<details><summary><b>中文摘要</b></summary>

大型语言模型 (LLM) 的发展已将移动计算从以应用程序为中心的交互转变为系统级自主代理。当前的实现主要依赖于“屏幕即界面”范式，该范式继承了结构性漏洞并与移动生态系统的经济基础发生冲突。在本文中，我们以豆宝手机助手为代表案例，对最先进的移动代理进行了系统的安全分析。我们将威胁态势分解为四个维度——代理身份、外部接口、内部推理和操作执行——揭示了由于依赖非结构化视觉数据而产生的虚假应用程序身份、视觉欺骗、间接提示注入和未经授权的权限升级等关键缺陷。   为了应对这些挑战，我们提出了 Aura，一种用于全新安全代理操作系统的代理通用运行时架构。 Aura 用结构化的代理本机交互模型取代了脆弱的 GUI 抓取。它采用中心辐射型拓扑，其中特权系统代理协调意图，沙盒应用程序代理执行特定于域的任务，代理内核协调所有通信。代理内核强制执行四个防御支柱：(i) 通过全局代理注册表进行加密身份绑定； (ii) 通过多层语义防火墙进行语义输入清理； (iii) 通过污点感知记忆和计划轨迹对齐实现认知完整性； (iv) 具有不可否认审计的精细访问控制。 MobileSafetyBench评测显示，与豆宝相比，Aura将低风险任务成功率从大约75%提高到94.3%，将高风险攻击成功率从大约40%降低到4.4%，并实现了接近数量级的延迟增益。这些结果表明 Aura 是“屏幕即界面”范例的可行、安全的替代方案。

</details>

---

## 44. Interactive LLM-assisted Curriculum Learning for Multi-Task Evolutionary Policy Search

**中文标题**: 用于多任务进化政策搜索的交互式法学硕士辅助课程学习

**Date**: 2026-02-11 | **arXiv**: [2602.10891v1](http://arxiv.org/abs/2602.10891v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10891v1)

<details><summary><b>Abstract</b></summary>

Multi-task policy search is a challenging problem because policies are required to generalize beyond training cases. Curriculum learning has proven to be effective in this setting, as it introduces complexity progressively. However, designing effective curricula is labor-intensive and requires extensive domain expertise. LLM-based curriculum generation has only recently emerged as a potential solution, but was limited to operate in static, offline modes without leveraging real-time feedback from the optimizer. Here we propose an interactive LLM-assisted framework for online curriculum generation, where the LLM adaptively designs training cases based on real-time feedback from the evolutionary optimization process. We investigate how different feedback modalities, ranging from numeric metrics alone to combinations with plots and behavior visualizations, influence the LLM ability to generate meaningful curricula. Through a 2D robot navigation case study, tackled with genetic programming as optimizer, we evaluate our approach against static LLM-generated curricula and expert-designed baselines. We show that interactive curriculum generation outperforms static approaches, with multimodal feedback incorporating both progression plots and behavior visualizations yielding performance competitive with expert-designed curricula. This work contributes to understanding how LLMs can serve as interactive curriculum designers for embodied AI systems, with potential extensions to broader evolutionary robotics applications.

</details>

<details><summary><b>中文摘要</b></summary>

多任务策略搜索是一个具有挑战性的问题，因为策略需要泛化到训练案例之外。事实证明，课程学习在这种情况下是有效的，因为它逐渐引入了复杂性。然而，设计有效的课程是劳动密集型的，并且需要广泛的领域专业知识。基于 LLM 的课程生成最近才作为一种潜在的解决方案出现，但仅限于在静态、离线模式下运行，无法利用优化器的实时反馈。在这里，我们提出了一个用于在线课程生成的交互式法学硕士辅助框架，其中法学硕士根据进化优化过程的实时反馈自适应地设计训练案例。我们研究不同的反馈方式（从单独的数字指标到与绘图和行为可视化的组合）如何影响法学硕士生成有意义的课程的能力。通过 2D 机器人导航案例研究，并以遗传编程作为优化器进行处理，我们根据静态 LLM 生成的课程和专家设计的基线评估我们的方法。我们表明，交互式课程生成优于静态方法，多模式反馈结合了进度图和行为可视化，产生的性能可与专家设计的课程相媲美。这项工作有助于理解法学硕士如何充当具体人工智能系统的交互式课程设计者，并有可能扩展到更广泛的进化机器人应用。

</details>

---

## 45. The CLEF-2026 FinMMEval Lab: Multilingual and Multimodal Evaluation of Financial AI Systems

**中文标题**: CLEF-2026 FinMMEval 实验室：金融人工智能系统的多语言和多模式评估

**Date**: 2026-02-11 | **arXiv**: [2602.10886v1](http://arxiv.org/abs/2602.10886v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10886v1)

<details><summary><b>Abstract</b></summary>

We present the setup and the tasks of the FinMMEval Lab at CLEF 2026, which introduces the first multilingual and multimodal evaluation framework for financial Large Language Models (LLMs). While recent advances in financial natural language processing have enabled automated analysis of market reports, regulatory documents, and investor communications, existing benchmarks remain largely monolingual, text-only, and limited to narrow subtasks. FinMMEval 2026 addresses this gap by offering three interconnected tasks that span financial understanding, reasoning, and decision-making: Financial Exam Question Answering, Multilingual Financial Question Answering (PolyFiQA), and Financial Decision Making. Together, these tasks provide a comprehensive evaluation suite that measures models' ability to reason, generalize, and act across diverse languages and modalities. The lab aims to promote the development of robust, transparent, and globally inclusive financial AI systems, with datasets and evaluation resources publicly released to support reproducible research.

</details>

<details><summary><b>中文摘要</b></summary>

我们在 CLEF 2026 上介绍了 FinMMEval 实验室的设置和任务，该实验室引入了第一个针对金融大语言模型 (LLM) 的多语言和多模式评估框架。尽管金融自然语言处理的最新进展已经实现了对市场报告、监管文件和投资者沟通的自动分析，但现有基准仍然主要是单语言、纯文本，并且仅限于狭窄的子任务。 FinMMEval 2026 通过提供三个涵盖金融理解、推理和决策的相互关联的任务来解决这一差距：金融考试问答、多语言金融问答 (PolyFiQA) 和金融决策。这些任务共同提供了一个全面的评估套件，用于衡量模型跨不同语言和模式进行推理、泛化和行动的能力。该实验室旨在促进稳健、透明和全球包容的金融人工智能系统的发展，公开发布数据集和评估资源以支持可重复的研究。

</details>

---

## 46. Reinforcing Chain-of-Thought Reasoning with Self-Evolving Rubrics

**中文标题**: 用自我进化的标准强化思维链推理

**Date**: 2026-02-11 | **arXiv**: [2602.10885v1](http://arxiv.org/abs/2602.10885v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10885v1)

<details><summary><b>Abstract</b></summary>

Despite chain-of-thought (CoT) playing crucial roles in LLM reasoning, directly rewarding it is difficult: training a reward model demands heavy human labeling efforts, and static RMs struggle with evolving CoT distributions and reward hacking. These challenges motivate us to seek an autonomous CoT rewarding approach that requires no human annotation efforts and can evolve gradually. Inspired by recent self-evolving training methods, we propose \textbf{RLCER} (\textbf{R}einforcement \textbf{L}earning with \textbf{C}oT Supervision via Self-\textbf{E}volving \textbf{R}ubrics), which enhances the outcome-centric RLVR by rewarding CoTs with self-proposed and self-evolving rubrics. We show that self-proposed and self-evolving rubrics provide reliable CoT supervision signals even without outcome rewards, enabling RLCER to outperform outcome-centric RLVR. Moreover, when used as in-prompt hints, these self-proposed rubrics further improve inference-time performance.

</details>

<details><summary><b>中文摘要</b></summary>

尽管思想链 (CoT) 在 LLM 推理中发挥着至关重要的作用，但直接奖励它很困难：训练奖励模型需要大量的人工标记工作，而静态 RM 则难以应对不断变化的 CoT 分布和奖励黑客攻击。这些挑战促使我们寻求一种自主的 CoT 奖励方法，该方法不需要人工注释工作并且可以逐渐发展。受最近自我进化训练方法的启发，我们提出了 \textbf{RLCER} （\textbf{R}einforcement \textbf{L}earning with \textbf{C}oT Supervision via Self-\textbf{E}volving \textbf{R}ubrics），它通过用自我提出和自我进化的规则奖励 CoT 来增强以结果为中心的 RLVR。我们证明，即使没有结果奖励，自我提出和自我演化的规则也能提供可靠的 CoT 监督信号，使 RLCER 的表现优于以结果为中心的 RLVR。此外，当用作提示时，这些自行提出的规则进一步提高了推理时间性能。

</details>

---

## 47. ICA: Information-Aware Credit Assignment for Visually Grounded Long-Horizon Information-Seeking Agents

**中文标题**: ICA：视觉基础的长视野信息搜索代理的信息感知信用分配

**Date**: 2026-02-11 | **arXiv**: [2602.10863v1](http://arxiv.org/abs/2602.10863v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10863v1)

**Code**: https://github.com/pc-inno/ICA_MM_deepsearch.git.

<details><summary><b>Abstract</b></summary>

Despite the strong performance achieved by reinforcement learning-trained information-seeking agents, learning in open-ended web environments remains severely constrained by low signal-to-noise feedback. Text-based parsers often discard layout semantics and introduce unstructured noise, while long-horizon training typically relies on sparse outcome rewards that obscure which retrieval actions actually matter. We propose a visual-native search framework that represents webpages as visual snapshots, allowing agents to leverage layout cues to quickly localize salient evidence and suppress distractors. To learn effectively from these high-dimensional observations, we introduce Information-Aware Credit Assignment (ICA), a post-hoc method that estimates each retrieved snapshot's contribution to the final outcome via posterior analysis and propagates dense learning signals back to key search turns. Integrated with a GRPO-based training pipeline, our approach consistently outperforms text-based baselines on diverse information-seeking benchmarks, providing evidence that visual snapshot grounding with information-level credit assignment alleviates the credit-assignment bottleneck in open-ended web environments. The code and datasets will be released in https://github.com/pc-inno/ICA_MM_deepsearch.git.

</details>

<details><summary><b>中文摘要</b></summary>

尽管经过强化学习训练的信息搜索代理取得了出色的性能，但开放式网络环境中的学习仍然受到低信噪比反馈的严重限制。基于文本的解析器通常会丢弃布局语义并引入非结构化噪声，而长期训练通常依赖于稀疏的结果奖励，从而模糊了哪些检索操作真正重要。我们提出了一种视觉原生搜索框架，将网页表示为视觉快照，允许代理利用布局线索快速定位显着证据并抑制干扰因素。为了有效地从这些高维观察中学习，我们引入了信息感知信用分配（ICA），这是一种事后方法，通过后验分析估计每个检索到的快照对最终结果的贡献，并将密集的学习信号传播回关键搜索回合。与基于 GRPO 的训练管道相结合，我们的方法在各种信息搜索基准上始终优于基于文本的基线，提供了证据表明具有信息级信用分配的视觉快照基础可以缓解开放式网络环境中的信用分配瓶颈。代码和数据集将在 https://github.com/pc-inno/ICA_MM_deepsearch.git 中发布。

</details>

---

## 48. See, Plan, Snap: Evaluating Multimodal GUI Agents in Scratch

**中文标题**: 查看、计划、捕捉：在 Scratch 中评估多模式 GUI 代理

**Date**: 2026-02-11 | **arXiv**: [2602.10814v1](http://arxiv.org/abs/2602.10814v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10814v1)

<details><summary><b>Abstract</b></summary>

Block-based programming environments such as Scratch play a central role in low-code education, yet evaluating the capabilities of AI agents to construct programs through Graphical User Interfaces (GUIs) remains underexplored. We introduce ScratchWorld, a benchmark for evaluating multimodal GUI agents on program-by-construction tasks in Scratch. Grounded in the Use-Modify-Create pedagogical framework, ScratchWorld comprises 83 curated tasks spanning four distinct problem categories: Create, Debug, Extend, and Compute. To rigorously diagnose the source of agent failures, the benchmark employs two complementary interaction modes: primitive mode requires fine-grained drag-and-drop manipulation to directly assess visuomotor control, while composite mode uses high-level semantic APIs to disentangle program reasoning from GUI execution. To ensure reliable assessment, we propose an execution-based evaluation protocol that validates the functional correctness of the constructed Scratch programs through runtime tests within the browser environment. Extensive experiments across state-of-the-art multimodal language models and GUI agents reveal a substantial reasoning--acting gap, highlighting persistent challenges in fine-grained GUI manipulation despite strong planning capabilities.

</details>

<details><summary><b>中文摘要</b></summary>

Scratch 等基于块的编程环境在低代码教育中发挥着核心作用，但评估人工智能代理通过图形用户界面 (GUI) 构建程序的能力仍未得到充分探索。我们引入了 ScratchWorld，这是一个用于评估 Scratch 中的程序构建任务的多模式 GUI 代理的基准。 ScratchWorld 以“使用-修改-创建”教学框架为基础，包含 83 个精心策划的任务，涵盖四个不同的问题类别：创建、调试、扩展和计算。为了严格诊断代理故障的根源，该基准测试采用了两种互补的交互模式：原始模式需要细粒度的拖放操作来直接评估视觉运动控制，而复合模式则使用高级语义 API 将程序推理与 GUI 执行分开。为了确保评估的可靠性，我们提出了一种基于执行的评估协议，通过在浏览器环境中的运行时测试来验证所构建的 Scratch 程序的功能正确性。跨最先进的多模式语言模型和 GUI 代理的广泛实验揭示了巨大的推理-执行差距，凸显了尽管规划能力强大，但细粒度 GUI 操作方面持续存在的挑战。

</details>

---

## 49. VulReaD: Knowledge-Graph-guided Software Vulnerability Reasoning and Detection

**中文标题**: VulReaD：知识图引导的软件漏洞推理与检测

**Date**: 2026-02-11 | **arXiv**: [2602.10787v1](http://arxiv.org/abs/2602.10787v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10787v1)

<details><summary><b>Abstract</b></summary>

Software vulnerability detection (SVD) is a critical challenge in modern systems. Large language models (LLMs) offer natural-language explanations alongside predictions, but most work focuses on binary evaluation, and explanations often lack semantic consistency with Common Weakness Enumeration (CWE) categories. We propose VulReaD, a knowledge-graph-guided approach for vulnerability reasoning and detection that moves beyond binary classification toward CWE-level reasoning. VulReaD leverages a security knowledge graph (KG) as a semantic backbone and uses a strong teacher LLM to generate CWE-consistent contrastive reasoning supervision, enabling student model training without manual annotations. Students are fine-tuned with Odds Ratio Preference Optimization (ORPO) to encourage taxonomy-aligned reasoning while suppressing unsupported explanations. Across three real-world datasets, VulReaD improves binary F1 by 8-10% and multi-class classification by 30% Macro-F1 and 18% Micro-F1 compared to state-of-the-art baselines. Results show that LLMs outperform deep learning baselines in binary detection and that KG-guided reasoning enhances CWE coverage and interpretability.

</details>

<details><summary><b>中文摘要</b></summary>

软件漏洞检测（SVD）是现代系统中的一个严峻挑战。大型语言模型 (LLM) 提供自然语言解释和预测，但大多数工作侧重于二元评估，并且解释通常缺乏与常见弱点枚举 (CWE) 类别的语义一致性。我们提出了 VulReaD，一种用于漏洞推理和检测的知识图引导方法，它超越了二进制分类，转向了 CWE 级别的推理。 VulReaD利用安全知识图（KG）作为语义主干，并使用强大的LLM教师来生成CWE一致的对比推理监督，从而无需手动注释即可实现学生模型训练。学生使用优势比偏好优化 (ORPO) 进行微调，以鼓励分类学一致的推理，同时抑制不受支持的解释。在三个真实数据集上，与最先进的基线相比，VulReaD 将二进制 F1 提高了 8-10%，将多类分类提高了 30% Macro-F1 和 18% Micro-F1。结果表明，LLM 在二进制检测方面优于深度学习基线，并且知识图谱引导的推理增强了 CWE 的覆盖范围和可解释性。

</details>

---

## 50. Cross-Sectional Asset Retrieval via Future-Aligned Soft Contrastive Learning

**中文标题**: 通过面向未来的软对比学习进行横截面资产检索

**Date**: 2026-02-11 | **arXiv**: [2602.10711v1](http://arxiv.org/abs/2602.10711v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10711v1)

<details><summary><b>Abstract</b></summary>

Asset retrieval--finding similar assets in a financial universe--is central to quantitative investment decision-making. Existing approaches define similarity through historical price patterns or sector classifications, but such backward-looking criteria provide no guarantee about future behavior. We argue that effective asset retrieval should be future-aligned: the retrieved assets should be those most likely to exhibit correlated future returns. To this end, we propose Future-Aligned Soft Contrastive Learning (FASCL), a representation learning framework whose soft contrastive loss uses pairwise future return correlations as continuous supervision targets. We further introduce an evaluation protocol designed to directly assess whether retrieved assets share similar future trajectories. Experiments on 4,229 US equities demonstrate that FASCL consistently outperforms 13 baselines across all future-behavior metrics. The source code will be available soon.

</details>

<details><summary><b>中文摘要</b></summary>

资产检索——在金融领域中寻找相似资产——是量化投资决策的核心。现有方法通过历史价格模式或行业分类来定义相似性，但这种向后看的标准并不能保证未来的行为。我们认为，有效的资产检索应该与未来保持一致：检索到的资产应该是那些最有可能表现出相关的未来回报的资产。为此，我们提出了未来对齐软对比学习（FASCL），这是一种表示学习框架，其软对比损失使用成对的未来回报相关性作为连续监督目标。我们进一步引入了一种评估协议，旨在直接评估检索到的资产是否具有相似的未来轨迹。对 4,229 只美国股票的实验表明，FASCL 在所有未来行为指标中始终优于 13 个基线。源代码很快就会提供。

</details>

---

## 51. Interpretable Graph-Level Anomaly Detection via Contrast with Normal Prototypes

**中文标题**: 通过与正常原型对比进行可解释的图级异常检测

**Date**: 2026-02-11 | **arXiv**: [2602.10708v1](http://arxiv.org/abs/2602.10708v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10708v1)

<details><summary><b>Abstract</b></summary>

The task of graph-level anomaly detection (GLAD) is to identify anomalous graphs that deviate significantly from the majority of graphs in a dataset. While deep GLAD methods have shown promising performance, their black-box nature limits their reliability and deployment in real-world applications. Although some recent methods have made attempts to provide explanations for anomaly detection results, they either provide explanations without referencing normal graphs, or rely on abstract latent vectors as prototypes rather than concrete graphs from the dataset. To address these limitations, we propose Prototype-based Graph-Level Anomaly Detection (ProtoGLAD), an interpretable unsupervised framework that provides explanation for each detected anomaly by explicitly contrasting with its nearest normal prototype graph. It employs a point-set kernel to iteratively discover multiple normal prototype graphs and their associated clusters from the dataset, then identifying graphs distant from all discovered normal clusters as anomalies. Extensive experiments on multiple real-world datasets demonstrate that ProtoGLAD achieves competitive anomaly detection performance compared to state-of-the-art GLAD methods while providing better human-interpretable prototype-based explanations.

</details>

<details><summary><b>中文摘要</b></summary>

图级异常检测（GLAD）的任务是识别与数据集中的大多数图显着偏差的异常图。虽然深度 GLAD 方法表现出了良好的性能，但它们的黑盒性质限制了它们在实际应用中的可靠性和部署。尽管最近的一些方法尝试为异常检测结果提供解释，但它们要么在不引用正常图的情况下提供解释，要么依赖抽象潜在向量作为原型而不是数据集中的具体图。为了解决这些限制，我们提出了基于原型的图级异常检测（ProtoGLAD），这是一种可解释的无监督框架，它通过与最接近的正常原型图明确对比来为每个检测到的异常提供解释。它采用点集内核迭代地从数据集中发现多个正常原型图及其关联的簇，然后将远离所有发现的正常簇的图识别为异常。对多个真实世界数据集的大量实验表明，与最先进的 GLAD 方法相比，ProtoGLAD 实现了有竞争力的异常检测性能，同时提供了更好的人类可解释的基于原型的解释。

</details>

---

## 52. Neuro-symbolic Action Masking for Deep Reinforcement Learning

**中文标题**: 用于深度强化学习的神经符号动作掩蔽

**Date**: 2026-02-11 | **arXiv**: [2602.10598v1](http://arxiv.org/abs/2602.10598v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10598v1)

<details><summary><b>Abstract</b></summary>

Deep reinforcement learning (DRL) may explore infeasible actions during training and execution. Existing approaches assume a symbol grounding function that maps high-dimensional states to consistent symbolic representations and a manually specified action masking techniques to constrain actions. In this paper, we propose Neuro-symbolic Action Masking (NSAM), a novel framework that automatically learn symbolic models, which are consistent with given domain constraints of high-dimensional states, in a minimally supervised manner during the DRL process. Based on the learned symbolic model of states, NSAM learns action masks that rules out infeasible actions. NSAM enables end-to-end integration of symbolic reasoning and deep policy optimization, where improvements in symbolic grounding and policy learning mutually reinforce each other. We evaluate NSAM on multiple domains with constraints, and experimental results demonstrate that NSAM significantly improves sample efficiency of DRL agent while substantially reducing constraint violations.

</details>

<details><summary><b>中文摘要</b></summary>

深度强化学习（DRL）可能会探索训练和执行过程中不可行的动作。现有方法假设符号基础函数将高维状态映射到一致的符号表示，并采用手动指定的动作屏蔽技术来约束动作。在本文中，我们提出了神经符号动作掩蔽（NSAM），这是一种新的框架，可以在 DRL 过程中以最小监督的方式自动学习符号模型，这些模型与高维状态的给定域约束一致。基于学习到的状态符号模型，NSAM 学习排除不可行动作的动作掩码。 NSAM 能够实现符号推理和深度策略优化的端到端集成，其中符号基础和策略学习的改进相辅相成。我们在具有约束的多个域上评估 NSAM，实验结果表明，NSAM 显着提高了 DRL 代理的样本效率，同时大大减少了约束违规。

</details>

---

## 53. LAP: Language-Action Pre-Training Enables Zero-shot Cross-Embodiment Transfer

**中文标题**: LAP：语言-动作预训练实现零样本跨实施例迁移

**Date**: 2026-02-11 | **arXiv**: [2602.10556v1](http://arxiv.org/abs/2602.10556v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10556v1)

<details><summary><b>Abstract</b></summary>

A long-standing goal in robotics is a generalist policy that can be deployed zero-shot on new robot embodiments without per-embodiment adaptation. Despite large-scale multi-embodiment pre-training, existing Vision-Language-Action models (VLAs) remain tightly coupled to their training embodiments and typically require costly fine-tuning. We introduce Language-Action Pre-training (LAP), a simple recipe that represents low-level robot actions directly in natural language, aligning action supervision with the pre-trained vision-language model's input-output distribution. LAP requires no learned tokenizer, no costly annotation, and no embodiment-specific architectural design. Based on LAP, we present LAP-3B, which to the best of our knowledge is the first VLA to achieve substantial zero-shot transfer to previously unseen robot embodiments without any embodiment-specific fine-tuning. Across multiple novel robots and manipulation tasks, LAP-3B attains over 50% average zero-shot success, delivering roughly a 2x improvement over the strongest prior VLAs. We further show that LAP enables efficient adaptation and favorable scaling, while unifying action prediction and VQA in a shared language-action format that yields additional gains through co-training.

</details>

<details><summary><b>中文摘要</b></summary>

机器人技术的一个长期目标是一种通用策略，可以在新的机器人实施例上进行零射击部署，而无需针对每个实施例进行调整。尽管进行了大规模的多实施例预训练，现有的视觉-语言-动作模型（VLA）仍然与其训练实施例紧密耦合，并且通常需要昂贵的微调。我们引入了语言动作预训练（LAP），这是一种简单的方法，直接用自然语言表示低级机器人动作，使动作监督与预训练的视觉语言模型的输入输出分布保持一致。 LAP 不需要学习分词器，不需要昂贵的注释，也不需要特定于实施例的架构设计。基于 LAP，我们提出了 LAP-3B，据我们所知，它是第一个实现到以前未见过的机器人实施例的基本零样本转移的 VLA，而无需任何特定于实施例的微调。在多个新颖的机器人和操纵任务中，LAP-3B 获得了超过 50% 的平均零射击成功率，比之前最强的 VLA 大约提高了 2 倍。我们进一步表明，LAP 能够实现高效的适应和有利的扩展，同时以共享的语言-动作格式统一动作预测和 VQA，从而通过协同训练产生额外的收益。

</details>

---

## 54. $μ$pscaling small models: Principled warm starts and hyperparameter transfer

**中文标题**: $μ$pscaling 小模型：有原则的热启动和超参数传输

**Date**: 2026-02-11 | **arXiv**: [2602.10545v1](http://arxiv.org/abs/2602.10545v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10545v1)

<details><summary><b>Abstract</b></summary>

Modern large-scale neural networks are often trained and released in multiple sizes to accommodate diverse inference budgets. To improve efficiency, recent work has explored model upscaling: initializing larger models from trained smaller ones in order to transfer knowledge and accelerate convergence. However, this method can be sensitive to hyperparameters that need to be tuned at the target upscaled model size, which is prohibitively costly to do directly. It remains unclear whether the most common workaround -- tuning on smaller models and extrapolating via hyperparameter scaling laws -- is still sound when using upscaling. We address this with principled approaches to upscaling with respect to model widths and efficiently tuning hyperparameters in this setting. First, motivated by $μ$P and any-dimensional architectures, we introduce a general upscaling method applicable to a broad range of architectures and optimizers, backed by theory guaranteeing that models are equivalent to their widened versions and allowing for rigorous analysis of infinite-width limits. Second, we extend the theory of $μ$Transfer to a hyperparameter transfer technique for models upscaled using our method and empirically demonstrate that this method is effective on realistic datasets and architectures.

</details>

<details><summary><b>中文摘要</b></summary>

现代大规模神经网络通常以多种规模进行训练和发布，以适应不同的推理预算。为了提高效率，最近的工作探索了模型升级：从经过训练的较小模型初始化较大模型，以转移知识并加速收敛。然而，这种方法可能对需要在目标放大模型大小上进行调整的超参数敏感，直接这样做成本高昂。目前尚不清楚最常见的解决方法——调整较小的模型并通过超参数缩放定律进行推断——在使用升级时是否仍然有效。我们通过原则性的方法来解决这个问题，在模型宽度方面进行放大，并在此设置中有效地调整超参数。首先，在 $μ$P 和任意维架构的推动下，我们引入了一种适用于各种架构和优化器的通用升级方法，该方法以理论为支持，保证模型与其扩展版本等效，并允许对无限宽度限制进行严格分析。其次，我们将 $μ$Transfer 的理论扩展到使用我们的方法放大的模型的超参数传输技术，并凭经验证明该方法对于现实数据集和架构是有效的。

</details>

---

## 55. Co-jump: Cooperative Jumping with Quadrupedal Robots via Multi-Agent Reinforcement Learning

**中文标题**: 协同跳跃：通过多智能体强化学习与四足机器人协同跳跃

**Date**: 2026-02-11 | **arXiv**: [2602.10514v1](http://arxiv.org/abs/2602.10514v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10514v1)

<details><summary><b>Abstract</b></summary>

While single-agent legged locomotion has witnessed remarkable progress, individual robots remain fundamentally constrained by physical actuation limits. To transcend these boundaries, we introduce Co-jump, a cooperative task where two quadrupedal robots synchronize to execute jumps far beyond their solo capabilities. We tackle the high-impulse contact dynamics of this task under a decentralized setting, achieving synchronization without explicit communication or pre-specified motion primitives. Our framework leverages Multi-Agent Proximal Policy Optimization (MAPPO) enhanced by a progressive curriculum strategy, which effectively overcomes the sparse-reward exploration challenges inherent in mechanically coupled systems. We demonstrate robust performance in simulation and successful transfer to physical hardware, executing multi-directional jumps onto platforms up to 1.5 m in height. Specifically, one of the robots achieves a foot-end elevation of 1.1 m, which represents a 144% improvement over the 0.45 m jump height of a standalone quadrupedal robot, demonstrating superior vertical performance. Notably, this precise coordination is achieved solely through proprioceptive feedback, establishing a foundation for communication-free collaborative locomotion in constrained environments.

</details>

<details><summary><b>中文摘要</b></summary>

虽然单代理腿运动已经取得了显着的进步，但单个机器人仍然从根本上受到物理驱动限制的限制。为了超越这些界限，我们引入了协同跳跃，这是一种合作任务，其中两个四足机器人同步执行远远超出其单独能力的跳跃。我们在分散的设置下处理该任务的高脉冲接触动力学，无需显式通信或预先指定的运动基元即可实现同步。我们的框架利用渐进式课程策略增强的多智能体近端策略优化（MAPPO），有效克服了机械耦合系统固有的稀疏奖励探索挑战。我们在模拟中展示了强大的性能，并成功转移到物理硬件，在高达 1.5 m 的平台上执行多向跳跃。具体来说，其中一台机器人的足端高度达到了 1.1 m，这比独立四足机器人的 0.45 m 跳跃高度提高了 144%，展示了卓越的垂直性能。值得注意的是，这种精确的协调仅通过本体感觉反馈来实现，为受限环境中的无通信协作运动奠定了基础。

</details>

---

## 56. Driving Reaction Trajectories via Latent Flow Matching

**中文标题**: 通过潜在流匹配驱动反应轨迹

**Date**: 2026-02-11 | **arXiv**: [2602.10476v1](http://arxiv.org/abs/2602.10476v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10476v1)

<details><summary><b>Abstract</b></summary>

Recent advances in reaction prediction have achieved near-saturated accuracy on standard benchmarks (e.g., USPTO), yet most state-of-the-art models formulate the task as a one-shot mapping from reactants to products, offering limited insight into the underlying reaction process. Procedural alternatives introduce stepwise generation but often rely on mechanism-specific supervision, discrete symbolic edits, and computationally expensive inference. In this work, we propose LatentRxnFlow, a new reaction prediction paradigm that models reactions as continuous latent trajectories anchored at the thermodynamic product state. Built on Conditional Flow Matching, our approach learns time-dependent latent dynamics directly from standard reactant-product pairs, without requiring mechanistic annotations or curated intermediate labels. While LatentRxnFlow achieves state-of-the-art performance on USPTO benchmarks, more importantly, the continuous formulation exposes the full generative trajectory, enabling trajectory-level diagnostics that are difficult to realize with discrete or one-shot models. We show that latent trajectory analysis allows us to localize and characterize failure modes and to mitigate certain errors via gated inference. Furthermore, geometric properties of the learned trajectories provide an intrinsic signal of epistemic uncertainty, helping prioritize reliably predictable reaction outcomes and flag ambiguous cases for additional validation. Overall, LatentRxnFlow combines strong predictive accuracy with improved transparency, diagnosability, and uncertainty awareness, moving reaction prediction toward more trustworthy deployment in high-throughput discovery workflows.

</details>

<details><summary><b>中文摘要</b></summary>

反应预测的最新进展已在标准基准（例如美国专利商标局）上实现了接近饱和的准确性，但大多数最先进的模型将任务制定为从反应物到产物的一次性映射，对潜在反应过程的了解有限。程序替代方案引入了逐步生成，但通常依赖于特定于机制的监督、离散符号编辑和计算成本高昂的推理。在这项工作中，我们提出了 LatentRxnFlow，一种新的反应预测范式，它将反应建模为锚定于热力学产物状态的连续潜在轨迹。我们的方法基于条件流匹配，直接从标准反应物-产物对学习时间相关的潜在动态，无需机械注释或策划的中间标签。虽然 LatentRxnFlow 在 USPTO 基准上实现了最先进的性能，但更重要的是，连续公式暴露了完整的生成轨迹，从而实现了离散或一次性模型难以实现的轨迹级诊断。我们表明，潜在轨迹分析使我们能够定位和表征故障模式，并通过门控推理来减轻某些错误。此外，学习轨迹的几何特性提供了认知不确定性的内在信号，有助于优先考虑可靠预测的反应结果，并标记不明确的情况以进行额外验证。总体而言，LatentRxnFlow 将强大的预测准确性与改进的透明度、可诊断性和不确定性意识相结合，将反应预测推向高通量发现工作流程中更值得信赖的部署。

</details>

---

## 57. Found-RL: foundation model-enhanced reinforcement learning for autonomous driving

**中文标题**: Found-RL：自动驾驶的基础模型增强强化学习

**Date**: 2026-02-11 | **arXiv**: [2602.10458v1](http://arxiv.org/abs/2602.10458v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10458v1)

**Code**: https://github.com/ys-qu/found-rl.

<details><summary><b>Abstract</b></summary>

Reinforcement Learning (RL) has emerged as a dominant paradigm for end-to-end autonomous driving (AD). However, RL suffers from sample inefficiency and a lack of semantic interpretability in complex scenarios. Foundation Models, particularly Vision-Language Models (VLMs), can mitigate this by offering rich, context-aware knowledge, yet their high inference latency hinders deployment in high-frequency RL training loops. To bridge this gap, we present Found-RL, a platform tailored to efficiently enhance RL for AD using foundation models. A core innovation is the asynchronous batch inference framework, which decouples heavy VLM reasoning from the simulation loop, effectively resolving latency bottlenecks to support real-time learning. We introduce diverse supervision mechanisms: Value-Margin Regularization (VMR) and Advantage-Weighted Action Guidance (AWAG) to effectively distill expert-like VLM action suggestions into the RL policy. Additionally, we adopt high-throughput CLIP for dense reward shaping. We address CLIP's dynamic blindness via Conditional Contrastive Action Alignment, which conditions prompts on discretized speed/command and yields a normalized, margin-based bonus from context-specific action-anchor scoring. Found-RL provides an end-to-end pipeline for fine-tuned VLM integration and shows that a lightweight RL model can achieve near-VLM performance compared with billion-parameter VLMs while sustaining real-time inference (approx. 500 FPS). Code, data, and models will be publicly available at https://github.com/ys-qu/found-rl.

</details>

<details><summary><b>中文摘要</b></summary>

强化学习（RL）已成为端到端自动驾驶（AD）的主导范例。然而，强化学习面临着样本效率低下以及复杂场景下缺乏语义可解释性的问题。基础模型，特别是视觉语言模型 (VLM)，可以通过提供丰富的上下文感知知识来缓解这一问题，但其高推理延迟阻碍了高频 RL 训练循环中的部署。为了弥补这一差距，我们推出了 Found-RL，这是一个专门为使用基础模型有效增强 AD 强化学习而定制的平台。核心创新是异步批量推理框架，将繁重的VLM推理与仿真循环解耦，有效解决延迟瓶颈，支持实时学习。 We introduce diverse supervision mechanisms: Value-Margin Regularization (VMR) and Advantage-Weighted Action Guidance (AWAG) to effectively distill expert-like VLM action suggestions into the RL policy.此外，我们采用高通量 CLIP 进行密集奖励塑造。 We address CLIP's dynamic blindness via Conditional Contrastive Action Alignment, which conditions prompts on discretized speed/command and yields a normalized, margin-based bonus from context-specific action-anchor scoring. Found-RL provides an end-to-end pipeline for fine-tuned VLM integration and shows that a lightweight RL model can achieve near-VLM performance compared with billion-parameter VLMs while sustaining real-time inference (approx. 500 FPS).代码、数据和模型将在 https://github.com/ys-qu/found-rl 上公开提供。

</details>

---

## 58. Constructing Industrial-Scale Optimization Modeling Benchmark

**中文标题**: 构建工业规模优化建模基准

**Date**: 2026-02-11 | **arXiv**: [2602.10450v1](http://arxiv.org/abs/2602.10450v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10450v1)

<details><summary><b>Abstract</b></summary>

Optimization modeling underpins decision-making in logistics, manufacturing, energy, and finance, yet translating natural-language requirements into correct optimization formulations and solver-executable code remains labor-intensive. Although large language models (LLMs) have been explored for this task, evaluation is still dominated by toy-sized or synthetic benchmarks, masking the difficulty of industrial problems with $10^{3}$--$10^{6}$ (or more) variables and constraints. A key bottleneck is the lack of benchmarks that align natural-language specifications with reference formulations/solver code grounded in real optimization models. To fill in this gap, we introduce MIPLIB-NL, built via a structure-aware reverse construction methodology from real mixed-integer linear programs in MIPLIB~2017. Our pipeline (i) recovers compact, reusable model structure from flat solver formulations, (ii) reverse-generates natural-language specifications explicitly tied to this recovered structure under a unified model--data separation format, and (iii) performs iterative semantic validation through expert review and human--LLM interaction with independent reconstruction checks. This yields 223 one-to-one reconstructions that preserve the mathematical content of the original instances while enabling realistic natural-language-to-optimization evaluation. Experiments show substantial performance degradation on MIPLIB-NL for systems that perform strongly on existing benchmarks, exposing failure modes invisible at toy scale.

</details>

<details><summary><b>中文摘要</b></summary>

优化建模支撑着物流、制造、能源和金融领域的决策，但将自然语言需求转化为正确的优化公式和求解器可执行代码仍然是劳动密集型的。尽管大型语言模型 (LLM) 已针对此任务进行了探索，但评估仍然以玩具大小或综合基准为主，掩盖了具有 10^{3}$--$10^{6}$（或更多）变量和约束的工业问题的难度。一个关键瓶颈是缺乏将自然语言规范与基于实际优化模型的参考公式/求解器代码保持一致的基准。为了填补这一空白，我们引入了 MIPLIB-NL，它是通过 MIPLIB~2017 中真实混合整数线性程序的结构感知逆向构造方法构建的。我们的流程（i）从平面求解器公式中恢复紧凑、可重用的模型结构，（ii）在统一模型数据分离格式下反向生成与该恢复结构明确相关的自然语言规范，以及（iii）通过专家评审和人与法学硕士交互以及独立重建检查来执行迭代语义验证。这会产生 223 个一对一的重建，保留原始实例的数学内容，同时实现现实的自然语言优化评估。实验表明，对于在现有基准测试中表现出色的系统，MIPLIB-NL 的性能会大幅下降，从而暴露出玩具规模上不可见的故障模式。

</details>

---

## 59. A Unified Theory of Random Projection for Influence Functions

**中文标题**: 影响函数随机投影的统一理论

**Date**: 2026-02-11 | **arXiv**: [2602.10449v1](http://arxiv.org/abs/2602.10449v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10449v1)

<details><summary><b>Abstract</b></summary>

Influence functions and related data attribution scores take the form of $g^{\top}F^{-1}g^{\prime}$, where $F\succeq 0$ is a curvature operator. In modern overparameterized models, forming or inverting $F\in\mathbb{R}^{d\times d}$ is prohibitive, motivating scalable influence computation via random projection with a sketch $P \in \mathbb{R}^{m\times d}$. This practice is commonly justified via the Johnson--Lindenstrauss (JL) lemma, which ensures approximate preservation of Euclidean geometry for a fixed dataset. However, JL does not address how sketching behaves under inversion. Furthermore, there is no existing theory that explains how sketching interacts with other widely-used techniques, such as ridge regularization and structured curvature approximations.   We develop a unified theory characterizing when projection provably preserves influence functions. When $g,g^{\prime}\in\text{range}(F)$, we show that: 1) Unregularized projection: exact preservation holds iff $P$ is injective on $\text{range}(F)$, which necessitates $m\geq \text{rank}(F)$; 2) Regularized projection: ridge regularization fundamentally alters the sketching barrier, with approximation guarantees governed by the effective dimension of $F$ at the regularization scale; 3) Factorized influence: for Kronecker-factored curvatures $F=A\otimes E$, the guarantees continue to hold for decoupled sketches $P=P_A\otimes P_E$, even though such sketches exhibit row correlations that violate i.i.d. assumptions. Beyond this range-restricted setting, we analyze out-of-range test gradients and quantify a \emph{leakage} term that arises when test gradients have components in $\ker(F)$. This yields guarantees for influence queries on general test points.   Overall, this work develops a novel theory that characterizes when projection provably preserves influence and provides principled guidance for choosing the sketch size in practice.

</details>

<details><summary><b>中文摘要</b></summary>

影响函数和相关数据归因分数采用 $g^{\top}F^{-1}g^{\prime}$ 的形式，其中 $F\succeq 0$ 是曲率算子。在现代超参数化模型中，形成或反转 $F\in\mathbb{R}^{d\times d}$ 是禁止的，通过使用草图 $P \in \mathbb{R}^{m\times d}$ 进行随机投影来激发可扩展的影响计算。这种做法通常通过 Johnson-Lindenstrauss (JL) 引理来证明，该引理确保固定数据集的欧几里得几何的近似保留。然而，JL 没有解决草图在反转下的行为方式。此外，没有现有的理论可以解释草图绘制如何与其他广泛使用的技术（例如脊正则化和结构化曲率近似）相互作用。   我们开发了一个统一的理论来描述投影何时可证明保留影响函数。当 $g,g^{\prime}\in\text{range}(F)$ 时，我们证明： 1) 非正则化投影：精确保留成立，当且仅当 $P$ 在 $\text{range}(F)$ 上单射，这需要 $m\geq \text{rank}(F)$； 2) 正则化投影：岭正则化从根本上改变了草图障碍，并由正则化尺度下 $F$ 的有效维度控制近似保证； 3) 因子影响：对于克罗内克因子曲率 $F=A\otimes E$，解耦草图 $P=P_A\otimes P_E$ 的保证继续成立，即使此类草图表现出违反独立同分布的行相关性。假设。除了这个范围限制设置之外，我们分析超出范围的测试梯度并量化当测试梯度在 $\ker(F)$ 中包含组件时出现的 \emph{leakage} 项。这为一般测试点的影响查询提供了保证。   总体而言，这项工作开发了一种新颖的理论，该理论描述了投影何时可证明保留影响力，并为实践中选择草图尺寸提供了原则性指导。

</details>

---

## 60. A Dual-Stream Physics-Augmented Unsupervised Architecture for Runtime Embedded Vehicle Health Monitoring

**中文标题**: 用于运行时嵌入式车辆健康监测的双流物理增强无监督架构

**Date**: 2026-02-11 | **arXiv**: [2602.10432v1](http://arxiv.org/abs/2602.10432v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10432v1)

<details><summary><b>Abstract</b></summary>

Runtime quantification of vehicle operational intensity is essential for predictive maintenance and condition monitoring in commercial and heavy-duty fleets. Traditional metrics like mileage fail to capture mechanical burden, while unsupervised deep learning models detect statistical anomalies, typically transient surface shocks, but often conflate statistical stability with mechanical rest. We identify this as a critical blind spot: high-load steady states, such as hill climbing with heavy payloads, appear statistically normal yet impose significant drivetrain fatigue. To resolve this, we propose a Dual-Stream Architecture that fuses unsupervised learning for surface anomaly detection with macroscopic physics proxies for cumulative load estimation. This approach leverages low-frequency sensor data to generate a multi-dimensional health vector, distinguishing between dynamic hazards and sustained mechanical effort. Validated on a RISC-V embedded platform, the architecture demonstrates low computational overhead, enabling comprehensive, edge-based health monitoring on resource-constrained ECUs without the latency or bandwidth costs of cloud-based monitoring.

</details>

<details><summary><b>中文摘要</b></summary>

车辆运行强度的运行时量化对于商业和重型车队的预测性维护和状态监测至关重要。里程等传统指标无法捕捉机械负荷，而无监督深度学习模型可以检测统计异常，通常是瞬态表面冲击，但常常将统计稳定性与机械休息混为一谈。我们认为这是一个关键的盲点：高负载稳态，例如负载较重的爬山，在统计上看起来是正常的，但会造成严重的传动系统疲劳。为了解决这个问题，我们提出了一种双流架构，它将用于表面异常检测的无监督学习与用于累积负载估计的宏观物理代理相融合。这种方法利用低频传感器数据生成多维健康向量，区分动态危险和持续的机械作用。该架构在 RISC-V 嵌入式平台上进行了验证，显示出较低的计算开销，能够对资源受限的 ECU 进行全面的、基于边缘的运行状况监控，而不会产生基于云的监控的延迟或带宽成本。

</details>

---

## 61. Multi-Task Reinforcement Learning of Drone Aerobatics by Exploiting Geometric Symmetries

**中文标题**: 利用几何对称性进行无人机特技飞行的多任务强化学习

**Date**: 2026-02-11 | **arXiv**: [2602.10997v1](http://arxiv.org/abs/2602.10997v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10997v1)

<details><summary><b>Abstract</b></summary>

Flight control for autonomous micro aerial vehicles (MAVs) is evolving from steady flight near equilibrium points toward more aggressive aerobatic maneuvers, such as flips, rolls, and Power Loop. Although reinforcement learning (RL) has shown great potential in these tasks, conventional RL methods often suffer from low data efficiency and limited generalization. This challenge becomes more pronounced in multi-task scenarios where a single policy is required to master multiple maneuvers. In this paper, we propose a novel end-to-end multi-task reinforcement learning framework, called GEAR (Geometric Equivariant Aerobatics Reinforcement), which fully exploits the inherent SO(2) rotational symmetry in MAV dynamics and explicitly incorporates this property into the policy network architecture. By integrating an equivariant actor network, FiLM-based task modulation, and a multi-head critic, GEAR achieves both efficiency and flexibility in learning diverse aerobatic maneuvers, enabling a data-efficient, robust, and unified framework for aerobatic control. GEAR attains a 98.85\% success rate across various aerobatic tasks, significantly outperforming baseline methods. In real-world experiments, GEAR demonstrates stable execution of multiple maneuvers and the capability to combine basic motion primitives to complete complex aerobatics.

</details>

<details><summary><b>中文摘要</b></summary>

自主微型飞行器 (MAV) 的飞行控制正在从平衡点附近的稳定飞行发展到更激进的特技飞行，例如翻转、滚转和动力循环。尽管强化学习 (RL) 在这些任务中显示出巨大的潜力，但传统的 RL 方法往往存在数据效率低和泛化能力有限的问题。在需要单一策略来掌握多种操作的多任务场景中，这一挑战变得更加明显。在本文中，我们提出了一种新颖的端到端多任务强化学习框架，称为 GEAR（几何等变特技飞行强化），它充分利用了 MAV 动力学中固有的 SO(2) 旋转对称性，并明确地将这一属性合并到策略网络架构中。通过集成等变参与者网络、基于 FiLM 的任务调制和多头批评器，GEAR 在学习各种特技飞行方面实现了效率和灵活性，从而为特技飞行控制提供了数据高效、稳健且统一的框架。 GEAR 在各种特技飞行任务中取得了 98.85% 的成功率，显着优于基线方法。在现实世界的实验中，GEAR 展示了多种机动的稳定执行以及结合基本运动原语来完成复杂特技飞行的能力。

</details>

---

## 62. Scaling World Model for Hierarchical Manipulation Policies

**中文标题**: 分级操纵策略的扩展世界模型

**Date**: 2026-02-11 | **arXiv**: [2602.10983v1](http://arxiv.org/abs/2602.10983v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10983v1)

<details><summary><b>Abstract</b></summary>

Vision-Language-Action (VLA) models are promising for generalist robot manipulation but remain brittle in out-of-distribution (OOD) settings, especially with limited real-robot data. To resolve the generalization bottleneck, we introduce a hierarchical Vision-Language-Action framework \our{} that leverages the generalization of large-scale pre-trained world model for robust and generalizable VIsual Subgoal TAsk decomposition VISTA. Our hierarchical framework \our{} consists of a world model as the high-level planner and a VLA as the low-level executor. The high-level world model first divides manipulation tasks into subtask sequences with goal images, and the low-level policy follows the textual and visual guidance to generate action sequences. Compared to raw textual goal specification, these synthesized goal images provide visually and physically grounded details for low-level policies, making it feasible to generalize across unseen objects and novel scenarios. We validate both visual goal synthesis and our hierarchical VLA policies in massive out-of-distribution scenarios, and the performance of the same-structured VLA in novel scenarios could boost from 14% to 69% with the guidance generated by the world model. Results demonstrate that our method outperforms previous baselines with a clear margin, particularly in out-of-distribution scenarios. Project page: \href{https://vista-wm.github.io/}{https://vista-wm.github.io}

</details>

<details><summary><b>中文摘要</b></summary>

视觉-语言-动作（VLA）模型对于通用机器人操作很有希望，但在分布外（OOD）设置中仍然很脆弱，尤其是在真实机器人数据有限的情况下。为了解决泛化瓶颈，我们引入了分层视觉-语言-动作框架 \our{}，该框架利用大规模预训练世界模型的泛化来实现稳健且可泛化的视觉子目标任务分解 VISTA。我们的分层框架 \our{} 由作为高级规划器的世界模型和作为低级执行器的 VLA 组成。高层世界模型首先将操作任务划分为具有目标图像的子任务序列，低层策略遵循文本和视觉指导来生成动作序列。与原始文本目标规范相比，这些合成的目标图像为低级策略提供了视觉和物理基础的细节，使得在未见过的物体和新场景中进行泛化成为可能。我们在大规模分布外场景中验证了视觉目标合成和分层 VLA 策略，并且在世界模型生成的指导下，相同结构的 VLA 在新颖场景中的性能可以从 14% 提高到 69%。结果表明，我们的方法明显优于以前的基线，特别是在分布外的情况下。项目页面：\href{https://vista-wm.github.io/}{https://vista-wm.github.io}

</details>

---

## 63. RADAR: Benchmarking Vision-Language-Action Generalization via Real-World Dynamics, Spatial-Physical Intelligence, and Autonomous Evaluation

**中文标题**: RADAR：通过现实世界动力学、空间物理智能和自主评估对视觉-语言-动作泛化进行基准测试

**Date**: 2026-02-11 | **arXiv**: [2602.10980v1](http://arxiv.org/abs/2602.10980v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10980v1)

<details><summary><b>Abstract</b></summary>

VLA models have achieved remarkable progress in embodied intelligence; however, their evaluation remains largely confined to simulations or highly constrained real-world settings. This mismatch creates a substantial reality gap, where strong benchmark performance often masks poor generalization in diverse physical environments. We identify three systemic shortcomings in current benchmarking practices that hinder fair and reliable model comparison. (1) Existing benchmarks fail to model real-world dynamics, overlooking critical factors such as dynamic object configurations, robot initial states, lighting changes, and sensor noise. (2) Current protocols neglect spatial--physical intelligence, reducing evaluation to rote manipulation tasks that do not probe geometric reasoning. (3) The field lacks scalable fully autonomous evaluation, instead relying on simplistic 2D metrics that miss 3D spatial structure or on human-in-the-loop systems that are costly, biased, and unscalable. To address these limitations, we introduce RADAR (Real-world Autonomous Dynamics And Reasoning), a benchmark designed to systematically evaluate VLA generalization under realistic conditions. RADAR integrates three core components: (1) a principled suite of physical dynamics; (2) dedicated tasks that explicitly test spatial reasoning and physical understanding; and (3) a fully autonomous evaluation pipeline based on 3D metrics, eliminating the need for human supervision. We apply RADAR to audit multiple state-of-the-art VLA models and uncover severe fragility beneath their apparent competence. Performance drops precipitously under modest physical dynamics, with the expectation of 3D IoU declining from 0.261 to 0.068 under sensor noise. Moreover, models exhibit limited spatial reasoning capability. These findings position RADAR as a necessary bench toward reliable and generalizable real-world evaluation of VLA models.

</details>

<details><summary><b>中文摘要</b></summary>

VLA模型在具身智能方面取得了显着的进步；然而，他们的评估仍然主要局限于模拟或高度受限的现实环境。这种不匹配造成了巨大的现实差距，强大的基准性能往往掩盖了不同物理环境中较差的泛化能力。我们发现当前基准测试实践中的三个系统性缺陷阻碍了公平和可靠的模型比较。 (1) 现有基准无法对现实世界的动态进行建模，忽略了动态对象配置、机器人初始状态、照明变化和传感器噪声等关键因素。 （2）当前协议忽视了空间物理智能，减少了对不探究几何推理的死记硬背操作任务的评估。 (3) 该领域缺乏可扩展的完全自主评估，而是依赖于忽略 3D 空间结构的简单 2D 指标，或者依赖于成本高昂、存在偏见且不可扩展的人机交互系统。为了解决这些限制，我们引入了 RADAR（真实世界自主动力学和推理），这是一个旨在系统地评估现实条件下 VLA 泛化能力的基准。 RADAR 集成了三个核心组件：(1) 一套原则性的物理动力学； (2) 明确测试空间推理和物理理解的专门任务； (3) 基于 3D 指标的完全自主的评估流程，无需人工监督。我们应用 RADAR 来审核多个最先进的 VLA 模型，并发现其表面能力之下的严重脆弱性。在适度的物理动力学条件下，性能急剧下降，在传感器噪声下，3D IoU 的预期从 0.261 下降到 0.068。此外，模型表现出有限的空间推理能力。这些发现使 RADAR 成为对 VLA 模型进行可靠且可推广的现实世界评估的必要基础。

</details>

---

## 64. Lie Group Variational Integrator for the Geometrically Exact Rod with Circular Cross-Section Incorporating Cross-Sectional Deformation

**中文标题**: 结合截面变形的圆形截面几何精确杆的李群变分积分器

**Date**: 2026-02-11 | **arXiv**: [2602.10963v1](http://arxiv.org/abs/2602.10963v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10963v1)

<details><summary><b>Abstract</b></summary>

In this paper, we derive the continuous space-time equations of motion of a three-dimensional geometrically exact rod, or the Cosserat rod, incorporating planar cross-sectional deformation. We then adopt the Lie group variational integrator technique to obtain a discrete model of the rod incorporating both rotational motion and cross-sectional deformation as well. The resulting discrete model possesses several desirable features: it ensures volume conservation of the discrete elements by considering cross-sectional deformation through a local dilatation factor, it demonstrates the beneficial properties associated with the variational integrator technique, such as the preservation of the rotational configuration, and energy conservation with a bounded error. An exhaustive set of numerical results under various initial conditions of the rod demonstrates the efficacy of the model in replicating the physics of the system.

</details>

<details><summary><b>中文摘要</b></summary>

在本文中，我们推导了三维几何精确杆（或 Cosserat 杆）的连续时空运动方程，其中包含平面横截面变形。然后，我们采用李群变分积分器技术来获得同时包含旋转运动和横截面变形的杆的离散模型。由此产生的离散模型具有几个理想的特征：它通过局部膨胀因子考虑横截面变形来确保离散单元的体积守恒，它展示了与变分积分器技术相关的有益特性，例如旋转配置的保存和有界误差的能量守恒。在杆的各种初始条件下的一组详尽的数值结果证明了该模型在复制系统物理特性方面的有效性。

</details>

---

## 65. Developing Neural Network-Based Gaze Control Systems for Social Robots

**中文标题**: 为社交机器人开发基于神经网络的注视控制系统

**Date**: 2026-02-11 | **arXiv**: [2602.10946v1](http://arxiv.org/abs/2602.10946v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10946v1)

<details><summary><b>Abstract</b></summary>

During multi-party interactions, gaze direction is a key indicator of interest and intent, making it essential for social robots to direct their attention appropriately. Understanding the social context is crucial for robots to engage effectively, predict human intentions, and navigate interactions smoothly. This study aims to develop an empirical motion-time pattern for human gaze behavior in various social situations (e.g., entering, leaving, waving, talking, and pointing) using deep neural networks based on participants' data. We created two video clips-one for a computer screen and another for a virtual reality headset-depicting different social scenarios. Data were collected from 30 participants: 15 using an eye-tracker and 15 using an Oculus Quest 1 headset. Deep learning models, specifically Long Short-Term Memory (LSTM) and Transformers, were used to analyze and predict gaze patterns. Our models achieved 60% accuracy in predicting gaze direction in a 2D animation and 65% accuracy in a 3D animation. Then, the best model was implemented onto the Nao robot; and 36 new participants evaluated its performance. The feedback indicated overall satisfaction, with those experienced in robotics rating the models more favorably.

</details>

<details><summary><b>中文摘要</b></summary>

在多方互动过程中，注视方向是兴趣和意图的关键指标，因此社交机器人必须适当地引导他们的注意力。了解社会背景对于机器人有效参与、预测人类意图和顺利进行交互至关重要。本研究旨在使用基于参与者数据的深度神经网络，开发各种社交情境（例如进入、离开、挥手、说话和指向）中人类注视行为的经验运动时间模式。我们创建了两个视频剪辑（一个用于计算机屏幕，另一个用于虚拟现实耳机），描绘了不同的社交场景。数据收集自 30 名参与者：15 名使用眼动仪，15 名使用 Oculus Quest 1 耳机。深度学习模型，特别是长短期记忆 (LSTM) 和 Transformer，用于分析和预测注视模式。我们的模型在 2D 动画中预测注视方向的准确率达到 60%，在 3D 动画中预测注视方向的准确率达到 65%。然后，将最佳模型应用到Nao机器人上； 36 位新参与者评估了其表现。反馈表明总体满意度，机器人领域经验丰富的人对模型的评价更高。

</details>

---

## 66. Design, Development, and Use of Maya Robot as an Assistant for the Therapy/Education of Children with Cancer: a Pilot Study

**中文标题**: 玛雅机器人的设计、开发和使用作为癌症儿童治疗/教育的助手：一项试点研究

**Date**: 2026-02-11 | **arXiv**: [2602.10942v1](http://arxiv.org/abs/2602.10942v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10942v1)

<details><summary><b>Abstract</b></summary>

This study centers around the design and implementation of the Maya Robot, a portable elephant-shaped social robot, intended to engage with children undergoing cancer treatment. Initial efforts were devoted to enhancing the robot's facial expression recognition accuracy, achieving a 98% accuracy through deep neural networks. Two subsequent preliminary exploratory experiments were designed to advance the study's objectives. The first experiment aimed to compare pain levels experienced by children during the injection process, with and without the presence of the Maya robot. Twenty-five children, aged 4 to 9, undergoing cancer treatment participated in this counterbalanced study. The paired T-test results revealed a significant reduction in perceived pain when the robot was actively present in the injection room. The second experiment sought to assess perspectives of hospitalized children and their mothers during engagement with Maya through a game. Forty participants, including 20 children aged 4 to 9 and their mothers, were involved. Post Human-Maya Interactions, UTAUT questionnaire results indicated that children experienced significantly less anxiety than their parents during the interaction and game play. Notably, children exhibited higher trust levels in both the robot and the games, presenting a statistically significant difference in trust levels compared to their parents (P-value < 0.05). This preliminary exploratory study highlights the positive impact of utilizing Maya as an assistant for therapy/education in a clinical setting, particularly benefiting children undergoing cancer treatment. The findings underscore the potential of social robots in pediatric healthcare contexts, emphasizing improved pain management and emotional well-being among young patients.

</details>

<details><summary><b>中文摘要</b></summary>

这项研究的重点是玛雅机器人的设计和实现，玛雅机器人是一种便携式象形社交机器人，旨在帮助接受癌症治疗的儿童。最初的努力致力于提高机器人的面部表情识别准确率，通过深度神经网络实现了 98% 的准确率。随后设计了两项初步探索性实验来推进研究目标。第一个实验旨在比较儿童在注射过程中所经历的疼痛程度，无论是否有玛雅机器人在场。 25 名 4 至 9 岁正在接受癌症治疗的儿童参与了这项平衡研究。配对 T 测试结果显示，当机器人主动出现在注射室时，感知到的疼痛显着减少。第二个实验试图评估住院儿童及其母亲在通过游戏与玛雅互动时的看法。共有 40 名参与者参与其中，其中包括 20 名 4 至 9 岁的儿童及其母亲。人类与玛雅人互动后，UTAUT 问卷结果表明，孩子们在互动和游戏过程中所经历的焦虑明显低于父母。值得注意的是，孩子们对机器人和游戏都表现出较高的信任水平，与父母相比，信任水平存在统计上的显着差异（P 值 < 0.05）。这项初步探索性研究强调了利用 Maya 作为临床环境中治疗/教育助手的积极影响，特别是有利于接受癌症治疗的儿童。研究结果强调了社交机器人在儿科医疗保健环境中的潜力，强调改善年轻患者的疼痛管理和情绪健康。

</details>

---

## 67. Safe mobility support system using crowd mapping and avoidance route planning using VLM

**中文标题**: 使用人群测绘的安全移动支持系统和使用 VLM 的避让路线规划

**Date**: 2026-02-11 | **arXiv**: [2602.10910v1](http://arxiv.org/abs/2602.10910v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10910v1)

<details><summary><b>Abstract</b></summary>

Autonomous mobile robots offer promising solutions for labor shortages and increased operational efficiency. However, navigating safely and effectively in dynamic environments, particularly crowded areas, remains challenging. This paper proposes a novel framework that integrates Vision-Language Models (VLM) and Gaussian Process Regression (GPR) to generate dynamic crowd-density maps (``Abstraction Maps'') for autonomous robot navigation. Our approach utilizes VLM's capability to recognize abstract environmental concepts, such as crowd densities, and represents them probabilistically via GPR. Experimental results from real-world trials on a university campus demonstrated that robots successfully generated routes avoiding both static obstacles and dynamic crowds, enhancing navigation safety and adaptability.

</details>

<details><summary><b>中文摘要</b></summary>

自主移动机器人为劳动力短缺和提高运营效率提供了有前景的解决方案。然而，在动态环境（尤其是拥挤的区域）中安全有效地导航仍然具有挑战性。本文提出了一种新颖的框架，该框架集成了视觉语言模型（VLM）和高斯过程回归（GPR）来生成用于自主机器人导航的动态人群密度图（“抽象图”）。我们的方法利用 VLM 的能力来识别抽象的环境概念，例如人群密度，并通过探地雷达以概率方式表示它们。在大学校园进行的实际试验结果表明，机器人成功生成了避开静态障碍物和动态人群的路线，增强了导航安全性和适应性。

</details>

---

## 68. Biomimetic Mantaray robot toward the underwater autonomous -- Experimental verification of swimming and diving by flapping motion -

**中文标题**: 仿生Mantaray机器人走向水下自主——扑动游泳和潜水的实验验证——

**Date**: 2026-02-11 | **arXiv**: [2602.10904v1](http://arxiv.org/abs/2602.10904v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10904v1)

<details><summary><b>Abstract</b></summary>

This study presents the development and experimental verification of a biomimetic manta ray robot for underwater autonomous exploration. Inspired by manta rays, the robot uses flapping motion for propulsion to minimize seabed disturbance and enhance efficiency compared to traditional screw propulsion. The robot features pectoral fins driven by servo motors and a streamlined control box to reduce fluid resistance. The control system, powered by a Raspberry Pi 3B, includes an IMU and pressure sensor for real-time monitoring and control. Experiments in a pool assessed the robot's swimming and diving capabilities. Results show stable swimming and diving motions with PD control. The robot is suitable for applications in environments like aquariums and fish nurseries, requiring minimal disturbance and efficient maneuverability. Our findings demonstrate the potential of bio-inspired robotic designs to improve ecological monitoring and underwater exploration.

</details>

<details><summary><b>中文摘要</b></summary>

本研究介绍了用于水下自主探索的仿生蝠鲼机器人的开发和实验验证。受蝠鲼的启发，该机器人使用扑动运动进行推进，与传统的螺旋推进相比，最大限度地减少海底扰动并提高效率。该机器人具有由伺服电机驱动的胸鳍和流线型控制箱，以减少流体阻力。该控制系统由 Raspberry Pi 3B 供电，包括 IMU 和压力传感器，用于实时监控。在泳池中进行的实验评估了机器人的游泳和潜水能力。结果显示，通过 PD 控制可以实现稳定的游泳和潜水动作。该机器人适用于水族馆和养鱼场等环境中的应用，需要最小的干扰和高效的机动性。我们的研究结果证明了仿生机器人设计在改善生态监测和水下探索方面的潜力。

</details>

---

## 69. Semi-Supervised Cross-Domain Imitation Learning

**中文标题**: 半监督跨领域模仿学习

**Date**: 2026-02-11 | **arXiv**: [2602.10793v1](http://arxiv.org/abs/2602.10793v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10793v1)

**Code**: https://github.com/NYCU-RL-Bandits-Lab/CDIL.

<details><summary><b>Abstract</b></summary>

Cross-domain imitation learning (CDIL) accelerates policy learning by transferring expert knowledge across domains, which is valuable in applications where the collection of expert data is costly. Existing methods are either supervised, relying on proxy tasks and explicit alignment, or unsupervised, aligning distributions without paired data, but often unstable. We introduce the Semi-Supervised CDIL (SS-CDIL) setting and propose the first algorithm for SS-CDIL with theoretical justification. Our method uses only offline data, including a small number of target expert demonstrations and some unlabeled imperfect trajectories. To handle domain discrepancy, we propose a novel cross-domain loss function for learning inter-domain state-action mappings and design an adaptive weight function to balance the source and target knowledge. Experiments on MuJoCo and Robosuite show consistent gains over the baselines, demonstrating that our approach achieves stable and data-efficient policy learning with minimal supervision. Our code is available at~ https://github.com/NYCU-RL-Bandits-Lab/CDIL.

</details>

<details><summary><b>中文摘要</b></summary>

跨领域模仿学习（CDIL）通过跨领域转移专家知识来加速政策学习，这在收集专家数据成本高昂的应用程序中非常有价值。现有的方法要么是有监督的，依赖于代理任务和显式对齐，要么是无监督的，在没有配对数据的情况下对齐分布，但通常不稳定。我们引入了半监督 CDIL (SS-CDIL) 设置，并提出了第一个具有理论依据的 SS-CDIL 算法。我们的方法仅使用离线数据，包括少量目标专家演示和一些未标记的不完美轨迹。为了处理域差异，我们提出了一种新颖的跨域损失函数来学习域间状态动作映射，并设计了一个自适应权重函数来平衡源知识和目标知识。 MuJoCo 和 Robosuite 上的实验显示出相对于基线的一致增益，这表明我们的方法可以在最少的监督下实现稳定且数据高效的政策学习。我们的代码可在〜https://github.com/NYCU-RL-Bandits-Lab/CDIL 获取。

</details>

---

## 70. Say, Dream, and Act: Learning Video World Models for Instruction-Driven Robot Manipulation

**中文标题**: 说、梦想和行动：学习指令驱动机器人操作的视频世界模型

**Date**: 2026-02-11 | **arXiv**: [2602.10717v1](http://arxiv.org/abs/2602.10717v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10717v1)

<details><summary><b>Abstract</b></summary>

Robotic manipulation requires anticipating how the environment evolves in response to actions, yet most existing systems lack this predictive capability, often resulting in errors and inefficiency. While Vision-Language Models (VLMs) provide high-level guidance, they cannot explicitly forecast future states, and existing world models either predict only short horizons or produce spatially inconsistent frames. To address these challenges, we propose a framework for fast and predictive video-conditioned action. Our approach first selects and adapts a robust video generation model to ensure reliable future predictions, then applies adversarial distillation for fast, few-step video generation, and finally trains an action model that leverages both generated videos and real observations to correct spatial errors. Extensive experiments show that our method produces temporally coherent, spatially accurate video predictions that directly support precise manipulation, achieving significant improvements in embodiment consistency, spatial referring ability, and task completion over existing baselines. Codes & Models will be released.

</details>

<details><summary><b>中文摘要</b></summary>

机器人操纵需要预测环境如何响应行动而演变，但大多数现有系统缺乏这种预测能力，常常导致错误和低效率。虽然视觉语言模型（VLM）提供高级指导，但它们无法明确预测未来状态，并且现有的世界模型要么仅预测短期情况，要么产生空间不一致的框架。为了应对这些挑战，我们提出了一个快速、预测性视频条件动作框架。我们的方法首先选择并调整一个强大的视频生成模型，以确保可靠的未来预测，然后应用对抗性蒸馏来快速、几步视频生成，最后训练一个动作模型，利用生成的视频和真实观察来纠正空间错误。大量的实验表明，我们的方法产生时间上一致、空间上准确的视频预测，直接支持精确操作，在现有基线的基础上实现了实施例一致性、空间参考能力和任务完成度的显着改进。代码和型号将被发布。

</details>

---

## 71. Omnidirectional Dual-Arm Aerial Manipulator with Proprioceptive Contact Localization for Landing on Slanted Roofs

**中文标题**: 具有本体感觉接触定位功能的全向双臂空中机械手，用于在倾斜屋顶上着陆

**Date**: 2026-02-11 | **arXiv**: [2602.10703v1](http://arxiv.org/abs/2602.10703v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10703v1)

<details><summary><b>Abstract</b></summary>

Operating drones in urban environments often means they need to land on rooftops, which can have different geometries and surface irregularities. Accurately detecting roof inclination using conventional sensing methods, such as vision-based or acoustic techniques, can be unreliable, as measurement quality is strongly influenced by external factors including weather conditions and surface materials. To overcome these challenges, we propose a novel unmanned aerial manipulator morphology featuring a dual-arm aerial manipulator with an omnidirectional 3D workspace and extended reach. Building on this design, we develop a proprioceptive contact detection and contact localization strategy based on a momentum-based torque observer. This enables the UAM to infer the inclination of slanted surfaces blindly - through physical interaction - prior to touchdown. We validate the approach in flight experiments, demonstrating robust landings on surfaces with inclinations of up to 30.5 degrees and achieving an average surface inclination estimation error of 2.87 degrees over 9 experiments at different incline angles.

</details>

<details><summary><b>中文摘要</b></summary>

在城市环境中操作无人机通常意味着它们需要降落在屋顶上，屋顶可能具有不同的几何形状和表面不规则性。使用基于视觉或声学技术等传统传感方法准确检测屋顶倾斜度可能不可靠，因为测量质量受到天气条件和表面材料等外部因素的强烈影响。为了克服这些挑战，我们提出了一种新颖的无人机形态，其特点是具有全向 3D 工作空间和扩展范围的双臂空中操纵器。在此设计的基础上，我们开发了一种基于动量扭矩观测器的本体感受接触检测和接触定位策略。这使得 UAM 能够在着陆之前通过物理交互盲目地推断倾斜表面的倾斜度。我们在飞行实验中验证了该方法，展示了在倾斜度高达 30.5 度的表面上的稳健着陆，并在不同倾斜角度的 9 次实验中实现了 2.87 度的平均表面倾斜度估计误差。

</details>

---

## 72. 3D-Printed Anisotropic Soft Magnetic Coating for Directional Rolling of a Magnetically Actuated Capsule Robot

**中文标题**: 用于磁驱动胶囊机器人定向滚动的 3D 打印各向异性软磁涂层

**Date**: 2026-02-11 | **arXiv**: [2602.10688v1](http://arxiv.org/abs/2602.10688v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10688v1)

<details><summary><b>Abstract</b></summary>

Capsule robots are promising tools for minimally invasive diagnostics and therapy, with applications from gastrointestinal endoscopy to targeted drug delivery and biopsy sampling. Conventional magnetic capsule robots embed bulky permanent magnets at both ends, reducing the usable cavity by about 10-20 mm and limiting integration of functional modules. We propose a compact, 3D-printed soft capsule robot with a magnetic coating that replaces internal magnets, enabling locomotion via a thin, functional shell while preserving the entire interior cavity as a continuous volume for medical payloads. The compliant silicone-magnetic composite also improves swallowability, even with a slightly larger capsule size. Magnetostatic simulations and experiments confirm that programmed NSSN/SNNS pole distributions provide strong anisotropy and reliable torque generation, enabling stable bidirectional rolling, omnidirectional steering, climbing on 7.5 degree inclines, and traversal of 5 mm protrusions. Rolling motion is sustained when the magnetic field at the capsule reaches at least 0.3 mT, corresponding to an effective actuation depth of 30 mm in our setup. Future work will optimize material composition, coating thickness, and magnetic layouts to enhance force output and durability, while next-generation robotic-arm-based field generators with closed-loop feedback will address nonlinearities and expand maneuverability. Together, these advances aim to transition coating-based capsule robots toward reliable clinical deployment and broaden their applications in minimally invasive diagnostics and therapy.

</details>

<details><summary><b>中文摘要</b></summary>

胶囊机器人是微创诊断和治疗的有前途的工具，其应用范围从胃肠内窥镜检查到靶向药物输送和活检取样。传统的磁力胶囊机器人在两端嵌入了笨重的永磁体，使可用腔减少了约10-20毫米，并限制了功能模块的集成。我们提出了一种紧凑的 3D 打印软胶囊机器人，其磁性涂层取代了内部磁铁，能够通过薄而功能性的外壳进行运动，同时保留整个内部空腔作为医疗有效负载的连续空间。即使胶囊尺寸稍大，顺应性的硅酮磁性复合材料也能提高吞咽性。静磁仿真和实验证实，编程的 NSSN/SNNS 磁极分布可提供强大的各向异性和可靠的扭矩生成，从而实现稳定的双向滚动、全向转向、在 7.5 度倾斜上攀爬以及穿越 5 毫米突起。当胶囊处的磁场达到至少 0.3 mT（相当于我们设置中 30 毫米的有效驱动深度）时，滚动运动就会持续。未来的工作将优化材料成分、涂层厚度和磁性布局，以增强力输出和耐用性，而具有闭环反馈的下一代基于机械臂的场发生器将解决非线性问题并扩大可操作性。总之，这些进步旨在将基于涂层的胶囊机器人转向可靠的临床部署，并扩大其在微创诊断和治疗中的应用。

</details>

---

## 73. Assessing Vision-Language Models for Perception in Autonomous Underwater Robotic Software

**中文标题**: 评估自主水下机器人软件中感知的视觉语言模型

**Date**: 2026-02-11 | **arXiv**: [2602.10655v1](http://arxiv.org/abs/2602.10655v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10655v1)

<details><summary><b>Abstract</b></summary>

Autonomous Underwater Robots (AURs) operate in challenging underwater environments, including low visibility and harsh water conditions. Such conditions present challenges for software engineers developing perception modules for the AUR software. To successfully carry out these tasks, deep learning has been incorporated into the AUR software to support its operations. However, the unique challenges of underwater environments pose difficulties for deep learning models, which often rely on labeled data that is scarce and noisy. This may undermine the trustworthiness of AUR software that relies on perception modules. Vision-Language Models (VLMs) offer promising solutions for AUR software as they generalize to unseen objects and remain robust in noisy conditions by inferring information from contextual cues. Despite this potential, their performance and uncertainty in underwater environments remain understudied from a software engineering perspective. Motivated by the needs of an industrial partner in assurance and risk management for maritime systems to assess the potential use of VLMs in this context, we present an empirical evaluation of VLM-based perception modules within the AUR software. We assess their ability to detect underwater trash by computing performance, uncertainty, and their relationship, to enable software engineers to select appropriate VLMs for their AUR software.

</details>

<details><summary><b>中文摘要</b></summary>

自主水下机器人 (AUR) 在充满挑战的水下环境中运行，包括能见度低和恶劣的水条件。这种情况给开发 AUR 软件感知模块的软件工程师带来了挑战。为了成功执行这些任务，深度学习已被纳入 AUR 软件中以支持其操作。然而，水下环境的独特挑战给深度学习模型带来了困难，深度学习模型通常依赖于稀缺且嘈杂的标记数据。这可能会破坏依赖感知模块的 AUR 软件的可信度。视觉语言模型 (VLM) 为 AUR 软件提供了有前途的解决方案，因为它们可以泛化到看不见的对象，并通过从上下文线索推断信息在嘈杂的条件下保持鲁棒性。尽管有这种潜力，但从软件工程的角度来看，它们在水下环境中的性能和不确定性仍然没有得到充分研究。出于海事系统保障和风险管理方面的工业合作伙伴需要评估 VLM 在此背景下的潜在用途的需求，我们对 AUR 软件中基于 VLM 的感知模块进行了实证评估。我们通过计算性能、不确定性及其关系来评估他们检测水下垃圾的能力，以使软件工程师能够为其 AUR 软件选择合适的 VLM。

</details>

---

## 74. Pitch Angle Control of a Magnetically Actuated Capsule Robot with Nonlinear FEA-based MPC and EKF Multisensory Fusion

**中文标题**: 采用基于非线性 FEA 的 MPC 和 EKF 多传感器融合的磁驱动胶囊机器人的俯仰角控制

**Date**: 2026-02-11 | **arXiv**: [2602.10610v1](http://arxiv.org/abs/2602.10610v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10610v1)

<details><summary><b>Abstract</b></summary>

Magnetically actuated capsule robots promise minimally invasive diagnosis and therapy in the gastrointestinal (GI) tract, but existing systems largely neglect control of capsule pitch, a degree of freedom critical for contact-rich interaction with inclined gastric walls. This paper presents a nonlinear, model-based framework for magnetic pitch control of an ingestible capsule robot actuated by a four-coil electromagnetic array. Angle-dependent magnetic forces and torques acting on embedded permanent magnets are characterized using three-dimensional finite-element simulations and embedded as lookup tables in a control-oriented rigid-body pitching model with rolling contact and actuator dynamics. A constrained model predictive controller (MPC) is designed to regulate pitch while respecting hardware-imposed current and slew-rate limits. Experiments on a compliant stomach-inspired surface demonstrate robust pitch reorientation from both horizontal and upright configurations, achieving about three to five times faster settling and reduced oscillatory motion than on-off control. Furthermore, an extended Kalman filter (EKF) fusing inertial sensing with intermittent visual measurements enables stable closed-loop control when the camera update rate is reduced from 30 Hz to 1 Hz, emulating clinically realistic imaging constraints. These results establish finite-element-informed MPC with sensor fusion as a scalable strategy for pitch regulation, controlled docking, and future multi-degree-of-freedom capsule locomotion.

</details>

<details><summary><b>中文摘要</b></summary>

磁驱动胶囊机器人有望在胃肠道中进行微创诊断和治疗，但现有系统在很大程度上忽视了胶囊间距的控制，而胶囊间距对于与倾斜胃壁的丰富接触相互作用至关重要。本文提出了一种基于模型的非线性框架，用于由四线圈电磁阵列驱动的可摄取胶囊机器人的磁性俯仰控制。使用三维有限元模拟来表征作用在嵌入式永磁体上的与角度相关的磁力和扭矩，并将其作为查找表嵌入到具有滚动接触和执行器动力学的面向控制的刚体俯仰模型中。约束模型预测控制器 (MPC) 旨在调节桨距，同时遵守硬件施加的电流和转换速率限制。在受胃启发的顺应表面上进行的实验表明，水平和直立配置均可实现稳健的俯仰重新定向，与开关控制相比，可实现约三到五倍的沉降速度和减少的振荡运动。此外，当相机更新率从 30 Hz 降低到 1 Hz 时，将惯性传感与间歇视觉测量融合在一起的扩展卡尔曼滤波器 (EKF) 可以实现稳定的闭环控制，从而模拟临床实际成像约束。这些结果建立了基于有限元的 MPC 与传感器融合，作为俯仰调节、受控对接和未来多自由度胶囊运动的可扩展策略。

</details>

---

## 75. Flow-Enabled Generalization to Human Demonstrations in Few-Shot Imitation Learning

**中文标题**: 在少样本模仿学习中对人类演示的流程启用泛化

**Date**: 2026-02-11 | **arXiv**: [2602.10594v1](http://arxiv.org/abs/2602.10594v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10594v1)

<details><summary><b>Abstract</b></summary>

Imitation Learning (IL) enables robots to learn complex skills from demonstrations without explicit task modeling, but it typically requires large amounts of demonstrations, creating significant collection costs. Prior work has investigated using flow as an intermediate representation to enable the use of human videos as a substitute, thereby reducing the amount of required robot demonstrations. However, most prior work has focused on the flow, either on the object or on specific points of the robot/hand, which cannot describe the motion of interaction. Meanwhile, relying on flow to achieve generalization to scenarios observed only in human videos remains limited, as flow alone cannot capture precise motion details. Furthermore, conditioning on scene observation to produce precise actions may cause the flow-conditioned policy to overfit to training tasks and weaken the generalization indicated by the flow. To address these gaps, we propose SFCrP, which includes a Scene Flow prediction model for Cross-embodiment learning (SFCr) and a Flow and Cropped point cloud conditioned Policy (FCrP). SFCr learns from both robot and human videos and predicts any point trajectories. FCrP follows the general flow motion and adjusts the action based on observations for precision tasks. Our method outperforms SOTA baselines across various real-world task settings, while also exhibiting strong spatial and instance generalization to scenarios seen only in human videos.

</details>

<details><summary><b>中文摘要</b></summary>

模仿学习（IL）使机器人能够从演示中学习复杂的技能，而无需明确的任务建模，但它通常需要大量的演示，从而产生大量的收集成本。之前的工作已经研究了使用流作为中间表示，以允许使用人类视频作为替代品，从而减少所需的机器人演示的数量。然而，大多数先前的工作都集中在流上，无论是在物体上还是在机器人/手的特定点上，这无法描述交互的运动。与此同时，依靠流来实现对仅在人类视频中观察到的场景的泛化仍然有限，因为单独的流无法捕获精确的运动细节。此外，对场景观察进行调节以产生精确的动作可能会导致流调节策略过度适应训练任务并削弱流所指示的泛化能力。为了解决这些差距，我们提出了 SFCrP，其中包括用于跨实施例学习的场景流预测模型（SFCr）以及流和裁剪点云条件策略（FCrP）。 SFCr 从机器人和人类视频中学习并预测任何点轨迹。 FCrP 遵循一般流动运动，并根据精确任务的观察来调整动作。我们的方法在各种现实世界任务设置中都优于 SOTA 基线，同时还对仅在人类视频中看到的场景表现出强大的空间和实例泛化能力。

</details>

---

## 76. Morphogenetic Assembly and Adaptive Control for Heterogeneous Modular Robots

**中文标题**: 异构模块化机器人的形态组装和自适应控制

**Date**: 2026-02-11 | **arXiv**: [2602.10561v1](http://arxiv.org/abs/2602.10561v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10561v1)

<details><summary><b>Abstract</b></summary>

This paper presents a closed-loop automation framework for heterogeneous modular robots, covering the full pipeline from morphological construction to adaptive control. In this framework, a mobile manipulator handles heterogeneous functional modules including structural, joint, and wheeled modules to dynamically assemble diverse robot configurations and provide them with immediate locomotion capability. To address the state-space explosion in large-scale heterogeneous reconfiguration, we propose a hierarchical planner: the high-level planner uses a bidirectional heuristic search with type-penalty terms to generate module-handling sequences, while the low level planner employs A* search to compute optimal execution trajectories. This design effectively decouples discrete configuration planning from continuous motion execution. For adaptive motion generation of unknown assembled configurations, we introduce a GPU accelerated Annealing-Variance Model Predictive Path Integral (MPPI) controller. By incorporating a multi stage variance annealing strategy to balance global exploration and local convergence, the controller enables configuration-agnostic, real-time motion control. Large scale simulations show that the type-penalty term is critical for planning robustness in heterogeneous scenarios. Moreover, the greedy heuristic produces plans with lower physical execution costs than the Hungarian heuristic. The proposed annealing-variance MPPI significantly outperforms standard MPPI in both velocity tracking accuracy and control frequency, achieving real time control at 50 Hz. The framework validates the full-cycle process, including module assembly, robot merging and splitting, and dynamic motion generation.

</details>

<details><summary><b>中文摘要</b></summary>

本文提出了一种异构模块化机器人的闭环自动化框架，涵盖了从形态构建到自适应控制的完整流程。在此框架中，移动机械手处理异构功能模块，包括结构、关节和轮式模块，以动态组装不同的机器人配置并为它们提供即时运动能力。为了解决大规模异构重配置中的状态空间爆炸问题，我们提出了一种分层规划器：高层规划器使用带有类型惩罚项的双向启发式搜索来生成模块处理序列，而低层规划器则采用 A* 搜索来计算最佳执行轨迹。该设计有效地将离散配置规划与连续运动执行分离。对于未知组装配置的自适应运动生成，我们引入了 GPU 加速的退火方差模型预测路径积分 (MPPI) 控制器。通过结合多阶段方差退火策略来平衡全局探索和局部收敛，控制器可实现与配置无关的实时运动控制。大规模模拟表明，类型惩罚项对于异构场景中的规划鲁棒性至关重要。此外，贪婪启发式产生的计划的物理执行成本比匈牙利启发式更低。所提出的退火方差 MPPI 在速度跟踪精度和控制频率方面都显着优于标准 MPPI，实现了 50 Hz 的实时控制。该框架验证了全周期过程，包括模块组装、机器人合并和分裂以及动态运动生成。

</details>

---

## 77. Towards Long-Lived Robots: Continual Learning VLA Models via Reinforcement Fine-Tuning

**中文标题**: 迈向长寿机器人：通过强化微调持续学习 VLA 模型

**Date**: 2026-02-11 | **arXiv**: [2602.10503v1](http://arxiv.org/abs/2602.10503v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10503v1)

<details><summary><b>Abstract</b></summary>

Pretrained on large-scale and diverse datasets, VLA models demonstrate strong generalization and adaptability as general-purpose robotic policies. However, Supervised Fine-Tuning (SFT), which serves as the primary mechanism for adapting VLAs to downstream domains, requires substantial amounts of task-specific data and is prone to catastrophic forgetting. To address these limitations, we propose LifeLong-RFT, a simple yet effective Reinforcement Fine-Tuning (RFT) strategy for VLA models independent of online environmental feedback and pre-trained reward models. By integrating chunking-level on-policy reinforcement learning with the proposed Multi-Dimensional Process Reward (MDPR) mechanism, LifeLong-RFT quantifies the heterogeneous contributions of intermediate action chunks across three dimensions to facilitate policy optimization. Specifically, (1) the Quantized Action Consistency Reward (QACR) ensures accurate action prediction within the discrete action space; (2) the Continuous Trajectory Alignment Reward (CTAR) aligns decoded continuous action chunks with reference trajectories to ensure precise control; (3) the Format Compliance Reward (FCR) guarantees the structural validity of outputs. Comprehensive experiments across SimplerEnv, LIBERO, and real-world tasks demonstrate that LifeLong-RFT exhibits strong performance in multi-task learning. Furthermore, for continual learning on the LIBERO benchmark, our method achieves a 22% gain in average success rate over SFT, while effectively adapting to new tasks using only 20% of the training data. Overall, our method provides a promising post-training paradigm for VLAs.

</details>

<details><summary><b>中文摘要</b></summary>

VLA 模型在大规模和多样化的数据集上进行了预训练，表现出作为通用机器人策略的强大泛化性和适应性。然而，监督微调（SFT）作为使 VLA 适应下游域的主要机制，需要大量特定于任务的数据，并且容易发生灾难性遗忘。为了解决这些限制，我们提出了 LifeLong-RFT，这是一种简单而有效的强化微调（RFT）策略，适用于独立于在线环境反馈和预训练奖励模型的 VLA 模型。通过将分块级别的策略强化学习与所提出的多维过程奖励（MDPR）机制相结合，LifeLong-RFT 量化了三个维度上的中间动作块的异构贡献，以促进策略优化。具体来说，（1）量化动作一致性奖励（QACR）确保离散动作空间内准确的动作预测； （2）连续轨迹对齐奖励（CTAR）将解码的连续动作块与参考轨迹对齐，以确保精确控制； （3）格式合规奖励（FCR）保证输出的结构有效性。跨 SimplerEnv、LIBERO 和现实世界任务的综合实验表明，LifeLong-RFT 在多任务学习中表现出强大的性能。此外，对于 LIBERO 基准的持续学习，我们的方法比 SFT 的平均成功率提高了 22%，同时仅使用 20% 的训练数据就能有效地适应新任务。总的来说，我们的方法为 VLA 提供了一个有前途的训练后范例。

</details>

---

## 78. RadarEye: Robust Liquid Level Tracking Using mmWave Radar in Robotic Pouring

**中文标题**: RadarEye：在机器人浇注中使用毫米波雷达进行稳健的液位跟踪

**Date**: 2026-02-11 | **arXiv**: [2602.10417v1](http://arxiv.org/abs/2602.10417v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10417v1)

<details><summary><b>Abstract</b></summary>

Transparent liquid manipulation in robotic pouring remains challenging for perception systems: specular/refraction effects and lighting variability degrade visual cues, undermining reliable level estimation. To address this challenge, we introduce RadarEye, a real-time mmWave radar signal processing pipeline for robust liquid level estimation and tracking during the whole pouring process. RadarEye integrates (i) a high-resolution range-angle beamforming module for liquid level sensing and (ii) a physics-informed mid-pour tracker that suppresses multipath to maintain lock on the liquid surface despite stream-induced clutter and source container reflections. The pipeline delivers sub-millisecond latency. In real-robot water-pouring experiments, RadarEye achieves a 0.35 cm median absolute height error at 0.62 ms per update, substantially outperforming vision and ultrasound baselines.

</details>

<details><summary><b>中文摘要</b></summary>

机器人浇注中的透明液体操作对于感知系统来说仍然具有挑战性：镜面/折射效应和照明变化会降低视觉线索，破坏可靠的液位估计。为了应对这一挑战，我们推出了 RadarEye，这是一种实时毫米波雷达信号处理管道，可在整个浇注过程中进行可靠的液位估计和跟踪。 RadarEye 集成了 (i) 用于液位传感的高分辨率距离角波束形成模块和 (ii) 物理信息的中倾跟踪器，该跟踪器可抑制多路径，以保持对液面的锁定，尽管存在流引起的杂波和源容器反射。该管道提供亚毫秒级延迟。在真实的机器人倒水实验中，RadarEye 在每次更新 0.62 毫秒时实现了 0.35 厘米的中值绝对高度误差，大大优于视觉和超声基线。

</details>

---

## 79. LocoVLM: Grounding Vision and Language for Adapting Versatile Legged Locomotion Policies

**中文标题**: LocoVLM：适应多功能腿式运动策略的基础愿景和语言

**Date**: 2026-02-11 | **arXiv**: [2602.10399v1](http://arxiv.org/abs/2602.10399v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10399v1)

<details><summary><b>Abstract</b></summary>

Recent advances in legged locomotion learning are still dominated by the utilization of geometric representations of the environment, limiting the robot's capability to respond to higher-level semantics such as human instructions. To address this limitation, we propose a novel approach that integrates high-level commonsense reasoning from foundation models into the process of legged locomotion adaptation. Specifically, our method utilizes a pre-trained large language model to synthesize an instruction-grounded skill database tailored for legged robots. A pre-trained vision-language model is employed to extract high-level environmental semantics and ground them within the skill database, enabling real-time skill advisories for the robot. To facilitate versatile skill control, we train a style-conditioned policy capable of generating diverse and robust locomotion skills with high fidelity to specified styles. To the best of our knowledge, this is the first work to demonstrate real-time adaptation of legged locomotion using high-level reasoning from environmental semantics and instructions with instruction-following accuracy of up to 87% without the need for online query to on-the-cloud foundation models.

</details>

<details><summary><b>中文摘要</b></summary>

腿式运动学习的最新进展仍然以环境几何表示的利用为主，限制了机器人响应更高级别语义（例如人类指令）的能力。为了解决这一限制，我们提出了一种新颖的方法，将基础模型的高级常识推理集成到腿式运动适应过程中。具体来说，我们的方法利用预先训练的大型语言模型来合成为腿式机器人量身定制的基于指令的技能数据库。采用预先训练的视觉语言模型来提取高级环境语义并将其嵌入技能数据库中，从而为机器人提供实时技能建议。为了促进多功能技能控制，我们训练了一种以风格为条件的策略，该策略能够生成多样化且强大的运动技能，并且对指定风格具有高保真度。据我们所知，这是第一个利用环境语义和指令进行高级推理来演示腿式运动实时适应的工作，指令跟踪准确度高达 87%，而无需在线查询云基础模型。

</details>

---

## 80. TVCACHE: A Stateful Tool-Value Cache for Post-Training LLM Agents

**中文标题**: TVCACHE：用于训练后 LLM 代理的状态工具值缓存

**Date**: 2026-02-11 | **arXiv**: [2602.10986v1](http://arxiv.org/abs/2602.10986v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10986v1)

<details><summary><b>Abstract</b></summary>

In RL post-training of LLM agents, calls to external tools take several seconds or even minutes, leaving allocated GPUs idle and inflating post-training time and cost. While many tool invocations repeat across parallel rollouts and could in principle be cached, naively caching their outputs for reuse is incorrect since tool outputs depend on the environment state induced by prior agent interactions. We present TVCACHE, a stateful tool-value cache for LLM agent post-training. TVCACHE maintains a tree of observed tool-call sequences and performs longest-prefix matching for cache lookups: a hit occurs only when the agent's full tool history matches a previously executed sequence, guaranteeing identical environment state. On three diverse workloads-terminal-based tasks, SQL generation, and video understanding. TVCACHE achieves cache hit rates of up to 70% and reduces median tool call execution time by up to 6.9X, with no degradation in post-training reward accumulation.

</details>

<details><summary><b>中文摘要</b></summary>

在 LLM 代理的强化学习后期训练中，调用外部工具需要几秒钟甚至几分钟的时间，导致分配的 GPU 闲置，并增加训练后的时间和成本。虽然许多工具调用在并行部署中重复，并且原则上可以缓存，但天真地缓存其输出以供重用是不正确的，因为工具输出取决于先前代理交互引起的环境状态。我们推出了 TVCACHE，这是一种用于 LLM 代理后期训练的有状态工具值缓存。 TVCACHE 维护观察到的工具调用序列树，并执行缓存查找的最长前缀匹配：仅当代理的完整工具历史记录与先前执行的序列匹配时才会发生命中，从而保证相同的环境状态。关于三种不同的工作负载——基于终端的任务、SQL 生成和视频理解。 TVCACHE 实现了高达 70% 的缓存命中率，并将工具调用执行时间中位数减少了 6.9 倍，并且训练后奖励积累没有下降。

</details>

---

## 81. Stochastic Parroting in Temporal Attention -- Regulating the Diagonal Sink

**中文标题**: 时间注意力中的随机鹦鹉学舌——调节对角下沉

**Date**: 2026-02-11 | **arXiv**: [2602.10956v1](http://arxiv.org/abs/2602.10956v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10956v1)

<details><summary><b>Abstract</b></summary>

Spatio-temporal models analyze spatial structures and temporal dynamics, which makes them prone to information degeneration among space and time. Prior literature has demonstrated that over-squashing in causal attention or temporal convolutions creates a bias on the first tokens. To analyze whether such a bias is present in temporal attention mechanisms, we derive sensitivity bounds on the expected value of the Jacobian of a temporal attention layer. We theoretically show how off-diagonal attention scores depend on the sequence length, and that temporal attention matrices suffer a diagonal attention sink. We suggest regularization methods, and experimentally demonstrate their effectiveness.

</details>

<details><summary><b>中文摘要</b></summary>

时空模型分析空间结构和时间动态，这使得它们容易出现空间和时间之间的信息退化。先前的文献已经证明，因果注意力或时间卷积的过度压缩会对第一个标记产生偏差。为了分析时间注意机制中是否存在这种偏差，我们推导了时间注意层的雅可比行列式的期望值的敏感性界限。我们从理论上证明了非对角注意力分数如何取决于序列长度，并且时间注意力矩阵遭受对角注意力下沉。我们提出正则化方法，并通过实验证明其有效性。

</details>

---

## 82. Anomaly Detection with Machine Learning Algorithms in Large-Scale Power Grids

**中文标题**: 大规模电网中机器学习算法的异常检测

**Date**: 2026-02-11 | **arXiv**: [2602.10888v1](http://arxiv.org/abs/2602.10888v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10888v1)

<details><summary><b>Abstract</b></summary>

We apply several machine learning algorithms to the problem of anomaly detection in operational data for large-scale, high-voltage electric power grids. We observe important differences in the performance of the algorithms. Neural networks typically outperform classical algorithms such as k-nearest neighbors and support vector machines, which we explain by the strong contextual nature of the anomalies. We show that unsupervised learning algorithm work remarkably well and that their predictions are robust against simultaneous, concurring anomalies.

</details>

<details><summary><b>中文摘要</b></summary>

我们将多种机器学习算法应用于大规模高压电网运行数据的异常检测问题。我们观察到算法性能的重要差异。神经网络通常优于经典算法，例如 k 最近邻和支持向量机，我们通过异常的强烈上下文性质来解释这一点。我们证明无监督学习算法工作得非常好，并且它们的预测对于同时发生的异常情况是稳健的。

</details>

---

## 83. SimuScene: Training and Benchmarking Code Generation to Simulate Physical Scenarios

**中文标题**: SimuScene：模拟物理场景的训练和基准测试代码生成

**Date**: 2026-02-11 | **arXiv**: [2602.10840v1](http://arxiv.org/abs/2602.10840v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10840v1)

<details><summary><b>Abstract</b></summary>

Large language models (LLMs) have been extensively studied for tasks like math competitions, complex coding, and scientific reasoning, yet their ability to accurately represent and simulate physical scenarios via code remains underexplored. We propose SimuScene, the first systematic study that trains and evaluates LLMs on simulating physical scenarios across five physics domains and 52 physical concepts. We build an automatic pipeline to collect data, with human verification to ensure quality. The final dataset contains 7,659 physical scenarios with 334 human-verified examples as the test set. We evaluated 10 contemporary LLMs and found that even the strongest model achieves only a 21.5% pass rate, demonstrating the difficulty of the task. Finally, we introduce a reinforcement learning pipeline with visual rewards that uses a vision-language model as a judge to train textual models. Experiments show that training with our data improves physical simulation via code while substantially enhancing general code generation performance.

</details>

<details><summary><b>中文摘要</b></summary>

大型语言模型 (LLM) 已针对数学竞赛、复杂编码和科学推理等任务进行了广泛研究，但它们通过代码准确表示和模拟物理场景的能力仍未得到充分开发。我们提出了 SimuScene，这是第一个系统研究，旨在训练和评估法学硕士模拟跨五个物理领域和 52 个物理概念的物理场景。我们建立了一个自动管道来收集数据，并通过人工验证来确保质量。最终数据集包含 7,659 个物理场景，其中有 334 个经过人工验证的示例作为测试集。我们评估了 10 位当代法学硕士，发现即使是最强的模型也只能达到 21.5% 的通过率，可见任务的难度。最后，我们引入了带有视觉奖励的强化学习管道，它使用视觉语言模型作为判断来训练文本模型。实验表明，使用我们的数据进行训练可以通过代码改进物理模拟，同时显着提高一般代码生成性能。

</details>

---

## 84. Self-Supervised Learning for Speaker Recognition: A study and review

**中文标题**: 说话人识别的自我监督学习：研究与回顾

**Date**: 2026-02-11 | **arXiv**: [2602.10829v1](http://arxiv.org/abs/2602.10829v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10829v1)

<details><summary><b>Abstract</b></summary>

Deep learning models trained in a supervised setting have revolutionized audio and speech processing. However, their performance inherently depends on the quantity of human-annotated data, making them costly to scale and prone to poor generalization under unseen conditions. To address these challenges, Self-Supervised Learning (SSL) has emerged as a promising paradigm, leveraging vast amounts of unlabeled data to learn relevant representations. The application of SSL for Automatic Speech Recognition (ASR) has been extensively studied, but research on other downstream tasks, notably Speaker Recognition (SR), remains in its early stages. This work describes major SSL instance-invariance frameworks (e.g., SimCLR, MoCo, and DINO), initially developed for computer vision, along with their adaptation to SR. Various SSL methods for SR, proposed in the literature and built upon these frameworks, are also presented. An extensive review of these approaches is then conducted: (1) the effect of the main hyperparameters of SSL frameworks is investigated; (2) the role of SSL components is studied (e.g., data-augmentation, projector, positive sampling); and (3) SSL frameworks are evaluated on SR with in-domain and out-of-domain data, using a consistent experimental setup, and a comprehensive comparison of SSL methods from the literature is provided. Specifically, DINO achieves the best downstream performance and effectively models intra-speaker variability, although it is highly sensitive to hyperparameters and training conditions, while SimCLR and MoCo provide robust alternatives that effectively capture inter-speaker variability and are less prone to collapse. This work aims to highlight recent trends and advancements, identifying current challenges in the field.

</details>

<details><summary><b>中文摘要</b></summary>

在监督环境中训练的深度学习模型彻底改变了音频和语音处理。然而，它们的性能本质上取决于人工注释数据的数量，这使得它们的扩展成本高昂，并且在未见的条件下容易出现泛化不良的情况。为了应对这些挑战，自我监督学习（SSL）已成为一种有前景的范例，它利用大量未标记的数据来学习相关的表示。 SSL 在自动语音识别 (ASR) 中的应用已得到广泛研究，但对其他下游任务（尤其是说话人识别 (SR)）的研究仍处于早期阶段。这项工作描述了最初为计算机视觉开发的主要 SSL 实例不变性框架（例如 SimCLR、MoCo 和 DINO），以及它们对 SR 的适应。还介绍了文献中提出的并基于这些框架构建的各种用于 SR 的 SSL 方法。然后对这些方法进行了广泛的审查：（1）研究了 SSL 框架主要超参数的影响； (2) 研究 SSL 组件的作用（例如数据增强、投影仪、正采样）； (3) 使用一致的实验设置，使用域内和域外数据在 SR 上评估 SSL 框架，并对文献中的 SSL 方法进行全面比较。具体来说，尽管 DINO 对超参数和训练条件高度敏感，但它实现了最佳的下游性能并有效地模拟了说话人内部的变异性，而 SimCLR 和 MoCo 提供了强大的替代方案，可以有效捕获说话人之间的变异性并且不易崩溃。这项工作旨在突出最新趋势和进展，确定该领域当前的挑战。

</details>

---

## 85. RePO: Bridging On-Policy Learning and Off-Policy Knowledge through Rephrasing Policy Optimization

**中文标题**: RePO：通过重新表述策略优化来桥接策略内学习和策略外知识

**Date**: 2026-02-11 | **arXiv**: [2602.10819v1](http://arxiv.org/abs/2602.10819v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10819v1)

<details><summary><b>Abstract</b></summary>

Aligning large language models (LLMs) on domain-specific data remains a fundamental challenge. Supervised fine-tuning (SFT) offers a straightforward way to inject domain knowledge but often degrades the model's generality. In contrast, on-policy reinforcement learning (RL) preserves generality but fails to effectively assimilate hard samples that exceed the model's current reasoning level. Recent off-policy RL attempts improve hard sample utilization, yet they suffer from severe training instability due to the forced distribution shift toward off-policy knowledge. To reconcile effective off-policy knowledge absorption with the stability of on-policy RL, we propose Rephrasing Policy Optimization (RePO). In RePO, the policy model is prompted to first comprehend off-policy knowledge and then rephrase it into trajectories that conform to its own stylistic and parametric distribution. RePO dynamically replaces low-reward rollouts with these rephrased, high-quality trajectories. This strategy guides the model toward correct reasoning paths while strictly preserving on-policy training dynamics. Experiments on several benchmarks demonstrate that RePO improves hard-sample utilization and outperforms existing baselines, achieving state-of-the-art performance.

</details>

<details><summary><b>中文摘要</b></summary>

将大型语言模型 (LLM) 与特定领域的数据保持一致仍然是一项基本挑战。有监督微调（SFT）提供了一种注入领域知识的直接方法，但通常会降低模型的通用性。相比之下，在策略强化学习（RL）保留了通用性，但无法有效地同化超出模型当前推理水平的硬样本。最近的离策略强化学习尝试提高了硬样本利用率，但由于强制分布转向离策略知识，它们遭受了严重的训练不稳定问题。为了协调有效的离策略知识吸收与在策略强化学习的稳定性，我们提出了改写策略优化（RePO）。在RePO中，策略模型被提示首先理解非策略知识，然后将其重新表述为符合其自身风格和参数分布的轨迹。 RePO 用这些重新表述的高质量轨迹动态地取代了低奖励的部署。该策略引导模型走向正确的推理路径，同时严格保留策略训练动态。多个基准测试的实验表明，RePO 提高了硬样本利用率并优于现有基准，实现了最先进的性能。

</details>

---

## 86. Deep Learning-based Method for Expressing Knowledge Boundary of Black-Box LLM

**中文标题**: 基于深度学习的Black-Box LLM知识边界表达方法

**Date**: 2026-02-11 | **arXiv**: [2602.10801v1](http://arxiv.org/abs/2602.10801v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10801v1)

<details><summary><b>Abstract</b></summary>

Large Language Models (LLMs) have achieved remarkable success, however, the emergence of content generation distortion (hallucination) limits their practical applications. The core cause of hallucination lies in LLMs' lack of awareness regarding their stored internal knowledge, preventing them from expressing their knowledge state on questions beyond their internal knowledge boundaries, as humans do. However, existing research on knowledge boundary expression primarily focuses on white-box LLMs, leaving methods suitable for black-box LLMs which offer only API access without revealing internal parameters-largely unexplored. Against this backdrop, this paper proposes LSCL (LLM-Supervised Confidence Learning), a deep learning-based method for expressing the knowledge boundaries of black-box LLMs. Based on the knowledge distillation framework, this method designs a deep learning model. Taking the input question, output answer, and token probability from a black-box LLM as inputs, it constructs a mapping between the inputs and the model' internal knowledge state, enabling the quantification and expression of the black-box LLM' knowledge boundaries. Experiments conducted on diverse public datasets and with multiple prominent black-box LLMs demonstrate that LSCL effectively assists black-box LLMs in accurately expressing their knowledge boundaries. It significantly outperforms existing baseline models on metrics such as accuracy and recall rate. Furthermore, considering scenarios where some black-box LLMs do not support access to token probability, an adaptive alternative method is proposed. The performance of this alternative approach is close to that of LSCL and surpasses baseline models.

</details>

<details><summary><b>中文摘要</b></summary>

大型语言模型（LLM）取得了显着的成功，然而，内容生成失真（幻觉）的出现限制了其实际应用。产生幻觉的核心原因在于法学硕士对自己储存的内部知识缺乏认识，导致他们无法像人类一样在超出其内部知识边界的问题上表达自己的知识状态。然而，现有的知识边界表达研究主要集中在白盒 LLM 上，而适用于黑盒 LLM 的方法仅提供 API 访问而不透露内部参数——很大程度上尚未探索。在此背景下，本文提出了LSCL（LLM-Supervised Confidence Learning），一种基于深度学习的方法，用于表达黑盒LLM的知识边界。该方法基于知识蒸馏框架，设计了深度学习模型。以黑盒LLM的输入问题、输出答案和token概率作为输入，构建输入与模型内部知识状态之间的映射，实现黑盒LLM知识边界的量化和表达。在不同的公共数据集和多个著名的黑盒法学硕士上进行的实验表明，LSCL 有效地帮助黑盒法学硕士准确表达其知识边界。它在准确性和召回率等指标上显着优于现有的基线模型。此外，考虑到一些黑盒LLM不支持访问令牌概率的场景，提出了一种自适应替代方法。这种替代方法的性能接近 LSCL 并超过基线模型。

</details>

---

## 87. SnapMLA: Efficient Long-Context MLA Decoding via Hardware-Aware FP8 Quantized Pipelining

**中文标题**: SnapMLA：通过硬件感知 FP8 量化流水线进行高效的长上下文 MLA 解码

**Date**: 2026-02-11 | **arXiv**: [2602.10718v1](http://arxiv.org/abs/2602.10718v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10718v1)

**Code**: https://github.com/meituan-longcat/SGLang-FluentLLM.

<details><summary><b>Abstract</b></summary>

While FP8 attention has shown substantial promise in innovations like FlashAttention-3, its integration into the decoding phase of the DeepSeek Multi-head Latent Attention (MLA) architecture presents notable challenges. These challenges include numerical heterogeneity arising from the decoupling of positional embeddings, misalignment of quantization scales in FP8 PV GEMM, and the need for optimized system-level support. In this paper, we introduce SnapMLA, an FP8 MLA decoding framework optimized to improve long-context efficiency through the following hardware-aware algorithm-kernel co-optimization techniques: (i) RoPE-Aware Per-Token KV Quantization, where the RoPE part is maintained in high precision, motivated by our comprehensive analysis of the heterogeneous quantization sensitivity inherent to the MLA KV cache. Furthermore, per-token granularity is employed to align with the autoregressive decoding process and maintain quantization accuracy. (ii) Quantized PV Computation Pipeline Reconstruction, which resolves the misalignment of quantization scale in FP8 PV computation stemming from the shared KV structure of the MLA KV cache. (iii) End-to-End Dataflow Optimization, where we establish an efficient data read-and-write workflow using specialized kernels, ensuring efficient data flow and performance gains. Extensive experiments on state-of-the-art MLA LLMs show that SnapMLA achieves up to a 1.91x improvement in throughput, with negligible risk of performance degradation in challenging long-context tasks, including mathematical reasoning and code generation benchmarks. Code is available at https://github.com/meituan-longcat/SGLang-FluentLLM.

</details>

<details><summary><b>中文摘要</b></summary>

虽然 FP8 注意力在 FlashAttention-3 等创新中显示出了巨大的前景，但将其集成到 DeepSeek 多头潜在注意力 (MLA) 架构的解码阶段却带来了显着的挑战。这些挑战包括位置嵌入解耦产生的数值异质性、FP8 PV GEMM 中量化尺度的错位以及优化系统级支持的需求。在本文中，我们介绍了 SnapMLA，这是一种经过优化的 FP8 MLA 解码框架，通过以下硬件感知算法-内核协同优化技术来提高长上下文效率：（i）RoPE 感知每令牌 KV 量化，其中 RoPE 部分保持高精度，其动机是我们对 MLA KV 缓存固有的异构量化敏感性的全面分析。此外，每个令牌的粒度用于与自回归解码过程保持一致并保持量化精度。 (ii)量化PV计算管道重构，解决了由于MLA KV缓存共享KV结构导致的FP8 PV计算中量化尺度错位的问题。 (iii) 端到端数据流优化，我们使用专用内核建立高效的数据读写工作流程，确保高效的数据流和性能提升。对最先进的 MLA LLM 进行的大量实验表明，SnapMLA 的吞吐量提高了 1.91 倍，在具有挑战性的长上下文任务（包括数学推理和代码生成基准）中，性能下降的风险可以忽略不计。代码可在 https://github.com/meituan-longcat/SGLang-FluentLLM 获取。

</details>

---

## 88. Robust Assortment Optimization from Observational Data

**中文标题**: 根据观测数据进行稳健的分类优化

**Date**: 2026-02-11 | **arXiv**: [2602.10696v1](http://arxiv.org/abs/2602.10696v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10696v1)

<details><summary><b>Abstract</b></summary>

Assortment optimization is a fundamental challenge in modern retail and recommendation systems, where the goal is to select a subset of products that maximizes expected revenue under complex customer choice behaviors. While recent advances in data-driven methods have leveraged historical data to learn and optimize assortments, these approaches typically rely on strong assumptions -- namely, the stability of customer preferences and the correctness of the underlying choice models. However, such assumptions frequently break in real-world scenarios due to preference shifts and model misspecification, leading to poor generalization and revenue loss. Motivated by this limitation, we propose a robust framework for data-driven assortment optimization that accounts for potential distributional shifts in customer choice behavior. Our approach models potential preference shift from a nominal choice model that generates data and seeks to maximize worst-case expected revenue. We first establish the computational tractability of robust assortment planning when the nominal model is known, then advance to the data-driven setting, where we design statistically optimal algorithms that minimize the data requirements while maintaining robustness. Our theoretical analysis provides both upper bounds and matching lower bounds on the sample complexity, offering theoretical guarantees for robust generalization. Notably, we uncover and identify the notion of ``robust item-wise coverage'' as the minimal data requirement to enable sample-efficient robust assortment learning. Our work bridges the gap between robustness and statistical efficiency in assortment learning, contributing new insights and tools for reliable assortment optimization under uncertainty.

</details>

<details><summary><b>中文摘要</b></summary>

分类优化是现代零售和推荐系统中的一个基本挑战，其目标是选择在复杂的客户选择行为下最大化预期收入的产品子集。虽然数据驱动方法的最新进展利用历史数据来学习和优化分类，但这些方法通常依赖于强有力的假设，即客户偏好的稳定性和基础选择模型的正确性。然而，由于偏好转变和模型错误指定，此类假设在现实场景中经常被打破，导致概括性差和收入损失。受此限制的启发，我们提出了一个强大的数据驱动分类优化框架，该框架考虑了客户选择行为的潜在分布变化。我们的方法对名义选择模型的潜在偏好转变进行建模，该模型生成数据并寻求最大化最坏情况的预期收入。我们首先在标称模型已知的情况下建立鲁棒分类规划的计算易处理性，然后进入数据驱动设置，在该设置中我们设计统计最优算法，在保持鲁棒性的同时最大限度地减少数据需求。我们的理论分析提供了样本复杂性的上限和匹配的下限，为稳健的泛化提供了理论保证。值得注意的是，我们发现并确定了“鲁棒逐项覆盖”的概念，作为实现样本高效鲁棒分类学习的最低数据要求。我们的工作弥合了分类学习的稳健性和统计效率之间的差距，为不确定性下可靠的分类优化提供了新的见解和工具。

</details>

---

## 89. A solvable high-dimensional model where nonlinear autoencoders learn structure invisible to PCA while test loss misaligns with generalization

**中文标题**: 一种可解的高维模型，其中非线性自动编码器学习 PCA 不可见的结构，而测试损失与泛化不一致

**Date**: 2026-02-11 | **arXiv**: [2602.10680v1](http://arxiv.org/abs/2602.10680v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10680v1)

<details><summary><b>Abstract</b></summary>

Many real-world datasets contain hidden structure that cannot be detected by simple linear correlations between input features. For example, latent factors may influence the data in a coordinated way, even though their effect is invisible to covariance-based methods such as PCA. In practice, nonlinear neural networks often succeed in extracting such hidden structure in unsupervised and self-supervised learning. However, constructing a minimal high-dimensional model where this advantage can be rigorously analyzed has remained an open theoretical challenge. We introduce a tractable high-dimensional spiked model with two latent factors: one visible to covariance, and one statistically dependent yet uncorrelated, appearing only in higher-order moments. PCA and linear autoencoders fail to recover the latter, while a minimal nonlinear autoencoder provably extracts both. We analyze both the population risk, and empirical risk minimization. Our model also provides a tractable example where self-supervised test loss is poorly aligned with representation quality: nonlinear autoencoders recover latent structure that linear methods miss, even though their reconstruction loss is higher.

</details>

<details><summary><b>中文摘要</b></summary>

许多现实世界的数据集包含隐藏结构，无法通过输入特征之间的简单线性相关性来检测。例如，潜在因素可能会以协调的方式影响数据，尽管它们的影响对于基于协方差的方法（例如 PCA）是不可见的。在实践中，非线性神经网络通常能够在无监督和自监督学习中成功提取此类隐藏结构。然而，构建一个可以严格分析这种优势的最小高维模型仍然是一个开放的理论挑战。我们引入了一种易于处理的高维尖峰模型，具有两个潜在因素：一个对协方差可见，另一个在统计上依赖但不相关，仅出现在高阶矩中。 PCA 和线性自动编码器无法恢复后者，而最小非线性自动编码器可以证明两者都可以提取。我们分析了人口风险和经验风险最小化。我们的模型还提供了一个易于处理的示例，其中自监督测试损失与表示质量不一致：非线性自动编码器恢复线性方法错过的潜在结构，即使它们的重建损失更高。

</details>

---

## 90. On the Role of Consistency Between Physics and Data in Physics-Informed Neural Networks

**中文标题**: 关于物理与数据一致性在物理信息神经网络中的作用

**Date**: 2026-02-11 | **arXiv**: [2602.10611v1](http://arxiv.org/abs/2602.10611v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10611v1)

<details><summary><b>Abstract</b></summary>

Physics-informed neural networks (PINNs) have gained significant attention as a surrogate modeling strategy for partial differential equations (PDEs), particularly in regimes where labeled data are scarce and physical constraints can be leveraged to regularize the learning process. In practice, however, PINNs are frequently trained using experimental or numerical data that are not fully consistent with the governing equations due to measurement noise, discretization errors, or modeling assumptions. The implications of such data-to-PDE inconsistencies on the accuracy and convergence of PINNs remain insufficiently understood. In this work, we systematically analyze how data inconsistency fundamentally limits the attainable accuracy of PINNs. We introduce the concept of a consistency barrier, defined as an intrinsic lower bound on the error that arises from mismatches between the fidelity of the data and the exact enforcement of the PDE residual. To isolate and quantify this effect, we consider the 1D viscous Burgers equation with a manufactured analytical solution, which enables full control over data fidelity and residual errors. PINNs are trained using datasets of progressively increasing numerical accuracy, as well as perfectly consistent analytical data. Results show that while the inclusion of the PDE residual allows PINNs to partially mitigate low-fidelity data and recover the dominant physical structure, the training process ultimately saturates at an error level dictated by the data inconsistency. When high-fidelity numerical data are employed, PINN solutions become indistinguishable from those trained on analytical data, indicating that the consistency barrier is effectively removed. These findings clarify the interplay between data quality and physics enforcement in PINNs providing practical guidance for the construction and interpretation of physics-informed surrogate models.

</details>

<details><summary><b>中文摘要</b></summary>

物理信息神经网络 (PINN) 作为偏微分方程 (PDE) 的替代建模策略而受到广泛关注，特别是在标记数据稀缺且可以利用物理约束来规范学习过程的情况下。然而，在实践中，PINN 经常使用实验或数值数据进行训练，由于测量噪声、离散化误差或建模假设，这些数据与控制方程并不完全一致。这种数据与偏微分方程的不一致对 PINN 准确性和收敛性的影响仍未得到充分理解。在这项工作中，我们系统地分析了数据不一致如何从根本上限制了 PINN 可达到的准确性。我们引入了一致性屏障的概念，它被定义为由于数据保真度与偏微分方程残差的精确执行之间不匹配而产生的误差的内在下限。为了隔离和量化这种影响，我们考虑使用制造的解析解的一维粘性伯格斯方程，这使得能够完全控制数据保真度和残差。 PINN 使用数值精度逐渐提高的数据集以及完全一致的分析数据进行训练。结果表明，虽然包含 PDE 残差允许 PINN 部分减轻低保真度数据并恢复主要物理结构，但训练过程最终会在数据不一致所决定的错误水平上饱和。当采用高保真数值数据时，PINN 解决方案与分析数据训练的解决方案变得无法区分，这表明一致性障碍已被有效消除。这些发现阐明了 PINN 中数据质量和物理执行之间的相互作用，为构建和解释基于物理的替代模型提供了实用指导。

</details>

---

## 91. dnaHNet: A Scalable and Hierarchical Foundation Model for Genomic Sequence Learning

**中文标题**: dnaHNet：基因组序列学习的可扩展和分层基础模型

**Date**: 2026-02-11 | **arXiv**: [2602.10603v1](http://arxiv.org/abs/2602.10603v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10603v1)

<details><summary><b>Abstract</b></summary>

Genomic foundation models have the potential to decode DNA syntax, yet face a fundamental tradeoff in their input representation. Standard fixed-vocabulary tokenizers fragment biologically meaningful motifs such as codons and regulatory elements, while nucleotide-level models preserve biological coherence but incur prohibitive computational costs for long contexts. We introduce dnaHNet, a state-of-the-art tokenizer-free autoregressive model that segments and models genomic sequences end-to-end. Using a differentiable dynamic chunking mechanism, dnaHNet compresses raw nucleotides into latent tokens adaptively, balancing compression with predictive accuracy. Pretrained on prokaryotic genomes, dnaHNet outperforms leading architectures including StripedHyena2 in scaling and efficiency. This recursive chunking yields quadratic FLOP reductions, enabling $>3 \times$ inference speedup over Transformers. On zero-shot tasks, dnaHNet achieves superior performance in predicting protein variant fitness and gene essentiality, while automatically discovering hierarchical biological structures without supervision. These results establish dnaHNet as a scalable, interpretable framework for next-generation genomic modeling.

</details>

<details><summary><b>中文摘要</b></summary>

基因组基础模型具有解码 DNA 语法的潜力，但在输入表示方面面临着根本性的权衡。标准的固定词汇分词器将具有生物学意义的基序（例如密码子和调控元件）片段化，而核苷酸水平模型保留了生物一致性，但在长上下文中会产生高昂的计算成本。我们引入了 dnaHNet，这是一种最先进的无分词器的自回归模型，可以端到端地对基因组序列进行分段和建模。 dnaHNet 使用可微的动态分块机制，自适应地将原始核苷酸压缩为潜在标记，平衡压缩与预测准确性。 dnaHNet 在原核基因组上进行预训练，在扩展性和效率方面优于包括 StripedHyena2 在内的领先架构。这种递归分块可减少二次方的 FLOP，从而使推理速度比 Transformer 提高 >3 倍。在零样本任务中，dnaHNet 在预测蛋白质变异适应性和基因必要性方面实现了卓越的性能，同时在无需监督的情况下自动发现分层生物结构。这些结果将 dnaHNet 确立为下一代基因组建模的可扩展、可解释的框架。

</details>

---

## 92. TRACE: Theoretical Risk Attribution under Covariate-shift Effects

**中文标题**: TRACE：协变量转移效应下的理论风险归因

**Date**: 2026-02-11 | **arXiv**: [2602.10588v1](http://arxiv.org/abs/2602.10588v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10588v1)

<details><summary><b>Abstract</b></summary>

When a source-trained model $Q$ is replaced by a model $\tilde{Q}$ trained on shifted data, its performance on the source domain can change unpredictably. To address this, we study the two-model risk change, $ΔR := R_P(\tilde{Q}) - R_P(Q)$, under covariate shift. We introduce TRACE (Theoretical Risk Attribution under Covariate-shift Effects), a framework that decomposes $|ΔR|$ into an interpretable upper bound. This decomposition disentangles the risk change into four actionable factors: two generalization gaps, a model change penalty, and a covariate shift penalty, transforming the bound into a powerful diagnostic tool for understanding why performance has changed. To make TRACE a fully computable diagnostic, we instantiate each term. The covariate shift penalty is estimated via a model sensitivity factor (from high-quantile input gradients) and a data-shift measure; we use feature-space Optimal Transport (OT) by default and provide a robust alternative using Maximum Mean Discrepancy (MMD). The model change penalty is controlled by the average output distance between the two models on the target sample. Generalization gaps are estimated on held-out data. We validate our framework in an idealized linear regression setting, showing the TRACE bound correctly captures the scaling of the true risk difference with the magnitude of the shift. Across synthetic and vision benchmarks, TRACE diagnostics are valid and maintain a strong monotonic relationship with the true performance degradation. Crucially, we derive a deployment gate score that correlates strongly with $|ΔR|$ and achieves high AUROC/AUPRC for gating decisions, enabling safe, label-efficient model replacement.

</details>

<details><summary><b>中文摘要</b></summary>

当源训练模型 $Q$ 替换为基于移位数据训练的模型 $\tilde{Q}$ 时，其在源域上的性能可能会发生不可预测的变化。为了解决这个问题，我们研究了协变量偏移下的双模型风险变化 $ΔR := R_P(\tilde{Q}) - R_P(Q)$。我们引入 TRACE（协变量转移效应下的理论风险归因），这是一个将 $|ΔR|$ 分解为可解释上限的框架。这种分解将风险变化分解为四个可操作的因素：两个泛化差距、一个模型变化惩罚和一个协变量转移惩罚，将界限转变为一个强大的诊断工具，用于理解性能变化的原因。为了使 TRACE 成为完全可计算的诊断，我们实例化了每个术语。协变量移位惩罚是通过模型灵敏度因子（来自高分位数输入梯度）和数据移位度量来估计的；我们默认使用特征空间最优传输（OT），并使用最大平均差异（MMD）提供强大的替代方案。模型改变惩罚由目标样本上两个模型之间的平均输出距离控制。泛化差距是根据保留的数据估计的。我们在理想化的线性回归设置中验证了我们的框架，显示 TRACE 界限正确捕获了真实风险差异与变化幅度的比例。在综合和视觉基准测试中，TRACE 诊断是有效的，并且与真实的性能下降保持着很强的单调关系。至关重要的是，我们得出了与 $|ΔR|$ 密切相关的部署门得分，并为门控决策实现了高 AUROC/AUPRC，从而实现了安全、标签高效的模型替换。

</details>

---

## 93. Predictive-State Communication: Innovation Coding and Reconciliation under Delay

**中文标题**: 预测状态通信：延迟下的创新编码与协调

**Date**: 2026-02-11 | **arXiv**: [2602.10542v1](http://arxiv.org/abs/2602.10542v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10542v1)

<details><summary><b>Abstract</b></summary>

Shannon theory models communication as the reliable transfer of symbol sequences, with performance governed by capacity and rate-distortion limits. When both endpoints possess strong predictors -- as in modern large language models and related generative priors -- literal symbol transport is no longer the only operational regime. We propose predictive-state communication (PSC), in which the transmitter and receiver maintain an explicit shared predictive state, and the physical channel is used primarily to convey innovations, i.e., corrective information that reconciles the receiver's provisional trajectory with the transmitter's realized trajectory. This viewpoint replaces entropy-rate accounting by cross-entropy accounting under model mismatch, and it introduces feasibility constraints that depend jointly on capacity, delay, and perceptual continuity requirements; the resulting operating set is typically a bounded perception-capacity band rather than a one-sided threshold. We outline the protocol and architectural implications (state identifiers, anchors, bounded rollback, and patch-based updates) and provide a stylized illustrative example to visualize the induced feasibility region and its dependence on predictive quality.

</details>

<details><summary><b>中文摘要</b></summary>

香农理论将通信建模为符号序列的可靠传输，其性能受容量和速率失真限制控制。当两个端点都拥有强大的预测因子时（如在现代大型语言模型和相关的生成先验中），文字符号传输不再是唯一的操作机制。我们提出预测状态通信（PSC），其中发射器和接收器保持明确的共享预测状态，并且物理信道主要用于传达创新，即使接收器的临时轨迹与发射器的实现轨迹相一致的校正信息。该观点在模型失配的情况下用交叉熵核算取代了熵率核算，并引入了共同依赖于容量、延迟和感知连续性要求的可行性约束；由此产生的操作集通常是一个有界的感知能力带，而不是一个单侧阈值。我们概述了协议和架构含义（状态标识符、锚点、有界回滚和基于补丁的更新），并提供了一个程式化的说明性示例来可视化诱导的可行性区域及其对预测质量的依赖性。

</details>

---

## 94. Privacy-Utility Tradeoffs in Quantum Information Processing

**中文标题**: 量子信息处理中的隐私与效用权衡

**Date**: 2026-02-11 | **arXiv**: [2602.10510v1](http://arxiv.org/abs/2602.10510v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10510v1)

<details><summary><b>Abstract</b></summary>

When sensitive information is encoded in data, it is important to ensure the privacy of information when attempting to learn useful information from the data. There is a natural tradeoff whereby increasing privacy requirements may decrease the utility of a learning protocol. In the quantum setting of differential privacy, such tradeoffs between privacy and utility have so far remained largely unexplored. In this work, we study optimal privacy-utility tradeoffs for both generic and application-specific utility metrics when privacy is quantified by $(\varepsilon,δ)$-quantum local differential privacy. In the generic setting, we focus on optimizing fidelity and trace distance between the original state and the privatized state. We show that the depolarizing mechanism achieves the optimal utility for given privacy requirements. We then study the specific application of learning the expectation of an observable with respect to an input state when only given access to privatized states. We derive a lower bound on the number of samples of privatized data required to achieve a fixed accuracy guarantee with high probability. To prove this result, we employ existing lower bounds on private quantum hypothesis testing, thus showcasing the first operational use of them. We also devise private mechanisms that achieve optimal sample complexity with respect to the privacy parameters and accuracy parameters, demonstrating that utility can be significantly improved for specific tasks in contrast to the generic setting. In addition, we show that the number of samples required to privately learn observable expectation values scales as $Θ((\varepsilon β)^{-2})$, where $\varepsilon \in (0,1)$ is the privacy parameter and $β$ is the accuracy tolerance. We conclude by initiating the study of private classical shadows, which promise useful applications for private learning tasks.

</details>

<details><summary><b>中文摘要</b></summary>

当敏感信息被编码在数据中时，在尝试从数据中学习有用信息时确保信息的隐私非常重要。存在一种自然的权衡，即增加隐私要求可能会降低学习协议的效用。在差分隐私的量子环境中，迄今为止，隐私和实用性之间的这种权衡在很大程度上仍未得到探索。在这项工作中，我们研究了当隐私通过 $(\varepsilon,δ)$-量子局部差分隐私进行量化时，通用和特定于应用程序的效用指标的最佳隐私-效用权衡。在通用设置中，我们专注于优化原始状态和私有化状态之间的保真度和跟踪距离。我们表明，去极化机制对于给定的隐私要求实现了最佳效用。然后，我们研究当仅允许访问私有化状态时学习可观察值相对于输入状态的期望的具体应用。我们得出了以高概率实现固定精度保证所需的私有化数据样本数量的下限。为了证明这个结果，我们采用了私人量子假设检验的现有下限，从而展示了它们的首次操作用途。我们还设计了私有机制，可以在隐私参数和准确性参数方面实现最佳样本复杂性，这表明与通用设置相比，特定任务的效用可以显着提高。此外，我们还表明，私下学习可观察期望值所需的样本数量为 $θ((\varepsilon β)^{-2})$，其中 $\varepsilon \in (0,1)$ 是隐私参数，$β$ 是精度容差。最后，我们启动了私人经典阴影的研究，这有望为私人学习任务提供有用的应用。

</details>

---

## 95. Pricing Query Complexity of Multiplicative Revenue Approximation

**中文标题**: 乘法收入近似的定价查询复杂性

**Date**: 2026-02-11 | **arXiv**: [2602.10483v1](http://arxiv.org/abs/2602.10483v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10483v1)

<details><summary><b>Abstract</b></summary>

We study the pricing query complexity of revenue maximization for a single buyer whose private valuation is drawn from an unknown distribution. In this setting, the seller must learn the optimal monopoly price by posting prices and observing only binary purchase decisions, rather than the realized valuations. Prior work has established tight query complexity bounds for learning a near-optimal price with additive error $\varepsilon$ when the valuation distribution is supported on $[0,1]$. However, our understanding of how to learn a near-optimal price that achieves at least a $(1-\varepsilon)$ fraction of the optimal revenue remains limited.   In this paper, we study the pricing query complexity of the single-buyer revenue maximization problem under such multiplicative error guarantees in several settings. Observe that when pricing queries are the only source of information about the buyer's distribution, no algorithm can achieve a non-trivial approximation, since the scale of the distribution cannot be learned from pricing queries alone. Motivated by this fundamental impossibility, we consider two natural and well-motivated models that provide "scale hints": (i) a one-sample hint, in which the algorithm observes a single realized valuation before making pricing queries; and (ii) a value-range hint, in which the valuation support is known to lie within $[1, H]$. For each type of hint, we establish pricing query complexity guarantees that are tight up to polylogarithmic factors for several classes of distributions, including monotone hazard rate (MHR) distributions, regular distributions, and general distributions.

</details>

<details><summary><b>中文摘要</b></summary>

我们研究单个买家收入最大化的定价查询复杂性，其私人估值来自未知分布。在这种情况下，卖方必须通过发布价格并仅观察二元购买决策而不是已实现的估值来了解最佳垄断价格。先前的工作已经建立了严格的查询复杂性界限，用于在 $[0,1]$ 支持估值分布时学习具有附加误差 $\varepsilon$ 的接近最优价格。然而，我们对如何学习接近最优价格以实现至少 $(1-\varepsilon)$ 部分最优收入的理解仍然有限。   在本文中，我们研究了在多种设置下这种乘法误差保证下单买家收入最大化问题的定价查询复杂性。请注意，当定价查询是有关买方分布的唯一信息来源时，任何算法都无法实现非平凡的近似，因为分布的规模无法仅从定价查询中获悉。受这种根本不可能的启发，我们考虑了两种提供“规模提示”的自然且动机良好的模型：（i）单样本提示，其中算法在进行定价查询之前观察单个已实现的估值； (ii) 价值范围提示，其中已知估值支持位于 $[1, H]$ 范围内。对于每种类型的提示，我们建立了定价查询复杂性保证，该保证严格遵守几类分布的多对数因子，包括单调风险率 (MHR) 分布、正则分布和一般分布。

</details>

---

## 96. Distributed Online Convex Optimization with Nonseparable Costs and Constraints

**中文标题**: 具有不可分离成本和约束的分布式在线凸优化

**Date**: 2026-02-11 | **arXiv**: [2602.10452v1](http://arxiv.org/abs/2602.10452v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10452v1)

<details><summary><b>Abstract</b></summary>

This paper studies distributed online convex optimization with time-varying coupled constraints, motivated by distributed online control in network systems. Most prior work assumes a separability condition: the global objective and coupled constraint functions are sums of local costs and individual constraints. In contrast, we study a group of agents, networked via a communication graph, that collectively select actions to minimize a sequence of nonseparable global cost functions and to stratify nonseparable long-term constraints based on full-information feedback and intra-agent communication. We propose a distributed online primal-dual belief consensus algorithm, where each agent maintains and updates a local belief of the global collective decisions, which are repeatedly exchanged with neighboring agents. Unlike the previous consensus primal-dual algorithms under separability that ask agents to only communicate their local decisions, our belief-sharing protocol eliminates coupling between the primal consensus disagreement and the dual constraint violation, yielding sublinear regret and cumulative constraint violation (CCV) bounds, both in $O({T}^{1/2})$, where $T$ denotes the time horizon. Such a result breaks the long-standing $O(T^{3/4})$ barrier for CCV and matches the lower bound of online constrained convex optimization, indicating the online learning efficiency at the cost of communication overhead.

</details>

<details><summary><b>中文摘要</b></summary>

本文研究了具有时变耦合约束的分布式在线凸优化，其动机是网络系统中的分布式在线控制。大多数先前的工作都假设可分离条件：全局目标函数和耦合约束函数是局部成本和个体约束的总和。相比之下，我们研究一组通过通信图联网的代理，它们共同选择行动以最小化一系列不可分离的全局成本函数，并基于完整信息反馈和代理内部通信对不可分离的长期约束进行分层。我们提出了一种分布式在线原始对偶信念共识算法，其中每个智能体维护和更新全局集体决策的局部信念，并与相邻智能体重复交换。与之前的可分离性下的共识原始对偶算法要求代理仅传达其本地决策不同，我们的信念共享协议消除了原始共识分歧和对偶约束违反之间的耦合，产生次线性后悔和累积约束违反（CCV）界限，两者都在 $O({T}^{1/2})$ 中，其中 $T$ 表示时间范围。这样的结果打破了CCV长期以来的$O(T^{3/4})$障碍，并与在线约束凸优化的下限相匹配，表明以通信开销为代价的在线学习效率。

</details>

---

## 97. Chamfer-Linkage for Hierarchical Agglomerative Clustering

**中文标题**: 用于分层凝聚聚类的倒角连接

**Date**: 2026-02-11 | **arXiv**: [2602.10444v1](http://arxiv.org/abs/2602.10444v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10444v1)

<details><summary><b>Abstract</b></summary>

Hierarchical Agglomerative Clustering (HAC) is a widely-used clustering method based on repeatedly merging the closest pair of clusters, where inter-cluster distances are determined by a linkage function. Unlike many clustering methods, HAC does not optimize a single explicit global objective; clustering quality is therefore primarily evaluated empirically, and the choice of linkage function plays a crucial role in practice. However, popular classical linkages, such as single-linkage, average-linkage and Ward's method show high variability across real-world datasets and do not consistently produce high-quality clusterings in practice.   In this paper, we propose \emph{Chamfer-linkage}, a novel linkage function that measures the distance between clusters using the Chamfer distance, a popular notion of distance between point-clouds in machine learning and computer vision. We argue that Chamfer-linkage satisfies desirable concept representation properties that other popular measures struggle to satisfy. Theoretically, we show that Chamfer-linkage HAC can be implemented in $O(n^2)$ time, matching the efficiency of classical linkage functions. Experimentally, we find that Chamfer-linkage consistently yields higher-quality clusterings than classical linkages such as average-linkage and Ward's method across a diverse collection of datasets. Our results establish Chamfer-linkage as a practical drop-in replacement for classical linkage functions, broadening the toolkit for hierarchical clustering in both theory and practice.

</details>

<details><summary><b>中文摘要</b></summary>

层次聚合聚类（HAC）是一种广泛使用的聚类方法，基于重复合并最接近的一对聚类，其中聚类间的距离由链接函数确定。与许多聚类方法不同，HAC 不会优化单个显式全局目标；因此，聚类质量主要根据经验进行评估，而链接函数的选择在实践中起着至关重要的作用。然而，流行的经典链接，例如单链接、平均链接和 Ward 方法，在现实世界的数据集中表现出高度的可变性，并且在实践中并不能始终如一地产生高质量的聚类。   在本文中，我们提出了 \emph{Chamfer-linkage}，这是一种新颖的链接函数，它使用 Chamfer 距离（机器学习和计算机视觉中点云之间的距离的流行概念）来测量簇之间的距离。我们认为倒角联动满足了其他流行措施难以满足的理想概念表示属性。理论上，我们表明倒角链接 HAC 可以在 $O(n^2)$ 时间内实现，与经典链接函数的效率相匹配。通过实验，我们发现在不同的数据集中，Chamfer-linkage 始终比传统的链接（例如平均链接和 Ward 方法）产生更高质量的聚类。我们的结果将 Chamfer-linkage 确立为经典联动函数的实用替代品，在理论和实践上拓宽了层次聚类的工具包。

</details>

---

## 98. Binary Flow Matching: Prediction-Loss Space Alignment for Robust Learning

**中文标题**: 二元流匹配：用于鲁棒学习的预测损失空间对齐

**Date**: 2026-02-11 | **arXiv**: [2602.10420v1](http://arxiv.org/abs/2602.10420v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10420v1)

<details><summary><b>Abstract</b></summary>

Flow matching has emerged as a powerful framework for generative modeling, with recent empirical successes highlighting the effectiveness of signal-space prediction ($x$-prediction). In this work, we investigate the transfer of this paradigm to binary manifolds, a fundamental setting for generative modeling of discrete data. While $x$-prediction remains effective, we identify a latent structural mismatch that arises when it is coupled with velocity-based objectives ($v$-loss), leading to a time-dependent singular weighting that amplifies gradient sensitivity to approximation errors. Motivated by this observation, we formalize prediction-loss alignment as a necessary condition for flow matching training. We prove that re-aligning the objective to the signal space ($x$-loss) eliminates the singular weighting, yielding uniformly bounded gradients and enabling robust training under uniform timestep sampling without reliance on heuristic schedules. Finally, with alignment secured, we examine design choices specific to binary data, revealing a topology-dependent distinction between probabilistic objectives (e.g., cross-entropy) and geometric losses (e.g., mean squared error). Together, these results provide theoretical foundations and practical guidelines for robust flow matching on binary -- and related discrete -- domains, positioning signal-space alignment as a key principle for robust diffusion learning.

</details>

<details><summary><b>中文摘要</b></summary>

流匹配已成为生成建模的强大框架，最近的经验成功凸显了信号空间预测（$x$-预测）的有效性。在这项工作中，我们研究了这种范式到二元流形的转移，这是离散数据生成建模的基本设置。虽然$x$-预测仍然有效，但我们发现当它与基于速度的目标（$v$-loss）结合时会出现潜在的结构失配，从而导致依赖于时间的奇异权重，从而放大了对近似误差的梯度敏感性。受这一观察的启发，我们将预测损失对齐形式化为流匹配训练的必要条件。我们证明，将目标重新与信号空间（$x$-loss）对齐可以消除奇异权重，产生均匀有界的梯度，并在均匀时间步采样下实现稳健的训练，而无需依赖启发式计划。最后，在确保对齐的情况下，我们检查特定于二进制数据的设计选择，揭示概率目标（例如交叉熵）和几何损失（例如均方误差）之间依赖于拓扑的区别。总之，这些结果为二进制域和相关离散域上的鲁棒流匹配提供了理论基础和实践指南，将信号空间对齐定位为鲁棒扩散学习的关键原则。

</details>

---

## 99. Gated Removal of Normalization in Transformers Enables Stable Training and Efficient Inference

**中文标题**: Transformer 中标准化的门控去除可实现稳定的训练和高效的推理

**Date**: 2026-02-11 | **arXiv**: [2602.10408v1](http://arxiv.org/abs/2602.10408v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10408v1)

<details><summary><b>Abstract</b></summary>

Normalization is widely viewed as essential for stabilizing Transformer training. We revisit this assumption for pre-norm Transformers and ask to what extent sample-dependent normalization is needed inside Transformer blocks. We introduce TaperNorm, a drop-in replacement for RMSNorm/LayerNorm that behaves exactly like the standard normalizer early in training and then smoothly tapers to a learned sample-independent linear/affine map. A single global gate is held at $g{=}1$ during gate warmup, used to calibrate the scaling branch via EMAs, and then cosine-decayed to $g{=}0$, at which point per-token statistics vanish and the resulting fixed scalings can be folded into adjacent linear projections. Our theoretical and empirical results isolate scale anchoring as the key role played by output normalization: as a (near) $0$-homogeneous map it removes radial gradients at the output, whereas without such an anchor cross-entropy encourages unbounded logit growth (``logit chasing''). We further show that a simple fixed-target auxiliary loss on the pre-logit residual-stream scale provides an explicit alternative anchor and can aid removal of the final normalization layer. Empirically, TaperNorm matches normalized baselines under identical setups while eliminating per-token statistics and enabling these layers to be folded into adjacent linear projections at inference. On an efficiency microbenchmark, folding internal scalings yields up to $1.22\times$ higher throughput in last-token logits mode. These results take a step towards norm-free Transformers while identifying the special role output normalization plays.

</details>

<details><summary><b>中文摘要</b></summary>

标准化被广泛认为对于稳定 Transformer 训练至关重要。我们重新审视预规范 Transformer 的这一假设，并询问 Transformer 块内需要多大程度的样本相关规范化。我们引入了 TaperNorm，它是 RMSNorm/LayerNorm 的直接替代品，其行为在训练早期与标准标准化器完全相同，然后平滑地逐渐减小到学习的与样本无关的线性/仿射映射。在门预热期间，单个全局门保持在 $g{=}1$，用于通过 EMA 校准缩放分支，然后余弦衰减到 $g{=}0$，此时每个代币的统计数据消失，所得的固定缩放可以折叠到相邻的线性投影中。我们的理论和实证结果将尺度锚定作为输出归一化所发挥的关键作用：作为（接近）$0$同质映射，它消除了输出处的径向梯度，而如果没有这样的锚定，交叉熵会鼓励无界的 logit 增长（“logit 追逐”）。我们进一步表明，在 pre-logit 残差流尺度上的简单固定目标辅助损失提供了明确的替代锚点，并且可以帮助去除最终的归一化层。根据经验，TaperNorm 在相同的设置下匹配标准化基线，同时消除每个标记的统计数据，并使这些层能够在推理时折叠到相邻的线性投影中。在效率微基准测试中，折叠内部缩放在最后令牌 logits 模式下可带来高达 $1.22\times$ 的吞吐量提升。这些结果向无范数 Transformer 迈出了一步，同时确定了输出标准化所扮演的特殊角色。

</details>

---

## 100. Deep learning outperforms traditional machine learning methods in predicting childhood malnutrition: evidence from survey data

**中文标题**: 深度学习在预测儿童营养不良方面优于传统机器学习方法：调查数据的证据

**Date**: 2026-02-11 | **arXiv**: [2602.10381v1](http://arxiv.org/abs/2602.10381v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10381v1)

<details><summary><b>Abstract</b></summary>

Childhood malnutrition remains a major public health concern in Nepal and other low-resource settings, while conventional case-finding approaches are labor-intensive and frequently unavailable in remote areas. This study provides the first comprehensive assessment of machine learning and deep learning methodologies for identifying malnutrition among children under five years of age in Nepal. We systematically compared 16 algorithms spanning deep learning, gradient boosting, and traditional machine learning families, using data from the Nepal Multiple Indicator Cluster Survey (MICS) 2019. A composite malnutrition indicator was constructed by integrating stunting, wasting, and underweight status, and model performance was evaluated using ten metrics, with emphasis on F1-score and recall to account for substantial class imbalance and the high cost of failing to detect malnourished children. Among all models, TabNet demonstrated the best performance, likely attributable to its attention-based architecture, and outperformed both support vector machine and AdaBoost classifiers. A consensus feature importance analysis identified maternal education, household wealth index, and child age as the primary predictors of malnutrition, followed by geographic characteristics, vaccination status, and meal frequency. Collectively, these results demonstrate a scalable, survey-based screening framework for identifying children at elevated risk of malnutrition and for guiding targeted nutritional interventions. The proposed approach supports Nepal's progress toward the Sustainable Development Goals and offers a transferable methodological template for similar low-resource settings globally.

</details>

<details><summary><b>中文摘要</b></summary>

儿童营养不良仍然是尼泊尔和其他资源匮乏地区的一个主要公共卫生问题，而传统的病例发现方法是劳动密集型的，并且在偏远地区常常无法实现。这项研究首次对机器学习和深度学习方法进行了全面评估，以识别尼泊尔五岁以下儿童的营养不良情况。我们使用 2019 年尼泊尔多指标聚类调查 (MICS) 的数据，系统地比较了涵盖深度学习、梯度提升和传统机器学习系列的 16 种算法。通过整合发育迟缓、消瘦和体重不足状态构建了综合营养不良指标，并使用 10 个指标评估模型性能，重点是 F1 分数和召回率，以考虑严重的类别不平衡和未能检测到营养不良儿童的高昂成本。在所有模型中，TabNet 表现出了最好的性能，这可能归功于其基于注意力的架构，并且优于支持向量机和 AdaBoost 分类器。共识特征重要性分析确定孕产妇教育、家庭财富指数和儿童年龄是营养不良的主要预测因素，其次是地理特征、疫苗接种状况和进餐频率。总的来说，这些结果展示了一个可扩展的、基于调查的筛查框架，用于识别营养不良风险较高的儿童并指导有针对性的营养干预措施。拟议的方法支持尼泊尔在实现可持续发展目标方面取得进展，并为全球类似的资源匮乏环境提供了可转移的方法模板。

</details>

---

## 101. ENIGMA: EEG-to-Image in 15 Minutes Using Less Than 1% of the Parameters

**中文标题**: ENIGMA：使用不到 1% 的参数在 15 分钟内将脑电图转换为图像

**Date**: 2026-02-10 | **arXiv**: [2602.10361v1](http://arxiv.org/abs/2602.10361v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10361v1)

<details><summary><b>Abstract</b></summary>

To be practical for real-life applications, models for brain-computer interfaces must be easily and quickly deployable on new subjects, effective on affordable scanning hardware, and small enough to run locally on accessible computing resources. To directly address these current limitations, we introduce ENIGMA, a multi-subject electroencephalography (EEG)-to-Image decoding model that reconstructs seen images from EEG recordings and achieves state-of-the-art (SOTA) performance on the research-grade THINGS-EEG2 and consumer-grade AllJoined-1.6M benchmarks, while fine-tuning effectively on new subjects with as little as 15 minutes of data. ENIGMA boasts a simpler architecture and requires less than 1% of the trainable parameters necessary for previous approaches. Our approach integrates a subject-unified spatio-temporal backbone along with a set of multi-subject latent alignment layers and an MLP projector to map raw EEG signals to a rich visual latent space. We evaluate our approach using a broad suite of image reconstruction metrics that have been standardized in the adjacent field of fMRI-to-Image research, and we describe the first EEG-to-Image study to conduct extensive behavioral evaluations of our reconstructions using human raters. Our simple and robust architecture provides a significant performance boost across both research-grade and consumer-grade EEG hardware, and a substantial improvement in fine-tuning efficiency and inference cost. Finally, we provide extensive ablations to determine the architectural choices most responsible for our performance gains in both single and multi-subject cases across multiple benchmark datasets. Collectively, our work provides a substantial step towards the development of practical brain-computer interface applications.

</details>

<details><summary><b>中文摘要</b></summary>

为了在现实生活中应用，脑机接口模型必须能够轻松快速地部署在新的主题上，在经济实惠的扫描硬件上有效，并且足够小以在可访问的计算资源上本地运行。为了直接解决当前的这些限制，我们引入了 ENIGMA，这是一种多主体脑电图 (EEG) 到图像解码模型，可以重建从 EEG 记录中看到的图像，并在研究级 THINGS-EEG2 和消费级 AllJoined-1.6M 基准上实现最先进的 (SOTA) 性能，同时用短短 15 分钟的数据对新主体进行有效微调。 ENIGMA 拥有更简单的架构，所需的可训练参数不到以前方法的 1%。我们的方法集成了主题统一的时空主干以及一组多主题潜在对齐层和 MLP 投影仪，以将原始 EEG 信号映射到丰富的视觉潜在空间。我们使用一系列广泛的图像重建指标来评估我们的方法，这些指标在功能磁共振成像到图像研究的相邻领域已经标准化，并且我们描述了第一个脑电图到图像研究，以使用人类评估者对我们的重建进行广泛的行为评估。我们简单而强大的架构显着提升了研究级和消费级脑电图硬件的性能，并显着提高了微调效率和推理成本。最后，我们提供了广泛的消融，以确定在跨多个基准数据集的单主题和多主题案例中最能提高性能的架构选择。总的来说，我们的工作为开发实用的脑机接口应用程序迈出了实质性的一步。

</details>

---

## 102. Uncertainty-Aware Ordinal Deep Learning for cross-Dataset Diabetic Retinopathy Grading

**中文标题**: 用于跨数据集糖尿病视网膜病变分级的不确定性有序深度学习

**Date**: 2026-02-10 | **arXiv**: [2602.10315v1](http://arxiv.org/abs/2602.10315v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10315v1)

<details><summary><b>Abstract</b></summary>

Diabetes mellitus is a chronic metabolic disorder characterized by persistent hyperglycemia due to insufficient insulin production or impaired insulin utilization. One of its most severe complications is diabetic retinopathy (DR), a progressive retinal disease caused by microvascular damage, leading to hemorrhages, exudates, and potential vision loss. Early and reliable detection of DR is therefore critical for preventing irreversible blindness.   In this work, we propose an uncertainty-aware deep learning framework for automated DR severity grading that explicitly models the ordinal nature of disease progression. Our approach combines a convolutional backbone with lesion-query attention pooling and an evidential Dirichlet-based ordinal regression head, enabling both accurate severity prediction and principled estimation of predictive uncertainty. The model is trained using an ordinal evidential loss with annealed regularization to encourage calibrated confidence under domain shift.   We evaluate the proposed method on a multi-domain training setup combining APTOS, Messidor-2, and a subset of EyePACS fundus datasets. Experimental results demonstrate strong cross-dataset generalization, achieving competitive classification accuracy and high quadratic weighted kappa on held-out test sets, while providing meaningful uncertainty estimates for low-confidence cases. These results suggest that ordinal evidential learning is a promising direction for robust and clinically reliable diabetic retinopathy grading.

</details>

<details><summary><b>中文摘要</b></summary>

糖尿病是一种慢性代谢性疾病，其特征是由于胰岛素产生不足或胰岛素利用受损而导致持续高血糖。其最严重的并发症之一是糖尿病视网膜病变（DR），这是一种由微血管损伤引起的进行性视网膜疾病，导致出血、渗出和潜在的视力丧失。因此，早期、可靠地检测 DR 对于预防不可逆性失明至关重要。   在这项工作中，我们提出了一种用于自动 DR 严重程度分级的不确定性感知深度学习框架，该框架明确地模拟了疾病进展的顺序性质。我们的方法将卷积骨干与病变查询注意力池和基于证据狄利克雷的序数回归头相结合，从而实现准确的严重性预测和预测不确定性的原则估计。该模型使用序数证据损失和退火正则化进行训练，以鼓励域转移下的校准置信度。   我们在结合 APTOS、Messidor-2 和 EyePACS 眼底数据集子集的多域训练设置上评估所提出的方法。实验结果证明了强大的跨数据集泛化能力，在保留的测试集上实现了有竞争力的分类精度和高二次加权 kappa，同时为低置信度案例提供了有意义的不确定性估计。这些结果表明，有序证据学习是稳健且临床可靠的糖尿病视网膜病变分级的一个有前途的方向。

</details>

---

## 103. ERGO: Excess-Risk-Guided Optimization for High-Fidelity Monocular 3D Gaussian Splatting

**中文标题**: ERGO：高保真单目 3D 高斯泼溅的过度风险引导优化

**Date**: 2026-02-10 | **arXiv**: [2602.10278v1](http://arxiv.org/abs/2602.10278v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10278v1)

<details><summary><b>Abstract</b></summary>

Generating 3D content from a single image remains a fundamentally challenging and ill-posed problem due to the inherent absence of geometric and textural information in occluded regions. While state-of-the-art generative models can synthesize auxiliary views to provide additional supervision, these views inevitably contain geometric inconsistencies and textural misalignments that propagate and amplify artifacts during 3D reconstruction. To effectively harness these imperfect supervisory signals, we propose an adaptive optimization framework guided by excess risk decomposition, termed ERGO. Specifically, ERGO decomposes the optimization losses in 3D Gaussian splatting into two components, i.e., excess risk that quantifies the suboptimality gap between current and optimal parameters, and Bayes error that models the irreducible noise inherent in synthesized views. This decomposition enables ERGO to dynamically estimate the view-specific excess risk and adaptively adjust loss weights during optimization. Furthermore, we introduce geometry-aware and texture-aware objectives that complement the excess-risk-derived weighting mechanism, establishing a synergistic global-local optimization paradigm. Consequently, ERGO demonstrates robustness against supervision noise while consistently enhancing both geometric fidelity and textural quality of the reconstructed 3D content. Extensive experiments on the Google Scanned Objects dataset and the OmniObject3D dataset demonstrate the superiority of ERGO over existing state-of-the-art methods.

</details>

<details><summary><b>中文摘要</b></summary>

由于遮挡区域固有地缺乏几何和纹理信息，从单个图像生成 3D 内容仍然是一个根本性的挑战和不适定问题。虽然最先进的生成模型可以合成辅助视图来提供额外的监督，但这些视图不可避免地包含几何不一致和纹理错位，这些不一致和纹理错位会在 3D 重建过程中传播和放大伪影。为了有效地利用这些不完善的监管信号，我们提出了一种以过度风险分解为指导的自适应优化框架，称为 ERGO。具体来说，ERGO 将 3D 高斯分布中的优化损失分解为两个部分，即量化当前参数和最优参数之间的次优差距的超额风险，以及对合成视图中固有的不可约噪声进行建模的贝叶斯误差。这种分解使 ERGO 能够动态估计视图特定的超额风险，并在优化过程中自适应调整损失权重。此外，我们引入了几何感知和纹理感知目标，补充了过度风险衍生的加权机制，建立了协同的全局局部优化范例。因此，ERGO 展示了针对监督噪声的鲁棒性，同时持续增强重建 3D 内容的几何保真度和纹理质量。对 Google Scanned Objects 数据集和 OmniObject3D 数据集的大量实验证明了 ERGO 相对于现有最先进方法的优越性。

</details>

---

## 104. Colorimeter-Supervised Skin Tone Estimation from Dermatoscopic Images for Fairness Auditing

**中文标题**: 色度计监督下的皮肤镜图像肤色估计，用于公平性审核

**Date**: 2026-02-10 | **arXiv**: [2602.10265v1](http://arxiv.org/abs/2602.10265v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10265v1)

<details><summary><b>Abstract</b></summary>

Neural-network-based diagnosis from dermatoscopic images is increasingly used for clinical decision support, yet studies report performance disparities across skin tones. Fairness auditing of these models is limited by the lack of reliable skin-tone annotations in public dermatoscopy datasets. We address this gap with neural networks that predict Fitzpatrick skin type via ordinal regression and the Individual Typology Angle (ITA) via color regression, using in-person Fitzpatrick labels and colorimeter measurements as targets. We further leverage extensive pretraining on synthetic and real dermatoscopic and clinical images. The Fitzpatrick model achieves agreement comparable to human crowdsourced annotations, and ITA predictions show high concordance with colorimeter-derived ITA, substantially outperforming pixel-averaging approaches. Applying these estimators to ISIC 2020 and MILK10k, we find that fewer than 1% of subjects belong to Fitzpatrick types V and VI. We release code and pretrained models as an open-source tool for rapid skin-tone annotation and bias auditing. This is, to our knowledge, the first dermatoscopic skin-tone estimation neural network validated against colorimeter measurements, and it supports growing evidence of clinically relevant performance gaps across skin-tone groups.

</details>

<details><summary><b>中文摘要</b></summary>

基于皮肤镜图像的神经网络诊断越来越多地用于临床决策支持，但研究报告了不同肤色的性能差异。由于公共皮肤镜数据集中缺乏可靠的肤色注释，这些模型的公平性审核受到限制。我们通过神经网络解决了这一差距，该神经网络通过序数回归预测菲茨帕特里克皮肤类型，并通过颜色回归预测个体类型学角度（ITA），并使用现场菲茨帕特里克标签和色度计测量作为目标。我们进一步利用对合成和真实皮肤镜和临床图像的广泛预训练。 Fitzpatrick 模型达到了与人类众包注释相当的一致性，ITA 预测与色度计衍生的 ITA 高度一致，大大优于像素平均方法。将这些估计量应用于 ISIC 2020 和 MILK10k，我们发现不到 1% 的受试者属于 Fitzpatrick V 型和 VI 型。我们发布代码和预训练模型作为开源工具，用于快速肤色注释和偏差审核。据我们所知，这是第一个针对色度计测量进行验证的皮肤镜肤色估计神经网络，并且它支持了越来越多的证据表明不同肤色群体之间的临床相关性能差距。

</details>

---

## 105. DEGMC: Denoising Diffusion Models Based on Riemannian Equivariant Group Morphological Convolutions

**中文标题**: DEGMC：基于黎曼等变群形态卷积的去噪扩散模型

**Date**: 2026-02-10 | **arXiv**: [2602.10221v1](http://arxiv.org/abs/2602.10221v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10221v1)

<details><summary><b>Abstract</b></summary>

In this work, we address two major issues in recent Denoising Diffusion Probabilistic Models (DDPM): {\bf 1)} geometric key feature extraction and {\bf 2)} network equivariance. Since the DDPM prediction network relies on the U-net architecture, which is theoretically only translation equivariant, we introduce a geometric approach combined with an equivariance property of the more general Euclidean group, which includes rotations, reflections, and permutations. We introduce the notion of group morphological convolutions in Riemannian manifolds, which are derived from the viscosity solutions of first-order Hamilton-Jacobi-type partial differential equations (PDEs) that act as morphological multiscale dilations and erosions. We add a convection term to the model and solve it using the method of characteristics. This helps us better capture nonlinearities, represent thin geometric structures, and incorporate symmetries into the learning process. Experimental results on the MNIST, RotoMNIST, and CIFAR-10 datasets show noticeable improvements compared to the baseline DDPM model.

</details>

<details><summary><b>中文摘要</b></summary>

在这项工作中，我们解决了最近的去噪扩散概率模型（DDPM）中的两个主要问题：{\bf 1)}几何关键特征提取和{\bf 2)}网络等方差。由于 DDPM 预测网络依赖于 U-net 架构，理论上只是平移等变，因此我们引入了一种与更一般的欧几里得群的等变属性相结合的几何方法，其中包括旋转、反射和排列。我们在黎曼流形中引入群形态卷积的概念，该概念源自一阶 Hamilton-Jacobi 型偏微分方程 (PDE) 的粘度解，充当形态多尺度膨胀和腐蚀。我们在模型中添加对流项并使用特征方法求解。这有助于我们更好地捕捉非线性，表示薄的几何结构，并将对称性纳入学习过程。与基线 DDPM 模型相比，MNIST、RotoMNIST 和 CIFAR-10 数据集上的实验结果显示出显着的改进。

</details>

---

## 106. When the Prompt Becomes Visual: Vision-Centric Jailbreak Attacks for Large Image Editing Models

**中文标题**: 当提示变得可视化时：针对大图像编辑模型的以视觉为中心的越狱攻击

**Date**: 2026-02-10 | **arXiv**: [2602.10179v1](http://arxiv.org/abs/2602.10179v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10179v1)

<details><summary><b>Abstract</b></summary>

Recent advances in large image editing models have shifted the paradigm from text-driven instructions to vision-prompt editing, where user intent is inferred directly from visual inputs such as marks, arrows, and visual-text prompts. While this paradigm greatly expands usability, it also introduces a critical and underexplored safety risk: the attack surface itself becomes visual. In this work, we propose Vision-Centric Jailbreak Attack (VJA), the first visual-to-visual jailbreak attack that conveys malicious instructions purely through visual inputs. To systematically study this emerging threat, we introduce IESBench, a safety-oriented benchmark for image editing models. Extensive experiments on IESBench demonstrate that VJA effectively compromises state-of-the-art commercial models, achieving attack success rates of up to 80.9% on Nano Banana Pro and 70.1% on GPT-Image-1.5. To mitigate this vulnerability, we propose a training-free defense based on introspective multimodal reasoning, which substantially improves the safety of poorly aligned models to a level comparable with commercial systems, without auxiliary guard models and with negligible computational overhead. Our findings expose new vulnerabilities, provide both a benchmark and practical defense to advance safe and trustworthy modern image editing systems. Warning: This paper contains offensive images created by large image editing models.

</details>

<details><summary><b>中文摘要</b></summary>

大型图像编辑模型的最新进展已将范式从文本驱动指令转变为视觉提示编辑，其中用户意图直接从视觉输入（例如标记、箭头和视觉文本提示）推断出来。虽然这种范例极大地扩展了可用性，但它也引入了一个关键的且尚未充分探索的安全风险：攻击面本身变得可见。在这项工作中，我们提出了以视觉为中心的越狱攻击（VJA），这是第一个纯粹通过视觉输入传达恶意指令的视觉到视觉越狱攻击。为了系统地研究这一新兴威胁，我们引入了 IESBench，这是一种面向图像编辑模型的安全基准。 IESBench 上的大量实验表明，VJA 有效地破坏了最先进的商业模型，在 Nano Banana Pro 上实现了高达 80.9% 的攻击成功率，在 GPT-Image-1.5 上实现了高达 70.1% 的攻击成功率。为了减轻这个漏洞，我们提出了一种基于内省多模态推理的免训练防御，它大大提高了对齐不良模型的安全性，达到与商业系统相当的水平，无需辅助防护模型，计算开销可以忽略不计。我们的研究结果暴露了新的漏洞，为推进安全可靠的现代图像编辑系统提供了基准和实际防御。警告：本文包含由大型图像编辑模型创建的令人反感的图像。

</details>

---

## 107. SAGE: Scalable Agentic 3D Scene Generation for Embodied AI

**中文标题**: SAGE：用于嵌入式 AI 的可扩展代理 3D 场景生成

**Date**: 2026-02-10 | **arXiv**: [2602.10116v1](http://arxiv.org/abs/2602.10116v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10116v1)

<details><summary><b>Abstract</b></summary>

Real-world data collection for embodied agents remains costly and unsafe, calling for scalable, realistic, and simulator-ready 3D environments. However, existing scene-generation systems often rely on rule-based or task-specific pipelines, yielding artifacts and physically invalid scenes. We present SAGE, an agentic framework that, given a user-specified embodied task (e.g., "pick up a bowl and place it on the table"), understands the intent and automatically generates simulation-ready environments at scale. The agent couples multiple generators for layout and object composition with critics that evaluate semantic plausibility, visual realism, and physical stability. Through iterative reasoning and adaptive tool selection, it self-refines the scenes until meeting user intent and physical validity. The resulting environments are realistic, diverse, and directly deployable in modern simulators for policy training. Policies trained purely on this data exhibit clear scaling trends and generalize to unseen objects and layouts, demonstrating the promise of simulation-driven scaling for embodied AI. Code, demos, and the SAGE-10k dataset can be found on the project page here: https://nvlabs.github.io/sage.

</details>

<details><summary><b>中文摘要</b></summary>

实体代理的真实世界数据收集仍然昂贵且不安全，需要可扩展、真实且可用于模拟器的 3D 环境。然而，现有的场景生成系统通常依赖于基于规则或特定于任务的管道，从而产生伪像和物理上无效的场景。我们提出了 SAGE，一个代理框架，给定用户指定的具体任务（例如，“拿起一个碗并将其放在桌子上”），它可以理解意图并自动大规模生成模拟就绪环境。该代理将多个用于布局和对象组合的生成器与评估语义合理性、视觉真实性和物理稳定性的评论家结合起来。通过迭代推理和自适应工具选择，它可以自我完善场景，直到满足用户意图和物理有效性。由此产生的环境是真实的、多样化的，并且可以直接部署在现代模拟器中进行政策培训。纯粹基于这些数据训练的策略表现出明显的扩展趋势，并推广到看不见的对象和布局，展示了模拟驱动的扩展对具体人工智能的前景。代码、演示和 SAGE-10k 数据集可以在项目页面上找到：https://nvlabs.github.io/sage。

</details>

---

## 108. Quantum Multiple Rotation Averaging

**中文标题**: 量子多次旋转平均

**Date**: 2026-02-10 | **arXiv**: [2602.10115v1](http://arxiv.org/abs/2602.10115v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10115v1)

<details><summary><b>Abstract</b></summary>

Multiple rotation averaging (MRA) is a fundamental optimization problem in 3D vision and robotics that aims to recover globally consistent absolute rotations from noisy relative measurements. Established classical methods, such as L1-IRLS and Shonan, face limitations including local minima susceptibility and reliance on convex relaxations that fail to preserve the exact manifold geometry, leading to reduced accuracy in high-noise scenarios. We introduce IQARS (Iterative Quantum Annealing for Rotation Synchronization), the first algorithm that reformulates MRA as a sequence of local quadratic non-convex sub-problems executable on quantum annealers after binarization, to leverage inherent hardware advantages. IQARS removes convex relaxation dependence and better preserves non-Euclidean rotation manifold geometry while leveraging quantum tunneling and parallelism for efficient solution space exploration. We evaluate IQARS's performance on synthetic and real-world datasets. While current annealers remain in their nascent phase and only support solving problems of limited scale with constrained performance, we observed that IQARS on D-Wave annealers can already achieve ca. 12% higher accuracy than Shonan, i.e., the best-performing classical method evaluated empirically.

</details>

<details><summary><b>中文摘要</b></summary>

多次旋转平均 (MRA) 是 3D 视觉和机器人技术中的一个基本优化问题，旨在从嘈杂的相对测量中恢复全局一致的绝对旋转。已建立的经典方法（例如 L1-IRLS 和 Shonan）面临局限性，包括局部最小值敏感性和对凸松弛的依赖，而凸松弛无法保留精确的流形几何形状，从而导致高噪声场景中的精度降低。我们引入了 IQARS（旋转同步迭代量子退火），这是第一个将 MRA 重新表述为二值化后在量子退火器上可执行的局部二次非凸子问题序列的算法，以利用固有的硬件优势。 IQARS 消除了凸松弛依赖性并更好地保留了非欧几里德旋转流形几何形状，同时利用量子隧道和并行性进行有效的解决方案空间探索。我们评估 IQARS 在合成数据集和真实数据集上的性能。虽然当前的退火器仍处于起步阶段，仅支持解决规模有限且性能有限的问题，但我们观察到 D-Wave 退火器上的 IQARS 已经可以实现约 100% 的性能。比湘南（根据经验评估的表现最好的经典方法）准确率高 12%。

</details>

---

## 109. ConsID-Gen: View-Consistent and Identity-Preserving Image-to-Video Generation

**中文标题**: ConsID-Gen：视图一致且保留身份的图像到视频生成

**Date**: 2026-02-10 | **arXiv**: [2602.10113v1](http://arxiv.org/abs/2602.10113v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10113v1)

<details><summary><b>Abstract</b></summary>

Image-to-Video generation (I2V) animates a static image into a temporally coherent video sequence following textual instructions, yet preserving fine-grained object identity under changing viewpoints remains a persistent challenge. Unlike text-to-video models, existing I2V pipelines often suffer from appearance drift and geometric distortion, artifacts we attribute to the sparsity of single-view 2D observations and weak cross-modal alignment. Here we address this problem from both data and model perspectives. First, we curate ConsIDVid, a large-scale object-centric dataset built with a scalable pipeline for high-quality, temporally aligned videos, and establish ConsIDVid-Bench, where we present a novel benchmarking and evaluation framework for multi-view consistency using metrics sensitive to subtle geometric and appearance deviations. We further propose ConsID-Gen, a view-assisted I2V generation framework that augments the first frame with unposed auxiliary views and fuses semantic and structural cues via a dual-stream visual-geometric encoder as well as a text-visual connector, yielding unified conditioning for a Diffusion Transformer backbone. Experiments across ConsIDVid-Bench demonstrate that ConsID-Gen consistently outperforms in multiple metrics, with the best overall performance surpassing leading video generation models like Wan2.1 and HunyuanVideo, delivering superior identity fidelity and temporal coherence under challenging real-world scenarios. We will release our model and dataset at https://myangwu.github.io/ConsID-Gen.

</details>

<details><summary><b>中文摘要</b></summary>

图像到视频生成 (I2V) 将静态图像按照文本指令动画化为时间连贯的视频序列，但在不断变化的视点下保留细粒度的对象身份仍然是一个持续的挑战。与文本到视频模型不同，现有的 I2V 管道经常遭受外观漂移和几何失真的影响，我们将这些伪影归因于单视图 2D 观察的稀疏性和弱的跨模式对齐。这里我们从数据和模型两个角度来解决这个问题。首先，我们策划 ConsIDVid，这是一个以可扩展管道构建的大规模以对象为中心的数据集，用于高质量、时间对齐的视频，并建立 ConsIDVid-Bench，在其中我们使用对细微几何和外观偏差敏感的指标，提出了一种新颖的多视图一致性基准测试和评估框架。我们进一步提出 ConsID-Gen，一种视图辅助的 I2V 生成框架，它使用未设置的辅助视图增强第一帧，并通过双流视觉几何编码器以及文本视觉连接器融合语义和结构线索，从而为 Diffusion Transformer 主干产生统一条件。 ConsIDVid-Bench 的实验表明，ConsID-Gen 在多个指标上始终表现出色，其最佳整体性能超越了 Wan2.1 和 HunyuanVideo 等领先的视频生成模型，在具有挑战性的现实场景下提供卓越的身份保真度和时间一致性。我们将在 https://myangwu.github.io/ConsID-Gen 发布我们的模型和数据集。

</details>

---

## 110. Olaf-World: Orienting Latent Actions for Video World Modeling

**中文标题**: Olaf-World：定向视频世界建模的潜在动作

**Date**: 2026-02-10 | **arXiv**: [2602.10104v1](http://arxiv.org/abs/2602.10104v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10104v1)

<details><summary><b>Abstract</b></summary>

Scaling action-controllable world models is limited by the scarcity of action labels. While latent action learning promises to extract control interfaces from unlabeled video, learned latents often fail to transfer across contexts: they entangle scene-specific cues and lack a shared coordinate system. This occurs because standard objectives operate only within each clip, providing no mechanism to align action semantics across contexts. Our key insight is that although actions are unobserved, their semantic effects are observable and can serve as a shared reference. We introduce Seq$Δ$-REPA, a sequence-level control-effect alignment objective that anchors integrated latent action to temporal feature differences from a frozen, self-supervised video encoder. Building on this, we present Olaf-World, a pipeline that pretrains action-conditioned video world models from large-scale passive video. Extensive experiments demonstrate that our method learns a more structured latent action space, leading to stronger zero-shot action transfer and more data-efficient adaptation to new control interfaces than state-of-the-art baselines.

</details>

<details><summary><b>中文摘要</b></summary>

动作可控世界模型的扩展受到动作标签稀缺的限制。虽然潜在动作学习有望从未标记的视频中提取控制界面，但学习到的潜在动作通常无法跨上下文迁移：它们纠缠了特定于场景的线索并且缺乏共享的坐标系。发生这种情况是因为标准目标仅在每个剪辑内运行，没有提供跨上下文对齐动作语义的机制。我们的主要见解是，虽然动作是不可观察的，但它们的语义效果是可观察的并且可以作为共享参考。我们引入了 Seq$Δ$-REPA，这是一种序列级控制效果对齐目标，它将集成的潜在动作锚定到来自冻结的自监督视频编码器的时间特征差异。在此基础上，我们提出了 Olaf-World，这是一个从大规模被动视频中预训练动作条件视频世界模型的管道。大量的实验表明，我们的方法学习了一个更加结构化的潜在动作空间，与最先进的基线相比，可以实现更强的零样本动作转移和更高效的数据适应新的控制界面。

</details>

---

## 111. VideoWorld 2: Learning Transferable Knowledge from Real-world Videos

**中文标题**: VideoWorld 2：从现实世界的视频中学习可转移的知识

**Date**: 2026-02-10 | **arXiv**: [2602.10102v1](http://arxiv.org/abs/2602.10102v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10102v1)

<details><summary><b>Abstract</b></summary>

Learning transferable knowledge from unlabeled video data and applying it in new environments is a fundamental capability of intelligent agents. This work presents VideoWorld 2, which extends VideoWorld and offers the first investigation into learning transferable knowledge directly from raw real-world videos. At its core, VideoWorld 2 introduces a dynamic-enhanced Latent Dynamics Model (dLDM) that decouples action dynamics from visual appearance: a pretrained video diffusion model handles visual appearance modeling, enabling the dLDM to learn latent codes that focus on compact and meaningful task-related dynamics. These latent codes are then modeled autoregressively to learn task policies and support long-horizon reasoning. We evaluate VideoWorld 2 on challenging real-world handcraft making tasks, where prior video generation and latent-dynamics models struggle to operate reliably. Remarkably, VideoWorld 2 achieves up to 70% improvement in task success rate and produces coherent long execution videos. In robotics, we show that VideoWorld 2 can acquire effective manipulation knowledge from the Open-X dataset, which substantially improves task performance on CALVIN. This study reveals the potential of learning transferable world knowledge directly from raw videos, with all code, data, and models to be open-sourced for further research.

</details>

<details><summary><b>中文摘要</b></summary>

从未标记的视频数据中学习可转移的知识并将其应用到新环境中是智能代理的基本能力。这项工作提出了 VideoWorld 2，它扩展了 VideoWorld，并首次对直接从原始现实世界视频中学习可转移知识进行了研究。 VideoWorld 2 的核心引入了动态增强的潜在动态模型 (dLDM)，它将动作动态与视觉外观分离：预训练的视频扩散模型处理视觉外观建模，使 dLDM 能够学习专注于紧凑且有意义的任务相关动态的潜在代码。然后对这些潜在代码进行自回归建模，以学习任务策略并支持长期推理。我们在具有挑战性的现实世界手工制作任务中评估了 VideoWorld 2，其中先前的视频生成和潜在动态模型难以可靠运行。值得注意的是，VideoWorld 2 将任务成功率提高了 70%，并生成连贯的长执行视频。在机器人技术中，我们证明 VideoWorld 2 可以从 Open-X 数据集中获取有效的操作知识，这大大提高了 CALVIN 上的任务性能。这项研究揭示了直接从原始视频中学习可转移的世界知识的潜力，所有代码、数据和模型都将开源以供进一步研究。

</details>

---

## 112. VLA-JEPA: Enhancing Vision-Language-Action Model with Latent World Model

**中文标题**: VLA-JEPA：利用潜在世界模型增强视觉-语言-动作模型

**Date**: 2026-02-10 | **arXiv**: [2602.10098v1](http://arxiv.org/abs/2602.10098v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10098v1)

<details><summary><b>Abstract</b></summary>

Pretraining Vision-Language-Action (VLA) policies on internet-scale video is appealing, yet current latent-action objectives often learn the wrong thing: they remain anchored to pixel variation rather than action-relevant state transitions, making them vulnerable to appearance bias, nuisance motion, and information leakage. We introduce VLA-JEPA, a JEPA-style pretraining framework that sidesteps these pitfalls by design. The key idea is \emph{leakage-free state prediction}: a target encoder produces latent representations from future frames, while the student pathway sees only the current observation -- future information is used solely as supervision targets, never as input. By predicting in latent space rather than pixel space, VLA-JEPA learns dynamics abstractions that are robust to camera motion and irrelevant background changes. This yields a simple two-stage recipe -- JEPA pretraining followed by action-head fine-tuning -- without the multi-stage complexity of prior latent-action pipelines. Experiments on LIBERO, LIBERO-Plus, SimplerEnv and real-world manipulation tasks show that VLA-JEPA achieves consistent gains in generalization and robustness over existing methods.

</details>

<details><summary><b>中文摘要</b></summary>

在互联网规模的视频上预训练视觉-语言-动作（VLA）策略很有吸引力，但当前的潜在动作目标经常学到错误的东西：它们仍然锚定于像素变化而不是与动作相关的状态转换，这使得它们容易受到外观偏差、令人讨厌的运动和信息泄漏的影响。我们引入了 VLA-JEPA，这是一种 JEPA 风格的预训练框架，它通过设计避开了这些陷阱。关键思想是 \emph{无泄漏状态预测}：目标编码器从未来帧生成潜在表示，而学生路径只能看到当前的观察结果 - 未来信息仅用作监督目标，从不用作输入。通过在潜在空间而不是像素空间中进行预测，VLA-JEPA 学习了对相机运动和不相关背景变化具有鲁棒性的动态抽象。这产生了一个简单的两阶段配方——JEPA 预训练，然后是动作头微调——没有先前潜在动作管道的多阶段复杂性。对 LIBERO、LIBERO-Plus、SimplerEnv 和现实世界操作任务的实验表明，VLA-JEPA 在泛化性和鲁棒性方面比现有方法取得了一致的进步。

</details>

---

## 113. Causality in Video Diffusers is Separable from Denoising

**中文标题**: 视频扩散器中的因果关系与去噪是可分离的

**Date**: 2026-02-10 | **arXiv**: [2602.10095v1](http://arxiv.org/abs/2602.10095v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10095v1)

<details><summary><b>Abstract</b></summary>

Causality -- referring to temporal, uni-directional cause-effect relationships between components -- underlies many complex generative processes, including videos, language, and robot trajectories. Current causal diffusion models entangle temporal reasoning with iterative denoising, applying causal attention across all layers, at every denoising step, and over the entire context. In this paper, we show that the causal reasoning in these models is separable from the multi-step denoising process. Through systematic probing of autoregressive video diffusers, we uncover two key regularities: (1) early layers produce highly similar features across denoising steps, indicating redundant computation along the diffusion trajectory; and (2) deeper layers exhibit sparse cross-frame attention and primarily perform intra-frame rendering. Motivated by these findings, we introduce Separable Causal Diffusion (SCD), a new architecture that explicitly decouples once-per-frame temporal reasoning, via a causal transformer encoder, from multi-step frame-wise rendering, via a lightweight diffusion decoder. Extensive experiments on both pretraining and post-training tasks across synthetic and real benchmarks show that SCD significantly improves throughput and per-frame latency while matching or surpassing the generation quality of strong causal diffusion baselines.

</details>

<details><summary><b>中文摘要</b></summary>

因果关系——指的是组件之间的时间性、单向因果关系——是许多复杂生成过程的基础，包括视频、语言和机器人轨迹。当前的因果扩散模型将时间推理与迭代去噪结合起来，在所有层、每个去噪步骤以及整个上下文中应用因果注意力。在本文中，我们证明这些模型中的因果推理与多步骤去噪过程是可分离的。通过对自回归视频扩散器的系统探测，我们发现了两个关键规律：（1）早期层在去噪步骤中产生高度相似的特征，表明沿扩散轨迹的冗余计算； （2）更深的层表现出稀疏的跨帧注意力，并且主要执行帧内渲染。受这些发现的启发，我们引入了可分离因果扩散（SCD），这是一种新架构，它通过因果变换编码器将每帧一次的时间推理与通过轻量级扩散解码器的多步逐帧渲染明确解耦。对合成基准和真实基准的训练前和训练后任务进行的大量实验表明，SCD 显着提高了吞吐量和每帧延迟，同时匹配或超越了强因果扩散基准的生成质量。

</details>

---

## 114. 4RC: 4D Reconstruction via Conditional Querying Anytime and Anywhere

**中文标题**: 4RC：随时随地条件查询4D重建

**Date**: 2026-02-10 | **arXiv**: [2602.10094v1](http://arxiv.org/abs/2602.10094v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10094v1)

<details><summary><b>Abstract</b></summary>

We present 4RC, a unified feed-forward framework for 4D reconstruction from monocular videos. Unlike existing approaches that typically decouple motion from geometry or produce limited 4D attributes such as sparse trajectories or two-view scene flow, 4RC learns a holistic 4D representation that jointly captures dense scene geometry and motion dynamics. At its core, 4RC introduces a novel encode-once, query-anywhere and anytime paradigm: a transformer backbone encodes the entire video into a compact spatio-temporal latent space, from which a conditional decoder can efficiently query 3D geometry and motion for any query frame at any target timestamp. To facilitate learning, we represent per-view 4D attributes in a minimally factorized form by decomposing them into base geometry and time-dependent relative motion. Extensive experiments demonstrate that 4RC outperforms prior and concurrent methods across a wide range of 4D reconstruction tasks.

</details>

<details><summary><b>中文摘要</b></summary>

我们提出了 4RC，一个用于单目视频 4D 重建的统一前馈框架。与通常将运动与几何体解耦或产生有限的 4D 属性（例如稀疏轨迹或双视图场景流）的现有方法不同，4RC 学习联合捕获密集场景几何体和运动动力学的整体 4D 表示。 4RC 的核心引入了一种新颖的一次编码、随时随地查询的范例：变压器主干将整个视频编码到紧凑的时空潜在空间中，条件解码器可以从中有效地查询任何目标时间戳处任何查询帧的 3D 几何和运动。为了便于学习，我们通过将每个视图的 4D 属性分解为基本几何形状和与时间相关的相对运动，以最小分解形式表示它们。大量实验表明，4RC 在各种 4D 重建任务中均优于先前方法和并发方法。

</details>

---

## 115. Can Image Splicing and Copy-Move Forgery Be Detected by the Same Model? Forensim: An Attention-Based State-Space Approach

**中文标题**: 图像拼接和复制移动伪造可以用同一模型检测吗？ Forensim：基于注意力的状态空间方法

**Date**: 2026-02-10 | **arXiv**: [2602.10079v1](http://arxiv.org/abs/2602.10079v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10079v1)

<details><summary><b>Abstract</b></summary>

We introduce Forensim, an attention-based state-space framework for image forgery detection that jointly localizes both manipulated (target) and source regions. Unlike traditional approaches that rely solely on artifact cues to detect spliced or forged areas, Forensim is designed to capture duplication patterns crucial for understanding context. In scenarios such as protest imagery, detecting only the forged region, for example a duplicated act of violence inserted into a peaceful crowd, can mislead interpretation, highlighting the need for joint source-target localization. Forensim outputs three-class masks (pristine, source, target) and supports detection of both splicing and copy-move forgeries within a unified architecture. We propose a visual state-space model that leverages normalized attention maps to identify internal similarities, paired with a region-based block attention module to distinguish manipulated regions. This design enables end-to-end training and precise localization. Forensim achieves state-of-the-art performance on standard benchmarks. We also release CMFD-Anything, a new dataset addressing limitations of existing copy-move forgery datasets.

</details>

<details><summary><b>中文摘要</b></summary>

我们引入了 Forensim，这是一种基于注意力的状态空间框架，用于图像伪造检测，可联合定位操纵（目标）区域和源区域。与仅依靠工件线索来检测拼接或伪造区域的传统方法不同，Forensim 旨在捕获对于理解上下文至关重要的重复模式。在抗议图像等场景中，仅检测伪造区域（例如，在和平人群中插入重复的暴力行为）可能会误导解释，从而凸显了联合源目标定位的必要性。 Forensim 输出三类掩码（原始、源、目标），并支持在统一架构内检测拼接和复制移动伪造。我们提出了一种视觉状态空间模型，利用归一化注意力图来识别内部相似性，并与基于区域的块注意力模块配对来区分操纵区域。这种设计可以实现端到端训练和精确定位。 Forensim 在标准基准测试中实现了最先进的性能。我们还发布了 CMFD-Anything，这是一个新的数据集，解决了现有复制-移动伪造数据集的局限性。

</details>

---

## 116. Spatio-Temporal Attention for Consistent Video Semantic Segmentation in Automated Driving

**中文标题**: 自动驾驶中一致视频语义分割的时空注意力

**Date**: 2026-02-10 | **arXiv**: [2602.10052v1](http://arxiv.org/abs/2602.10052v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10052v1)

<details><summary><b>Abstract</b></summary>

Deep neural networks, especially transformer-based architectures, have achieved remarkable success in semantic segmentation for environmental perception. However, existing models process video frames independently, thus failing to leverage temporal consistency, which could significantly improve both accuracy and stability in dynamic scenes. In this work, we propose a Spatio-Temporal Attention (STA) mechanism that extends transformer attention blocks to incorporate multi-frame context, enabling robust temporal feature representations for video semantic segmentation. Our approach modifies standard self-attention to process spatio-temporal feature sequences while maintaining computational efficiency and requiring minimal changes to existing architectures. STA demonstrates broad applicability across diverse transformer architectures and remains effective across both lightweight and larger-scale models. A comprehensive evaluation on the Cityscapes and BDD100k datasets shows substantial improvements of 9.20 percentage points in temporal consistency metrics and up to 1.76 percentage points in mean intersection over union compared to single-frame baselines. These results demonstrate STA as an effective architectural enhancement for video-based semantic segmentation applications.

</details>

<details><summary><b>中文摘要</b></summary>

深度神经网络，特别是基于 Transformer 的架构，在环境感知的语义分割方面取得了显着的成功。然而，现有模型独立处理视频帧，因此无法利用时间一致性，而时间一致性可以显着提高动态场景的准确性和稳定性。在这项工作中，我们提出了一种时空注意力（STA）机制，该机制扩展了变压器注意块以合并多帧上下文，从而为视频语义分割提供了鲁棒的时间特征表示。我们的方法修改了标准的自注意力来处理时空特征序列，同时保持计算效率并且需要对现有架构进行最小的更改。 STA 在不同的变压器架构中展示了广泛的适用性，并且在轻量级和大型模型中仍然有效。对 Cityscapes 和 BDD100k 数据集的综合评估显示，与单帧基线相比，联合的时间一致性指标显着提高了 9.20 个百分点，平均交集提高了 1.76 个百分点。这些结果表明 STA 是基于视频的语义分割应用程序的有效架构增强。

</details>

---

## 117. Fake-HR1: Rethinking Reasoning of Vision Language Model for Synthetic Image Detection

**中文标题**: Fake-HR1：重新思考用于合成图像检测的视觉语言模型的推理

**Date**: 2026-02-10 | **arXiv**: [2602.10042v2](http://arxiv.org/abs/2602.10042v2) | **PDF**: [Link](http://arxiv.org/pdf/2602.10042v2)

<details><summary><b>Abstract</b></summary>

Recent studies have demonstrated that incorporating Chain-of-Thought (CoT) reasoning into the detection process can enhance a model's ability to detect synthetic images. However, excessively lengthy reasoning incurs substantial resource overhead, including token consumption and latency, which is particularly redundant when handling obviously generated forgeries. To address this issue, we propose Fake-HR1, a large-scale hybrid-reasoning model that, to the best of our knowledge, is the first to adaptively determine whether reasoning is necessary based on the characteristics of the generative detection task. To achieve this, we design a two-stage training framework: we first perform Hybrid Fine-Tuning (HFT) for cold-start initialization, followed by online reinforcement learning with Hybrid-Reasoning Grouped Policy Optimization (HGRPO) to implicitly learn when to select an appropriate reasoning mode. Experimental results show that Fake-HR1 adaptively performs reasoning across different types of queries, surpassing existing LLMs in both reasoning ability and generative detection performance, while significantly improving response efficiency.

</details>

<details><summary><b>中文摘要</b></summary>

最近的研究表明，将思想链 (CoT) 推理纳入检测过程可以增强模型检测合成图像的能力。然而，过长的推理会带来大量的资源开销，包括令牌消耗和延迟，这在处理明显生成的伪造时尤其多余。为了解决这个问题，我们提出了 Fake-HR1，这是一种大规模混合推理模型，据我们所知，它是第一个根据生成检测任务的特征自适应地确定是否需要推理的模型。为了实现这一目标，我们设计了一个两阶段的训练框架：我们首先执行混合微调（HFT）进行冷启动初始化，然后使用混合推理分组策略优化（HGRPO）进行在线强化学习，以隐式学习何时选择合适的推理模式。实验结果表明，Fake-HR1能够自适应地跨不同类型的查询进行推理，在推理能力和生成检测性能上都超越了现有的LLM，同时显着提高了响应效率。

</details>

---

## 118. Faster-GS: Analyzing and Improving Gaussian Splatting Optimization

**中文标题**: Faster-GS：分析和改进高斯泼溅优化

**Date**: 2026-02-10 | **arXiv**: [2602.09999v1](http://arxiv.org/abs/2602.09999v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09999v1)

<details><summary><b>Abstract</b></summary>

Recent advances in 3D Gaussian Splatting (3DGS) have focused on accelerating optimization while preserving reconstruction quality. However, many proposed methods entangle implementation-level improvements with fundamental algorithmic modifications or trade performance for fidelity, leading to a fragmented research landscape that complicates fair comparison. In this work, we consolidate and evaluate the most effective and broadly applicable strategies from prior 3DGS research and augment them with several novel optimizations. We further investigate underexplored aspects of the framework, including numerical stability, Gaussian truncation, and gradient approximation. The resulting system, Faster-GS, provides a rigorously optimized algorithm that we evaluate across a comprehensive suite of benchmarks. Our experiments demonstrate that Faster-GS achieves up to 5$\times$ faster training while maintaining visual quality, establishing a new cost-effective and resource efficient baseline for 3DGS optimization. Furthermore, we demonstrate that optimizations can be applied to 4D Gaussian reconstruction, leading to efficient non-rigid scene optimization.

</details>

<details><summary><b>中文摘要</b></summary>

3D 高斯分布 (3DGS) 的最新进展集中于加速优化，同时保持重建质量。然而，许多提出的方法将实现级别的改进与基本算法修改或保真度性能的交易纠缠在一起，导致研究环境分散，使公平比较变得复杂。在这项工作中，我们整合和评估了先前 3DGS 研究中最有效和最广泛适用的策略，并通过几种新颖的优化对其进行了增强。我们进一步研究了该框架尚未开发的方面，包括数值稳定性、高斯截断和梯度近似。由此产生的系统 Faster-GS 提供了严格优化的算法，我们通过一套全面的基准测试对其进行评估。我们的实验表明，Faster-GS 在保持视觉质量的同时实现了高达 5 美元\倍的训练速度，为 3DGS 优化建立了新的经济高效且资源高效的基准。此外，我们证明优化可以应用于 4D 高斯重建，从而实现高效的非刚性场景优化。

</details>

---

## 119. Efficient Special Stain Classification

**中文标题**: 高效的特殊染色分类

**Date**: 2026-02-10 | **arXiv**: [2602.09989v1](http://arxiv.org/abs/2602.09989v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09989v1)

<details><summary><b>Abstract</b></summary>

Stains are essential in histopathology to visualize specific tissue characteristics, with Haematoxylin and Eosin (H&E) serving as the clinical standard. However, pathologists frequently   utilize a variety of special stains for the diagnosis of specific morphologies. Maintaining accurate metadata for these slides is critical for quality control in clinical archives and for   the integrity of computational pathology datasets. In this work, we compare two approaches for automated classification of stains using whole slide images, covering the 14 most commonly   used special stains in our institute alongside standard and frozen-section H&E. We evaluate a Multi-Instance Learning (MIL) pipeline and a proposed lightweight thumbnail-based approach.   On internal test data, MIL achieved the highest performance (macro F1: 0.941 for 16 classes; 0.969 for 14 merged classes), while the thumbnail approach remained competitive (0.897 and   0.953, respectively). On external TCGA data, the thumbnail model generalized best (weighted F1: 0.843 vs. 0.807 for MIL). The thumbnail approach also increased throughput by two orders of   magnitude (5.635 vs. 0.018 slides/s for MIL with all patches). We conclude that thumbnail-based classification provides a scalable and robust solution for routine visual quality control   in digital pathology workflows.

</details>

<details><summary><b>中文摘要</b></summary>

染色对于组织病理学中观察特定组织特征至关重要，苏木精和曙红 (H&E) 是临床标准。然而，病理学家经常利用各种特殊染色来诊断特定形态。维护这些载玻片的准确元数据对于临床档案的质量控制和计算病理学数据集的完整性至关重要。在这项工作中，我们比较了两种使用整个载玻片图像自动分类染色剂的方法，涵盖了我们研究所最常用的 14 种特殊染色剂以及标准和冰冻切片 H&E。我们评估了多实例学习（MIL）管道和提出的轻量级基于缩略图的方法。   在内部测试数据上，MIL 实现了最高性能（宏观 F1：16 个类别为 0.941；14 个合并类别为 0.969），而缩略图方法仍然具有竞争力（分别为 0.897 和 0.953）。在外部 TCGA 数据上，缩略图模型概括性最好（加权 F1：0.843 对比 MIL 的 0.807）。缩略图方法还将吞吐量提高了两个数量级（对于具有所有补丁的 MIL，吞吐量为 5.635 vs. 0.018 幻灯片/秒）。我们的结论是，基于缩略图的分类为数字病理工作流程中的常规视觉质量控制提供了可扩展且强大的解决方案。

</details>

---

## 120. Online Monitoring Framework for Automotive Time Series Data using JEPA Embeddings

**中文标题**: 使用 JEPA 嵌入的汽车时间序列数据在线监控框架

**Date**: 2026-02-10 | **arXiv**: [2602.09985v1](http://arxiv.org/abs/2602.09985v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09985v1)

<details><summary><b>Abstract</b></summary>

As autonomous vehicles are rolled out, measures must be taken to ensure their safe operation. In order to supervise a system that is already in operation, monitoring frameworks are frequently employed. These run continuously online in the background, supervising the system status and recording anomalies. This work proposes an online monitoring framework to detect anomalies in object state representations. Thereby, a key challenge is creating a framework for anomaly detection without anomaly labels, which are usually unavailable for unknown anomalies. To address this issue, this work applies a self-supervised embedding method to translate object data into a latent representation space. For this, a JEPA-based self-supervised prediction task is constructed, allowing training without anomaly labels and the creation of rich object embeddings. The resulting expressive JEPA embeddings serve as input for established anomaly detection methods, in order to identify anomalies within object state representations. This framework is particularly useful for applications in real-world environments, where new or unknown anomalies may occur during operation for which there are no labels available. Experiments performed on the publicly available, real-world nuScenes dataset illustrate the framework's capabilities.

</details>

<details><summary><b>中文摘要</b></summary>

随着自动驾驶汽车的推出，必须采取措施确保其安全运行。为了监控已经运行的系统，经常使用监控框架。它们在后台持续在线运行，监控系统状态并记录异常情况。这项工作提出了一种在线监控框架来检测对象状态表示中的异常情况。因此，一个关键的挑战是创建一个没有异常标签的异常检测框架，而异常标签通常无法用于未知异常。为了解决这个问题，这项工作应用了自监督嵌入方法将对象数据转换为潜在表示空间。为此，构建了一个基于 JEPA 的自监督预测任务，允许在没有异常标签的情况下进行训练并创建丰富的对象嵌入。由此产生的富有表现力的 JEPA 嵌入可作为已建立的异常检测方法的输入，以便识别对象状态表示中的异常。该框架对于现实环境中的应用程序特别有用，在现实环境中，在没有可用标签的操作过程中可能会出现新的或未知的异常情况。在公开的真实 nuScenes 数据集上进行的实验说明了该框架的功能。

</details>

---

## 121. Coupled Inference in Diffusion Models for Semantic Decomposition

**中文标题**: 语义分解扩散模型中的耦合推理

**Date**: 2026-02-10 | **arXiv**: [2602.09983v1](http://arxiv.org/abs/2602.09983v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09983v1)

<details><summary><b>Abstract</b></summary>

Many visual scenes can be described as compositions of latent factors. Effective recognition, reasoning, and editing often require not only forming such compositional representations, but also solving the decomposition problem. One popular choice for constructing these representations is through the binding operation. Resonator networks, which can be understood as coupled Hopfield networks, were proposed as a way to perform decomposition on such bound representations. Recent works have shown notable similarities between Hopfield networks and diffusion models. Motivated by these observations, we introduce a framework for semantic decomposition using coupled inference in diffusion models. Our method frames semantic decomposition as an inverse problem and couples the diffusion processes using a reconstruction-driven guidance term that encourages the composition of factor estimates to match the bound vector. We also introduce a novel iterative sampling scheme that improves the performance of our model. Finally, we show that attention-based resonator networks are a special case of our framework. Empirically, we demonstrate that our coupled inference framework outperforms resonator networks across a range of synthetic semantic decomposition tasks.

</details>

<details><summary><b>中文摘要</b></summary>

许多视觉场景可以被描述为潜在因素的组合。有效的识别、推理和编辑通常不仅需要形成这种组合表示，还需要解决分解问题。构建这些表示的一种流行选择是通过绑定操作。谐振器网络可以理解为耦合的 Hopfield 网络，被提出作为对此类边界表示进行分解的一种方法。最近的研究表明 Hopfield 网络和扩散模型之间存在显着的相似之处。受这些观察的启发，我们引入了在扩散模型中使用耦合推理进行语义分解的框架。我们的方法将语义分解构建为逆问题，并使用重建驱动的指导项耦合扩散过程，该指导项鼓励因子估计的组合以匹配边界向量。我们还引入了一种新颖的迭代采样方案，可以提高模型的性能。最后，我们表明基于注意力的谐振器网络是我们框架的一个特例。根据经验，我们证明我们的耦合推理框架在一系列合成语义分解任务中优于谐振器网络。

</details>

---

## 122. Learning to Detect Baked Goods with Limited Supervision

**中文标题**: 学习在有限的监督下检测烘焙食品

**Date**: 2026-02-10 | **arXiv**: [2602.09979v1](http://arxiv.org/abs/2602.09979v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09979v1)

<details><summary><b>Abstract</b></summary>

Monitoring leftover products provides valuable insights that can be used to optimize future production. This is especially important for German bakeries because freshly baked goods have a very short shelf life. Automating this process can reduce labor costs, improve accuracy, and streamline operations. We propose automating this process using an object detection model to identify baked goods from images. However, the large diversity of German baked goods makes fully supervised training prohibitively expensive and limits scalability. Although open-vocabulary detectors (e.g., OWLv2, Grounding DINO) offer lexibility, we demonstrate that they are insufficient for our task. While motivated by bakeries, our work addresses the broader challenges of deploying computer vision in industries, where tasks are specialized and annotated datasets are scarce. We compile dataset splits with varying supervision levels, covering 19 classes of baked goods. We propose two training workflows to train an object detection model with limited supervision. First, we combine OWLv2 and Grounding DINO localization with image-level supervision to train the model in a weakly supervised manner. Second, we improve viewpoint robustness by fine-tuning on video frames annotated using Segment Anything 2 as a pseudo-label propagation model. Using these workflows, we train YOLOv11 for our detection task due to its favorable speed accuracy tradeoff. Relying solely on image-level supervision, the model achieves a mean Average Precision (mAP) of 0.91. Finetuning with pseudo-labels raises model performance by 19.3% under non-ideal deployment conditions. Combining these workflows trains a model that surpasses our fully-supervised baseline model under non-ideal deployment conditions, despite relying only on image-level supervision.

</details>

<details><summary><b>中文摘要</b></summary>

监控剩余产品​​可以提供宝贵的见解，可用于优化未来的生产。这对于德国面包店尤其重要，因为新鲜烘焙的食品保质期很短。自动化此过程可以降低劳动力成本、提高准确性并简化操作。我们建议使用对象检测模型来自动化此过程，以从图像中识别烘焙食品。然而，德国烘焙食品的多样性使得完全监督的培训成本高昂，并且限制了可扩展性。尽管开放词汇检测器（例如 OWLv2、Grounding DINO）提供了灵活性，但我们证明它们不足以完成我们的任务。虽然受到面包店的推动，但我们的工作解决了在行业中部署计算机视觉的更广泛的挑战，这些行业的任务是专业化的，并且带注释的数据集稀缺。我们编译了具有不同监督级别的数据集分割，涵盖 19 类烘焙食品。我们提出了两种训练工作流程来训练具有有限监督的对象检测模型。首先，我们将 OWLv2 和 Grounding DINO 定位与图像级监督相结合，以弱监督的方式训练模型。其次，我们通过对使用 Segment Anything 2 作为伪标签传播模型注释的视频帧进行微调来提高视点鲁棒性。使用这些工作流程，我们训练 YOLOv11 来完成我们的检测任务，因为它具有有利的速度精度权衡。仅依靠图像级监督，该模型的平均精度 (mAP) 为 0.91。在非理想部署条件下，使用伪标签进行微调可将模型性能提高 19.3%。结合这些工作流程可以训练出一个模型，该模型在非理想部署条件下超越了我们完全监督的基线模型，尽管仅依赖于图像级监督。

</details>

---

## 123. Bladder Vessel Segmentation using a Hybrid Attention-Convolution Framework

**中文标题**: 使用混合注意力卷积框架的膀胱血管分割

**Date**: 2026-02-10 | **arXiv**: [2602.09949v1](http://arxiv.org/abs/2602.09949v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09949v1)

<details><summary><b>Abstract</b></summary>

Urinary bladder cancer surveillance requires tracking tumor sites across repeated interventions, yet the deformable and hollow bladder lacks stable landmarks for orientation. While blood vessels visible during endoscopy offer a patient-specific "vascular fingerprint" for navigation, automated segmentation is challenged by imperfect endoscopic data, including sparse labels, artifacts like bubbles or variable lighting, continuous deformation, and mucosal folds that mimic vessels. State-of-the-art vessel segmentation methods often fail to address these domain-specific complexities. We introduce a Hybrid Attention-Convolution (HAC) architecture that combines Transformers to capture global vessel topology prior with a CNN that learns a residual refinement map to precisely recover thin-vessel details. To prioritize structural connectivity, the Transformer is trained on optimized ground truth data that exclude short and terminal branches. Furthermore, to address data scarcity, we employ a physics-aware pretraining, that is a self-supervised strategy using clinically grounded augmentations on unlabeled data. Evaluated on the BlaVeS dataset, consisting of endoscopic video frames, our approach achieves high accuracy (0.94) and superior precision (0.61) and clDice (0.66) compared to state-of-the-art medical segmentation models. Crucially, our method successfully suppresses false positives from mucosal folds that dynamically appear and vanish as the bladder fills and empties during surgery. Hence, HAC provides the reliable structural stability required for clinical navigation.

</details>

<details><summary><b>中文摘要</b></summary>

膀胱癌监测需要通过重复干预来跟踪肿瘤部位，但可变形且中空的膀胱缺乏稳定的定位标志。虽然内窥镜检查期间可见的血管为导航提供了患者特定的“血管指纹”，但自动分割受到不完善的内窥镜数据的挑战，包括稀疏的标签、气泡或可变照明等伪影、连续变形和模仿血管的粘膜褶皱。最先进的血管分割方法通常无法解决这些特定领域的复杂性。我们引入了一种混合注意力卷积 (HAC) 架构，该架构结合了 Transformer 来捕获全局血管拓扑，并使用 CNN 来学习残差细化图以精确恢复薄血管细节。为了优先考虑结构连接性，变压器接受了优化的地面实况数据的训练，排除了短分支和终端分支。此外，为了解决数据稀缺问题，我们采用了物理感知预训练，这是一种自我监督策略，对未标记的数据使用基于临床的增强。在由内窥镜视频帧组成的 BlaVeS 数据集上进行评估，与最先进的医学分割模型相比，我们的方法实现了高精度 (0.94) 和卓越的精度 (0.61) 以及 clDice (0.66)。至关重要的是，我们的方法成功地抑制了粘膜褶皱的假阳性，这些假阳性在手术期间随着膀胱的填充和排空而动态地出现和消失。因此，HAC 提供了临床导航所需的可靠的结构稳定性。

</details>

---

## 124. VersaViT: Enhancing MLLM Vision Backbones via Task-Guided Optimization

**中文标题**: VersaViT：通过任务引导优化增强 MLLM 视觉骨干

**Date**: 2026-02-10 | **arXiv**: [2602.09934v1](http://arxiv.org/abs/2602.09934v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09934v1)

<details><summary><b>Abstract</b></summary>

Multimodal Large Language Models (MLLMs) have recently achieved remarkable success in visual-language understanding, demonstrating superior high-level semantic alignment within their vision encoders. An important question thus arises: Can these encoders serve as versatile vision backbones, capable of reliably performing classic vision-centric tasks as well? To address the question, we make the following contributions: (i) we identify that the vision encoders within MLLMs exhibit deficiencies in their dense feature representations, as evidenced by their suboptimal performance on dense prediction tasks (e.g., semantic segmentation, depth estimation); (ii) we propose VersaViT, a well-rounded vision transformer that instantiates a novel multi-task framework for collaborative post-training. This framework facilitates the optimization of the vision backbone via lightweight task heads with multi-granularity supervision; (iii) extensive experiments across various downstream tasks demonstrate the effectiveness of our method, yielding a versatile vision backbone suited for both language-mediated reasoning and pixel-level understanding.

</details>

<details><summary><b>中文摘要</b></summary>

多模态大语言模型 (MLLM) 最近在视觉语言理解方面取得了显着的成功，在其视觉编码器中展示了卓越的高级语义对齐。因此出现了一个重要的问题：这些编码器能否作为多功能视觉骨干，能够可靠地执行经典的以视觉为中心的任务？为了解决这个问题，我们做出以下贡献：（i）我们发现 MLLM 中的视觉编码器在密集特征表示方面表现出缺陷，正如它们在密集预测任务（例如语义分割、深度估计）上的次优性能所证明的那样； (ii) 我们提出了 VersaViT，这是一种全面的视觉转换器，它实例化了用于协作后训练的新颖的多任务框架。该框架通过具有多粒度监督的轻量级任务头促进视觉主干的优化； （iii）跨各种下游任务的广泛实验证明了我们方法的有效性，产生了适合语言介导推理和像素级理解的多功能视觉主干。

</details>

---

## 125. ArtisanGS: Interactive Tools for Gaussian Splat Selection with AI and Human in the Loop

**中文标题**: ArtisanGS：利用 AI 和 Human in the Loop 进行高斯 Splat 选择的交互式工具

**Date**: 2026-02-10 | **arXiv**: [2602.10173v1](http://arxiv.org/abs/2602.10173v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10173v1)

<details><summary><b>Abstract</b></summary>

Representation in the family of 3D Gaussian Splats (3DGS) are growing into a viable alternative to traditional graphics for an expanding number of application, including recent techniques that facilitate physics simulation and animation. However, extracting usable objects from in-the-wild captures remains challenging and controllable editing techniques for this representation are limited. Unlike the bulk of emerging techniques, focused on automatic solutions or high-level editing, we introduce an interactive suite of tools centered around versatile Gaussian Splat selection and segmentation. We propose a fast AI-driven method to propagate user-guided 2D selection masks to 3DGS selections. This technique allows for user intervention in the case of errors and is further coupled with flexible manual selection and segmentation tools. These allow a user to achieve virtually any binary segmentation of an unstructured 3DGS scene. We evaluate our toolset against the state-of-the-art for Gaussian Splat selection and demonstrate their utility for downstream applications by developing a user-guided local editing approach, leveraging a custom Video Diffusion Model. With flexible selection tools, users have direct control over the areas that the AI can modify. Our selection and editing tools can be used for any in-the-wild capture without additional optimization.

</details>

<details><summary><b>中文摘要</b></summary>

3D 高斯图 (3DGS) 系列中的表示正在发展成为传统图形的可行替代品，其应用范围不断扩大，包括促进物理模拟和动画的最新技术。然而，从野外捕获中提取可用对象仍然具有挑战性，并且这种表示的可控编辑技术是有限的。与大量专注于自动解决方案或高级编辑的新兴技术不同，我们引入了一套以多功能高斯 Splat 选择和分割为中心的交互式工具。我们提出了一种快速 AI 驱动的方法，将用户引导的 2D 选择掩模传播到 3DGS 选择。该技术允许用户在出现错误时进行干预，并进一步与灵活的手动选择和分段工具相结合。这些允许用户实现非结构化 3DGS 场景的几乎任何二进制分割。我们根据最先进的高斯 Splat 选择来评估我们的工具集，并通过开发用户引导的本地编辑方法，利用自定义视频扩散模型来展示它们对下游应用程序的实用性。借助灵活的选择工具，用户可以直接控制人工智能可以修改的区域。我们的选择和编辑工具可用于任何野外捕捉，无需额外优化。

</details>

---

## 126. Monocular Normal Estimation via Shading Sequence Estimation

**中文标题**: 通过阴影序列估计进行单目法线估计

**Date**: 2026-02-10 | **arXiv**: [2602.09929v2](http://arxiv.org/abs/2602.09929v2) | **PDF**: [Link](http://arxiv.org/pdf/2602.09929v2)

<details><summary><b>Abstract</b></summary>

Monocular normal estimation aims to estimate the normal map from a single RGB image of an object under arbitrary lights. Existing methods rely on deep models to directly predict normal maps. However, they often suffer from 3D misalignment: while the estimated normal maps may appear to have a correct appearance, the reconstructed surfaces often fail to align with the geometric details. We argue that this misalignment stems from the current paradigm: the model struggles to distinguish and reconstruct varying geometry represented in normal maps, as the differences in underlying geometry are reflected only through relatively subtle color variations. To address this issue, we propose a new paradigm that reformulates normal estimation as shading sequence estimation, where shading sequences are more sensitive to various geometric information. Building on this paradigm, we present RoSE, a method that leverages image-to-video generative models to predict shading sequences. The predicted shading sequences are then converted into normal maps by solving a simple ordinary least-squares problem. To enhance robustness and better handle complex objects, RoSE is trained on a synthetic dataset, MultiShade, with diverse shapes, materials, and light conditions. Experiments demonstrate that RoSE achieves state-of-the-art performance on real-world benchmark datasets for object-based monocular normal estimation.

</details>

<details><summary><b>中文摘要</b></summary>

单目法线估计旨在从任意光照下物体的单个 RGB 图像估计法线图。现有方法依赖深度模型来直接预测法线贴图。然而，它们经常遭受 3D 未对准的影响：虽然估计的法线贴图可能看起来具有正确的外观，但重建的表面通常无法与几何细节对齐。我们认为这种错位源于当前的范式：模型难以区分和重建法线贴图中表示的不同几何形状，因为底层几何形状的差异仅通过相对微妙的颜色变化反映出来。为了解决这个问题，我们提出了一种新的范式，将法线估计重新表述为着色序列估计，其中着色序列对各种几何信息更加敏感。在此范例的基础上，我们提出了 RoSE，一种利用图像到视频生成模型来预测着色序列的方法。然后通过解决简单的普通最小二乘问题将预测的着色序列转换为法线贴图。为了增强鲁棒性并更好地处理复杂对象，RoSE 在具有不同形状、材料和光照条件的合成数据集 MultiShade 上进行训练。实验表明，RoSE 在基于对象的单目法线估计的真实世界基准数据集上实现了最先进的性能。

</details>

---

## 127. AdaTSQ: Pushing the Pareto Frontier of Diffusion Transformers via Temporal-Sensitivity Quantization

**中文标题**: AdaTSQ：通过时间敏感性量化推动扩散变压器的帕累托前沿

**Date**: 2026-02-10 | **arXiv**: [2602.09883v1](http://arxiv.org/abs/2602.09883v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09883v1)

**Code**: https://github.com/Qiushao-E/AdaTSQ.

<details><summary><b>Abstract</b></summary>

Diffusion Transformers (DiTs) have emerged as the state-of-the-art backbone for high-fidelity image and video generation. However, their massive computational cost and memory footprint hinder deployment on edge devices. While post-training quantization (PTQ) has proven effective for large language models (LLMs), directly applying existing methods to DiTs yields suboptimal results due to the neglect of the unique temporal dynamics inherent in diffusion processes. In this paper, we propose AdaTSQ, a novel PTQ framework that pushes the Pareto frontier of efficiency and quality by exploiting the temporal sensitivity of DiTs. First, we propose a Pareto-aware timestep-dynamic bit-width allocation strategy. We model the quantization policy search as a constrained pathfinding problem. We utilize a beam search algorithm guided by end-to-end reconstruction error to dynamically assign layer-wise bit-widths across different timesteps. Second, we propose a Fisher-guided temporal calibration mechanism. It leverages temporal Fisher information to prioritize calibration data from highly sensitive timesteps, seamlessly integrating with Hessian-based weight optimization. Extensive experiments on four advanced DiTs (e.g., Flux-Dev, Flux-Schnell, Z-Image, and Wan2.1) demonstrate that AdaTSQ significantly outperforms state-of-the-art methods like SVDQuant and ViDiT-Q. Our code will be released at https://github.com/Qiushao-E/AdaTSQ.

</details>

<details><summary><b>中文摘要</b></summary>

扩散变压器 (DiT) 已成为高保真图像和视频生成的最先进的支柱。然而，它们巨大的计算成本和内存占用阻碍了在边缘设备上的部署。虽然训练后量化 (PTQ) 已被证明对大型语言模型 (LLM) 有效，但由于忽略了扩散过程中固有的独特时间动态，直接将现有方法应用于 DiT 会产生次优结果。在本文中，我们提出了 AdaTSQ，这是一种新颖的 PTQ 框架，它通过利用 DiT 的时间敏感性来推动效率和质量的帕累托前沿。首先，我们提出了帕累托感知时间步动态位宽分配策略。我们将量化策略搜索建模为受限寻路问题。我们利用由端到端重建误差引导的波束搜索算法来跨不同时间步动态分配分层位宽。其次，我们提出了费舍尔引导的时间校准机制。它利用时态 Fisher 信息对来自高度敏感时间步长的校准数据进行优先级排序，与基于 Hessian 的权重优化无缝集成。对四种先进 DiT（例如 Flux-Dev、Flux-Schnell、Z-Image 和 Wan2.1）的大量实验表明，AdaTSQ 的性能显着优于 SVDQuant 和 ViDiT-Q 等最先进的方法。我们的代码将发布在https://github.com/Qiushao-E/AdaTSQ。

</details>

---

## 128. MVISTA-4D: View-Consistent 4D World Model with Test-Time Action Inference for Robotic Manipulation

**中文标题**: MVISTA-4D：视图一致的 4D 世界模型，具有用于机器人操作的测试时动作推理

**Date**: 2026-02-10 | **arXiv**: [2602.09878v1](http://arxiv.org/abs/2602.09878v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09878v1)

<details><summary><b>Abstract</b></summary>

World-model-based imagine-then-act becomes a promising paradigm for robotic manipulation, yet existing approaches typically support either purely image-based forecasting or reasoning over partial 3D geometry, limiting their ability to predict complete 4D scene dynamics. This work proposes a novel embodied 4D world model that enables geometrically consistent, arbitrary-view RGBD generation: given only a single-view RGBD observation as input, the model imagines the remaining viewpoints, which can then be back-projected and fused to assemble a more complete 3D structure across time. To efficiently learn the multi-view, cross-modality generation, we explicitly design cross-view and cross-modality feature fusion that jointly encourage consistency between RGB and depth and enforce geometric alignment across views. Beyond prediction, converting generated futures into actions is often handled by inverse dynamics, which is ill-posed because multiple actions can explain the same transition. We address this with a test-time action optimization strategy that backpropagates through the generative model to infer a trajectory-level latent best matching the predicted future, and a residual inverse dynamics model that turns this trajectory prior into accurate executable actions. Experiments on three datasets demonstrate strong performance on both 4D scene generation and downstream manipulation, and ablations provide practical insights into the key design choices.

</details>

<details><summary><b>中文摘要</b></summary>

基于世界模型的“想象然后行动”成为机器人操纵的一个有前景的范例，但现有方法通常支持纯粹基于图像的预测或对部分 3D 几何图形的推理，限制了它们预测完整 4D 场景动态的能力。这项工作提出了一种新颖的具体化 4D 世界模型，可实现几何一致的任意视图 RGBD 生成：仅将单视图 RGBD 观察作为输入，该模型会想象剩余的视点，然后可以对这些视点进行反向投影和融合，以跨时间组装更完整的 3D 结构。为了有效地学习多视图、跨模态生成，我们明确设计了跨视图和跨模态特征融合，共同促进 RGB 和深度之间的一致性，并强制跨视图的几何对齐。除了预测之外，将生成的未来转换为行动通常是通过逆动态来处理的，这是不适定的，因为多个行动可以解释相同的转变。我们通过测试时动作优化策略来解决这个问题，该策略通过生成模型进行反向传播，以推断出与预测的未来最匹配的轨迹级潜在变量，以及残差逆动态模型，将该轨迹先验转化为准确的可执行动作。对三个数据集的实验证明了 4D 场景生成和下游操作的强大性能，并且消融为关键设计选择提供了实用的见解。

</details>

---

## 129. Free-GVC: Towards Training-Free Extreme Generative Video Compression with Temporal Coherence

**中文标题**: Free-GVC：实现具有时间一致性的免训练极端生成视频压缩

**Date**: 2026-02-10 | **arXiv**: [2602.09868v1](http://arxiv.org/abs/2602.09868v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09868v1)

<details><summary><b>Abstract</b></summary>

Building on recent advances in video generation, generative video compression has emerged as a new paradigm for achieving visually pleasing reconstructions. However, existing methods exhibit limited exploitation of temporal correlations, causing noticeable flicker and degraded temporal coherence at ultra-low bitrates. In this paper, we propose Free-GVC, a training-free generative video compression framework that reformulates video coding as latent trajectory compression guided by a video diffusion prior. Our method operates at the group-of-pictures (GOP) level, encoding video segments into a compact latent space and progressively compressing them along the diffusion trajectory. To ensure perceptually consistent reconstruction across GOPs, we introduce an Adaptive Quality Control module that dynamically constructs an online rate-perception surrogate model to predict the optimal diffusion step for each GOP. In addition, an Inter-GOP Alignment module establishes frame overlap and performs latent fusion between adjacent groups, thereby mitigating flicker and enhancing temporal coherence. Experiments show that Free-GVC achieves an average of 93.29% BD-Rate reduction in DISTS over the latest neural codec DCVC-RT, and a user study further confirms its superior perceptual quality and temporal coherence at ultra-low bitrates.

</details>

<details><summary><b>中文摘要</b></summary>

基于视频生成领域的最新进展，生成视频压缩已成为实现视觉上令人愉悦的重建的新范例。然而，现有方法对时间相关性的利用有限，导致在超低比特率下出现明显的闪烁和时间相干性下降。在本文中，我们提出了 Free-GVC，这是一种免训练的生成视频压缩框架，它将视频编码重新表述为由视频扩散先验引导的潜在轨迹压缩。我们的方法在图片组（GOP）级别上运行，将视频片段编码到紧凑的潜在空间中，并沿着扩散轨迹逐步压缩它们。为了确保跨 GOP 的感知一致重建，我们引入了自适应质量控制模块，该模块动态构建在线速率感知代理模型来预测每个 GOP 的最佳扩散步骤。此外，GOP 间对齐模块可建立帧重叠并在相邻组之间执行潜在融合，从而减轻闪烁并增强时间一致性。实验表明，与最新的神经编解码器 DCVC-RT 相比，Free-GVC 在 DISTS 中实现了平均 93.29% 的 BD-Rate 降低，并且用户研究进一步证实了其在超低比特率下的卓越感知质量和时间一致性。

</details>

---

## 130. Code2World: A GUI World Model via Renderable Code Generation

**中文标题**: Code2World：通过可渲染代码生成的 GUI 世界模型

**Date**: 2026-02-10 | **arXiv**: [2602.09856v1](http://arxiv.org/abs/2602.09856v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09856v1)

**Code**: https://github.com/AMAP-ML/Code2World.

<details><summary><b>Abstract</b></summary>

Autonomous GUI agents interact with environments by perceiving interfaces and executing actions. As a virtual sandbox, the GUI World model empowers agents with human-like foresight by enabling action-conditioned prediction. However, existing text- and pixel-based approaches struggle to simultaneously achieve high visual fidelity and fine-grained structural controllability. To this end, we propose Code2World, a vision-language coder that simulates the next visual state via renderable code generation. Specifically, to address the data scarcity problem, we construct AndroidCode by translating GUI trajectories into high-fidelity HTML and refining synthesized code through a visual-feedback revision mechanism, yielding a corpus of over 80K high-quality screen-action pairs. To adapt existing VLMs into code prediction, we first perform SFT as a cold start for format layout following, then further apply Render-Aware Reinforcement Learning which uses rendered outcome as the reward signal by enforcing visual semantic fidelity and action consistency. Extensive experiments demonstrate that Code2World-8B achieves the top-performing next UI prediction, rivaling the competitive GPT-5 and Gemini-3-Pro-Image. Notably, Code2World significantly enhances downstream navigation success rates in a flexible manner, boosting Gemini-2.5-Flash by +9.5% on AndroidWorld navigation. The code is available at https://github.com/AMAP-ML/Code2World.

</details>

<details><summary><b>中文摘要</b></summary>

自主 GUI 代理通过感知界面并执行操作与环境进行交互。作为一个虚拟沙箱，GUI World 模型通过启用动作条件预测，使代理具有类似人类的远见。然而，现有的基于文本和像素的方法很难同时实现高视觉保真度和细粒度的结构可控性。为此，我们提出了 Code2World，一种视觉语言编码器，可通过可渲染代码生成来模拟下一个视觉状态。具体来说，为了解决数据稀缺问题，我们通过将 GUI 轨迹转换为高保真 HTML 并通过视觉反馈修订机制完善合成代码来构建 AndroidCode，从而生成超过 80K 高质量屏幕操作对的语料库。为了使现有的 VLM 适应代码预测，我们首先执行 SFT 作为格式布局遵循的冷启动，然后进一步应用渲染感知强化学习，通过强制视觉语义保真度和动作一致性，使用渲染结果作为奖励信号。大量实验表明，Code2World-8B 实现了性能最佳的下一个 UI 预测，可与竞争性的 GPT-5 和 Gemini-3-Pro-Image 相媲美。值得注意的是，Code2World 以灵活的方式显着提高了下游导航的成功率，使 Gemini-2.5-Flash 在 AndroidWorld 导航上提高了 9.5%。该代码可从 https://github.com/AMAP-ML/Code2World 获取。

</details>

---

## 131. Reason-IAD: Knowledge-Guided Dynamic Latent Reasoning for Explainable Industrial Anomaly Detection

**中文标题**: Reason-IAD：用于可解释工业异常检测的知识引导动态潜在推理

**Date**: 2026-02-10 | **arXiv**: [2602.09850v1](http://arxiv.org/abs/2602.09850v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09850v1)

**Code**: https://github.com/chenpeng052/Reason-IAD.

<details><summary><b>Abstract</b></summary>

Industrial anomaly detection demands precise reasoning over fine-grained defect patterns. However, existing multimodal large language models (MLLMs), pretrained on general-domain data, often struggle to capture category-specific anomalies, thereby limiting both detection accuracy and interpretability. To address these limitations, we propose Reason-IAD, a knowledge-guided dynamic latent reasoning framework for explainable industrial anomaly detection. Reason-IAD comprises two core components. First, a retrieval-augmented knowledge module incorporates category-specific textual descriptions into the model input, enabling context-aware reasoning over domain-specific defects. Second, an entropy-driven latent reasoning mechanism conducts iterative exploration within a compact latent space using optimizable latent think tokens, guided by an entropy-based reward that encourages confident and stable predictions. Furthermore, a dynamic visual injection strategy selectively incorporates the most informative image patches into the latent sequence, directing the reasoning process toward regions critical for anomaly detection. Extensive experimental results demonstrate that Reason-IAD consistently outperforms state-of-the-art methods. The code will be publicly available at https://github.com/chenpeng052/Reason-IAD.

</details>

<details><summary><b>中文摘要</b></summary>

工业异常检测需要对细粒度缺陷模式进行精确推理。然而，现有的多模态大语言模型（MLLM）在通用领域数据上进行预训练，通常难以捕获特定类别的异常，从而限制了检测的准确性和可解释性。为了解决这些限制，我们提出了 Reason-IAD，这是一种用于可解释的工业异常检测的知识引导的动态潜在推理框架。 Reason-IAD 包含两个核心组件。首先，检索增强知识模块将特定类别的文本描述合并到模型输入中，从而能够对特定领域的缺陷进行上下文感知推理。其次，熵驱动的潜在推理机制使用可优化的潜在思考令牌在紧凑的潜在空间内进行迭代探索，并以基于熵的奖励为指导，鼓励自信和稳定的预测。此外，动态视觉注入策略有选择地将信息最丰富的图像块合并到潜在序列中，将推理过程引导到对异常检测至关重要的区域。大量实验结果表明，Reason-IAD 始终优于最先进的方法。该代码将在 https://github.com/chenpeng052/Reason-IAD 上公开提供。

</details>

---

## 132. Kelix Technique Report

**中文标题**: Kelix 技术报告

**Date**: 2026-02-10 | **arXiv**: [2602.09843v2](http://arxiv.org/abs/2602.09843v2) | **PDF**: [Link](http://arxiv.org/pdf/2602.09843v2)

<details><summary><b>Abstract</b></summary>

Autoregressive large language models (LLMs) scale well by expressing diverse tasks as sequences of discrete natural-language tokens and training with next-token prediction, which unifies comprehension and generation under self-supervision. Extending this paradigm to multimodal data requires a shared, discrete representation across modalities. However, most vision-language models (VLMs) still rely on a hybrid interface: discrete text tokens paired with continuous Vision Transformer (ViT) features. Because supervision is largely text-driven, these models are often biased toward understanding and cannot fully leverage large-scale self-supervised learning on non-text data. Recent work has explored discrete visual tokenization to enable fully autoregressive multimodal modeling, showing promising progress toward unified understanding and generation. Yet existing discrete vision tokens frequently lose information due to limited code capacity, resulting in noticeably weaker understanding than continuous-feature VLMs. We present Kelix, a fully discrete autoregressive unified model that closes the understanding gap between discrete and continuous visual representations.

</details>

<details><summary><b>中文摘要</b></summary>

自回归大语言模型 (LLM) 通过将不同的任务表示为离散的自然语言标记序列并通过下一个标记预测进行训练，从而在自我监督下统一理解和生成，从而可以很好地扩展。将这种范式扩展到多模态数据需要跨模态的共享、离散表示。然而，大多数视觉语言模型 (VLM) 仍然依赖于混合接口：离散文本标记与连续视觉变换器 (ViT) 功能配对。由于监督很大程度上是文本驱动的，这些模型往往偏向于理解，无法充分利用对非文本数据的大规模自监督学习。最近的工作探索了离散视觉标记化，以实现完全自回归多模态建模，显示出在统一理解和生成方面取得的有希望的进展。然而，由于代码容量有限，现有的离散视觉令牌经常丢失信息，导致理解能力明显弱于连续特征 VLM。我们提出 Kelix，一个完全离散的自回归统一模型，它缩小了离散和连续视觉表示之间的理解差距。

</details>

---

## 133. ARK: A Dual-Axis Multimodal Retrieval Benchmark along Reasoning and Knowledge

**中文标题**: ARK：沿着推理和知识的双轴多模态检索基准

**Date**: 2026-02-10 | **arXiv**: [2602.09839v1](http://arxiv.org/abs/2602.09839v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09839v1)

<details><summary><b>Abstract</b></summary>

Existing multimodal retrieval benchmarks largely emphasize semantic matching on daily-life images and offer limited diagnostics of professional knowledge and complex reasoning. To address this gap, we introduce ARK, a benchmark designed to analyze multimodal retrieval from two complementary perspectives: (i) knowledge domains (five domains with 17 subtypes), which characterize the content and expertise retrieval relies on, and (ii) reasoning skills (six categories), which characterize the type of inference over multimodal evidence required to identify the correct candidate. Specifically, ARK evaluates retrieval with both unimodal and multimodal queries and candidates, covering 16 heterogeneous visual data types. To avoid shortcut matching during evaluation, most queries are paired with targeted hard negatives that require multi-step reasoning. We evaluate 23 representative text-based and multimodal retrievers on ARK and observe a pronounced gap between knowledge-intensive and reasoning-intensive retrieval, with fine-grained visual and spatial reasoning emerging as persistent bottlenecks. We further show that simple enhancements such as re-ranking and rewriting yield consistent improvements, but substantial headroom remains.

</details>

<details><summary><b>中文摘要</b></summary>

现有的多模态检索基准主要强调日常生活图像的语义匹配，并提供有限的专业知识和复杂推理的诊断。为了解决这一差距，我们引入了 ARK，这是一个旨在从两个互补角度分析多模态检索的基准：(i) 知识领域（具有 17 个子类型的 5 个领域），它描述了检索所依赖的内容和专业知识；(ii) 推理技能（六个类别），它描述了识别正确候选者所需的多模态证据的推理类型。具体来说，ARK 使用单模态和多模态查询和候选来评估检索，涵盖 16 种异构视觉数据类型。为了避免在评估过程中进行快捷匹配，大多数查询都与需要多步骤推理的目标硬否定配对。我们在 ARK 上评估了 23 个具有代表性的基于文本和多模态检索器，并观察到知识密集型检索和推理密集型检索之间存在明显差距，其中细粒度视觉和空间推理成为持续存在的瓶颈。我们进一步表明，重新排名和重写等简单的增强功能可以带来一致的改进，但仍然存在巨大的空间。

</details>

---

## 134. SAKED: Mitigating Hallucination in Large Vision-Language Models via Stability-Aware Knowledge Enhanced Decoding

**中文标题**: SAKED：通过稳定性感知知识增强解码减轻大型视觉语言模型中的幻觉

**Date**: 2026-02-10 | **arXiv**: [2602.09825v1](http://arxiv.org/abs/2602.09825v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09825v1)

<details><summary><b>Abstract</b></summary>

Hallucinations in Large Vision-Language Models (LVLMs) pose significant security and reliability risks in real-world applications. Inspired by the observation that humans are more error-prone when uncertain or hesitant, we investigate how instability in a model 's internal knowledge contributes to LVLM hallucinations. We conduct extensive empirical analyses from three perspectives, namely attention heads, model layers, and decoding tokens, and identify three key hallucination patterns: (i) visual activation drift across attention heads, (ii) pronounced knowledge fluctuations across layers, and (iii) visual focus distraction between neighboring output tokens. Building on these findings, we propose Stability-Aware Knowledge-Enhanced Decoding (SAKED), which introduces a layer-wise Knowledge Stability Score (KSS) to quantify knowledge stability throughout the model. By contrasting the most stability-aware and stability-agnostic layers, SAKED suppresses decoding noise and dynamically leverages the most reliable internal knowledge for faithful token generation. Moreover, SAKED is training-free and can be seamlessly integrated into different architectures. Extensive experiments demonstrate that SAKED achieves state-of-the-art performance for hallucination mitigation on various models, tasks, and benchmarks.

</details>

<details><summary><b>中文摘要</b></summary>

大视觉语言模型 (LVLM) 中的幻觉在现实应用中带来了重大的安全和可靠性风险。受人类在不确定或犹豫时更容易出错这一观察的启发，我们研究了模型内部知识的不稳定性如何导致 LVLM 幻觉。我们从三个角度（即注意力头、模型层和解码令牌）进行了广泛的实证分析，并确定了三种关键的幻觉模式：（i）注意力头之间的视觉激活漂移，（ii）跨层的明显知识波动，以及（iii）相邻输出令牌之间的视觉焦点分散。基于这些发现，我们提出了稳定性感知知识增强解码（SAKED），它引入了分层知识稳定性评分（KSS）来量化整个模型的知识稳定性。通过对比最稳定的感知层和与稳定性无关的层，SAKED 抑制解码噪声并动态利用最可靠的内部知识来忠实地生成令牌。此外，SAKED无需培训，可以无缝集成到不同的架构中。大量实验表明，SAKED 在各种模型、任务和基准测试中实现了最先进的幻觉缓解性能。

</details>

---

## 135. SciFlow-Bench: Evaluating Structure-Aware Scientific Diagram Generation via Inverse Parsing

**中文标题**: SciFlow-Bench：通过逆向解析评估结构感知科学图生成

**Date**: 2026-02-10 | **arXiv**: [2602.09809v1](http://arxiv.org/abs/2602.09809v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09809v1)

<details><summary><b>Abstract</b></summary>

Scientific diagrams convey explicit structural information, yet modern text-to-image models often produce visually plausible but structurally incorrect results. Existing benchmarks either rely on image-centric or subjective metrics insensitive to structure, or evaluate intermediate symbolic representations rather than final rendered images, leaving pixel-based diagram generation underexplored. We introduce SciFlow-Bench, a structure-first benchmark for evaluating scientific diagram generation directly from pixel-level outputs. Built from real scientific PDFs, SciFlow-Bench pairs each source framework figure with a canonical ground-truth graph and evaluates models as black-box image generators under a closed-loop, round-trip protocol that inverse-parses generated diagram images back into structured graphs for comparison. This design enforces evaluation by structural recoverability rather than visual similarity alone, and is enabled by a hierarchical multi-agent system that coordinates planning, perception, and structural reasoning. Experiments show that preserving structural correctness remains a fundamental challenge, particularly for diagrams with complex topology, underscoring the need for structure-aware evaluation.

</details>

<details><summary><b>中文摘要</b></summary>

科学图表传达了明确的结构信息，但现代文本到图像模型通常会产生视觉上合理但结构上不正确的结果。现有的基准要么依赖于以图像为中心的或对结构不敏感的主观指标，要么评估中间符号表示而不是最终渲染的图像，从而导致基于像素的图表生成尚未得到充分探索。我们引入了 SciFlow-Bench，这是一种结构优先的基准，用于直接从像素级输出评估科学图表的生成。 SciFlow-Bench 以真正的科学 PDF 为基础，将每个源框架图与规范的地面实况图配对，并在闭环、往返协议下将模型评估为黑盒图像生成器，该协议将生成的图表图像反向解析回结构化图以进行比较。该设计通过结构可恢复性而不是仅通过视觉相似性来强制进行评估，并通过协调规划、感知和结构推理的分层多智能体系统来实现。实验表明，保持结构正确性仍然是一个基本挑战，特别是对于具有复杂拓扑的图，这强调了结构感知评估的必要性。

</details>

---

## 136. Where Do Images Come From? Analyzing Captions to Geographically Profile Datasets

**中文标题**: 图像从哪里来？分析说明以地理剖析数据集

**Date**: 2026-02-10 | **arXiv**: [2602.09775v1](http://arxiv.org/abs/2602.09775v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09775v1)

<details><summary><b>Abstract</b></summary>

Recent studies show that text-to-image models often fail to generate geographically representative images, raising concerns about the representativeness of their training data and motivating the question: which parts of the world do these training examples come from? We geographically profile large-scale multimodal datasets by mapping image-caption pairs to countries based on location information extracted from captions using LLMs. Studying English captions from three widely used datasets (Re-LAION, DataComp1B, and Conceptual Captions) across $20$ common entities (e.g., house, flag), we find that the United States, the United Kingdom, and Canada account for $48.0\%$ of samples, while South American and African countries are severely under-represented with only $1.8\%$ and $3.8\%$ of images, respectively. We observe a strong correlation between a country's GDP and its representation in the data ($ρ= 0.82$). Examining non-English subsets for $4$ languages from the Re-LAION dataset, we find that representation skews heavily toward countries where these languages are predominantly spoken. Additionally, we find that higher representation does not necessarily translate to greater visual or semantic diversity. Finally, analyzing country-specific images generated by Stable Diffusion v1.3 trained on Re-LAION, we show that while generations appear realistic, they are severely limited in their coverage compared to real-world images.

</details>

<details><summary><b>中文摘要</b></summary>

最近的研究表明，文本到图像模型通常无法生成具有地理代表性的图像，这引起了人们对其训练数据代表性的担忧，并引发了一个问题：这些训练示例来自世界的哪些地区？我们根据使用法学硕士从字幕中提取的位置信息，将图像字幕对映射到国家/地区，从而对大规模多模式数据集进行地理分析。研究三个广泛使用的数据集（Re-LAION、DataComp1B 和 Conceptual Captions）中涉及 20 美元常见实体（例如房屋、旗帜）的英文字幕，我们发现美国、英国和加拿大占样本的 48.0\%$，而南美和非洲国家的代表性严重不足，分别只有 $1.8\%$ 和 $3.8\%$ 的图像。我们观察到一个国家的 GDP 与其在数据中的表示形式之间存在很强的相关性 ($ρ= 0.82$)。检查 Re-LAION 数据集中 4 美元语言的非英语子集，我们发现代表性严重偏向主要使用这些语言的国家。此外，我们发现更高的表示并不一定意味着更大的视觉或语义多样性。最后，通过分析在 Re-LAION 上训练的 Stable Diffusion v1.3 生成的特定国家图像，我们发现虽然各代图像看起来很真实，但与真实世界图像相比，它们的覆盖范围受到严重限制。

</details>

---

## 137. Self-Supervised Learning as Discrete Communication

**中文标题**: 作为离散沟通的自我监督学习

**Date**: 2026-02-10 | **arXiv**: [2602.09764v1](http://arxiv.org/abs/2602.09764v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09764v1)

<details><summary><b>Abstract</b></summary>

Most self-supervised learning (SSL) methods learn continuous visual representations by aligning different views of the same input, offering limited control over how information is structured across representation dimensions. In this work, we frame visual self-supervised learning as a discrete communication process between a teacher and a student network, where semantic information is transmitted through a fixed-capacity binary channel. Rather than aligning continuous features, the student predicts multi-label binary messages produced by the teacher. Discrete agreement is enforced through an element-wise binary cross-entropy objective, while a coding-rate regularization term encourages effective utilization of the constrained channel, promoting structured representations. We further show that periodically reinitializing the projection head strengthens this effect by encouraging embeddings that remain predictive across multiple discrete encodings. Extensive experiments demonstrate consistent improvements over continuous agreement baselines on image classification, retrieval, and dense visual prediction tasks, as well as under domain shift through self-supervised adaptation. Beyond backbone representations, we analyze the learned binary codes and show that they form a compact and informative discrete language, capturing semantic factors reusable across classes.

</details>

<details><summary><b>中文摘要</b></summary>

大多数自监督学习（SSL）方法通过对齐同一输入的不同视图来学习连续的视觉表示，从而对跨表示维度的信息结构提供有限的控制。在这项工作中，我们将视觉自监督学习构建为教师和学生网络之间的离散通信过程，其中语义信息通过固定容量的二进制通道传输。学生不是对齐连续特征，而是预测教师产生的多标签二进制消息。离散一致性是通过元素级二元交叉熵目标来强制执行的，而编码率正则化项则鼓励有效利用受限通道，从而促进结构化表示。我们进一步表明，定期重新初始化投影头可以通过鼓励在多个离散编码中保持预测性的嵌入来增强这种效果。大量的实验表明，在图像分类、检索和密集视觉预测任务上，以及通过自我监督适应进行域转移方面，在连续一致性基线上取得了一致的改进。除了主干表示之外，我们还分析了学习到的二进制代码，并表明它们形成了一种紧凑且信息丰富的离散语言，捕获了可跨类重用的语义因素。

</details>

---

## 138. Robust Vision Systems for Connected and Autonomous Vehicles: Security Challenges and Attack Vectors

**中文标题**: 适用于联网和自动驾驶车辆的鲁棒视觉系统：安全挑战和攻击向量

**Date**: 2026-02-10 | **arXiv**: [2602.09740v2](http://arxiv.org/abs/2602.09740v2) | **PDF**: [Link](http://arxiv.org/pdf/2602.09740v2)

<details><summary><b>Abstract</b></summary>

This article investigates the robustness of vision systems in Connected and Autonomous Vehicles (CAVs), which is critical for developing Level-5 autonomous driving capabilities. Safe and reliable CAV navigation undeniably depends on robust vision systems that enable accurate detection of objects, lane markings, and traffic signage. We analyze the key sensors and vision components essential for CAV navigation to derive a reference architecture for CAV vision system (CAVVS). This reference architecture provides a basis for identifying potential attack surfaces of CAVVS. Subsequently, we elaborate on identified attack vectors targeting each attack surface, rigorously evaluating their implications for confidentiality, integrity, and availability (CIA). Our study provides a comprehensive understanding of attack vector dynamics in vision systems, which is crucial for formulating robust security measures that can uphold the principles of the CIA triad.

</details>

<details><summary><b>中文摘要</b></summary>

本文研究了联网自动驾驶车辆 (CAV) 中视觉系统的稳健性，这对于开发 5 级自动驾驶功能至关重要。安全可靠的 CAV 导航无疑依赖于强大的视觉系统，能够准确检测物体、车道标记和交通标志。我们分析了 CAV 导航所必需的关键传感器和视觉组件，得出 CAV 视觉系统 (CAVVS) 的参考架构。该参考架构为识别 CAVVS 的潜在攻击面提供了基础。随后，我们详细阐述针对每个攻击面的已识别攻击向量，严格评估它们对机密性、完整性和可用性 (CIA) 的影响。我们的研究提供了对视觉系统中攻击向量动态的全面了解，这对于制定能够维护 CIA 三合会原则的强大安全措施至关重要。

</details>

---

## 139. Toward Fine-Grained Facial Control in 3D Talking Head Generation

**中文标题**: 实现 3D 头部说话中的细粒度面部控制

**Date**: 2026-02-10 | **arXiv**: [2602.09736v1](http://arxiv.org/abs/2602.09736v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09736v1)

<details><summary><b>Abstract</b></summary>

Audio-driven talking head generation is a core component of digital avatars, and 3D Gaussian Splatting has shown strong performance in real-time rendering of high-fidelity talking heads. However, achieving precise control over fine-grained facial movements remains a significant challenge, particularly due to lip-synchronization inaccuracies and facial jitter, both of which can contribute to the uncanny valley effect. To address these challenges, we propose Fine-Grained 3D Gaussian Splatting (FG-3DGS), a novel framework that enables temporally consistent and high-fidelity talking head generation. Our method introduces a frequency-aware disentanglement strategy to explicitly model facial regions based on their motion characteristics. Low-frequency regions, such as the cheeks, nose, and forehead, are jointly modeled using a standard MLP, while high-frequency regions, including the eyes and mouth, are captured separately using a dedicated network guided by facial area masks. The predicted motion dynamics, represented as Gaussian deltas, are applied to the static Gaussians to generate the final head frames, which are rendered via a rasterizer using frame-specific camera parameters. Additionally, a high-frequency-refined post-rendering alignment mechanism, learned from large-scale audio-video pairs by a pretrained model, is incorporated to enhance per-frame generation and achieve more accurate lip synchronization. Extensive experiments on widely used datasets for talking head generation demonstrate that our method outperforms recent state-of-the-art approaches in producing high-fidelity, lip-synced talking head videos.

</details>

<details><summary><b>中文摘要</b></summary>

音频驱动的头像生成是数字化身的核心组成部分，3D Gaussian Splatting 在高保真头像实时渲染方面表现出了强大的性能。然而，实现对细粒度面部运动的精确控制仍然是一个重大挑战，特别是由于口型同步不准确和面部抖动，这两者都可能导致恐怖谷效应。为了应对这些挑战，我们提出了细粒度 3D 高斯分布 (FG-3DGS)，这是一种新颖的框架，可以实现时间一致和高保真头部说话。我们的方法引入了频率感知的解缠结策略，以根据运动特征显式地建模面部区域。低频区域（例如脸颊、鼻子和前额）使用标准 MLP 联合建模，而高频区域（包括眼睛和嘴巴）则使用由面部区域掩模引导的专用网络单独捕获。预测的运动动态（表示为高斯增量）应用于静态高斯以生成最终的头部帧，该头部帧通过光栅化器使用特定于帧的相机参数进行渲染。此外，还采用了通过预训练模型从大规模音频-视频对中学习的高频细化后渲染对齐机制，以增强每帧生成并实现更准确的唇形同步。对广泛使用的头像生成数据集进行的大量实验表明，我们的方法在生成高保真、口型同步的头像视频方面优于最新的最先进方法。

</details>

---

## 140. Allure of Craquelure: A Variational-Generative Approach to Crack Detection in Paintings

**中文标题**: 裂纹的魅力：绘画裂纹检测的变分生成方法

**Date**: 2026-02-10 | **arXiv**: [2602.09730v1](http://arxiv.org/abs/2602.09730v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09730v1)

<details><summary><b>Abstract</b></summary>

Recent advances in imaging technologies, deep learning and numerical performance have enabled non-invasive detailed analysis of artworks, supporting their documentation and conservation. In particular, automated detection of craquelure in digitized paintings is crucial for assessing degradation and guiding restoration, yet remains challenging due to the possibly complex scenery and the visual similarity between cracks and crack-like artistic features such as brush strokes or hair. We propose a hybrid approach that models crack detection as an inverse problem, decomposing an observed image into a crack-free painting and a crack component. A deep generative model is employed as powerful prior for the underlying artwork, while crack structures are captured using a Mumford--Shah-type variational functional together with a crack prior. Joint optimization yields a pixel-level map of crack localizations in the painting.

</details>

<details><summary><b>中文摘要</b></summary>

成像技术、深度学习和数值性能的最新进展使得对艺术品进行非侵入式详细分析成为可能，支持其记录和保护。特别是，数字化绘画中裂纹的自动检测对于评估退化和指导修复至关重要，但由于可能复杂的场景以及裂纹和类似裂纹的艺术特征（例如笔触或头发）之间的视觉相似性，仍然具有挑战性。我们提出了一种混合方法，将裂纹检测建模为逆问题，将观察到的图像分解为无裂纹的绘画和裂纹组件。采用深度生成模型作为底层艺术品的强大先验，而使用 Mumford-Shah 型变分函数和裂纹先验来捕获裂纹结构。联合优化产生了绘画中裂纹定位的像素级图。

</details>

---

## 141. GenSeg-R1: RL-Driven Vision-Language Grounding for Fine-Grained Referring Segmentation

**中文标题**: GenSeg-R1：RL 驱动的视觉语言基础，用于细粒度参考分割

**Date**: 2026-02-10 | **arXiv**: [2602.09701v1](http://arxiv.org/abs/2602.09701v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09701v1)

<details><summary><b>Abstract</b></summary>

We study fine-grained referring image segmentation via a decoupled reason-then-segment pipeline. A vision-language model (VLM) receives an image and a natural-language query, reasons about the scene, and emits structured spatial prompts: a bounding box plus two interior keypoints for every referred instance. A frozen promptable segmenter (SAM 2) converts these prompts into high-quality masks.   Within our GenSeg-R1 framework we finetune Qwen3-VL models (4B and 8B parameters) using Group Relative Policy Optimization (GRPO), requiring no supervised reasoning-chain annotations. On RefCOCOg validation our best model (GenSeg-R1-8B) achieves 0.7127 cIoU and 0.7382 mIoU, substantially outperforming the corresponding Qwen3-VL Instruct baselines (+15.3 and +21.9 points, respectively) and surpassing Seg-Zero-7B [3] by +3.3 cIoU under identical evaluation.   We further introduce GenSeg-R1-G, a variant trained on GRefCOCO [9] with a SAM 2 in-the-loop reward that directly optimizes mask quality. On GRefCOCO validation GenSeg-R1-G achieves 76.69% target mIoU with 82.40% accuracy on negative (no-target) prompts, substantially outperforming Seg-R1-7B and Seg-Zero-7B, which lack no-target detection capability. On ReasonSeg test, GenSeg-R1-4B reaches 68.40% mIoU, surpassing Seg-Zero-7B by +7.0 and Seg-R1-7B by +10.7 points.

</details>

<details><summary><b>中文摘要</b></summary>

我们通过解耦的推理然后分段管道研究细粒度参考图像分割。视觉语言模型 (VLM) 接收图像和自然语言查询、场景推理，并发出结构化空间提示：一个边界框以及每个引用实例的两个内部关键点。冻结的提示分段器 (SAM 2) 将这些提示转换为高质量的蒙版。   在我们的 GenSeg-R1 框架中，我们使用组相对策略优化 (GRPO) 微调 Qwen3-VL 模型（4B 和 8B 参数），不需要监督推理链注释。在 RefCOCOg 验证中，我们的最佳模型 (GenSeg-R1-8B) 达到了 0.7127 cIoU 和 0.7382 mIoU，大大优于相应的 Qwen3-VL Instruct 基线（分别为 +15.3 和 +21.9 分），并在相同评估下超过 Seg-Zero-7B [3] +3.3 cIoU。   我们进一步介绍了 GenSeg-R1-G，这是一种在 GRefCOCO [9] 上训练的变体，具有 SAM 2 循环奖励，可直接优化掩模质量。在 GRefCOCO 验证中，GenSeg-R1-G 实现了 76.69% 的目标 mIoU，在阴性（无目标）提示上的准确率达到 82.40%，大大优于缺乏无目标检测能力的 Seg-R1-7B 和 Seg-Zero-7B。在 ReasonSeg 测试中，GenSeg-R1-4B 达到 68.40% mIoU，超过 Seg-Zero-7B +7.0 点，超过 Seg-R1-7B +10.7 点。

</details>

---

## 142. Semi-supervised Liver Segmentation and Patch-based Fibrosis Staging with Registration-aided Multi-parametric MRI

**中文标题**: 使用配准辅助多参数 MRI 进行半监督肝脏分割和基于斑块的纤维化分期

**Date**: 2026-02-10 | **arXiv**: [2602.09686v1](http://arxiv.org/abs/2602.09686v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09686v1)

**Code**: https://github.com/mileywang3061/Care-Liver

<details><summary><b>Abstract</b></summary>

Liver fibrosis poses a substantial challenge in clinical practice, emphasizing the necessity for precise liver segmentation and accurate disease staging. Based on the CARE Liver 2025 Track 4 Challenge, this study introduces a multi-task deep learning framework developed for liver segmentation (LiSeg) and liver fibrosis staging (LiFS) using multiparametric MRI. The LiSeg phase addresses the challenge of limited annotated images and the complexities of multi-parametric MRI data by employing a semi-supervised learning model that integrates image segmentation and registration. By leveraging both labeled and unlabeled data, the model overcomes the difficulties introduced by domain shifts and variations across modalities. In the LiFS phase, we employed a patchbased method which allows the visualization of liver fibrosis stages based on the classification outputs. Our approach effectively handles multimodality imaging data, limited labels, and domain shifts. The proposed method has been tested by the challenge organizer on an independent test set that includes in-distribution (ID) and out-of-distribution (OOD) cases using three-channel MRIs (T1, T2, DWI) and seven-channel MRIs (T1, T2, DWI, GED1-GED4). The code is freely available. Github link: https://github.com/mileywang3061/Care-Liver

</details>

<details><summary><b>中文摘要</b></summary>

肝纤维化在临床实践中提出了巨大的挑战，强调了精确的肝脏分割和准确的疾病分期的必要性。基于 CARE Liver 2025 Track 4 Challenge，本研究介绍了使用多参数 MRI 为肝脏分割 (LiSeg) 和肝纤维化分期 (LiFS) 开发的多任务深度学习框架。 LiSeg 阶段通过采用集成图像分割和配准的半监督学习模型来解决有限注释图像和多参数 MRI 数据复杂性的挑战。通过利用标记和未标记数据，该模型克服了域转移和跨模式变化带来的困难。在 LiFS 阶段，我们采用了基于补丁的方法，该方法允许根据分类输出可视化肝纤维化阶段。我们的方法有效地处理多模态成像数据、有限的标签和域转移。挑战组织者已在独立测试集上对所提出的方法进行了测试，该测试集包括使用三通道 MRI（T1、T2、DWI）和七通道 MRI（T1、T2、DWI、GED1-GED4）的分布内（ID）和分布外（OOD）案例。该代码是免费提供的。 Github 链接：https://github.com/mileywang3061/Care-Liver

</details>

---

## 143. TreeCUA: Efficiently Scaling GUI Automation with Tree-Structured Verifiable Evolution

**中文标题**: TreeCUA：通过树形结构的可验证演化有效扩展 GUI 自动化

**Date**: 2026-02-10 | **arXiv**: [2602.09662v1](http://arxiv.org/abs/2602.09662v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09662v1)

**Code**: https://github.com/UITron-hub/TreeCUA.

<details><summary><b>Abstract</b></summary>

Effectively scaling GUI automation is essential for computer-use agents (CUAs); however, existing work primarily focuses on scaling GUI grounding rather than the more crucial GUI planning, which requires more sophisticated data collection. In reality, the exploration process of a CUA across apps/desktops/web pages typically follows a tree structure, with earlier functional entry points often being explored more frequently. Thus, organizing large-scale trajectories into tree structures can reduce data cost and streamline the data scaling of GUI planning. In this work, we propose TreeCUA to efficiently scale GUI automation with tree-structured verifiable evolution. We propose a multi-agent collaborative framework to explore the environment, verify actions, summarize trajectories, and evaluate quality to generate high-quality and scalable GUI trajectories. To improve efficiency, we devise a novel tree-based topology to store and replay duplicate exploration nodes, and design an adaptive exploration algorithm to balance the depth (\emph{i.e.}, trajectory difficulty) and breadth (\emph{i.e.}, trajectory diversity). Moreover, we develop world knowledge guidance and global memory backtracking to avoid low-quality generation. Finally, we naturally extend and propose the TreeCUA-DPO method from abundant tree node information, improving GUI planning capability by referring to the branch information of adjacent trajectories. Experimental results show that TreeCUA and TreeCUA-DPO offer significant improvements, and out-of-domain (OOD) studies further demonstrate strong generalization. All trajectory node information and code will be available at https://github.com/UITron-hub/TreeCUA.

</details>

<details><summary><b>中文摘要</b></summary>

有效扩展 GUI 自动化对于计算机使用代理 (CUA) 至关重要；然而，现有的工作主要侧重于扩展 GUI 基础，而不是更重要的 GUI 规划，后者需要更复杂的数据收集。实际上，跨应用程序/桌面/网页的 CUA 探索过程通常遵循树形结构，早期的功能入口点通常会被更频繁地探索。因此，将大规模轨迹组织成树结构可以降低数据成本并简化 GUI 规划的数据扩展。在这项工作中，我们提出 TreeCUA 通过树形结构的可验证进化来有效地扩展 GUI 自动化。我们提出了一个多智能体协作框架来探索环境、验证动作、总结轨迹并评估质量，以生成高质量和可扩展的 GUI 轨迹。为了提高效率，我们设计了一种新颖的基于树的拓扑来存储和重放重复的探索节点，并设计了一种自适应探索算法来平衡深度（\emph{即，轨迹难度）和广度（\emph{即}，轨迹多样性）。此外，我们开发了世界知识指导和全局记忆回溯，以避免低质量的生成。最后，我们从丰富的树节点信息中自然地扩展和提出了TreeCUA-DPO方法，通过参考相邻轨迹的分支信息来提高GUI规划能力。实验结果表明，TreeCUA 和 TreeCUA-DPO 提供了显着的改进，域外（OOD）研究进一步证明了强大的泛化能力。所有轨迹节点信息和代码将在 https://github.com/UITron-hub/TreeCUA 上提供。

</details>

---

## 144. Time2General: Learning Spatiotemporal Invariant Representations for Domain-Generalization Video Semantic Segmentation

**中文标题**: Time2General：学习领域泛化视频语义分割的时空不变表示

**Date**: 2026-02-10 | **arXiv**: [2602.09648v1](http://arxiv.org/abs/2602.09648v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09648v1)

<details><summary><b>Abstract</b></summary>

Domain Generalized Video Semantic Segmentation (DGVSS) is trained on a single labeled driving domain and is directly deployed on unseen domains without target labels and test-time adaptation while maintaining temporally consistent predictions over video streams. In practice, both domain shift and temporal-sampling shift break correspondence-based propagation and fixed-stride temporal aggregation, causing severe frame-to-frame flicker even in label-stable regions. We propose Time2General, a DGVSS framework built on Stability Queries. Time2General introduces a Spatio-Temporal Memory Decoder that aggregates multi-frame context into a clip-level spatio-temporal memory and decodes temporally consistent per-frame masks without explicit correspondence propagation. To further suppress flicker and improve robustness to varying sampling rates, the Masked Temporal Consistency Loss is proposed to regularize temporal prediction discrepancies across different strides, and randomize training strides to expose the model to diverse temporal gaps. Extensive experiments on multiple driving benchmarks show that Time2General achieves a substantial improvement in cross-domain accuracy and temporal stability over prior DGSS and VSS baselines while running at up to 18 FPS. Code will be released after the review process.

</details>

<details><summary><b>中文摘要</b></summary>

域广义视频语义分割 (DGVSS) 在单个标记的驱动域上进行训练，并直接部署在不可见的域上，无需目标标签和测试时间适应，同时保持视频流的时间一致预测。在实践中，域移位和时间采样移位都会破坏基于对应的传播和固定步长时间聚合，即使在标签稳定区域也会导致严重的帧间闪烁。我们提出了 Time2General，一个基于稳定性查询构建的 DGVSS 框架。 Time2General 引入了时空内存解码器，它将多帧上下文聚合到剪辑级时空内存中，并在没有显式对应传播的情况下解码时间一致的每帧掩码。为了进一步抑制闪烁并提高对不同采样率的鲁棒性，提出了掩蔽时间一致性损失来规范不同步幅之间的时间预测差异，并随机化训练步幅以使模型暴露于不同的时间间隙。对多个驾驶基准的大量实验表明，与之前的 DGSS 和 VSS 基线相比，Time2General 在跨域精度和时间稳定性方面取得了实质性改进，同时运行速度高达 18 FPS。代码将在审核后发布。

</details>

---

## 145. Towards Training-free Multimodal Hate Localisation with Large Language Models

**中文标题**: 利用大型语言模型实现免训练多模式仇恨本地化

**Date**: 2026-02-10 | **arXiv**: [2602.09637v1](http://arxiv.org/abs/2602.09637v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09637v1)

<details><summary><b>Abstract</b></summary>

The proliferation of hateful content in online videos poses severe threats to individual well-being and societal harmony. However, existing solutions for video hate detection either rely heavily on large-scale human annotations or lack fine-grained temporal precision. In this work, we propose LELA, the first training-free Large Language Model (LLM) based framework for hate video localization. Distinct from state-of-the-art models that depend on supervised pipelines, LELA leverages LLMs and modality-specific captioning to detect and temporally localize hateful content in a training-free manner. Our method decomposes a video into five modalities, including image, speech, OCR, music, and video context, and uses a multi-stage prompting scheme to compute fine-grained hateful scores for each frame. We further introduce a composition matching mechanism to enhance cross-modal reasoning. Experiments on two challenging benchmarks, HateMM and MultiHateClip, demonstrate that LELA outperforms all existing training-free baselines by a large margin. We also provide extensive ablations and qualitative visualizations, establishing LELA as a strong foundation for scalable and interpretable hate video localization.

</details>

<details><summary><b>中文摘要</b></summary>

网络视频中仇恨内容的泛滥对个人福祉和社会和谐构成严重威胁。然而，现有的视频仇恨检测解决方案要么严重依赖大规模的人类注释，要么缺乏细粒度的时间精度。在这项工作中，我们提出了 LELA，这是第一个基于大语言模型 (LLM) 的免训练仇恨视频本地化框架。与依赖监督管道的最先进模型不同，LELA 利用 LLM 和特定模态字幕以无需培训的方式检测和临时定位仇恨内容。我们的方法将视频分解为五种模式，包括图像、语音、OCR、音乐和视频上下文，并使用多阶段提示方案来计算每帧的细粒度仇恨分数。我们进一步引入了一种组合匹配机制来增强跨模态推理。在 HateMM 和 MultiHateClip 这两个具有挑战性的基准上进行的实验表明，LELA 的性能大幅优于所有现有的免训练基准。我们还提供广泛的消融和定性可视化，将 LELA 建立为可扩展和可解释的仇恨视频本地化的坚实基础。

</details>

---

## 146. AGMark: Attention-Guided Dynamic Watermarking for Large Vision-Language Models

**中文标题**: AGMark：大型视觉语言模型的注意力引导动态水印

**Date**: 2026-02-10 | **arXiv**: [2602.09611v1](http://arxiv.org/abs/2602.09611v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09611v1)

<details><summary><b>Abstract</b></summary>

Watermarking has emerged as a pivotal solution for content traceability and intellectual property protection in Large Vision-Language Models (LVLMs). However, vision-agnostic watermarks may introduce visually irrelevant tokens and disrupt visual grounding by enforcing indiscriminate pseudo-random biases. Additionally, current vision-specific watermarks rely on a static, one-time estimation of vision critical weights and ignore the weight distribution density when determining the proportion of protected tokens. This design fails to account for dynamic changes in visual dependence during generation and may introduce low-quality tokens in the long tail. To address these challenges, we propose Attention-Guided Dynamic Watermarking (AGMark), a novel framework that embeds detectable signals while strictly preserving visual fidelity. At each decoding step, AGMark first dynamically identifies semantic-critical evidence based on attention weights for visual relevance, together with context-aware coherence cues, resulting in a more adaptive and well-calibrated evidence-weight distribution. It then determines the proportion of semantic-critical tokens by jointly considering uncertainty awareness (token entropy) and evidence calibration (weight density), thereby enabling adaptive vocabulary partitioning to avoid irrelevant tokens. Empirical results confirm that AGMark outperforms conventional methods, observably improving generation quality and yielding particularly strong gains in visual semantic fidelity in the later stages of generation. The framework maintains highly competitive detection accuracy (at least 99.36\% AUC) and robust attack resilience (at least 88.61\% AUC) without sacrificing inference efficiency, effectively establishing a new standard for reliability-preserving multi-modal watermarking.

</details>

<details><summary><b>中文摘要</b></summary>

水印已成为大型视觉语言模型 (LVLM) 中内容可追溯性和知识产权保护的关键解决方案。然而，与视觉无关的水印可能会引入视觉上不相关的标记，并通过强制执行不加区别的伪随机偏差来破坏视觉基础。此外，当前的视觉特定水印依赖于视觉临界权重的静态一次性估计，并且在确定受保护令牌的比例时忽略权重分布密度。这种设计未能考虑生成过程中视觉依赖性的动态变化，并且可能会在长尾中引入低质量的令牌。为了应对这些挑战，我们提出了注意力引导动态水印（AGMark），这是一种新颖的框架，可以嵌入可检测信号，同时严格保持视觉保真度。在每个解码步骤中，AGMark 首先根据视觉相关性的注意力权重以及上下文感知的连贯性线索动态识别语义关键证据，从而产生更具适应性和校准良好的证据权重分布。然后，它通过联合考虑不确定性意识（令牌熵）和证据校准（权重密度）来确定语义关键令牌的比例，从而实现自适应词汇划分以避免不相关的令牌。实证结果证实，AGMark 优于传统方法，显着提高了生成质量，并在生成后期阶段的视觉语义保真度方面取得了特别强劲的成果。该框架在不牺牲推理效率的情况下，保持了极具竞争力的检测精度（至少99.36％AUC）和强大的攻击弹性（至少88.61％AUC），有效地建立了保留可靠性的多模态水印的新标准。

</details>

---

## 147. Tele-Omni: a Unified Multimodal Framework for Video Generation and Editing

**中文标题**: Tele-Omni：用于视频生成和编辑的统一多模式框架

**Date**: 2026-02-10 | **arXiv**: [2602.09609v1](http://arxiv.org/abs/2602.09609v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09609v1)

<details><summary><b>Abstract</b></summary>

Recent advances in diffusion-based video generation have substantially improved visual fidelity and temporal coherence. However, most existing approaches remain task-specific and rely primarily on textual instructions, limiting their ability to handle multimodal inputs, contextual references, and diverse video generation and editing scenarios within a unified framework. Moreover, many video editing methods depend on carefully engineered pipelines tailored to individual operations, which hinders scalability and composability. In this paper, we propose Tele-Omni, a unified multimodal framework for video generation and editing that follows multimodal instructions, including text, images, and reference videos, within a single model. Tele-Omni leverages pretrained multimodal large language models to parse heterogeneous instructions and infer structured generation or editing intents, while diffusion-based generators perform high-quality video synthesis conditioned on these structured signals. To enable joint training across heterogeneous video tasks, we introduce a task-aware data processing pipeline that unifies multimodal inputs into a structured instruction format while preserving task-specific constraints. Tele-Omni supports a wide range of video-centric tasks, including text-to-video generation, image-to-video generation, first-last-frame video generation, in-context video generation, and in-context video editing. By decoupling instruction parsing from video synthesis and combining it with task-aware data design, Tele-Omni achieves flexible multimodal control while maintaining strong temporal coherence and visual consistency. Experimental results demonstrate that Tele-Omni achieves competitive performance across multiple tasks.

</details>

<details><summary><b>中文摘要</b></summary>

基于扩散的视频生成的最新进展极大地提高了视觉保真度和时间连贯性。然而，大多数现有方法仍然是特定于任务的，并且主要依赖于文本指令，限制了它们在统一框架内处理多模式输入、上下文参考以及不同视频生成和编辑场景的能力。此外，许多视频编辑方法依赖于针对单独操作精心设计的管道，这阻碍了可扩展性和可组合性。在本文中，我们提出了 Tele-Omni，这是一种用于视频生成和编辑的统一多模式框架，它遵循单一模型中的多模式指令，包括文本、图像和参考视频。 Tele-Omni 利用预训练的多模态大语言模型来解析异构指令并推断结构化生成或编辑意图，而基于扩散的生成器则根据这些结构化信号执行高质量视频合成。为了实现跨异构视频任务的联合训练，我们引入了任务感知数据处理管道，它将多模态输入统一为结构化指令格式，同时保留特定于任务的约束。 Tele-Omni 支持各种以视频为中心的任务，包括文本到视频生成、图像到视频生成、首尾帧视频生成、上下文视频生成和上下文视频编辑。通过将指令解析与视频合成解耦并将其与任务感知数据设计相结合，Tele-Omni 实现了灵活的多模式控制，同时保持了强大的时间连贯性和视觉一致性。实验结果表明，Tele-Omni 在多项任务中实现了具有竞争力的性能。

</details>

---

## 148. Hand2World: Autoregressive Egocentric Interaction Generation via Free-Space Hand Gestures

**中文标题**: Hand2World：通过自由空间手势生成自回归自我中心交互

**Date**: 2026-02-10 | **arXiv**: [2602.09600v1](http://arxiv.org/abs/2602.09600v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09600v1)

<details><summary><b>Abstract</b></summary>

Egocentric interactive world models are essential for augmented reality and embodied AI, where visual generation must respond to user input with low latency, geometric consistency, and long-term stability. We study egocentric interaction generation from a single scene image under free-space hand gestures, aiming to synthesize photorealistic videos in which hands enter the scene, interact with objects, and induce plausible world dynamics under head motion. This setting introduces fundamental challenges, including distribution shift between free-space gestures and contact-heavy training data, ambiguity between hand motion and camera motion in monocular views, and the need for arbitrary-length video generation. We present Hand2World, a unified autoregressive framework that addresses these challenges through occlusion-invariant hand conditioning based on projected 3D hand meshes, allowing visibility and occlusion to be inferred from scene context rather than encoded in the control signal. To stabilize egocentric viewpoint changes, we inject explicit camera geometry via per-pixel Plücker-ray embeddings, disentangling camera motion from hand motion and preventing background drift. We further develop a fully automated monocular annotation pipeline and distill a bidirectional diffusion model into a causal generator, enabling arbitrary-length synthesis. Experiments on three egocentric interaction benchmarks show substantial improvements in perceptual quality and 3D consistency while supporting camera control and long-horizon interactive generation.

</details>

<details><summary><b>中文摘要</b></summary>

以自我为中心的交互式世界模型对于增强现实和嵌入式人工智能至关重要，其中视觉生成必须以低延迟、几何一致性和长期稳定性响应用户输入。我们研究自由空间手势下单个场景图像的以自我为中心的交互生成，旨在合成逼真的视频，其中手进入场景，与物体交互，并在头部运动下诱导可信的世界动态。这种设置带来了根本性的挑战，包括自由空间手势和大量接触训练数据之间的分布变化、单目视图中手部运动和相机运动之间的模糊性，以及任意长度视频生成的需要。我们提出了 Hand2World，这是一个统一的自回归框架，它通过基于投影 3D 手部网格的遮挡不变手调节来解决这些挑战，允许从场景上下文中推断可见性和遮挡，而不是在控制信号中进行编码。为了稳定以自我为中心的视点变化，我们通过每像素 Plücker 射线嵌入注入显式相机几何形状，将相机运动与手部运动分开并防止背景漂移。我们进一步开发了一个全自动的单目注释管道，并将双向扩散模型提炼成因果生成器，从而实现任意长度的合成。对三个以自我为中心的交互基准进行的实验表明，感知质量和 3D 一致性得到了显着改善，同时支持相机控制和长视距交互生成。

</details>

---

## 149. Delving into Spectral Clustering with Vision-Language Representations

**中文标题**: 使用视觉语言表示深入研究谱聚类

**Date**: 2026-02-10 | **arXiv**: [2602.09586v1](http://arxiv.org/abs/2602.09586v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09586v1)

<details><summary><b>Abstract</b></summary>

Spectral clustering is known as a powerful technique in unsupervised data analysis. The vast majority of approaches to spectral clustering are driven by a single modality, leaving the rich information in multi-modal representations untapped. Inspired by the recent success of vision-language pre-training, this paper enriches the landscape of spectral clustering from a single-modal to a multi-modal regime. Particularly, we propose Neural Tangent Kernel Spectral Clustering that leverages cross-modal alignment in pre-trained vision-language models. By anchoring the neural tangent kernel with positive nouns, i.e., those semantically close to the images of interest, we arrive at formulating the affinity between images as a coupling of their visual proximity and semantic overlap. We show that this formulation amplifies within-cluster connections while suppressing spurious ones across clusters, hence encouraging block-diagonal structures. In addition, we present a regularized affinity diffusion mechanism that adaptively ensembles affinity matrices induced by different prompts. Extensive experiments on \textbf{16} benchmarks -- including classical, large-scale, fine-grained and domain-shifted datasets -- manifest that our method consistently outperforms the state-of-the-art by a large margin.

</details>

<details><summary><b>中文摘要</b></summary>

谱聚类被认为是无监督数据分析中的强大技术。绝大多数谱聚类方法都是由单一模态驱动的，而多模态表示中的丰富信息尚未得到利用。受最近视觉语言预训练成功的启发，本文丰富了谱聚类从单模态到多模态的前景。特别是，我们提出了神经切线核谱聚类，它利用预训练视觉语言模型中的跨模式对齐。通过用肯定名词（即语义上接近感兴趣图像的名词）锚定神经切线内核，我们将图像之间的亲和力表述为视觉接近度和语义重叠的耦合。我们表明，这种公式放大了簇内连接，同时抑制了簇间的虚假连接，从而鼓励了块对角结构。此外，我们提出了一种正则化的亲和力扩散机制，可以自适应地集成由不同提示引起的亲和力矩阵。对 \textbf{16} 基准的广泛实验——包括经典、大规模、细粒度和域转移数据集——表明我们的方法始终大幅优于最先进的方法。

</details>

---

## 150. Scalpel: Fine-Grained Alignment of Attention Activation Manifolds via Mixture Gaussian Bridges to Mitigate Multimodal Hallucination

**中文标题**: Scalpel：通过混合高斯桥对注意力激活流形进行细粒度对齐，以减轻多模态幻觉

**Date**: 2026-02-10 | **arXiv**: [2602.09541v1](http://arxiv.org/abs/2602.09541v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09541v1)

<details><summary><b>Abstract</b></summary>

Rapid progress in large vision-language models (LVLMs) has achieved unprecedented performance in vision-language tasks. However, due to the strong prior of large language models (LLMs) and misaligned attention across modalities, LVLMs often generate outputs inconsistent with visual content - termed hallucination. To address this, we propose \textbf{Scalpel}, a method that reduces hallucination by refining attention activation distributions toward more credible regions. Scalpel predicts trusted attention directions for each head in Transformer layers during inference and adjusts activations accordingly. It employs a Gaussian mixture model to capture multi-peak distributions of attention in trust and hallucination manifolds, and uses entropic optimal transport (equivalent to Schrödinger bridge problem) to map Gaussian components precisely. During mitigation, Scalpel dynamically adjusts intervention strength and direction based on component membership and mapping relationships between hallucination and trust activations. Extensive experiments across multiple datasets and benchmarks demonstrate that Scalpel effectively mitigates hallucinations, outperforming previous methods and achieving state-of-the-art performance. Moreover, Scalpel is model- and data-agnostic, requiring no additional computation, only a single decoding step.

</details>

<details><summary><b>中文摘要</b></summary>

大型视觉语言模型（LVLM）的快速进展在视觉语言任务中取得了前所未有的性能。然而，由于大语言模型 (LLM) 的强大先验和跨模态的注意力错位，LVLM 经常生成与视觉内容不一致的输出 - 称为幻觉。为了解决这个问题，我们提出了 \textbf{Scalpel}，一种通过细化注意力激活分布到更可信区域来减少幻觉的方法。 Scalpel 在推理过程中预测 Transformer 层中每个头的可信注意力方向，并相应地调整激活。它采用高斯混合模型来捕获信任和幻觉流形中注意力的多峰分布，并使用熵最优传输（相当于薛定谔桥问题）来精确映射高斯分量。在缓解过程中，Scalpel 根据组件成员资格以及幻觉和信任激活之间的映射关系动态调整干预强度和方向。跨多个数据集和基准的大量实验表明，Scalpel 可以有效减轻幻觉，超越以前的方法并实现最先进的性能。此外，Scalpel 与模型和数据无关，不需要额外的计算，只需要一个解码步骤。

</details>

---

## 151. AUHead: Realistic Emotional Talking Head Generation via Action Units Control

**中文标题**: AUHead：通过动作单元控制生成逼真的情感头部

**Date**: 2026-02-10 | **arXiv**: [2602.09534v1](http://arxiv.org/abs/2602.09534v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09534v1)

**Code**: https://github.com/laura990501/AUHead_ICLR

<details><summary><b>Abstract</b></summary>

Realistic talking-head video generation is critical for virtual avatars, film production, and interactive systems. Current methods struggle with nuanced emotional expressions due to the lack of fine-grained emotion control. To address this issue, we introduce a novel two-stage method (AUHead) to disentangle fine-grained emotion control, i.e. , Action Units (AUs), from audio and achieve controllable generation. In the first stage, we explore the AU generation abilities of large audio-language models (ALMs), by spatial-temporal AU tokenization and an "emotion-then-AU" chain-of-thought mechanism. It aims to disentangle AUs from raw speech, effectively capturing subtle emotional cues. In the second stage, we propose an AU-driven controllable diffusion model that synthesizes realistic talking-head videos conditioned on AU sequences. Specifically, we first map the AU sequences into the structured 2D facial representation to enhance spatial fidelity, and then model the AU-vision interaction within cross-attention modules. To achieve flexible AU-quality trade-off control, we introduce an AU disentanglement guidance strategy during inference, further refining the emotional expressiveness and identity consistency of the generated videos. Results on benchmark datasets demonstrate that our approach achieves competitive performance in emotional realism, accurate lip synchronization, and visual coherence, significantly surpassing existing techniques. Our implementation is available at https://github.com/laura990501/AUHead_ICLR

</details>

<details><summary><b>中文摘要</b></summary>

逼真的头部说话视频生成对于虚拟化身、电影制作和交互系统至关重要。由于缺乏细粒度的情绪控制，当前的方法难以处理微妙的情绪表达。为了解决这个问题，我们引入了一种新颖的两阶段方法（AUHead）来从音频中分离出细粒度的情感控制，即动作单元（AU），并实现可控生成。在第一阶段，我们通过时空AU标记化和“情感然后AU”的思想链机制来探索大型音频语言模型（ALM）的AU生成能力。它的目的是将 AU 与原始语音分开，有效捕捉微妙的情感线索。在第二阶段，我们提出了一种由 AU 驱动的可控扩散模型，该模型可以合成以 AU 序列为条件的逼真的头部说话视频。具体来说，我们首先将 AU 序列映射到结构化 2D 面部表示中以增强空间保真度，然后在交叉注意模块内对 AU 视觉交互进行建模。为了实现灵活的 AU 质量权衡控制，我们在推理过程中引入了 AU 解纠缠指导策略，进一步细化生成视频的情感表达和身份一致性。基准数据集的结果表明，我们的方法在情感真实性、准确的口型同步和视觉连贯性方面实现了竞争性能，显着超越了现有技术。我们的实现可在 https://github.com/laura990501/AUHead_ICLR 获取

</details>

---

## 152. DR.Experts: Differential Refinement of Distortion-Aware Experts for Blind Image Quality Assessment

**中文标题**: DR.Experts：用于盲图像质量评估的失真感知专家的差异化细化

**Date**: 2026-02-10 | **arXiv**: [2602.09531v1](http://arxiv.org/abs/2602.09531v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09531v1)

<details><summary><b>Abstract</b></summary>

Blind Image Quality Assessment, aiming to replicate human perception of visual quality without reference, plays a key role in vision tasks, yet existing models often fail to effectively capture subtle distortion cues, leading to a misalignment with human subjective judgments. We identify that the root cause of this limitation lies in the lack of reliable distortion priors, as methods typically learn shallow relationships between unified image features and quality scores, resulting in their insensitive nature to distortions and thus limiting their performance. To address this, we introduce DR.Experts, a novel prior-driven BIQA framework designed to explicitly incorporate distortion priors, enabling a reliable quality assessment. DR.Experts begins by leveraging a degradation-aware vision-language model to obtain distortion-specific priors, which are further refined and enhanced by the proposed Distortion-Saliency Differential Module through distinguishing them from semantic attentions, thereby ensuring the genuine representations of distortions. The refined priors, along with semantics and bridging representation, are then fused by a proposed mixture-of-experts style module named the Dynamic Distortion Weighting Module. This mechanism weights each distortion-specific feature as per its perceptual impact, ensuring that the final quality prediction aligns with human perception. Extensive experiments conducted on five challenging BIQA benchmarks demonstrate the superiority of DR.Experts over current methods and showcase its excellence in terms of generalization and data efficiency.

</details>

<details><summary><b>中文摘要</b></summary>

盲图像质量评估旨在在没有参考的情况下复制人类对视觉质量的感知，在视觉任务中发挥着关键作用，但现有模型往往无法有效捕获微妙的失真线索，导致与人类主观判断的不一致。我们发现这种限制的根本原因在于缺乏可靠的失真先验，因为方法通常学习统一图像特征和质量分数之间的浅层关系，导致它们对失真不敏感，从而限制了它们的性能。为了解决这个问题，我们引入了 DR.Experts，这是一种新颖的先验驱动的 BIQA 框架，旨在明确合并失真先验，从而实现可靠的质量评估。 DR.Experts 首先利用退化感知视觉语言模型来获取特定于失真的先验，并通过提出的失真显着性差分模块将其与语义注意区分开来进一步细化和增强，从而确保失真的真实表示。然后，经过改进的先验以及语义和桥接表示，由提出的名为动态失真加权模块的专家混合风格模块进行融合。该机制根据每个失真特定特征的感知影响对其进行加权，确保最终的质量预测与人类感知一致。在五个具有挑战性的 BIQA 基准上进行的大量实验证明了 DR.Experts 相对于当前方法的优越性，并展示了其在泛化和数据效率方面的卓越性能。

</details>

---

## 153. SCA-Net: Spatial-Contextual Aggregation Network for Enhanced Small Building and Road Change Detection

**中文标题**: SCA-Net：用于增强小型建筑和道路变化检测的空间上下文聚合网络

**Date**: 2026-02-10 | **arXiv**: [2602.09529v1](http://arxiv.org/abs/2602.09529v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09529v1)

<details><summary><b>Abstract</b></summary>

Automated change detection in remote sensing imagery is critical for urban management, environmental monitoring, and disaster assessment. While deep learning models have advanced this field, they often struggle with challenges like low sensitivity to small objects and high computational costs. This paper presents SCA-Net, an enhanced architecture built upon the Change-Agent framework for precise building and road change detection in bi-temporal images. Our model incorporates several key innovations: a novel Difference Pyramid Block for multi-scale change analysis, an Adaptive Multi-scale Processing module combining shape-aware and high-resolution enhancement blocks, and multi-level attention mechanisms (PPM and CSAGate) for joint contextual and detail processing. Furthermore, a dynamic composite loss function and a four-phase training strategy are introduced to stabilize training and accelerate convergence. Comprehensive evaluations on the LEVIR-CD and LEVIR-MCI datasets demonstrate SCA-Net's superior performance over Change-Agent and other state-of-the-art methods. Our approach achieves a significant 2.64% improvement in mean Intersection over Union (mIoU) on LEVIR-MCI and a remarkable 57.9% increase in IoU for small buildings, while reducing the training time by 61%. This work provides an efficient, accurate, and robust solution for practical change detection applications.

</details>

<details><summary><b>中文摘要</b></summary>

遥感图像的自动变化检测对于城市管理、环境监测和灾害评估至关重要。虽然深度学习模型推动了这一领域的发展，但它们经常面临诸如对小物体的敏感性低和计算成本高等挑战。本文提出了 SCA-Net，这是一种基于 Change-Agent 框架构建的增强架构，用于双时态图像中的精确建筑和道路变化检测。我们的模型融合了多项关键创新：用于多尺度变化分析的新颖差异金字塔模块、结合形状感知和高分辨率增强模块的自适应多尺度处理模块，以及用于联合上下文和细节处理的多级注意机制（PPM 和 CSAGate）。此外，引入动态复合损失函数和四阶段训练策略来稳定训练并加速收敛。对 LEVIR-CD 和 LEVIR-MCI 数据集的综合评估表明，SCA-Net 的性能优于 Change-Agent 和其他最先进的方法。我们的方法在 LEVIR-MCI 上的平均交集比 (mIoU) 显着提高了 2.64%，小型建筑物的 IoU 显着提高了 57.9%，同时减少了 61% 的训练时间。这项工作为实际变化检测应用提供了高效、准确且强大的解决方案。

</details>

---

## 154. SchröMind: Mitigating Hallucinations in Multimodal Large Language Models via Solving the Schrödinger Bridge Problem

**中文标题**: SchröMind：通过解决薛定谔桥问题减轻多模态大语言模型中的幻觉

**Date**: 2026-02-10 | **arXiv**: [2602.09528v1](http://arxiv.org/abs/2602.09528v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09528v1)

<details><summary><b>Abstract</b></summary>

Recent advancements in Multimodal Large Language Models (MLLMs) have achieved significant success across various domains. However, their use in high-stakes fields like healthcare remains limited due to persistent hallucinations, where generated text contradicts or ignores visual input. We contend that MLLMs can comprehend images but struggle to produce accurate token sequences. Minor perturbations can shift attention from truthful to untruthful states, and the autoregressive nature of text generation often prevents error correction. To address this, we propose SchröMind-a novel framework reducing hallucinations via solving the Schrödinger bridge problem. It establishes a token-level mapping between hallucinatory and truthful activations with minimal transport cost through lightweight training, while preserving the model's original capabilities. Extensive experiments on the POPE and MME benchmarks demonstrate the superiority of Schrödinger, which achieves state-of-the-art performance while introducing only minimal computational overhead.

</details>

<details><summary><b>中文摘要</b></summary>

多模态大语言模型 (MLLM) 的最新进展在各个领域取得了巨大的成功。然而，由于持续的幻觉，它们在医疗保健等高风险领域的使用仍然受到限制，其中生成的文本与视觉输入相矛盾或忽略。我们认为 MLLM 可以理解图像，但难以生成准确的标记序列。微小的扰动可能会将注意力从真实状态转移到不真实状态，而文本生成的自回归性质通常会阻止错误纠正。为了解决这个问题，我们提出了 SchröMind——一种通过解决薛定谔桥问题来减少幻觉的新颖框架。它通过轻量级训练以最小的传输成本在幻觉和真实激活之间建立了令牌级映射，同时保留了模型的原始功能。 POPE 和 MME 基准的大量实验证明了薛定谔的优越性，它实现了最先进的性能，同时只引入了最小的计算开销。

</details>

---

## 155. HLGFA: High-Low Resolution Guided Feature Alignment for Unsupervised Anomaly Detection

**中文标题**: HLGFA：用于无监督异常检测的高低分辨率引导特征对齐

**Date**: 2026-02-10 | **arXiv**: [2602.09524v1](http://arxiv.org/abs/2602.09524v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09524v1)

<details><summary><b>Abstract</b></summary>

Unsupervised industrial anomaly detection (UAD) is essential for modern manufacturing inspection, where defect samples are scarce and reliable detection is required. In this paper, we propose HLGFA, a high-low resolution guided feature alignment framework that learns normality by modeling cross-resolution feature consistency between high-resolution and low-resolution representations of normal samples, instead of relying on pixel-level reconstruction. Dual-resolution inputs are processed by a shared frozen backbone to extract multi-level features, and high-resolution representations are decomposed into structure and detail priors to guide the refinement of low-resolution features through conditional modulation and gated residual correction. During inference, anomalies are naturally identified as regions where cross-resolution alignment breaks down. In addition, a noise-aware data augmentation strategy is introduced to suppress nuisance-induced responses commonly observed in industrial environments. Extensive experiments on standard benchmarks demonstrate the effectiveness of HLGFA, achieving 97.9% pixel-level AUROC and 97.5% image-level AUROC on the MVTec AD dataset, outperforming representative reconstruction-based and feature-based methods.

</details>

<details><summary><b>中文摘要</b></summary>

无监督工业异常检测 (UAD) 对于缺陷样本稀缺且需要可靠检测的现代制造检测至关重要。在本文中，我们提出了 HLGFA，一种高低分辨率引导特征对齐框架，它通过对正常样本的高分辨率和低分辨率表示之间的跨分辨率特征一致性进行建模来学习正态性，而不是依赖于像素级重建。双分辨率输入由共享的冻结主干处理以提取多级特征，高分辨率表示被分解为结构和细节先验，以通过条件调制和门控残差校正指导低分辨率特征的细化。在推理过程中，异常自然被识别为跨分辨率对齐失败的区域。此外，还引入了噪声感知数据增强策略来抑制工业环境中常见的滋扰引起的响应。标准基准上的大量实验证明了 HLGFA 的有效性，在 MVTec AD 数据集上实现了 97.9% 的像素级 AUROC 和 97.5% 的图像级 AUROC，优于代表性的基于重建和基于特征的方法。

</details>

---

## 156. Singpath-VL Technical Report

**中文标题**: Singpath-VL技术报告

**Date**: 2026-02-10 | **arXiv**: [2602.09523v1](http://arxiv.org/abs/2602.09523v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09523v1)

<details><summary><b>Abstract</b></summary>

We present Singpath-VL, a vision-language large model, to fill the vacancy of AI assistant in cervical cytology. Recent advances in multi-modal large language models (MLLMs) have significantly propelled the field of computational pathology. However, their application in cytopathology, particularly cervical cytology, remains underexplored, primarily due to the scarcity of large-scale, high-quality annotated datasets. To bridge this gap, we first develop a novel three-stage pipeline to synthesize a million-scale image-description dataset. The pipeline leverages multiple general-purpose MLLMs as weak annotators, refines their outputs through consensus fusion and expert knowledge injection, and produces high-fidelity descriptions of cell morphology. Using this dataset, we then fine-tune the Qwen3-VL-4B model via a multi-stage strategy to create a specialized cytopathology MLLM. The resulting model, named Singpath-VL, demonstrates superior performance in fine-grained morphological perception and cell-level diagnostic classification. To advance the field, we will open-source a portion of the synthetic dataset and benchmark.

</details>

<details><summary><b>中文摘要</b></summary>

我们推出视觉语言大模型Singpath-VL，填补宫颈细胞学人工智能助手的空缺。多模态大语言模型（MLLM）的最新进展极大地推动了计算病理学领域的发展。然而，它们在细胞病理学，特别是宫颈细胞学中的应用仍未得到充分探索，这主要是由于缺乏大规模、高质量的注释数据集。为了弥补这一差距，我们首先开发了一种新颖的三阶段管道来合成百万级图像描述数据集。该管道利用多个通用 MLLM 作为弱注释器，通过共识融合和专家知识注入完善其输出，并生成细胞形态的高保真描述。然后，我们使用该数据集通过多阶段策略微调 Qwen3-VL-4B 模型，以创建专门的细胞病理学 MLLM。由此产生的模型被命名为 Singpath-VL，在细粒度形态感知和细胞级诊断分类方面表现出卓越的性能。为了推进该领域的发展，我们将开源部分合成数据集和基准。

</details>

---

## 157. Attention to details, logits to truth: visual-aware attention and logits enhancement to mitigate hallucinations in LVLMs

**中文标题**: 关注细节，logits 真实：视觉感知注意力和 logits 增强以减轻 LVLM 中的幻觉

**Date**: 2026-02-10 | **arXiv**: [2602.09521v1](http://arxiv.org/abs/2602.09521v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09521v1)

<details><summary><b>Abstract</b></summary>

Existing Large Vision-Language Models (LVLMs) exhibit insufficient visual attention, leading to hallucinations. To alleviate this problem, some previous studies adjust and amplify visual attention. These methods present a limitation that boosting attention for all visual tokens inevitably increases attention to task irrelevant tokens. To tackle this challenge, we propose a training free attentional intervention algorithm to enhance the attention of task-relevant tokens based on the argument that task-relevant tokens generally demonstrate high visual-textual similarities. Specifically, the vision-text cross-attention submatrices, which represent visual-textual correlations, are extracted to construct the reweighting matrices to reallocate attention. Besides, to enhance the contribution of visual tokens, we inject visual attention values into the beam search decoding to identify solutions with higher visual attention. Extensive experiments demonstrate that this method significantly reduces hallucinations across mainstream LVLMs, while preserving the accuracy and coherence of generated content.

</details>

<details><summary><b>中文摘要</b></summary>

现有的大视觉语言模型（LVLM）表现出视觉注意力不足，导致幻觉。为了缓解这个问题，之前的一些研究调整并增强了视觉注意力。这些方法存在一个局限性，即提高对所有视觉标记的注意力不可避免地会增加对与任务无关的标记的注意力。为了应对这一挑战，我们提出了一种免训练注意力干预算法，以基于任务相关标记通常表现出高度视觉文本相似性的论点来增强任务相关标记的注意力。具体来说，提取代表视觉文本相关性的视觉文本交叉注意力子矩阵来构造重新加权矩阵以重新分配注意力。此外，为了增强视觉标记的贡献，我们将视觉注意力值注入波束搜索解码中，以识别具有更高视觉注意力的解决方案。大量实验表明，该方法可显着减少主流 LVLM 中的幻觉，同时保持生成内容的准确性和连贯性。

</details>

---

## 158. A Universal Action Space for General Behavior Analysis

**中文标题**: 用于一般行为分析的通用行动空间

**Date**: 2026-02-10 | **arXiv**: [2602.09518v1](http://arxiv.org/abs/2602.09518v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09518v1)

**Code**: https://github.com/franktpmvu/Universal-Action-Space.

<details><summary><b>Abstract</b></summary>

Analyzing animal and human behavior has long been a challenging task in computer vision. Early approaches from the 1970s to the 1990s relied on hand-crafted edge detection, segmentation, and low-level features such as color, shape, and texture to locate objects and infer their identities-an inherently ill-posed problem. Behavior analysis in this era typically proceeded by tracking identified objects over time and modeling their trajectories using sparse feature points, which further limited robustness and generalization. A major shift occurred with the introduction of ImageNet by Deng and Li in 2010, which enabled large-scale visual recognition through deep neural networks and effectively served as a comprehensive visual dictionary. This development allowed object recognition to move beyond complex low-level processing toward learned high-level representations. In this work, we follow this paradigm to build a large-scale Universal Action Space (UAS) using existing labeled human-action datasets. We then use this UAS as the foundation for analyzing and categorizing mammalian and chimpanzee behavior datasets. The source code is released on GitHub at https://github.com/franktpmvu/Universal-Action-Space.

</details>

<details><summary><b>中文摘要</b></summary>

分析动物和人类行为长期以来一直是计算机视觉领域的一项具有挑战性的任务。 20 世纪 70 年代到 90 年代的早期方法依赖于手工边缘检测、分割和颜色、形状和纹理等低级特征来定位对象并推断其身份，这本质上是一个不适定问题。这个时代的行为分析通常是通过随着时间的推移跟踪已识别的对象并使用稀疏特征点对其轨迹进行建模来进行的，这进一步限制了鲁棒性和泛化性。 2010 年，Deng 和 Li 引入 ImageNet，发生了重大转变，它通过深度神经网络实现了大规模视觉识别，并有效地充当了综合视觉词典。这一发展使得对象识别能够超越复杂的低级处理，转向学习的高级表示。在这项工作中，我们遵循这个范例，使用现有的标记人类行为数据集构建一个大规模的通用行动空间（UAS）。然后，我们使用该无人机作为分析和分类哺乳动物和黑猩猩行为数据集的基础。源代码发布在 GitHub 上：https://github.com/franktpmvu/Universal-Action-Space。

</details>

---

## 159. Equilibrium contrastive learning for imbalanced image classification

**中文标题**: 不平衡图像分类的平衡对比学习

**Date**: 2026-02-10 | **arXiv**: [2602.09506v1](http://arxiv.org/abs/2602.09506v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09506v1)

<details><summary><b>Abstract</b></summary>

Contrastive learning (CL) is a predominant technique in image classification, but they showed limited performance with an imbalanced dataset. Recently, several supervised CL methods have been proposed to promote an ideal regular simplex geometric configuration in the representation space-characterized by intra-class feature collapse and uniform inter-class mean spacing, especially for imbalanced datasets. In particular, existing prototype-based methods include class prototypes, as additional samples to consider all classes. However, the existing CL methods suffer from two limitations. First, they do not consider the alignment between the class means/prototypes and classifiers, which could lead to poor generalization. Second, existing prototype-based methods treat prototypes as only one additional sample per class, making their influence depend on the number of class instances in a batch and causing unbalanced contributions across classes. To address these limitations, we propose Equilibrium Contrastive Learning (ECL), a supervised CL framework designed to promote geometric equilibrium, where class features, means, and classifiers are harmoniously balanced under data imbalance. The proposed ECL framework uses two main components. First, ECL promotes the representation geometric equilibrium (i.e., a regular simplex geometry characterized by collapsed class samples and uniformly distributed class means), while balancing the contributions of class-average features and class prototypes. Second, ECL establishes a classifier-class center geometric equilibrium by aligning classifier weights and class prototypes. We ran experiments with three long-tailed datasets, the CIFAR-10(0)-LT, ImageNet-LT, and the two imbalanced medical datasets, the ISIC 2019 and our constructed LCCT dataset. Results show that ECL outperforms existing SOTA supervised CL methods designed for imbalanced classification.

</details>

<details><summary><b>中文摘要</b></summary>

对比学习（CL）是图像分类中的主要技术，但它们在不平衡的数据集上表现出有限的性能。最近，人们提出了几种有监督的 CL 方法来促进表示空间中理想的正则单纯形几何配置，其特征是类内特征崩溃和均匀的类间平均间距，特别是对于不平衡数据集。特别是，现有的基于原型的方法包括类原型，作为考虑所有类的附加样本。然而，现有的 CL 方法存在两个局限性。首先，他们没有考虑类手段/原型和分类器之间的对齐，这可能导致泛化不良。其次，现有的基于原型的方法将原型视为每个类的一个附加样本，使其影响取决于一批中类实例的数量，并导致类之间的贡献不平衡。为了解决这些限制，我们提出了平衡对比学习（ECL），这是一种有监督的 CL 框架，旨在促进几何平衡，其中类特征、均值和分类器在数据不平衡的情况下和谐平衡。所提出的 ECL 框架使用两个主要组件。首先，ECL 促进表示几何平衡（即，以折叠类样本和均匀分布类均值为特征的正则单纯形几何），同时平衡类平均特征和类原型的贡献。其次，ECL 通过对齐分类器权重和类原型来建立分类器类中心几何平衡。我们使用三个长尾数据集（CIFAR-10(0)-LT、ImageNet-LT）和两个不平衡医学数据集（ISIC 2019 和我们构建的 LCCT 数据集）进行了实验。结果表明，ECL 优于现有的专为不平衡分类设计的 SOTA 监督 CL 方法。

</details>

---

## 160. Beyond Next-Token Alignment: Distilling Multimodal Large Language Models via Token Interactions

**中文标题**: 超越下一个令牌对齐：通过令牌交互提炼多模式大型语言模型

**Date**: 2026-02-10 | **arXiv**: [2602.09483v1](http://arxiv.org/abs/2602.09483v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09483v1)

**Code**: https://github.com/lchen1019/Align-TI.

<details><summary><b>Abstract</b></summary>

Multimodal Large Language Models (MLLMs) demonstrate impressive cross-modal capabilities, yet their substantial size poses significant deployment challenges. Knowledge distillation (KD) is a promising solution for compressing these models, but existing methods primarily rely on static next-token alignment, neglecting the dynamic token interactions, which embed essential capabilities for multimodal understanding and generation. To this end, we introduce Align-TI, a novel KD framework designed from the perspective of Token Interactions. Our approach is motivated by the insight that MLLMs rely on two primary interactions: vision-instruction token interactions to extract relevant visual information, and intra-response token interactions for coherent generation. Accordingly, Align-TI introduces two components: IVA enables the student model to imitate the teacher's instruction-relevant visual information extract capability by aligning on salient visual regions. TPA captures the teacher's dynamic generative logic by aligning the sequential token-to-token transition probabilities. Extensive experiments demonstrate Align-TI's superiority. Notably, our approach achieves $2.6\%$ relative improvement over Vanilla KD, and our distilled Align-TI-2B even outperforms LLaVA-1.5-7B (a much larger MLLM) by $7.0\%$, establishing a new state-of-the-art distillation framework for training parameter-efficient MLLMs. Code is available at https://github.com/lchen1019/Align-TI.

</details>

<details><summary><b>中文摘要</b></summary>

多模态大型语言模型 (MLLM) 展示了令人印象深刻的跨模态功能，但其庞大的规模带来了重大的部署挑战。知识蒸馏（KD）是压缩这些模型的一种有前景的解决方案，但现有方法主要依赖于静态下一个令牌对齐，忽略了动态令牌交互，而动态令牌交互嵌入了多模态理解和生成的基本功能。为此，我们引入Align-TI，一个从Token交互角度设计的新颖的KD框架。我们的方法的动机是认识到 MLLM 依赖于两种主要交互：用于提取相关视觉信息的视觉指令令牌交互，以及用于连贯生成的响应内令牌交互。因此，Align-TI 引入了两个组件：IVA 使学生模型能够通过对齐显着视觉区域来模仿教师的与教学相关的视觉信息提取能力。 TPA 通过调整顺序标记到标记的转换概率来捕获教师的动态生成逻辑。大量的实验证明了Align-TI 的优越性。值得注意的是，我们的方法比 Vanilla KD 实现了 2.6\%$ 的相对改进，并且我们的蒸馏 Align-TI-2B 甚至比 LLaVA-1.5-7B（更大的 MLLM）高出 7.0\%$，为训练参数高效的 MLLM 建立了一个新的最先进的蒸馏框架。代码可在 https://github.com/lchen1019/Align-TI 获取。

</details>

---

## 161. Weakly Supervised Contrastive Learning for Histopathology Patch Embeddings

**中文标题**: 组织病理学斑块嵌入的弱监督对比学习

**Date**: 2026-02-10 | **arXiv**: [2602.09477v1](http://arxiv.org/abs/2602.09477v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09477v1)

<details><summary><b>Abstract</b></summary>

Digital histopathology whole slide images (WSIs) provide gigapixel-scale high-resolution images that are highly useful for disease diagnosis. However, digital histopathology image analysis faces significant challenges due to the limited training labels, since manually annotating specific regions or small patches cropped from large WSIs requires substantial time and effort. Weakly supervised multiple instance learning (MIL) offers a practical and efficient solution by requiring only bag-level (slide-level) labels, while each bag typically contains multiple instances (patches). Most MIL methods directly use frozen image patch features generated by various image encoders as inputs and primarily focus on feature aggregation. However, feature representation learning for encoder pretraining in MIL settings has largely been neglected.   In our work, we propose a novel feature representation learning framework called weakly supervised contrastive learning (WeakSupCon) that incorporates bag-level label information during training. Our method does not rely on instance-level pseudo-labeling, yet it effectively separates patches with different labels in the feature space. Experimental results demonstrate that the image features generated by our WeakSupCon method lead to improved downstream MIL performance compared to self-supervised contrastive learning approaches in three datasets. Our related code is available at github.com/BzhangURU/Paper_WeakSupCon_for_MIL

</details>

<details><summary><b>中文摘要</b></summary>

数字组织病理学全切片图像 (WSI) 提供十亿像素级高分辨率图像，对于疾病诊断非常有用。然而，由于训练标签有限，数字组织病理学图像分析面临重大挑战，因为手动注释特定区域或从大型 WSI 中裁剪的小块需要大量时间和精力。弱监督多实例学习（MIL）提供了一种实用且高效的解决方案，只需要包级（幻灯片级）标签，而每个包通常包含多个实例（补丁）。大多数 MIL 方法直接使用各种图像编码器生成的冻结图像块特征作为输入，并且主要关注特征聚合。然而，MIL 设置中编码器预训练的特征表示学习在很大程度上被忽视了。   在我们的工作中，我们提出了一种新颖的特征表示学习框架，称为弱监督对比学习（WeakSupCon），该框架在训练期间结合了袋级标签信息。我们的方法不依赖于实例级伪标签，但它有效地分离了特征空间中具有不同标签的补丁。实验结果表明，与三个数据集中的自监督对比学习方法相比，我们的 WeakSupCon 方法生成的图像特征可以提高下游 MIL 性能。我们的相关代码可在 github.com/BzhangURU/Paper_WeakSupCon_for_MIL 获取

</details>

---

## 162. FD-DB: Frequency-Decoupled Dual-Branch Network for Unpaired Synthetic-to-Real Domain Translation

**中文标题**: FD-DB：用于不成对合成到真实域转换的频率解耦双分支网络

**Date**: 2026-02-10 | **arXiv**: [2602.09476v2](http://arxiv.org/abs/2602.09476v2) | **PDF**: [Link](http://arxiv.org/pdf/2602.09476v2)

<details><summary><b>Abstract</b></summary>

Synthetic data provide low-cost, accurately annotated samples for geometry-sensitive vision tasks, but appearance and imaging differences between synthetic and real domains cause severe domain shift and degrade downstream performance. Unpaired synthetic-to-real translation can reduce this gap without paired supervision, yet existing methods often face a trade-off between photorealism and structural stability: unconstrained generation may introduce deformation or spurious textures, while overly rigid constraints limit adaptation to real-domain statistics. We propose FD-DB, a frequency-decoupled dual-branch model that separates appearance transfer into low-frequency interpretable editing and high-frequency residual compensation. The interpretable branch predicts physically meaningful editing parameters (white balance, exposure, contrast, saturation, blur, and grain) to build a stable low-frequency appearance base with strong content preservation. The free branch complements fine details through residual generation, and a gated fusion mechanism combines the two branches under explicit frequency constraints to limit low-frequency drift. We further adopt a two-stage training schedule that first stabilizes the editing branch and then releases the residual branch to improve optimization stability. Experiments on the YCB-V dataset show that FD-DB improves real-domain appearance consistency and significantly boosts downstream semantic segmentation performance while preserving geometric and semantic structures.

</details>

<details><summary><b>中文摘要</b></summary>

合成数据为几何敏感的视觉任务提供了低成本、准确注释的样本，但合成域和真实域之间的外观和成像差异会导致严重的域偏移并降低下游性能。不成对的合成到真实的翻译可以在没有成对监督的情况下缩小这种差距，但现有的方法通常面临照片真实性和结构稳定性之间的权衡：无约束的生成可能会引入变形或虚假纹理，而过于严格的约束限制了对实域统计数据的适应。我们提出了 FD-DB，一种频率解耦双分支模型，将外观传输分离为低频可解释编辑和高频残差补偿。可解释分支预测物理上有意义的编辑参数（白平衡、曝光、对比度、饱和度、模糊和颗粒），以构建具有强大内容保留的稳定低频外观基础。自由分支通过残差生成补充精细细节，门控融合机制在明确的频率约束下组合两个分支以限制低频漂移。我们进一步采用两阶段训练计划，首先稳定编辑分支，然后释放残余分支以提高优化稳定性。在 YCB-V 数据集上的实验表明，FD-DB 提高了实域外观一致性，并显着提高了下游语义分割性能，同时保留了几何和语义结构。

</details>

---

## 163. A Scoping Review of Deep Learning for Urban Visual Pollution and Proposal of a Real-Time Monitoring Framework with a Visual Pollution Index

**中文标题**: 城市视觉污染深度学习的范围审查以及具有视觉污染指数的实时监测框架的提议

**Date**: 2026-02-10 | **arXiv**: [2602.09446v1](http://arxiv.org/abs/2602.09446v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09446v1)

<details><summary><b>Abstract</b></summary>

Urban Visual Pollution (UVP) has emerged as a critical concern, yet research on automatic detection and application remains fragmented. This scoping review maps the existing deep learning-based approaches for detecting, classifying, and designing a comprehensive application framework for visual pollution management. Following the PRISMA-ScR guidelines, seven academic databases (Scopus, Web of Science, IEEE Xplore, ACM DL, ScienceDirect, SpringerNatureLink, and Wiley) were systematically searched and reviewed, and 26 articles were found. Most research focuses on specific pollutant categories and employs variations of YOLO, Faster R-CNN, and EfficientDet architectures. Although several datasets exist, they are limited to specific areas and lack standardized taxonomies. Few studies integrate detection into real-time application systems, yet they tend to be geographically skewed. We proposed a framework for monitoring visual pollution that integrates a visual pollution index to assess the severity of visual pollution for a certain area. This review highlights the need for a unified UVP management system that incorporates pollutant taxonomy, a cross-city benchmark dataset, a generalized deep learning model, and an assessment index that supports sustainable urban aesthetics and enhances the well-being of urban dwellers.

</details>

<details><summary><b>中文摘要</b></summary>

城市视觉污染（UVP）已成为一个严重问题，但自动检测和应用的研究仍然分散。本次范围审查描绘了现有的基于深度学习的方法，用于检测、分类和设计视觉污染管理的综合应用框架。遵循 PRISMA-ScR 指南，对 7 个学术数据库（Scopus、Web of Science、IEEE Xplore、ACM DL、ScienceDirect、SpringerNatureLink 和 Wiley）进行了系统检索和审查，共找到 26 篇文章。大多数研究都集中在特定的污染物类别上，并采用 YOLO、Faster R-CNN 和 EfficientDet 架构的变体。尽管存在多个数据集，但它们仅限于特定领域并且缺乏标准化分类法。很少有研究将检测集成到实时应用系统中，但它们往往存在地域偏差。我们提出了一个视觉污染监测框架，该框架集成了视觉污染指数来评估特定区域视觉污染的严重程度。本次审查强调需要一个统一的UVP管理系统，该系统包含污染物分类、跨城市基准数据集、广义深度学习模型以及支持可持续城市美学和提高城市居民福祉的评估指数。

</details>

---

## 164. Fine-T2I: An Open, Large-Scale, and Diverse Dataset for High-Quality T2I Fine-Tuning

**中文标题**: Fine-T2I：用于高质量 T2I 微调的开放、大规模且多样化的数据集

**Date**: 2026-02-10 | **arXiv**: [2602.09439v1](http://arxiv.org/abs/2602.09439v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09439v1)

<details><summary><b>Abstract</b></summary>

High-quality and open datasets remain a major bottleneck for text-to-image (T2I) fine-tuning. Despite rapid progress in model architectures and training pipelines, most publicly available fine-tuning datasets suffer from low resolution, poor text-image alignment, or limited diversity, resulting in a clear performance gap between open research models and enterprise-grade models. In this work, we present Fine-T2I, a large-scale, high-quality, and fully open dataset for T2I fine-tuning. Fine-T2I spans 10 task combinations, 32 prompt categories, 11 visual styles, and 5 prompt templates, and combines synthetic images generated by strong modern models with carefully curated real images from professional photographers. All samples are rigorously filtered for text-image alignment, visual fidelity, and prompt quality, with over 95% of initial candidates removed. The final dataset contains over 6 million text-image pairs, around 2 TB on disk, approaching the scale of pretraining datasets while maintaining fine-tuning-level quality. Across a diverse set of pretrained diffusion and autoregressive models, fine-tuning on Fine-T2I consistently improves both generation quality and instruction adherence, as validated by human evaluation, visual comparison, and automatic metrics. We release Fine-T2I under an open license to help close the data gap in T2I fine-tuning in the open community.

</details>

<details><summary><b>中文摘要</b></summary>

高质量和开放的数据集仍然是文本到图像（T2I）微调的主要瓶颈。尽管模型架构和训练流程取得了快速进展，但大多数公开可用的微调数据集都存在分辨率低、文本图像对齐差或多样性有限的问题，导致开放研究模型和企业级模型之间存在明显的性能差距。在这项工作中，我们提出了 Fine-T2I，一个用于 T2I 微调的大规模、高质量、完全开放的数据集。 Fine-T2I跨越10种任务组合、32种提示类别、11种视觉风格和5种提示模板，并将强大的现代模型生成的合成图像与专业摄影师精心策划的真实图像相结合。所有样本都经过严格的文本图像对齐、视觉保真度和提示质量过滤，超过 95% 的初始候选样本被删除。最终数据集包含超过 600 万个文本图像对，磁盘大小约为 2 TB，接近预训练数据集的规模，同时保持微调级别的质量。在一系列不同的预训练扩散和自回归模型中，Fine-T2I 上的微调不断提高生成质量和指令依从性，这一点已通过人工评估、视觉比较和自动指标进行验证。我们在开放许可下发布 Fine-T2I，以帮助缩小开放社区中 T2I 微调的数据差距。

</details>

---

## 165. SceneReVis: A Self-Reflective Vision-Grounded Framework for 3D Indoor Scene Synthesis via Multi-turn RL

**中文标题**: SceneReVis：通过多转 RL 进行 3D 室内场景合成的自反射视觉框架

**Date**: 2026-02-10 | **arXiv**: [2602.09432v1](http://arxiv.org/abs/2602.09432v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09432v1)

<details><summary><b>Abstract</b></summary>

Current one-pass 3D scene synthesis methods often suffer from spatial hallucinations, such as collisions, due to a lack of deliberative reasoning. To bridge this gap, we introduce SceneReVis, a vision-grounded self-reflection framework that employs an iterative ``diagnose-and-act'' loop to explicitly intercept and resolve spatial conflicts using multi-modal feedback. To support this step-wise paradigm, we construct SceneChain-12k, a large-scale dataset of causal construction trajectories derived through a novel reverse engineering pipeline. We further propose a two-stage training recipe that transitions from Supervised Fine-Tuning to Agentic Reinforcement Learning, evolving the model into an active spatial planner. Extensive experiments demonstrate that SceneReVis achieves state-of-the-art performance in high-fidelity generation and goal-oriented optimization, with robust generalization to long-tail domains.

</details>

<details><summary><b>中文摘要</b></summary>

由于缺乏深思熟虑的推理，当前的一次性 3D 场景合成方法经常会出现空间幻觉，例如碰撞。为了弥补这一差距，我们引入了 SceneReVis，这是一个基于视觉的自我反思框架，它采用迭代的“诊断和行动”循环，使用多模态反馈来明确拦截和解决空间冲突。为了支持这种逐步范例，我们构建了 SceneChain-12k，这是一个通过新颖的逆向工程管道导出的因果构建轨迹的大型数据集。我们进一步提出了一个两阶段的训练方法，从监督微调过渡到代理强化学习，将模型演变成主动空间规划器。大量实验表明，SceneReVis 在高保真生成和面向目标的优化方面实现了最先进的性能，并对长尾域具有强大的泛化能力。

</details>

---

## 166. Understanding and Enhancing Encoder-based Adversarial Transferability against Large Vision-Language Models

**中文标题**: 理解和增强针对大型视觉语言模型的基于编码器的对抗性可迁移性

**Date**: 2026-02-10 | **arXiv**: [2602.09431v1](http://arxiv.org/abs/2602.09431v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09431v1)

<details><summary><b>Abstract</b></summary>

Large vision-language models (LVLMs) have achieved impressive success across multimodal tasks, but their reliance on visual inputs exposes them to significant adversarial threats. Existing encoder-based attacks perturb the input image by optimizing solely on the vision encoder, rather than the entire LVLM, offering a computationally efficient alternative to end-to-end optimization. However, their transferability across different LVLM architectures in realistic black-box scenarios remains poorly understood. To address this gap, we present the first systematic study towards encoder-based adversarial transferability in LVLMs. Our contributions are threefold. First, through large-scale benchmarking over eight diverse LVLMs, we reveal that existing attacks exhibit severely limited transferability. Second, we perform in-depth analysis, disclosing two root causes that hinder the transferability: (1) inconsistent visual grounding across models, where different models focus their attention on distinct regions; (2) redundant semantic alignment within models, where a single object is dispersed across multiple overlapping token representations. Third, we propose Semantic-Guided Multimodal Attack (SGMA), a novel framework to enhance the transferability. Inspired by the discovered causes in our analysis, SGMA directs perturbations toward semantically critical regions and disrupts cross-modal grounding at both global and local levels. Extensive experiments across different victim models and tasks show that SGMA achieves higher transferability than existing attacks. These results expose critical security risks in LVLM deployment and underscore the urgent need for robust multimodal defenses.

</details>

<details><summary><b>中文摘要</b></summary>

大型视觉语言模型（LVLM）在多模式任务中取得了令人印象深刻的成功，但它们对视觉输入的依赖使它们面临重大的对抗性威胁。现有的基于编码器的攻击通过仅优化视觉编码器而不是整个 LVLM 来扰乱输入图像，从而为端到端优化提供了计算高效的替代方案。然而，它们在现实黑盒场景中跨不同 LVLM 架构的可转移性仍然知之甚少。为了解决这一差距，我们提出了第一个针对 LVLM 中基于编码器的对抗性可转移性的系统研究。我们的贡献是三重的。首先，通过对八个不同的 LVLM 进行大规模基准测试，我们发现现有攻击的可转移性受到严重限制。其次，我们进行了深入分析，揭示了阻碍可迁移性的两个根本原因：（1）模型间视觉基础不一致，不同模型将注意力集中在不同的区域； (2) 模型内的冗余语义对齐，其中单个对象分散在多个重叠的标记表示中。第三，我们提出了语义引导多模态攻击（SGMA），这是一种增强可转移性的新颖框架。受到我们分析中发现的原因的启发，SGMA 将扰动导向语义关键区域，并破坏全局和局部层面的跨模式基础。跨不同受害者模型和任务的大量实验表明，SGMA 比现有攻击实现了更高的可转移性。这些结果暴露了 LVLM 部署中的关键安全风险，并强调了对强大的多模式防御的迫切需要。

</details>

---

## 167. Bridging the Modality Gap in Roadside LiDAR: A Training-Free Vision-Language Model Framework for Vehicle Classification

**中文标题**: 弥合路边激光雷达的模态差距：用于车辆分类的免训练视觉语言模型框架

**Date**: 2026-02-10 | **arXiv**: [2602.09425v1](http://arxiv.org/abs/2602.09425v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09425v1)

<details><summary><b>Abstract</b></summary>

Fine-grained truck classification is critical for intelligent transportation systems (ITS), yet current LiDAR-based methods face scalability challenges due to their reliance on supervised deep learning and labor-intensive manual annotation. Vision-Language Models (VLMs) offer promising few-shot generalization, but their application to roadside LiDAR is limited by a modality gap between sparse 3D point clouds and dense 2D imagery. We propose a framework that bridges this gap by adapting off-the-shelf VLMs for fine-grained truck classification without parameter fine-tuning. Our new depth-aware image generation pipeline applies noise removal, spatial and temporal registration, orientation rectification, morphological operations, and anisotropic smoothing to transform sparse, occluded LiDAR scans into depth-encoded 2D visual proxies. Validated on a real-world dataset of 20 vehicle classes, our approach achieves competitive classification accuracy with as few as 16-30 examples per class, offering a scalable alternative to data-intensive supervised baselines. We further observe a "Semantic Anchor" effect: text-based guidance regularizes performance in ultra-low-shot regimes $k < 4$, but degrades accuracy in more-shot settings due to semantic mismatch. Furthermore, we demonstrate the efficacy of this framework as a Cold Start strategy, using VLM-generated labels to bootstrap lightweight supervised models. Notably, the few-shot VLM-based model achieves over correct classification rate of 75 percent for specific drayage categories (20ft, 40ft, and 53ft containers) entirely without the costly training or fine-tuning, significantly reducing the intensive demands of initial manual labeling, thus achieving a method of practical use in ITS applications.

</details>

<details><summary><b>中文摘要</b></summary>

细粒度的卡车分类对于智能交通系统 (ITS) 至关重要，但当前基于 LiDAR 的方法由于依赖监督深度学习和劳动密集型手动注释而面临可扩展性挑战。视觉语言模型 (VLM) 提供了有希望的少样本泛化，但它们在路边 LiDAR 中的应用受到稀疏 3D 点云和密集 2D 图像之间模态差距的限制。我们提出了一个框架，通过采用现成的 VLM 来进行细粒度的卡车分类，而无需进行参数微调，从而弥补了这一差距。我们新的深度感知图像生成管道应用噪声去除、空间和时间配准、方向校正、形态操作和各向异性平滑来将稀疏、遮挡的 LiDAR 扫描转换为深度编码的 2D 视觉代理。我们的方法在包含 20 个车辆类别的真实数据集上进行了验证，每类只需 16-30 个示例即可实现有竞争力的分类准确性，为数据密集型监督基线提供了可扩展的替代方案。我们进一步观察到“语义锚”效应：基于文本的指导规范了​​超低镜头状态 $k < 4$ 中的性能，但由于语义不匹配而降低了更多镜头设置中的准确性。此外，我们还证明了该框架作为冷启动策略的有效性，使用 VLM 生成的标签来引导轻量级监督模型。值得注意的是，基于few-shot VLM的模型对特定拖运类别（20英尺、40英尺和53英尺集装箱）的正确分类率达到了75%以上，完全不需要昂贵的培训或微调，显着减少了初始手动标签的密集需求，从而实现了在ITS应用中实际使用的方法。

</details>

---

## 168. AD$^2$: Analysis and Detection of Adversarial Threats in Visual Perception for End-to-End Autonomous Driving Systems

**中文标题**: AD$^2$：端到端自动驾驶系统视觉感知中的对抗性威胁分析和检测

**Date**: 2026-02-10 | **arXiv**: [2602.10160v1](http://arxiv.org/abs/2602.10160v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10160v1)

<details><summary><b>Abstract</b></summary>

End-to-end autonomous driving systems have achieved significant progress, yet their adversarial robustness remains largely underexplored. In this work, we conduct a closed-loop evaluation of state-of-the-art autonomous driving agents under black-box adversarial threat models in CARLA. Specifically, we consider three representative attack vectors on the visual perception pipeline: (i) a physics-based blur attack induced by acoustic waves, (ii) an electromagnetic interference attack that distorts captured images, and (iii) a digital attack that adds ghost objects as carefully crafted bounded perturbations on images. Our experiments on two advanced agents, Transfuser and Interfuser, reveal severe vulnerabilities to such attacks, with driving scores dropping by up to 99% in the worst case, raising valid safety concerns. To help mitigate such threats, we further propose a lightweight Attack Detection model for Autonomous Driving systems (AD$^2$) based on attention mechanisms that capture spatial-temporal consistency. Comprehensive experiments across multi-camera inputs on CARLA show that our detector achieves superior detection capability and computational efficiency compared to existing approaches.

</details>

<details><summary><b>中文摘要</b></summary>

端到端自动驾驶系统已经取得了重大进展，但其对抗鲁棒性在很大程度上仍未得到充分探索。在这项工作中，我们在 CARLA 的黑盒对抗威胁模型下对最先进的自动驾驶代理进行了闭环评估。具体来说，我们考虑视觉感知管道上的三个代表性攻击向量：（i）由声波引起的基于物理的模糊攻击，（ii）扭曲捕获图像的电磁干扰攻击，以及（iii）将幽灵对象添加为图像上精心设计的有界扰动的数字攻击。我们对两种先进代理 Transfuser 和 Interfuser 进行的实验揭示了此类攻击的严重漏洞，在最坏的情况下驾驶分数下降高达 99%，引发了合理的安全担忧。为了帮助减轻此类威胁，我们进一步提出了一种基于捕获时空一致性的注意力机制的自动驾驶系统的轻量级攻击检测模型（AD$^2$）。 CARLA 上多摄像机输入的综合实验表明，与现有方法相比，我们的检测器实现了卓越的检测能力和计算效率。

</details>

---

## 169. LARV: Data-Free Layer-wise Adaptive Rescaling Veneer for Model Merging

**中文标题**: LARV：用于模型合并的无数据逐层自适应缩放胶合板

**Date**: 2026-02-10 | **arXiv**: [2602.09413v1](http://arxiv.org/abs/2602.09413v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09413v1)

<details><summary><b>Abstract</b></summary>

Model merging aims to combine multiple fine-tuned models into a single multi-task model without access to training data. Existing task-vector merging methods such as TIES, TSV-M, and Iso-C/CTS differ in their aggregation rules but treat all layers nearly uniformly. This assumption overlooks the strong layer-wise heterogeneity in large vision transformers, where shallow layers are sensitive to interference while deeper layers encode stable task-specific features. We introduce LARV, a training-free, data-free, merger-agnostic Layer-wise Adaptive Rescaling Veneer that plugs into any task-vector merger and assigns a per-layer scale to each task vector before aggregation, and show it consistently boosts diverse merging rules. LARV adaptively suppresses shallow-layer interference and amplifies deeper-layer alignment using a simple deterministic schedule, requiring no retraining or modification to existing mergers. To our knowledge, this is the first work to perform layer-aware scaling for task-vector merging. LARV computes simple data-free layer proxies and turns them into scales through a lightweight rule; we study several instantiations within one framework (e.g., tiered two/three-level scaling with fixed values, or continuous mappings) and show that tiered choices offer the best robustness, while continuous mappings remain an ablation. LARV is orthogonal to the base merger and adds negligible cost. On FusionBench with Vision Transformers, LARV consistently improves all task-vector baselines across 8/14/20-task settings; for example, Iso-C + LARV reaches 85.9% on ViT-B/32, 89.2% on ViT-B/16, and 92.6% on ViT-L/14. Layerwise analysis and corruption tests further indicate that LARV suppresses shallow-layer interference while modestly amplifying deeper, task-stable features, turning model merging into a robust, layer-aware procedure rather than a uniform one.

</details>

<details><summary><b>中文摘要</b></summary>

模型合并旨在将多个微调模型组合成一个多任务模型，而无需访问训练数据。现有的任务向量合并方法（例如 TIES、TSV-M 和 Iso-C/CTS）的聚合规则有所不同，但对所有层的处理几乎一致。这种假设忽略了大型视觉变换器中强烈的分层异质性，其中浅层对干扰敏感，而更深的层编码稳定的特定于任务的特征。我们引入了 LARV，这是一种免训练、免数据、与合并无关的逐层自适应重缩放单板，可插入任何任务向量合并，并在聚合之前为每个任务向量分配每层尺度，并表明它始终如一地增强不同的合并规则。 LARV 使用简单的确定性调度自适应地抑制浅层干扰并放大更深层对齐，无需对现有合并进行重新训练或修改。据我们所知，这是第一个针对任务向量合并执行分层感知缩放的工作。 LARV计算简单的无数据层代理，并通过轻量级规则将其转化为尺度；我们研究了一个框架内的几个实例（例如，具有固定值的分层两级/三级缩放或连续映射），并表明分层选择提供了最佳的鲁棒性，而连续映射仍然是一种消融。 LARV 与基础合并正交，增加的成本可以忽略不计。在带有 Vision Transformers 的 FusionBench 上，LARV 持续改进了 8/14/20 任务设置中的所有任务向量基线；例如，Iso-C + LARV 在 ViT-B/32 上达到 85.9%，在 ViT-B/16 上达到 89.2%，在 ViT-L/14 上达到 92.6%。分层分析和损坏测试进一步表明，LARV 抑制浅层干扰，同时适度放大更深层次的、任务稳定的特征，将模型合并转变为一种稳健的、分层感知的过程，而不是统一的过程。

</details>

---

## 170. K-Sort Eval: Efficient Preference Evaluation for Visual Generation via Corrected VLM-as-a-Judge

**中文标题**: K-Sort Eval：通过修正的 VLM-as-a-Judge 对视觉生成进行有效的偏好评估

**Date**: 2026-02-10 | **arXiv**: [2602.09411v1](http://arxiv.org/abs/2602.09411v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09411v1)

<details><summary><b>Abstract</b></summary>

The rapid development of visual generative models raises the need for more scalable and human-aligned evaluation methods. While the crowdsourced Arena platforms offer human preference assessments by collecting human votes, they are costly and time-consuming, inherently limiting their scalability. Leveraging vision-language model (VLMs) as substitutes for manual judgments presents a promising solution. However, the inherent hallucinations and biases of VLMs hinder alignment with human preferences, thus compromising evaluation reliability. Additionally, the static evaluation approach lead to low efficiency. In this paper, we propose K-Sort Eval, a reliable and efficient VLM-based evaluation framework that integrates posterior correction and dynamic matching. Specifically, we curate a high-quality dataset from thousands of human votes in K-Sort Arena, with each instance containing the outputs and rankings of K models. When evaluating a new model, it undergoes (K+1)-wise free-for-all comparisons with existing models, and the VLM provide the rankings. To enhance alignment and reliability, we propose a posterior correction method, which adaptively corrects the posterior probability in Bayesian updating based on the consistency between the VLM prediction and human supervision. Moreover, we propose a dynamic matching strategy, which balances uncertainty and diversity to maximize the expected benefit of each comparison, thus ensuring more efficient evaluation. Extensive experiments show that K-Sort Eval delivers evaluation results consistent with K-Sort Arena, typically requiring fewer than 90 model runs, demonstrating both its efficiency and reliability.

</details>

<details><summary><b>中文摘要</b></summary>

视觉生成模型的快速发展提出了对更具可扩展性和人性化评估方法的需求。虽然众包 Arena 平台通过收集人类投票来提供人类偏好评估，但它们成本高昂且耗时，本质上限制了其可扩展性。利用视觉语言模型（VLM）替代人工判断是一种很有前景的解决方案。然而，VLM 固有的幻觉和偏差阻碍了与人类偏好的一致性，从而损害了评估的可靠性。此外，静态评估方法导致效率低下。在本文中，我们提出了 K-Sort Eval，这是一种可靠且高效的基于 VLM 的评估框架，集成了后验校正和动态匹配。具体来说，我们从 K-Sort Arena 中数千个人类投票中策划了一个高质量的数据集，每个实例都包含 K 个模型的输出和排名。在评估新模型时，它会与现有模型进行 (K+1) 方式的自由比较，然后 VLM 提供排名。为了增强对齐和可靠性，我们提出了一种后验校正方法，该方法根据 VLM 预测和人类监督之间的一致性自适应地校正贝叶斯更新中的后验概率。此外，我们提出了一种动态匹配策略，平衡不确定性和多样性，以最大化每次比较的预期收益，从而确保更有效的评估。大量实验表明，K-Sort Eval 提供的评估结果与 K-Sort Arena 一致，通常需要少于 90 次模型运行，证明了其效率和可靠性。

</details>

---

## 171. Single-Slice-to-3D Reconstruction in Medical Imaging and Natural Objects: A Comparative Benchmark with SAM 3D

**中文标题**: 医学成像和自然物体中的单切片到 3D 重建：与 SAM 3D 的比较基准

**Date**: 2026-02-10 | **arXiv**: [2602.09407v1](http://arxiv.org/abs/2602.09407v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09407v1)

<details><summary><b>Abstract</b></summary>

A 3D understanding of anatomy is central to diagnosis and treatment planning, yet volumetric imaging remains costly with long wait times. Image-to-3D foundations models can solve this issue by reconstructing 3D data from 2D modalites. Current foundation models are trained on natural image distributions to reconstruct naturalistic objects from a single image by leveraging geometric priors across pixels. However, it is unclear whether these learned geometric priors transfer to medical data. In this study, we present a controlled zero-shot benchmark of single slice medical image-to-3D reconstruction across five state-of-the-art image-to-3D models: SAM3D, Hunyuan3D-2.1, Direct3D, Hi3DGen, and TripoSG. These are evaluated across six medical datasets spanning anatomical and pathological structures and two natrual datasets, using voxel based metrics and point cloud distance metrics. Across medical datasets, voxel based overlap remains moderate for all models, consistent with a depth reconstruction failure mode when inferring volume from a single slice. In contrast, global distance metrics show more separation between methods: SAM3D achieves the strongest overall topological similarity to ground truth medical 3D data, while alternative models are more prone to over-simplication of reconstruction. Our results quantify the limits of single-slice medical reconstruction and highlight depth ambiguity caused by the planar nature of 2D medical data, motivating multi-view image-to-3D reconstruction to enable reliable medical 3D inference.

</details>

<details><summary><b>中文摘要</b></summary>

对解剖结构的 3D 了解对于诊断和治疗计划至关重要，但体积成像的成本仍然很高，且等待时间较长。图像到 3D 基础模型可以通过从 2D 模态重建 3D 数据来解决这个问题。当前的基础模型是根据自然图像分布进行训练的，通过利用跨像素的几何先验从单个图像重建自然对象。然而，目前尚不清楚这些学习到的几何先验是否会转移到医学数据中。在这项研究中，我们提出了跨五个最先进的图像到 3D 模型的单切片医学图像到 3D 重建的受控零样本基准：SAM3D、Hunyuan3D-2.1、Direct3D、Hi3DGen 和 TripoSG。使用基于体素的指标和点云距离指标，对涵盖解剖和病理结构的六个医学数据集以及两个自然数据集进行评估。在整个医学数据集中，基于体素的重叠对于所有模型都保持适度，这与从单个切片推断体积时的深度重建失败模式一致。相比之下，全局距离度量显示方法之间有更多的分离：SAM3D 实现了与地面实况医学 3D 数据最强的整体拓扑相似性，而替代模型更容易过度简化重建。我们的结果量化了单切片医学重建的局限性，并突出了由 2D 医学数据的平面性质引起的深度模糊性，激发了多视图图像到 3D 重建，以实现可靠的医学 3D 推理。

</details>

---

## 172. Beyond Closed-Pool Video Retrieval: A Benchmark and Agent Framework for Real-World Video Search and Moment Localization

**中文标题**: 超越闭池视频检索：现实世界视频搜索和时刻定位的基准和代理框架

**Date**: 2026-02-10 | **arXiv**: [2602.10159v1](http://arxiv.org/abs/2602.10159v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10159v1)

<details><summary><b>Abstract</b></summary>

Traditional video retrieval benchmarks focus on matching precise descriptions to closed video pools, failing to reflect real-world searches characterized by fuzzy, multi-dimensional memories on the open web. We present \textbf{RVMS-Bench}, a comprehensive system for evaluating real-world video memory search. It consists of \textbf{1,440 samples} spanning \textbf{20 diverse categories} and \textbf{four duration groups}, sourced from \textbf{real-world open-web videos}. RVMS-Bench utilizes a hierarchical description framework encompassing \textbf{Global Impression, Key Moment, Temporal Context, and Auditory Memory} to mimic realistic multi-dimensional search cues, with all samples strictly verified via a human-in-the-loop protocol. We further propose \textbf{RACLO}, an agentic framework that employs abductive reasoning to simulate the human ``Recall-Search-Verify'' cognitive process, effectively addressing the challenge of searching for videos via fuzzy memories in the real world. Experiments reveal that existing MLLMs still demonstrate insufficient capabilities in real-world Video Retrieval and Moment Localization based on fuzzy memories. We believe this work will facilitate the advancement of video retrieval robustness in real-world unstructured scenarios.

</details>

<details><summary><b>中文摘要</b></summary>

传统的视频检索基准侧重于将精确描述与封闭视频池相匹配，无法反映开放网络上以模糊、多维记忆为特征的现实世界搜索。我们提出了 \textbf{RVMS-Bench}，一个用于评估现实世界视频内存搜索的综合系统。它由 \textbf{1,440 个样本}组成，涵盖 \textbf{20 个不同类别}和 \textbf{四个持续时间组}，源自 \textbf{真实世界的开放网络视频}。 RVMS-Bench 利用包含 \textbf{全局印象、关键时刻、时间上下文和听觉记忆}的分层描述框架来模拟现实的多维搜索线索，所有样本都通过人机交互协议进行严格验证。我们进一步提出\textbf{RACLO}，一种代理框架，采用溯因推理来模拟人类的“回忆-搜索-验证”认知过程，有效解决通过现实世界中的模糊记忆搜索视频的挑战。实验表明，现有的 MLLM 在基于模糊记忆的现实视频检索和时刻定位方面仍然表现出不足的能力。我们相信这项工作将有助于提高现实世界非结构化场景中视频检索的鲁棒性。

</details>

---

## 173. Fully Differentiable Bidirectional Dual-Task Synergistic Learning for Semi-Supervised 3D Medical Image Segmentation

**中文标题**: 用于半监督 3D 医学图像分割的完全可微双向双任务协同学习

**Date**: 2026-02-10 | **arXiv**: [2602.09378v1](http://arxiv.org/abs/2602.09378v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09378v1)

<details><summary><b>Abstract</b></summary>

Semi-supervised learning relaxes the need of large pixel-wise labeled datasets for image segmentation by leveraging unlabeled data. The scarcity of high-quality labeled data remains a major challenge in medical image analysis due to the high annotation costs and the need for specialized clinical expertise. Semi-supervised learning has demonstrated significant potential in addressing this bottleneck, with pseudo-labeling and consistency regularization emerging as two predominant paradigms. Dual-task collaborative learning, an emerging consistency-aware paradigm, seeks to derive supplementary supervision by establishing prediction consistency between related tasks. However, current methodologies are limited to unidirectional interaction mechanisms (typically regression-to-segmentation), as segmentation results can only be transformed into regression outputs in an offline manner, thereby failing to fully exploit the potential benefits of online bidirectional cross-task collaboration. Thus, we propose a fully Differentiable Bidirectional Synergistic Learning (DBiSL) framework, which seamlessly integrates and enhances four critical SSL components: supervised learning, consistency regularization, pseudo-supervised learning, and uncertainty estimation. Experiments on two benchmark datasets demonstrate our method's state-of-the-art performance. Beyond technical contributions, this work provides new insights into unified SSL framework design and establishes a new architectural foundation for dual-task-driven SSL, while offering a generic multitask learning framework applicable to broader computer vision applications. The code will be released on github upon acceptance.

</details>

<details><summary><b>中文摘要</b></summary>

半监督学习通过利用未标记的数据，缓解了图像分割对大型像素级标记数据集的需求。由于注释成本高且需要专门的临床专业知识，高质量标记数据的稀缺仍然是医学图像分析的主要挑战。半监督学习在解决这一瓶颈方面表现出了巨大的潜力，伪标签和一致性正则化成为两个主要范式。双任务协作学习是一种新兴的一致性意识范式，旨在通过建立相关任务之间的预测一致性来获得补充监督。然而，当前的方法仅限于单向交互机制（通常是回归到分割），因为分割结果只能以离线方式转换为回归输出，从而无法充分利用在线双向跨任务协作的潜在优势。因此，我们提出了一个完全可微的双向协同学习（DBiSL）框架，它无缝集成和增强了四个关键的 SSL 组件：监督学习、一致性正则化、伪监督学习和不确定性估计。对两个基准数据集的实验证明了我们的方法的最先进的性能。除了技术贡献之外，这项工作还提供了对统一 SSL 框架设计的新见解，并为双任务驱动的 SSL 建立了新的架构基础，同时提供了适用于更广泛的计算机视觉应用的通用多任务学习框架。代码一经接受将在github上发布。

</details>

---

## 174. Deep Modeling and Interpretation for Bladder Cancer Classification

**中文标题**: 膀胱癌分类的深度建模和解释

**Date**: 2026-02-10 | **arXiv**: [2602.09324v1](http://arxiv.org/abs/2602.09324v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09324v1)

<details><summary><b>Abstract</b></summary>

Deep models based on vision transformer (ViT) and convolutional neural network (CNN) have demonstrated remarkable performance on natural datasets. However, these models may not be similar in medical imaging, where abnormal regions cover only a small portion of the image. This challenge motivates this study to investigate the latest deep models for bladder cancer classification tasks. We propose the following to evaluate these deep models: 1) standard classification using 13 models (four CNNs and eight transormer-based models), 2) calibration analysis to examine if these models are well calibrated for bladder cancer classification, and 3) we use GradCAM++ to evaluate the interpretability of these models for clinical diagnosis. We simulate $\sim 300$ experiments on a publicly multicenter bladder cancer dataset, and the experimental results demonstrate that the ConvNext series indicate limited generalization ability to classify bladder cancer images (e.g., $\sim 60\%$ accuracy). In addition, ViTs show better calibration effects compared to ConvNext and swin transformer series. We also involve test time augmentation to improve the models interpretability. Finally, no model provides a one-size-fits-all solution for a feasible interpretable model. ConvNext series are suitable for in-distribution samples, while ViT and its variants are suitable for interpreting out-of-distribution samples.

</details>

<details><summary><b>中文摘要</b></summary>

基于视觉变换器（ViT）和卷积神经网络（CNN）的深度模型在自然数据集上表现出了卓越的性能。然而，这些模型在医学成像中可能并不相似，其中异常区域仅覆盖图像的一小部分。这一挑战促使本研究研究膀胱癌分类任务的最新深度模型。我们提出以下方法来评估这些深度模型：1）使用 13 个模型（四个 CNN 和八个基于 Transormer 的模型）进行标准分类，2）校准分析以检查这些模型是否针对膀胱癌分类进行了良好校准，3）我们使用 GradCAM++ 来评估这些模型对临床诊断的可解释性。我们在公开的多中心膀胱癌数据集上模拟 $\sim 300$ 实验，实验结果表明 ConvNext 系列表明膀胱癌图像分类的泛化能力有限（例如 $\sim 60\%$ 准确度）。此外，与ConvNext和swin变压器系列相比，ViTs表现出更好的校准效果。我们还增加了测试时间以提高模型的可解释性。最后，没有任何模型能够为可行的可解释模型提供一刀切的解决方案。 ConvNext系列适用于分布内样本，而ViT及其变体适用于解释分布外样本。

</details>

---

## 175. GAFR-Net: A Graph Attention and Fuzzy-Rule Network for Interpretable Breast Cancer Image Classification

**中文标题**: GAFR-Net：用于可解释乳腺癌图像分类的图注意力和模糊规则网络

**Date**: 2026-02-10 | **arXiv**: [2602.09318v1](http://arxiv.org/abs/2602.09318v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09318v1)

<details><summary><b>Abstract</b></summary>

Accurate classification of breast cancer histopathology images is pivotal for early oncological diagnosis and therapeutic intervention.However, conventional deep learning architectures often encounter performance degradation under limited annotations and suffer from a "blackbox" nature, hindering their clinical integration. To mitigate these limitations, we propose GAFRNet, a robust and interpretable Graph Attention and FuzzyRule Network specifically engineered for histopathology image classification with scarce supervision. GAFRNet constructs a similarity-driven graph representation to model intersample relationships and employs a multihead graph attention mechanism to capture complex relational features across heterogeneous tissue structures.Concurrently, a differentiable fuzzy-rule module encodes intrinsic topological descriptorsincluding node degree, clustering coefficient, and label consistencyinto explicit, human-understandable diagnostic logic. This design establishes transparent "IF-THEN" mappings that mimic the heuristic deduction process of medical experts, providing clear reasoning behind each prediction without relying on post-hoc attribution methods. Extensive evaluations on three benchmark datasets (BreakHis, Mini-DDSM, and ICIAR2018) demonstrate that GAFR-Net consistently outperforms various state-of-the-art methods across multiple magnifications and classification tasks. These results validate the superior generalization and practical utility of GAFR-Net as a reliable decision-support tool for weakly supervised medical image analysis.

</details>

<details><summary><b>中文摘要</b></summary>

乳腺癌组织病理学图像的准确分类对于早期肿瘤诊断和治疗干预至关重要。然而，传统的深度学习架构经常在有限的注释下遇到性能下降，并且具有“黑箱”性质，阻碍了其临床整合。为了减轻这些限制，我们提出了 GAFRNet，这是一种强大且可解释的图注意力和模糊规则网络，专门用于缺乏监督的组织病理学图像分类。 GAFRNet 构建相似性驱动的图表示来建模样本间关系，并采用多头图注意机制来捕获异质组织结构中的复杂关系特征。同时，可微分模糊规则模块将内在拓扑描述符（包括节点度、聚类系数和标签一致性）编码为明确的、人类可理解的诊断逻辑。该设计建立了透明的“IF-THEN”映射，模仿医学专家的启发式演绎过程，为每个预测背后提供清晰的推理，而不依赖于事后归因方法。对三个基准数据集（BreakHis、Mini-DDSM 和 ICIAR2018）的广泛评估表明，GAFR-Net 在多个放大倍率和分类任务中始终优于各种最先进的方法。这些结果验证了 GAFR-Net 作为弱监督医学图像分析的可靠决策支持工具的卓越泛化性和实用性。

</details>

---

## 176. X-Mark: Saliency-Guided Robust Dataset Ownership Verification for Medical Imaging

**中文标题**: X-Mark：显着性引导的稳健数据集所有权验证用于医学成像

**Date**: 2026-02-10 | **arXiv**: [2602.09284v1](http://arxiv.org/abs/2602.09284v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09284v1)

<details><summary><b>Abstract</b></summary>

High-quality medical imaging datasets are essential for training deep learning models, but their unauthorized use raises serious copyright and ethical concerns. Medical imaging presents a unique challenge for existing dataset ownership verification methods designed for natural images, as static watermark patterns generated in fixed-scale images scale poorly dynamic and high-resolution scans with limited visual diversity and subtle anatomical structures, while preserving diagnostic quality. In this paper, we propose X-Mark, a sample-specific clean-label watermarking method for chest x-ray copyright protection. Specifically, X-Mark uses a conditional U-Net to generate unique perturbations within salient regions of each sample. We design a multi-component training objective to ensure watermark efficacy, robustness against dynamic scaling processes while preserving diagnostic quality and visual-distinguishability. We incorporate Laplacian regularization into our training objective to penalize high-frequency perturbations and achieve watermark scale-invariance. Ownership verification is performed in a black-box setting to detect characteristic behaviors in suspicious models. Extensive experiments on CheXpert verify the effectiveness of X-Mark, achieving WSR of 100% and reducing probability of false positives in Ind-M scenario by 12%, while demonstrating resistance to potential adaptive attacks.

</details>

<details><summary><b>中文摘要</b></summary>

高质量的医学成像数据集对于训练深度学习模型至关重要，但未经授权的使用会引发严重的版权和道德问题。医学成像对为自然图像设计的现有数据集所有权验证方法提出了独特的挑战，因为固定比例图像中生成的静态水印图案在保持诊断质量的同时，无法动态缩放动态和高分辨率扫描，且视觉多样性有限，解剖结构微妙。在本文中，我们提出了 X-Mark，一种用于胸部 X 射线版权保护的样本特定清洁标签水印方法。具体来说，X-Mark 使用条件 U-Net 在每个样本的显着区域内生成独特的扰动。我们设计了一个多组件训练目标，以确保水印功效、动态缩放过程的鲁棒性，同时保持诊断质量和视觉可区分性。我们将拉普拉斯正则化纳入我们的训练目标中，以惩罚高频扰动并实现水印尺度不变性。所有权验证在黑盒设置中执行，以检测可疑模型中的特征行为。 CheXpert 上的大量实验验证了 X-Mark 的有效性，实现了 100% 的 WSR，将 Ind-M 场景中的误报概率降低了 12%，同时证明了对潜在自适应攻击的抵抗力。

</details>

---

## 177. The Complexity of Bayesian Network Learning: Revisiting the Superstructure

**中文标题**: 贝叶斯网络学习的复杂性：重新审视上层建筑

**Date**: 2026-02-10 | **arXiv**: [2602.10253v1](http://arxiv.org/abs/2602.10253v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10253v1)

<details><summary><b>Abstract</b></summary>

We investigate the parameterized complexity of Bayesian Network Structure Learning (BNSL), a classical problem that has received significant attention in empirical but also purely theoretical studies. We follow up on previous works that have analyzed the complexity of BNSL w.r.t. the so-called superstructure of the input. While known results imply that BNSL is unlikely to be fixed-parameter tractable even when parameterized by the size of a vertex cover in the superstructure, here we show that a different kind of parameterization - notably by the size of a feedback edge set - yields fixed-parameter tractability. We proceed by showing that this result can be strengthened to a localized version of the feedback edge set, and provide corresponding lower bounds that complement previous results to provide a complexity classification of BNSL w.r.t. virtually all well-studied graph parameters.   We then analyze how the complexity of BNSL depends on the representation of the input. In particular, while the bulk of past theoretical work on the topic assumed the use of the so-called non-zero representation, here we prove that if an additive representation can be used instead then BNSL becomes fixed-parameter tractable even under significantly milder restrictions to the superstructure, notably when parameterized by the treewidth alone. Last but not least, we show how our results can be extended to the closely related problem of Polytree Learning.

</details>

<details><summary><b>中文摘要</b></summary>

我们研究了贝叶斯网络结构学习（BNSL）的参数化复杂性，这是一个在实证研究和纯理论研究中都受到广泛关注的经典问题。我们跟进之前分析 BNSL w.r.t. 复杂性的工作。所谓输入的上层建筑。虽然已知结果表明 BNSL 不太可能是固定参数易处理的，即使通过上部结构中顶点覆盖的大小进行参数化，但这里我们表明，另一种参数化（特别是通过反馈边集的大小）产生固定参数易处理性。我们继续表明，这个结果可以增强为反馈边缘集的本地化版本，并提供相应的下界来补充之前的结果，以提供 BNSL w.r.t. 的复杂性分类。几乎所有经过充分研究的图形参数。   然后我们分析 BNSL 的复杂性如何取决于输入的表示。特别是，虽然过去关于该主题的大部分理论工作都假设使用所谓的非零表示，但在这里我们证明，如果可以使用加法表示，那么即使在对上层结构的限制明显更温和的情况下，BNSL 也会变得易于处理的固定参数，特别是当仅通过树宽进行参数化时。最后但并非最不重要的一点是，我们展示了如何将我们的结果扩展到密切相关的 Polytree 学习问题。

</details>

---

## 178. Transforming Policy-Car Swerving for Mitigating Stop-and-Go Traffic Waves: A Practice-Oriented Jam-Absorption Driving Strategy

**中文标题**: 转变政策汽车转向以缓解走走停停的交通波：以实践为导向的吸收堵塞驾驶策略

**Date**: 2026-02-10 | **arXiv**: [2602.10234v1](http://arxiv.org/abs/2602.10234v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10234v1)

**Code**: https://github.com/gotrafficgo.

<details><summary><b>Abstract</b></summary>

Stop-and-go waves, as a major form of freeway traffic congestion, cause severe and long-lasting adverse effects, including reduced traffic efficiency, increased driving risks, and higher vehicle emissions. Amongst the highway traffic management strategies, jam-absorption driving (JAD), in which a dedicated vehicle performs "slow-in" and "fast-out" maneuvers before being captured by a stop-and-go wave, has been proposed as a potential method for preventing the propagation of such waves. However, most existing JAD strategies remain impractical mainly due to the lack of discussion regarding implementation vehicles and operational conditions. Inspired by real-world observations of police-car swerving behavior, this paper first introduces a Single-Vehicle Two-Detector Jam-Absorption Driving (SVDD-JAD) problem, and then proposes a practical JAD strategy that transforms such behavior into a maneuver capable of suppressing the propagation of an isolated stop-and-go wave. Five key parameters that significantly affect the proposed strategy, namely, JAD speed, inflow traffic speed, wave width, wave speed, and in-wave speed, are identified and systematically analyzed. Using a SUMO-based simulation as an illustrative example, we further demonstrate how these parameters can be measured in practice with two stationary roadside traffic detectors. The results show that the proposed JAD strategy successfully suppresses the propagation of a stop-and-go wave, without triggering a secondary wave. This paper is expected to take a significant step toward making JAD practical, advancing it from a theoretical concept to a feasible and implementable strategy. To promote reproducibility in the transportation domain, we have also open-sourced all the code on our GitHub repository https://github.com/gotrafficgo.

</details>

<details><summary><b>中文摘要</b></summary>

走走停停的波浪作为高速公路交通拥堵的主要形式，会造成严重而持久的不利影响，包括交通效率降低、驾驶风险增加、车辆排放增加等。在高速公路交通管理策略中，拥堵吸收驾驶（JAD）已被提议作为防止此类波传播的潜在方法，其中专用车辆在被走走停停的波捕获之前执行“慢进”和“快出”机动。然而，大多数现有的联合AD策略仍然不切实际，主要是由于缺乏对实施工具和操作条件的讨论。受现实世界中警车转向行为观察的启发，本文首先介绍了单车双探测器干扰吸收驾驶（SVDD-JAD）问题，然后提出了一种实用的 JAD 策略，将这种行为转化为能够抑制孤立走走停停波传播的策略。确定并系统分析了对所提出的策略有显着影响的五个关键参数，即 JAD 速度、流入交通速度、波宽、波速和波内速度。使用基于 SUMO 的模拟作为说明性示例，我们进一步演示了如何使用两个固定路边交通检测器在实践中测量这些参数。结果表明，所提出的 JAD 策略成功地抑制了走走停停波的传播，而没有触发二次波。本文有望在 JAD 实用化方面迈出重要一步，将其从理论概念提升为可行且可实施的策略。为了促进交通领域的可重复性，我们还在 GitHub 存储库 https://github.com/gotrafficgo 上开源了所有代码。

</details>

---

## 179. ImprovEvolve: Ask AlphaEvolve to Improve the Input Solution and Then Improvise

**中文标题**: ImprovEvolve：要求 AlphaEvolve 改进输入解决方案，然后即兴创作

**Date**: 2026-02-10 | **arXiv**: [2602.10233v1](http://arxiv.org/abs/2602.10233v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10233v1)

<details><summary><b>Abstract</b></summary>

Recent advances in LLM-guided evolutionary computation, particularly AlphaEvolve, have demonstrated remarkable success in discovering novel mathematical constructions and solving challenging optimization problems. In this article, we present ImprovEvolve, a simple yet effective technique for enhancing LLM-based evolutionary approaches such as AlphaEvolve. Given an optimization problem, the standard approach is to evolve program code that, when executed, produces a solution close to the optimum. We propose an alternative program parameterization that maintains the ability to construct optimal solutions while reducing the cognitive load on the LLM. Specifically, we evolve a program (implementing, e.g., a Python class with a prescribed interface) that provides the following functionality: (1) propose a valid initial solution, (2) improve any given solution in terms of fitness, and (3) perturb a solution with a specified intensity. The optimum can then be approached by iteratively applying improve() and perturb() with a scheduled intensity. We evaluate ImprovEvolve on challenging problems from the AlphaEvolve paper: hexagon packing in a hexagon and the second autocorrelation inequality. For hexagon packing, the evolved program achieves new state-of-the-art results for 11, 12, 15, and 16 hexagons; a lightly human-edited variant further improves results for 14, 17, and 23 hexagons. For the second autocorrelation inequality, the human-edited program achieves a new state-of-the-art lower bound of 0.96258, improving upon AlphaEvolve's 0.96102.

</details>

<details><summary><b>中文摘要</b></summary>

LLM 引导的进化计算（特别是 AlphaEvolve）的最新进展在发现新颖的数学结构和解决具有挑战性的优化问题方面取得了显着的成功。在本文中，我们介绍了 ImprovEvolve，这是一种简单而有效的技术，用于增强基于 LLM 的进化方法（例如 AlphaEvolve）。给定优化问题，标准方法是改进程序代码，在执行时产生接近最优的解决方案。我们提出了一种替代程序参数化，它保持构建最佳解决方案的能力，同时减少法学硕士的认知负担。具体来说，我们开发一个程序（例如，实现具有规定接口的 Python 类），该程序提供以下功能：（1）提出有效的初始解决方案，（2）在适应度方面改进任何给定的解决方案，以及（3）以指定的强度扰动解决方案。然后可以通过以预定强度迭代应用 Improve() 和 perturb() 来接近最佳值。我们针对 AlphaEvolve 论文中的挑战性问题评估了 ImprovEvolve：六边形中的六边形堆积和第二自相关不等式。对于六边形堆积，改进的程序对于 11、12、15 和 16 六边形实现了新的最先进结果；经过轻微人工编辑的变体进一步改善了 14、17 和 23 六边形的结果。对于第二个自相关不等式，人工编辑的程序实现了新的最先进下限 0.96258，比 AlphaEvolve 的 0.96102 有所改进。

</details>

---

## 180. Towards Autonomous Mathematics Research

**中文标题**: 走向自主数学研究

**Date**: 2026-02-10 | **arXiv**: [2602.10177v1](http://arxiv.org/abs/2602.10177v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10177v1)

<details><summary><b>Abstract</b></summary>

Recent advances in foundational models have yielded reasoning systems capable of achieving a gold-medal standard at the International Mathematical Olympiad. The transition from competition-level problem-solving to professional research, however, requires navigating vast literature and constructing long-horizon proofs. In this work, we introduce Aletheia, a math research agent that iteratively generates, verifies, and revises solutions end-to-end in natural language. Specifically, Aletheia is powered by an advanced version of Gemini Deep Think for challenging reasoning problems, a novel inference-time scaling law that extends beyond Olympiad-level problems, and intensive tool use to navigate the complexities of mathematical research. We demonstrate the capability of Aletheia from Olympiad problems to PhD-level exercises and most notably, through several distinct milestones in AI-assisted mathematics research: (a) a research paper (Feng26) generated by AI without any human intervention in calculating certain structure constants in arithmetic geometry called eigenweights; (b) a research paper (LeeSeo26) demonstrating human-AI collaboration in proving bounds on systems of interacting particles called independent sets; and (c) an extensive semi-autonomous evaluation (Feng et al., 2026a) of 700 open problems on Bloom's Erdos Conjectures database, including autonomous solutions to four open questions. In order to help the public better understand the developments pertaining to AI and mathematics, we suggest codifying standard levels quantifying autonomy and novelty of AI-assisted results. We conclude with reflections on human-AI collaboration in mathematics.

</details>

<details><summary><b>中文摘要</b></summary>

基础模型的最新进展已经产生了能够在国际数学奥林匹克竞赛中达到金牌标准的推理系统。然而，从竞赛级问题解决到专业研究的转变需要查阅大量文献并构建长期证明。在这项工作中，我们介绍了 Aletheia，这是一种数学研究代理，可以用自然语言端到端地迭代生成、验证和修改解决方案。具体来说，Aletheia 由用于挑战性推理问题的 Gemini Deep Think 高级版本、超越奥林匹克级别问题的新颖推理时间缩放法则以及用于驾驭数学研究复杂性的密集工具使用提供支持。我们展示了 Aletheia 从奥林匹克问题到博士级别练习的能力，最值得注意的是，通过人工智能辅助数学研究中的几个不同里程碑：（a）由人工智能生成的研究论文（Feng26），在计算算术几何中称为特征权重的某些结构常数时无需任何人为干预； (b) 一篇研究论文（LeeSeo26）展示了人类与人工智能的协作，证明了称为独立集的相互作用粒子系统的界限； (c) 对 Bloom 的鄂尔多斯猜想数据库中的 700 个开放问题进行广泛的半自主评估（Feng 等人，2026a），包括四个开放问题的自主解决方案。为了帮助公众更好地了解人工智能和数学的发展，我们建议制定标准水平，量化人工智能辅助结果的自主性和新颖性。最后我们对人类与人工智能在数学领域的合作进行了反思。

</details>

---

## 181. Anagent For Enhancing Scientific Table & Figure Analysis

**中文标题**: 增强科学表格和图形分析的试剂

**Date**: 2026-02-10 | **arXiv**: [2602.10081v1](http://arxiv.org/abs/2602.10081v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10081v1)

<details><summary><b>Abstract</b></summary>

In scientific research, analysis requires accurately interpreting complex multimodal knowledge, integrating evidence from different sources, and drawing inferences grounded in domain-specific knowledge. However, current artificial intelligence (AI) systems struggle to consistently demonstrate such capabilities. The complexity and variability of scientific tables and figures, combined with heterogeneous structures and long-context requirements, pose fundamental obstacles to scientific table \& figure analysis. To quantify these challenges, we introduce AnaBench, a large-scale benchmark featuring $63,178$ instances from nine scientific domains, systematically categorized along seven complexity dimensions. To tackle these challenges, we propose Anagent, a multi-agent framework for enhanced scientific table \& figure analysis through four specialized agents: Planner decomposes tasks into actionable subtasks, Expert retrieves task-specific information through targeted tool execution, Solver synthesizes information to generate coherent analysis, and Critic performs iterative refinement through five-dimensional quality assessment. We further develop modular training strategies that leverage supervised finetuning and specialized reinforcement learning to optimize individual capabilities while maintaining effective collaboration. Comprehensive evaluation across 170 subdomains demonstrates that Anagent achieves substantial improvements, up to $\uparrow 13.43\%$ in training-free settings and $\uparrow 42.12\%$ with finetuning, while revealing that task-oriented reasoning and context-aware problem-solving are essential for high-quality scientific table \& figure analysis. Our project page: https://xhguo7.github.io/Anagent/.

</details>

<details><summary><b>中文摘要</b></summary>

在科学研究中，分析需要准确解释复杂的多模态知识，整合不同来源的证据，并根据特定领域的知识得出推论。然而，当前的人工智能（AI）系统很难始终如一地展示这种能力。科学表格和图形的复杂性和可变性，加上异构结构和长上下文要求，对科学表格和图形分析构成了根本障碍。为了量化这些挑战，我们引入了 AnaBench，这是一个大型基准测试，包含来自九个科学领域的价值 63,178 美元的实例，并按照七个复杂性维度进行系统分类。为了应对这些挑战，我们提出了 Anagent，一个通过四个专门代理来增强科学表格和图形分析的多代理框架：Planner 将任务分解为可操作的子任务，Expert 通过有针对性的工具执行检索特定于任务的信息，Solver 综合信息以生成连贯的分析，Critic 通过五维质量评估进行迭代细化。我们进一步开发模块化培训策略，利用监督微调和专业强化学习来优化个人能力，同时保持有效的协作。跨 170 个子域的综合评估表明 Anagent 取得了显着的改进，在免训练设置中高达 $\uparrow 13.43\%$，通过微调高达 $\uparrow 42.12\%$，同时揭示了面向任务的推理和上下文感知的问题解决对于高质量的科学表格和图形分析至关重要。我们的项目页面：https://xhguo7.github.io/Anagent/。

</details>

---

## 182. RoboSubtaskNet: Temporal Sub-task Segmentation for Human-to-Robot Skill Transfer in Real-World Environments

**中文标题**: RoboSubtaskNet：现实环境中人机技能转移的时间子任务分割

**Date**: 2026-02-10 | **arXiv**: [2602.10015v2](http://arxiv.org/abs/2602.10015v2) | **PDF**: [Link](http://arxiv.org/pdf/2602.10015v2)

<details><summary><b>Abstract</b></summary>

Temporally locating and classifying fine-grained sub-task segments in long, untrimmed videos is crucial to safe human-robot collaboration. Unlike generic activity recognition, collaborative manipulation requires sub-task labels that are directly robot-executable. We present RoboSubtaskNet, a multi-stage human-to-robot sub-task segmentation framework that couples attention-enhanced I3D features (RGB plus optical flow) with a modified MS-TCN employing a Fibonacci dilation schedule to capture better short-horizon transitions such as reach-pick-place. The network is trained with a composite objective comprising cross-entropy and temporal regularizers (truncated MSE and a transition-aware term) to reduce over-segmentation and to encourage valid sub-task progressions. To close the gap between vision benchmarks and control, we introduce RoboSubtask, a dataset of healthcare and industrial demonstrations annotated at the sub-task level and designed for deterministic mapping to manipulator primitives. Empirically, RoboSubtaskNet outperforms MS-TCN and MS-TCN++ on GTEA and our RoboSubtask benchmark (boundary-sensitive and sequence metrics), while remaining competitive on the long-horizon Breakfast benchmark. Specifically, RoboSubtaskNet attains F1 @ 50 = 79.5%, Edit = 88.6%, Acc = 78.9% on GTEA; F1 @ 50 = 30.4%, Edit = 52.0%, Acc = 53.5% on Breakfast; and F1 @ 50 = 94.2%, Edit = 95.6%, Acc = 92.2% on RoboSubtask. We further validate the full perception-to-execution pipeline on a 7-DoF Kinova Gen3 manipulator, achieving reliable end-to-end behavior in physical trials (overall task success approx 91.25%). These results demonstrate a practical path from sub-task level video understanding to deployed robotic manipulation in real-world settings.

</details>

<details><summary><b>中文摘要</b></summary>

在未经修剪的长视频中临时定位和分类细粒度的子任务片段对于安全的人机协作至关重要。与通用活动识别不同，协作操作需要机器人可以直接执行的子任务标签。我们提出了 RoboSubtaskNet，一个多阶段的人机子任务分割框架，它将注意力增强的 I3D 特征（RGB 加光流）与改进的 MS-TCN 结合起来，采用斐波那契扩张计划来捕获更好的短视野过渡，例如到达-拾取-放置。该网络采用由交叉熵和时间正则化器（截断的 MSE 和转换感知项）组成的复合目标进行训练，以减少过度分割并鼓励有效的子任务进展。为了缩小视觉基准和控制之间的差距，我们引入了 RoboSubtask，这是一个在子任务级别注释的医疗保健和工业演示数据集，旨在用于确定性映射到操纵器基元。根据经验，RoboSubtaskNet 在 GTEA 和我们的 RoboSubtask 基准（边界敏感和序列指标）上优于 MS-TCN 和 MS-TCN++，同时在长期早餐基准上保持竞争力。具体来说，RoboSubtaskNet 在 GTEA 上达到 F1 @ 50 = 79.5%，Edit = 88.6%，Acc = 78.9%；早餐时 F1 @ 50 = 30.4%，编辑 = 52.0%，Acc = 53.5%； RoboSubtask 上的 F1 @ 50 = 94.2%，编辑 = 95.6%，Acc = 92.2%。我们进一步验证了 7-DoF Kinova Gen3 机械臂上的完整感知到执行流程，在物理试验中实现了可靠的端到端行为（总体任务成功率约为 91.25%）。这些结果展示了从子任务级视频理解到在现实环境中部署机器人操作的实用路径。

</details>

---

## 183. Discovering High Level Patterns from Simulation Traces

**中文标题**: 从仿真跟踪中发现高级模式

**Date**: 2026-02-10 | **arXiv**: [2602.10009v1](http://arxiv.org/abs/2602.10009v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10009v1)

<details><summary><b>Abstract</b></summary>

Artificial intelligence (AI) agents embedded in environments with physics-based interaction face many challenges including reasoning, planning, summarization, and question answering. This problem is exacerbated when a human user wishes to either guide or interact with the agent in natural language. Although the use of Language Models (LMs) is the default choice, as an AI tool, they struggle with tasks involving physics. The LM's capability for physical reasoning is learned from observational data, rather than being grounded in simulation. A common approach is to include simulation traces as context, but this suffers from poor scalability as simulation traces contain larger volumes of fine-grained numerical and semantic data. In this paper, we propose a natural language guided method to discover coarse-grained patterns (e.g., 'rigid-body collision', 'stable support', etc.) from detailed simulation logs. Specifically, we synthesize programs that operate on simulation logs and map them to a series of high level activated patterns. We show, through two physics benchmarks, that this annotated representation of the simulation log is more amenable to natural language reasoning about physical systems. We demonstrate how this method enables LMs to generate effective reward programs from goals specified in natural language, which may be used within the context of planning or supervised learning.

</details>

<details><summary><b>中文摘要</b></summary>

嵌入基于物理交互的环境中的人工智能 (AI) 代理面临着许多挑战，包括推理、规划、总结和问答。当人类用户希望用自然语言指导代理或与代理交互时，这个问题会更加严重。尽管语言模型 (LM) 的使用是默认选择，但作为人工智能工具，它们在涉及物理的任务上遇到了困难。 LM 的物理推理能力是从观测数据中学习的，而不是基于模拟。一种常见的方法是将模拟跟踪作为上下文包含在内，但这会导致可扩展性较差，因为模拟跟踪包含大量细粒度的数值和语义数据。在本文中，我们提出了一种自然语言引导的方法，从详细的模拟日志中发现粗粒度模式（例如“刚体碰撞”、“稳定支撑”等）。具体来说，我们综合了对模拟日志进行操作的程序，并将它们映射到一系列高级激活模式。我们通过两个物理基准测试表明，这种带注释的模拟日志表示更适合关于物理系统的自然语言推理。我们演示了这种方法如何使 LM 根据自然语言指定的目标生成有效的奖励计划，这些计划可以在规划或监督学习的背景下使用。

</details>

---

## 184. ESTAR: Early-Stopping Token-Aware Reasoning For Efficient Inference

**中文标题**: ESTAR：提前停止令牌感知推理以实现高效推理

**Date**: 2026-02-10 | **arXiv**: [2602.10004v1](http://arxiv.org/abs/2602.10004v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10004v1)

<details><summary><b>Abstract</b></summary>

Large reasoning models (LRMs) achieve state-of-the-art performance by generating long chains-of-thought, but often waste computation on redundant reasoning after the correct answer has already been reached. We introduce Early-Stopping for Token-Aware Reasoning (ESTAR), which detects and reduces such reasoning redundancy to improve efficiency without sacrificing accuracy. Our method combines (i) a trajectory-based classifier that identifies when reasoning can be safely stopped, (ii) supervised fine-tuning to teach LRMs to propose self-generated <stop> signals, and (iii) <stop>-aware reinforcement learning that truncates rollouts at self-generated stop points with compute-aware rewards. Experiments on four reasoning datasets show that ESTAR reduces reasoning length by about 3.7x (from 4,799 to 1,290) while preserving accuracy (74.9% vs. 74.2%), with strong cross-domain generalization. These results highlight early stopping as a simple yet powerful mechanism for improving reasoning efficiency in LRMs.

</details>

<details><summary><b>中文摘要</b></summary>

大型推理模型（LRM）通过生成长的思维链来实现最先进的性能，但在得出正确答案后往往会在冗余推理上浪费计算。我们引入了早期停止令牌感知推理（ESTAR），它可以检测并减少这种推理冗余，以在不牺牲准确性的情况下提高效率。我们的方法结合了（i）基于轨迹的分类器，用于识别何时可以安全停止推理，（ii）监督微调，以教导 LRM 提出自生成的 <stop> 信号，以及（iii） <stop> 感知强化学习，通过计算感知奖励在自生成的停止点处截断推出。在四个推理数据集上的实验表明，ESTAR 将推理长度减少了约 3.7 倍（从 4,799 到 1,290），同时保持了准确性（74.9% vs. 74.2%），具有很强的跨域泛化能力。这些结果强调早期停止是一种简单而强大的机制，可以提高 LRM 的推理效率。

</details>

---

## 185. A Unified Assessment of the Poverty of the Stimulus Argument for Neural Language Models

**中文标题**: 神经语言模型刺激论证贫困的统一评估

**Date**: 2026-02-10 | **arXiv**: [2602.09992v1](http://arxiv.org/abs/2602.09992v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09992v1)

<details><summary><b>Abstract</b></summary>

How can children acquire native-level syntax from limited input? According to the Poverty of the Stimulus Hypothesis (PoSH), the linguistic input children receive is insufficient to explain certain generalizations that are robustly learned; innate linguistic constraints, many have argued, are thus necessary to explain language learning. Neural language models, which lack such language-specific constraints in their design, offer a computational test of this longstanding (but controversial) claim. We introduce \poshbench, a training-and-evaluation suite targeting question formation, islands to movement, and other English phenomena at the center of the PoSH arguments. Training Transformer models on 10--50M words of developmentally plausible text, we find indications of generalization on all phenomena even without direct positive evidence -- yet neural models remain less data-efficient and their generalizations are weaker than those of children. We further enhance our models with three recently proposed cognitively motivated inductive biases. We find these biases improve general syntactic competence but not \poshbench performance. Our findings challenge the claim that innate syntax is the only possible route to generalization, while suggesting that human-like data efficiency requires inductive biases beyond those tested here.

</details>

<details><summary><b>中文摘要</b></summary>

孩子如何从有限的输入中获得母语水平的语法？根据刺激贫困假说（PoSH），儿童接受的语言输入不足以解释某些经过稳健学习的概括；许多人认为，先天的语言限制对于解释语言学习是必要的。神经语言模型在设计中缺乏这种特定于语言的约束，为这一长期存在（但有争议）的主张提供了计算测试。我们引入了 \poshbench，这是一个针对问题形成、岛屿运动以及 PoSH 争论中心的其他英语现象的训练和评估套件。用 10--50M 字的发展合理文本训练 Transformer 模型，即使没有直接的积极证据，我们也发现了所有现象的泛化迹象——但神经模型的数据效率仍然较低，而且它们的泛化能力比儿童的要弱。我们通过最近提出的三种认知动机归纳偏差进一步增强了我们的模型。我们发现这些偏差提高了一般句法能力，但没有提高 \poshbench 性能。我们的研究结果挑战了先天语法是泛化唯一可能途径的说法，同时表明类人数据效率需要超出此处测试的归纳偏差。

</details>

---

## 186. Empirical Stability Analysis of Kolmogorov-Arnold Networks in Hard-Constrained Recurrent Physics-Informed Discovery

**中文标题**: 硬约束循环物理发现中柯尔莫哥洛夫-阿诺德网络的经验稳定性分析

**Date**: 2026-02-10 | **arXiv**: [2602.09988v1](http://arxiv.org/abs/2602.09988v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09988v1)

<details><summary><b>Abstract</b></summary>

We investigate the integration of Kolmogorov-Arnold Networks (KANs) into hard-constrained recurrent physics-informed architectures (HRPINN) to evaluate the fidelity of learned residual manifolds in oscillatory systems. Motivated by the Kolmogorov-Arnold representation theorem and preliminary gray-box results, we hypothesized that KANs would enable efficient recovery of unknown terms compared to MLPs. Through initial sensitivity analysis on configuration sensitivity, parameter scale, and training paradigm, we found that while small KANs are competitive on univariate polynomial residuals (Duffing), they exhibit severe hyperparameter fragility, instability in deeper configurations, and consistent failure on multiplicative terms (Van der Pol), generally outperformed by standard MLPs. These empirical challenges highlight limitations of the additive inductive bias in the original KAN formulation for state coupling and provide preliminary empirical evidence of inductive bias limitations for future hybrid modeling.

</details>

<details><summary><b>中文摘要</b></summary>

我们研究了将柯尔莫哥洛夫-阿诺德网络 (KAN) 集成到硬约束循环物理信息架构 (HRPINN) 中，以评估振荡系统中学习的残差流形的保真度。受 Kolmogorov-Arnold 表示定理和初步灰盒结果的启发，我们假设与 MLP 相比，KAN 能够有效恢复未知项。通过对配置敏感性、参数规模和训练范式的初始敏感性分析，我们发现，虽然小型 KAN 在单变量多项式残差（Duffing）方面具有竞争力，但它们表现出严重的超参数脆弱性、更深层次配置的不稳定性以及乘法项上的一致失败（Van der Pol），通常优于标准 MLP。这些经验挑战凸显了原始 KAN 状态耦合公式中的加性归纳偏差的局限性，并为未来混合建模的归纳偏差局限性提供了初步的经验证据。

</details>

---

## 187. Infusion: Shaping Model Behavior by Editing Training Data via Influence Functions

**中文标题**: Infusion：通过影响函数编辑训练数据来塑造模型行为

**Date**: 2026-02-10 | **arXiv**: [2602.09987v2](http://arxiv.org/abs/2602.09987v2) | **PDF**: [Link](http://arxiv.org/pdf/2602.09987v2)

**Code**: https://github.com/jrosseruk/infusion.

<details><summary><b>Abstract</b></summary>

Influence functions are commonly used to attribute model behavior to training documents. We explore the reverse: crafting training data that induces model behavior. Our framework, Infusion, uses scalable influence-function approximations to compute small perturbations to training documents that induce targeted changes in model behavior through parameter shifts. We evaluate Infusion on data poisoning tasks across vision and language domains. On CIFAR-10, we show that making subtle edits via Infusion to just 0.2% (100/45,000) of the training documents can be competitive with the baseline of inserting a small number of explicit behavior examples. We also find that Infusion transfers across architectures (ResNet $\leftrightarrow$ CNN), suggesting a single poisoned corpus can affect multiple independently trained models. In preliminary language experiments, we characterize when our approach increases the probability of target behaviors and when it fails, finding it most effective at amplifying behaviors the model has already learned. Taken together, these results show that small, subtle edits to training data can systematically shape model behavior, underscoring the importance of training data interpretability for adversaries and defenders alike. We provide the code here: https://github.com/jrosseruk/infusion.

</details>

<details><summary><b>中文摘要</b></summary>

影响函数通常用于将模型行为归因于训练文档。我们探索相反的方向：制作诱导模型行为的训练数据。我们的框架 Infusion 使用可扩展的影响函数近似来计算对训练文档的小扰动，这些扰动通过参数变化引起模型行为的有针对性的变化。我们评估 Infusion 对跨视觉和语言领域的数据中毒任务的影响。在 CIFAR-10 上，我们表明，通过 Infusion 对 0.2% (100/45,000) 的训练文档进行细微编辑可以与插入少量显式行为示例的基线相媲美。我们还发现 Infusion 跨架构传输（ResNet $\leftrightarrow$ CNN），这表明单个中毒语料库可以影响多个独立训练的模型。在初步的语言实验中，我们描述了我们的方法何时增加目标行为的概率以及何时失败，发现它在放大模型已经学到的行为方面最有效。总而言之，这些结果表明，对训练数据进行小的、微妙的编辑可以系统地塑造模型行为，强调了训练数据可解释性对于对手和防御者的重要性。我们在这里提供代码：https://github.com/jrosseruk/infusion。

</details>

---

## 188. Supervised Metric Regularization Through Alternating Optimization for Multi-Regime Physics-Informed Neural Networks

**中文标题**: 通过多机制物理信息神经网络的交替优化来监督度量正则化

**Date**: 2026-02-10 | **arXiv**: [2602.09980v1](http://arxiv.org/abs/2602.09980v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09980v1)

<details><summary><b>Abstract</b></summary>

Standard Physics-Informed Neural Networks (PINNs) often face challenges when modeling parameterized dynamical systems with sharp regime transitions, such as bifurcations. In these scenarios, the continuous mapping from parameters to solutions can result in spectral bias or "mode collapse", where the network averages distinct physical behaviors. We propose a Topology-Aware PINN (TAPINN) that aims to mitigate this challenge by structuring the latent space via Supervised Metric Regularization. Unlike standard parametric PINNs that map physical parameters directly to solutions, our method conditions the solver on a latent state optimized to reflect the metric-based separation between regimes, showing ~49% lower physics residual (0.082 vs. 0.160). We train this architecture using a phase-based Alternating Optimization (AO) schedule to manage gradient conflicts between the metric and physics objectives. Preliminary experiments on the Duffing Oscillator demonstrate that while standard baselines suffer from spectral bias and high-capacity Hypernetworks overfit (memorizing data while violating physics), our approach achieves stable convergence with 2.18x lower gradient variance than a multi-output Sobolev Error baseline, and 5x fewer parameters than a hypernetwork-based alternative.

</details>

<details><summary><b>中文摘要</b></summary>

在对具有急剧状态转变（例如分岔）的参数化动力系统进行建模时，标准物理信息神经网络 (PINN) 经常面临挑战。在这些场景中，从参数到解决方案的连续映射可能会导致频谱偏差或“模式崩溃”，其中网络对不同的物理行为进行平均。我们提出了一种拓扑感知 PINN (TAPINN)，旨在通过监督度量正则化构建潜在空间来缓解这一挑战。与将物理参数直接映射到解的标准参数 PINN 不同，我们的方法将求解器置于优化的潜在状态上，以反映状态之间基于度量的分离，显示物理残差降低约 49%（0.082 与 0.160）。我们使用基于阶段的交替优化（AO）计划来训练该架构，以管理度量目标和物理目标之间的梯度冲突。 Duffing 振荡器的初步实验表明，虽然标准基线存在谱偏差和高容量超网络过度拟合（在违反物理的情况下记忆数据），但我们的方法实现了稳定收敛，梯度方差比多输出 Sobolev 误差基线低 2.18 倍，参数比基于超网络的替代方案少 5 倍。

</details>

---

## 189. Closing Reasoning Gaps in Clinical Agents with Differential Reasoning Learning

**中文标题**: 通过差异推理学习缩小临床代理的推理差距

**Date**: 2026-02-10 | **arXiv**: [2602.09945v1](http://arxiv.org/abs/2602.09945v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09945v1)

<details><summary><b>Abstract</b></summary>

Clinical decision support requires not only correct answers but also clinically valid reasoning. We propose Differential Reasoning Learning (DRL), a framework that improves clinical agents by learning from reasoning discrepancies. From reference reasoning rationales (e.g., physician-authored clinical rationale, clinical guidelines, or outputs from more capable models) and the agent's free-form chain-of-thought (CoT), DRL extracts reasoning graphs as directed acyclic graphs (DAGs) and performs a clinically weighted graph edit distance (GED)-based discrepancy analysis. An LLM-as-a-judge aligns semantically equivalent nodes and diagnoses discrepancies between graphs. These graph-level discrepancy diagnostics are converted into natural-language instructions and stored in a Differential Reasoning Knowledge Base (DR-KB). At inference, we retrieve top-$k$ instructions via Retrieval-Augmented Generation (RAG) to augment the agent prompt and patch likely logic gaps. Evaluation on open medical question answering (QA) benchmarks and a Return Visit Admissions (RVA) prediction task from internal clinical data demonstrates gains over baselines, improving both final-answer accuracy and reasoning fidelity. Ablation studies confirm gains from infusing reference reasoning rationales and the top-$k$ retrieval strategy. Clinicians' review of the output provides further assurance of the approach. Together, results suggest that DRL supports more reliable clinical decision-making in complex reasoning scenarios and offers a practical mechanism for deployment under limited token budgets.

</details>

<details><summary><b>中文摘要</b></summary>

临床决策支持不仅需要正确的答案，还需要临床有效的推理。我们提出了差异推理学习（DRL），这是一个通过从推理差异中学习来改进临床代理的框架。根据参考推理原理（例如，医生撰写的临床原理、临床指南或功能更强大的模型的输出）和代理的自由形式思想链 (CoT)，DRL 将推理图提取为有向无环图 (DAG)，并执行基于临床加权图编辑距离 (GED) 的差异分析。法学硕士作为法官对齐语义上等效的节点并诊断图表之间的差异。这些图形级差异诊断被转换为自然语言指令并存储在差异推理知识库 (DR-KB) 中。在推理时，我们通过检索增强生成（RAG）检索 top-$k$ 指令，以增强代理提示并修补可能的逻辑间隙。根据内部临床数据对开放式医学问答 (QA) 基准和回诊入院 (RVA) 预测任务进行的评估表明，与基线相比有所提高，最终答案的准确性和推理保真度均得到提高。消融研究证实了注入参考推理原理和 top-$k$ 检索策略的收益。临床医生对输出的审查为该方法提供了进一步的保证。总之，结果表明 DRL 支持复杂推理场景中更可靠的临床决策，并提供了在有限代币预算下部署的实用机制。

</details>

---

## 190. Instruct2Act: From Human Instruction to Actions Sequencing and Execution via Robot Action Network for Robotic Manipulation

**中文标题**: Instruct2Act：从人类指令到通过机器人操作网络进行动作排序和执行

**Date**: 2026-02-10 | **arXiv**: [2602.09940v1](http://arxiv.org/abs/2602.09940v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09940v1)

<details><summary><b>Abstract</b></summary>

Robots often struggle to follow free-form human instructions in real-world settings due to computational and sensing limitations. We address this gap with a lightweight, fully on-device pipeline that converts natural-language commands into reliable manipulation. Our approach has two stages: (i) the instruction to actions module (Instruct2Act), a compact BiLSTM with a multi-head-attention autoencoder that parses an instruction into an ordered sequence of atomic actions (e.g., reach, grasp, move, place); and (ii) the robot action network (RAN), which uses the dynamic adaptive trajectory radial network (DATRN) together with a vision-based environment analyzer (YOLOv8) to generate precise control trajectories for each sub-action. The entire system runs on a modest system with no cloud services. On our custom proprietary dataset, Instruct2Act attains 91.5% sub-actions prediction accuracy while retaining a small footprint. Real-robot evaluations across four tasks (pick-place, pick-pour, wipe, and pick-give) yield an overall 90% success; sub-action inference completes in < 3.8s, with end-to-end executions in 30-60s depending on task complexity. These results demonstrate that fine-grained instruction-to-action parsing, coupled with DATRN-based trajectory generation and vision-guided grounding, provides a practical path to deterministic, real-time manipulation in resource-constrained, single-camera settings.

</details>

<details><summary><b>中文摘要</b></summary>

由于计算和传感的限制，机器人常常难以在现实世界中遵循自由形式的人类指令。我们通过轻量级、完全在设备上的管道来解决这一差距，该管道将自然语言命令转换为可靠的操作。我们的方法有两个阶段：（i）动作指令模块（Instruct2Act），一个紧凑的 BiLSTM，具有多头注意力自动编码器，可将指令解析为有序的原子动作序列（例如，到达、抓取、移动、放置）； (ii) 机器人动作网络 (RAN)，它使用动态自适应轨迹径向网络 (DATRN) 和基于视觉的环境分析器 (YOLOv8) 来为每个子动作生成精确的控制轨迹。整个系统运行在一个没有云服务的普通系统上。在我们的自定义专有数据集上，Instruct2Act 实现了 91.5% 的子动作预测准确率，同时保持了较小的占用空间。对四项任务（拾取放置、拾取倾倒、擦拭和拾取-给予）进行的真实机器人评估总体成功率为 90%；子动作推理在 3.8 秒内完成，根据任务复杂性，端到端执行在 30-60 秒内完成。这些结果表明，细粒度的指令到动作解析与基于 DATRN 的轨迹生成和视觉引导接地相结合，为资源受限的单摄像头设置中的确定性实时操作提供了一条实用路径。

</details>

---

## 191. Cosmo3DFlow: Wavelet Flow Matching for Spatial-to-Spectral Compression in Reconstructing the Early Universe

**中文标题**: Cosmo3DFlow：重建早期宇宙中用于空间到光谱压缩的小波流匹配

**Date**: 2026-02-10 | **arXiv**: [2602.10172v1](http://arxiv.org/abs/2602.10172v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10172v1)

<details><summary><b>Abstract</b></summary>

Reconstructing the early Universe from the evolved present-day Universe is a challenging and computationally demanding problem in modern astrophysics. We devise a novel generative framework, Cosmo3DFlow, designed to address dimensionality and sparsity, the critical bottlenecks inherent in current state-of-the-art methods for cosmological inference. By integrating 3D Discrete Wavelet Transform (DWT) with flow matching, we effectively represent high-dimensional cosmological structures. The Wavelet Transform addresses the ``void problem'' by translating spatial emptiness into spectral sparsity. It decouples high-frequency details from low-frequency structures through spatial compression, and wavelet-space velocity fields facilitate stable ordinary differential equation (ODE) solvers with large step sizes. Using large-scale cosmological $N$-body simulations, at $128^3$ resolution, we achieve up to $50\times$ faster sampling than diffusion models, combining a $10\times$ reduction in integration steps with lower per-step computational cost from wavelet compression. Our results enable initial conditions to be sampled in seconds, compared to minutes for previous methods.

</details>

<details><summary><b>中文摘要</b></summary>

从进化的当今宇宙重建早期宇宙是现代天体物理学中的一个具有挑战性和计算要求的问题。我们设计了一种新颖的生成框架 Cosmo3DFlow，旨在解决维度和稀疏性，这是当前最先进的宇宙学推理方法固有的关键瓶颈。通过将 3D 离散小波变换 (DWT) 与流匹配相结合，我们可以有效地表示高维宇宙结构。小波变换通过将空间空虚转化为光谱稀疏来解决“空虚问题”。它通过空间压缩将高频细节与低频结构解耦，小波空间速度场有助于稳定的大步长常微分方程 (ODE) 求解器。使用大规模宇宙学 $N$ 体模拟，在 $128^3$ 分辨率下，我们实现了比扩散模型快 $50\time$ 的采样速度，同时减少了 $10\times$ 的积分步骤以及降低了小波压缩的每步计算成本。我们的结果使得初始条件能够在几秒钟内进行采样，而以前的方法需要几分钟。

</details>

---

## 192. TaCo: A Benchmark for Lossless and Lossy Codecs of Heterogeneous Tactile Data

**中文标题**: TaCo：异构触觉数据无损和有损编解码器的基准

**Date**: 2026-02-10 | **arXiv**: [2602.09893v1](http://arxiv.org/abs/2602.09893v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09893v1)

<details><summary><b>Abstract</b></summary>

Tactile sensing is crucial for embodied intelligence, providing fine-grained perception and control in complex environments. However, efficient tactile data compression, which is essential for real-time robotic applications under strict bandwidth constraints, remains underexplored. The inherent heterogeneity and spatiotemporal complexity of tactile data further complicate this challenge. To bridge this gap, we introduce TaCo, the first comprehensive benchmark for Tactile data Codecs. TaCo evaluates 30 compression methods, including off-the-shelf compression algorithms and neural codecs, across five diverse datasets from various sensor types. We systematically assess both lossless and lossy compression schemes on four key tasks: lossless storage, human visualization, material and object classification, and dexterous robotic grasping. Notably, we pioneer the development of data-driven codecs explicitly trained on tactile data, TaCo-LL (lossless) and TaCo-L (lossy). Results have validated the superior performance of our TaCo-LL and TaCo-L. This benchmark provides a foundational framework for understanding the critical trade-offs between compression efficiency and task performance, paving the way for future advances in tactile perception.

</details>

<details><summary><b>中文摘要</b></summary>

触觉传感对于体现智能至关重要，可以在复杂环境中提供细粒度的感知和控制。然而，有效的触觉数据压缩对于严格带宽限制下的实时机器人应用程序至关重要，但仍未得到充分探索。触觉数据固有的异质性和时空复杂性使这一挑战进一步复杂化。为了弥补这一差距，我们推出了 TaCo，这是第一个针对触觉数据编解码器的综合基准测试。 TaCo 在来自不同传感器类型的五个不同数据集上评估了 30 种压缩方法，包括现成的压缩算法和神经编解码器。我们系统地评估了无损和有损压缩方案的四个关键任务：无损存储、人类可视化、材料和物体分类以及灵巧的机器人抓取。值得注意的是，我们率先开发了针对触觉数据、TaCo-LL（无损）和 TaCo-L（有损）进行明确训练的数据驱动编解码器。结果验证了我们的 TaCo-LL 和 TaCo-L 的卓越性能。该基准测试为理解压缩效率和任务性能之间的关键权衡提供了一个基础框架，为触觉感知的未来进步铺平了道路。

</details>

---

## 193. Efficient Unsupervised Environment Design through Hierarchical Policy Representation Learning

**中文标题**: 通过分层策略表示学习进行高效的无监督环境设计

**Date**: 2026-02-10 | **arXiv**: [2602.09813v1](http://arxiv.org/abs/2602.09813v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09813v1)

<details><summary><b>Abstract</b></summary>

Unsupervised Environment Design (UED) has emerged as a promising approach to developing general-purpose agents through automated curriculum generation. Popular UED methods focus on Open-Endedness, where teacher algorithms rely on stochastic processes for infinite generation of useful environments. This assumption becomes impractical in resource-constrained scenarios where teacher-student interaction opportunities are limited. To address this challenge, we introduce a hierarchical Markov Decision Process (MDP) framework for environment design. Our framework features a teacher agent that leverages student policy representations derived from discovered evaluation environments, enabling it to generate training environments based on the student's capabilities. To improve efficiency, we incorporate a generative model that augments the teacher's training dataset with synthetic data, reducing the need for teacher-student interactions. In experiments across several domains, we show that our method outperforms baseline approaches while requiring fewer teacher-student interactions in a single episode. The results suggest the applicability of our approach in settings where training opportunities are limited.

</details>

<details><summary><b>中文摘要</b></summary>

无监督环境设计（UED）已成为通过自动课程生成开发通用代理的一种有前景的方法。流行的 UED 方法侧重于开放性，其中教师算法依赖随机过程来无限生成有用的环境。在资源有限、师生互动机会有限的情况下，这种假设变得不切实际。为了应对这一挑战，我们引入了用于环境设计的分层马尔可夫决策过程（MDP）框架。我们的框架具有一个教师代理，它利用从发现的评估环境中派生的学生策略表示，使其能够根据学生的能力生成培训环境。为了提高效率，我们采用了生成模型，用合成数据增强教师的训练数据集，减少师生互动的需要。在跨多个领域的实验中，我们表明我们的方法优于基线方法，同时在单集中需要更少的师生互动。结果表明我们的方法在培训机会有限的环境中的适用性。

</details>

---

## 194. A Controlled Study of Double DQN and Dueling DQN Under Cross-Environment Transfer

**中文标题**: 跨环境传输下双DQN和决斗DQN的对照研究

**Date**: 2026-02-10 | **arXiv**: [2602.09810v2](http://arxiv.org/abs/2602.09810v2) | **PDF**: [Link](http://arxiv.org/pdf/2602.09810v2)

<details><summary><b>Abstract</b></summary>

Transfer learning in deep reinforcement learning is often motivated by improved stability and reduced training cost, but it can also fail under substantial domain shift. This paper presents a controlled empirical study examining how architectural differences between Double Deep Q-Networks (DDQN) and Dueling DQN influence transfer behavior across environments. Using CartPole as a source task and LunarLander as a structurally distinct target task, we evaluate a fixed layer-wise representation transfer protocol under identical hyperparameters and training conditions, with baseline agents trained from scratch used to contextualize transfer effects. Empirical results show that DDQN consistently avoids negative transfer under the examined setup and maintains learning dynamics comparable to baseline performance in the target environment. In contrast, Dueling DQN consistently exhibits negative transfer under identical conditions, characterized by degraded rewards and unstable optimization behavior. Statistical analysis across multiple random seeds confirms a significant performance gap under transfer. These findings suggest that architectural inductive bias is strongly associated with robustness to cross-environment transfer in value-based deep reinforcement learning under the examined transfer protocol.

</details>

<details><summary><b>中文摘要</b></summary>

深度强化学习中的迁移学习通常是出于提高稳定性和降低训练成本的动机，但它也可能在大量领域转移的情况下失败。本文提出了一项受控实证研究，探讨双深度 Q 网络 (DDQN) 和决斗 DQN 之间的架构差异如何影响跨环境的传输行为。使用 CartPole 作为源任务，LunarLander 作为结构不同的目标任务，我们在相同的超参数和训练条件下评估固定的逐层表示传输协议，并使用从头开始训练的基线代理来将传输效果情境化。经验结果表明，DDQN 在所检查的设置下始终避免负迁移，并保持与目标环境中的基线性能相当的学习动态。相比之下，Dueling DQN 在相同条件下始终表现出负迁移，其特点是奖励降低和优化行为不稳定。多个随机种子的统计分析证实了传输下的显着性能差距。这些发现表明，在所检查的传输协议下，架构归纳偏差与基于价值的深度强化学习中的跨环境传输的鲁棒性密切相关。

</details>

---

## 195. Would a Large Language Model Pay Extra for a View? Inferring Willingness to Pay from Subjective Choices

**中文标题**: 大型语言模型会为视图支付额外费用吗？从主观选择推断支付意愿

**Date**: 2026-02-10 | **arXiv**: [2602.09802v1](http://arxiv.org/abs/2602.09802v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09802v1)

<details><summary><b>Abstract</b></summary>

As Large Language Models (LLMs) are increasingly deployed in applications such as travel assistance and purchasing support, they are often required to make subjective choices on behalf of users in settings where no objectively correct answer exists. We study LLM decision-making in a travel-assistant context by presenting models with choice dilemmas and analyzing their responses using multinomial logit models to derive implied willingness to pay (WTP) estimates. These WTP values are subsequently compared to human benchmark values from the economics literature. In addition to a baseline setting, we examine how model behavior changes under more realistic conditions, including the provision of information about users' past choices and persona-based prompting. Our results show that while meaningful WTP values can be derived for larger LLMs, they also display systematic deviations at the attribute level. Additionally, they tend to overestimate human WTP overall, particularly when expensive options or business-oriented personas are introduced. Conditioning models on prior preferences for cheaper options yields valuations that are closer to human benchmarks. Overall, our findings highlight both the potential and the limitations of using LLMs for subjective decision support and underscore the importance of careful model selection, prompt design, and user representation when deploying such systems in practice.

</details>

<details><summary><b>中文摘要</b></summary>

随着大型语言模型 (LLM) 越来越多地部署在旅行援助和购买支持等应用中，它们通常需要在不存在客观正确答案的环境中代表用户做出主观选择。我们通过提出具有选择困境的模型并使用多项 Logit 模型分析其响应来得出隐含的支付意愿 (WTP) 估计，从而研究旅行辅助背景下的法学硕士决策。随后将这些 WTP 值与经济学文献中的人类基准值进行比较。除了基线设置之外，我们还研究模型行为在更现实的条件下如何变化，包括提供有关用户过去选择和基于角色的提示的信息。我们的结果表明，虽然对于较大的法学硕士可以得出有意义的支付意愿值，但它们也显示出属性级别的系统偏差。此外，他们往往会高估人类的整体支付意愿，特别是在引入昂贵的选项或面向业务的角色时。根据先前对更便宜期权的偏好建立的条件模型会产生更接近人类基准的估值。总的来说，我们的研究结果强调了使用法学硕士进行主观决策支持的潜力和局限性，并强调了在实践中部署此类系统时仔细选择模型、提示设计和用户表示的重要性。

</details>

---

## 196. GHS-TDA: A Synergistic Reasoning Framework Integrating Global Hypothesis Space with Topological Data Analysis

**中文标题**: GHS-TDA：全局假设空间与拓扑数据分析相结合的协同推理框架

**Date**: 2026-02-10 | **arXiv**: [2602.09794v1](http://arxiv.org/abs/2602.09794v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09794v1)

<details><summary><b>Abstract</b></summary>

Chain-of-Thought (CoT) has been shown to significantly improve the reasoning accuracy of large language models (LLMs) on complex tasks. However, due to the autoregressive, step-by-step generation paradigm, existing CoT methods suffer from two fundamental limitations. First, the reasoning process is highly sensitive to early decisions: once an initial error is introduced, it tends to propagate and amplify through subsequent steps, while the lack of a global coordination and revision mechanism makes such errors difficult to correct, ultimately leading to distorted reasoning chains. Second, current CoT approaches lack structured analysis techniques for filtering redundant reasoning and extracting key reasoning features, resulting in unstable reasoning processes and limited interpretability. To address these issues, we propose GHS-TDA. GHS-TDA first constructs a semantically enriched global hypothesis graph to aggregate, align, and coordinate multiple candidate reasoning paths, thereby providing alternative global correction routes when local reasoning fails. It then applies topological data analysis based on persistent homology to capture stable multi-scale structures, remove redundancy and inconsistencies, and extract a more reliable reasoning skeleton. By jointly leveraging reasoning diversity and topological stability, GHS-TDA achieves self-adaptive convergence, produces high-confidence and interpretable reasoning paths, and consistently outperforms strong baselines in terms of both accuracy and robustness across multiple reasoning benchmarks.

</details>

<details><summary><b>中文摘要</b></summary>

思想链 (CoT) 已被证明可以显着提高大型语言模型 (LLM) 在复杂任务上的推理准确性。然而，由于自回归、逐步生成范式，现有的 CoT 方法存在两个基本限制。首先，推理过程对早期决策高度敏感：一旦引入初始错误，它往往会通过后续步骤传播和放大，而缺乏全局协调和修正机制使得此类错误难以纠正，最终导致推理链扭曲。其次，当前的 CoT 方法缺乏过滤冗余推理和提取关键推理特征的结构化分析技术，导致推理过程不稳定和可解释性有限。为了解决这些问题，我们提出了 GHS-TDA。 GHS-TDA首先构建语义丰富的全局假设图来聚合、对齐和协调多个候选推理路径，从而在局部推理失败时提供替代的全局校正路径。然后，它应用基于持久同源性的拓扑数据分析来捕获稳定的多尺度结构，消除冗余和不一致，并提取更可靠的推理骨架。通过共同利用推理多样性和拓扑稳定性，GHS-TDA 实现了自适应收敛，产生高置信度和可解释的推理路径，并在多个推理基准的准确性和鲁棒性方面始终优于强大的基线。

</details>

---

## 197. Grounding LTL Tasks in Sub-Symbolic RL Environments for Zero-Shot Generalization

**中文标题**: 将 LTL 任务置于子符号 RL 环境中以实现零样本泛化

**Date**: 2026-02-10 | **arXiv**: [2602.09761v1](http://arxiv.org/abs/2602.09761v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09761v1)

<details><summary><b>Abstract</b></summary>

In this work we address the problem of training a Reinforcement Learning agent to follow multiple temporally-extended instructions expressed in Linear Temporal Logic in sub-symbolic environments. Previous multi-task work has mostly relied on knowledge of the mapping between raw observations and symbols appearing in the formulae. We drop this unrealistic assumption by jointly training a multi-task policy and a symbol grounder with the same experience. The symbol grounder is trained only from raw observations and sparse rewards via Neural Reward Machines in a semi-supervised fashion. Experiments on vision-based environments show that our method achieves performance comparable to using the true symbol grounding and significantly outperforms state-of-the-art methods for sub-symbolic environments.

</details>

<details><summary><b>中文摘要</b></summary>

在这项工作中，我们解决了训练强化学习代理以遵循子符号环境中以线性时序逻辑表示的多个时间扩展指令的问题。以前的多任务工作主要依赖于原始观察结果和公式中出现的符号之间的映射知识。我们通过联合训练多任务策略和具有相同经验的符号接地器来放弃这种不切实际的假设。符号接地器仅通过神经奖励机器以半监督的方式根据原始观察和稀疏奖励进行训练。基于视觉的环境的实验表明，我们的方法实现了与使用真实符号接地相当的性能，并且显着优于子符号环境的最先进方法。

</details>

---

## 198. ClinAlign: Scaling Healthcare Alignment from Clinician Preference

**中文标题**: ClinAlign：根据临床医生偏好调整医疗保健一致性

**Date**: 2026-02-10 | **arXiv**: [2602.09653v2](http://arxiv.org/abs/2602.09653v2) | **PDF**: [Link](http://arxiv.org/pdf/2602.09653v2)

<details><summary><b>Abstract</b></summary>

Although large language models (LLMs) demonstrate expert-level medical knowledge, aligning their open-ended outputs with fine-grained clinician preferences remains challenging. Existing methods often rely on coarse objectives or unreliable automated judges that are weakly grounded in professional guidelines. We propose a two-stage framework to address this gap. First, we introduce HealthRubrics, a dataset of 7,034 physician-verified preference examples in which clinicians refine LLM-drafted rubrics to meet rigorous medical standards. Second, we distill these rubrics into HealthPrinciples: 119 broadly reusable, clinically grounded principles organized by clinical dimensions, enabling scalable supervision beyond manual annotation. We use HealthPrinciples for (1) offline alignment by synthesizing rubrics for unlabeled queries and (2) an inference-time tool for guided self-revision. A 30B-A3B model trained with our framework achieves 33.4% on HealthBench-Hard, outperforming much larger models including Deepseek-R1 and o3, establishing a resource-efficient baseline for clinical alignment.

</details>

<details><summary><b>中文摘要</b></summary>

尽管大型语言模型（LLM）展示了专家级的医学知识，但将其开放式输出与细粒度的临床医生偏好保持一致仍然具有挑战性。现有的方法通常依赖于粗略的目标或不可靠的自动判断，这些判断缺乏专业指导。我们提出了一个两阶段框架来解决这一差距。首先，我们介绍 HealthRubrics，这是一个包含 7,034 个经医生验证的偏好示例的数据集，临床医生在其中完善了法学硕士起草的规则，以满足严格的医疗标准。其次，我们将这些准则提炼为 HealthPrinciples：119 个按临床维度组织的可广泛重复使用、基于临床的原则，从而实现超越手动注释的可扩展监督。我们使用 HealthPrinciples 来实现 (1) 通过合成未标记查询的量规进行离线对齐，以及 (2) 用于指导自我修订的推理时间工具。使用我们的框架训练的 30B-A3B 模型在 HealthBench-Hard 上达到了 33.4%，优于包括 Deepseek-R1 和 o3 在内的更大模型，为临床对齐建立了资源高效的基线。

</details>

---

## 199. Rethinking Security of Diffusion-based Generative Steganography

**中文标题**: 重新思考基于扩散的生成隐写术的安全性

**Date**: 2026-02-10 | **arXiv**: [2602.10219v1](http://arxiv.org/abs/2602.10219v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10219v1)

<details><summary><b>Abstract</b></summary>

Generative image steganography is a technique that conceals secret messages within generated images, without relying on pre-existing cover images. Recently, a number of diffusion model-based generative image steganography (DM-GIS) methods have been introduced, which effectively combat traditional steganalysis techniques. In this paper, we identify the key factors that influence DM-GIS security and revisit the security of existing methods. Specifically, we first provide an overview of the general pipelines of current DM-GIS methods, finding that the noise space of diffusion models serves as the primary embedding domain. Further, we analyze the relationship between DM-GIS security and noise distribution of diffusion models, theoretically demonstrating that any steganographic operation that disrupts the noise distribution compromise DM-GIS security. Building on this insight, we propose a Noise Space-based Diffusion Steganalyzer (NS-DSer)-a simple yet effective steganalysis framework allowing for detecting DM-GIS generated images in the diffusion model noise space. We reevaluate the security of existing DM-GIS methods using NS-DSer across increasingly challenging detection scenarios. Experimental results validate our theoretical analysis of DM-GIS security and show the effectiveness of NS-DSer across diverse detection scenarios.

</details>

<details><summary><b>中文摘要</b></summary>

生成图像隐写术是一种在生成的图像中隐藏秘密消息的技术，而不依赖于预先存在的封面图像。最近，一些基于扩散模型的生成图像隐写术（DM-GIS）方法被引入，有效对抗传统的隐写分析技术。在本文中，我们确定了影响 DM-GIS 安全性的关键因素，并重新审视了现有方法的安全性。具体来说，我们首先概述了当前 DM-GIS 方法的一般流程，发现扩散模型的噪声空间作为主要嵌入域。此外，我们分析了 DM-GIS 安全性与扩散模型噪声分布之间的关系，从理论上证明了任何破坏噪声分布的隐写操作都会损害 DM-GIS 安全性。基于这一见解，我们提出了一种基于噪声空间的扩散隐写分析器（NS-DSer）——一种简单而有效的隐写分析框架，允许在扩散模型噪声空间中检测 DM-GIS 生成的图像。我们在日益具有挑战性的检测场景中使用 NS-DSer 重新评估现有 DM-GIS 方法的安全性。实验结果验证了我们对 DM-GIS 安全性的理论分析，并显示了 NS-DSer 在不同检测场景中的有效性。

</details>

---

## 200. Solving Geodesic Equations with Composite Bernstein Polynomials for Trajectory Planning

**中文标题**: 用复合伯恩斯坦多项式求解测地线方程以进行轨迹规划

**Date**: 2026-02-10 | **arXiv**: [2602.10365v1](http://arxiv.org/abs/2602.10365v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10365v1)

<details><summary><b>Abstract</b></summary>

This work presents a trajectory planning method based on composite Bernstein polynomials for autonomous systems navigating complex environments. The method is implemented in a symbolic optimization framework that enables continuous paths and precise control over trajectory shape. Trajectories are planned over a cost surface that encodes obstacles as continuous fields rather than discrete boundaries. Regions near obstacles are assigned higher costs, naturally encouraging the trajectory to maintain a safe distance while still allowing efficient routing through constrained spaces. The use of composite Bernstein polynomials preserves continuity while enabling fine control over local curvature to satisfy geodesic constraints. The symbolic representation supports exact derivatives, improving optimization efficiency. The method applies to both two- and three-dimensional environments and is suitable for ground, aerial, underwater, and space systems. In spacecraft trajectory planning, for example, it enables the generation of continuous, dynamically feasible trajectories with high numerical efficiency, making it well suited for orbital maneuvers, rendezvous and proximity operations, cluttered gravitational environments, and planetary exploration missions with limited onboard computational resources. Demonstrations show that the approach efficiently generates smooth, collision-free paths in scenarios with multiple obstacles, maintaining clearance without extensive sampling or post-processing. The optimization incorporates three constraint types: (1) a Gaussian surface inequality enforcing minimum obstacle clearance; (2) geodesic equations guiding the path along locally efficient directions on the cost surface; and (3) boundary constraints enforcing fixed start and end conditions. The method can serve as a standalone planner or as an initializer for more complex motion planning problems.

</details>

<details><summary><b>中文摘要</b></summary>

这项工作提出了一种基于复合伯恩斯坦多项式的轨迹规划方法，用于导航复杂环境的自主系统。该方法在符号优化框架中实现，该框架能够实现连续路径和对轨迹形状的精确控制。轨迹是在成本面上规划的，该成本面将障碍物编码为连续场而不是离散边界。靠近障碍物的区域被分配更高的成本，自然会鼓励轨迹保持安全距离，同时仍然允许通过受限空间进行有效路由。复合伯恩斯坦多项式的使用保留了连续性，同时能够对局部曲率进行精细控制以满足测地线约束。符号表示支持精确导数，提高优化效率。该方法适用于二维和三维环境，适用于地面、空中、水下和空间系统。例如，在航天器轨迹规划中，它能够以高数值效率生成连续、动态可行的轨迹，使其非常适合轨道机动、交会和邻近操作、杂乱的引力环境以及机载计算资源有限的行星探索任务。演示表明，该方法在有多个障碍物的情况下有效生成平滑、无碰撞的路径，无需大量采样或后处理即可保持间隙。该优化包含三种约束类型：（1）强制执行最小障碍物间隙的高斯表面不等式； (2) 测地方程引导路径沿着成本面上的局部有效方向； (3) 强制执行固定开始和结束条件的边界约束。该方法可以用作独立的规划器或作为更复杂的运动规划问题的初始化器。

</details>

---

## 201. Adaptive Time Step Flow Matching for Autonomous Driving Motion Planning

**中文标题**: 自动驾驶运动规划的自适应时间步流匹配

**Date**: 2026-02-10 | **arXiv**: [2602.10285v1](http://arxiv.org/abs/2602.10285v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10285v1)

<details><summary><b>Abstract</b></summary>

Autonomous driving requires reasoning about interactions with surrounding traffic. A prevailing approach is large-scale imitation learning on expert driving datasets, aimed at generalizing across diverse real-world scenarios. For online trajectory generation, such methods must operate at real-time rates. Diffusion models require hundreds of denoising steps at inference, resulting in high latency. Consistency models mitigate this issue but rely on carefully tuned noise schedules to capture the multimodal action distributions common in autonomous driving. Adapting the schedule, typically requires expensive retraining. To address these limitations, we propose a framework based on conditional flow matching that jointly predicts future motions of surrounding agents and plans the ego trajectory in real time. We train a lightweight variance estimator that selects the number of inference steps online, removing the need for retraining to balance runtime and imitation learning performance. To further enhance ride quality, we introduce a trajectory post-processing step cast as a convex quadratic program, with negligible computational overhead. Trained on the Waymo Open Motion Dataset, the framework performs maneuvers such as lane changes, cruise control, and navigating unprotected left turns without requiring scenario-specific tuning. Our method maintains a 20 Hz update rate on an NVIDIA RTX 3070 GPU, making it suitable for online deployment. Compared to transformer, diffusion, and consistency model baselines, we achieve improved trajectory smoothness and better adherence to dynamic constraints. Experiment videos and code implementations can be found at https://flow-matching-self-driving.github.io/.

</details>

<details><summary><b>中文摘要</b></summary>

自动驾驶需要推理与周围交通的交互。一种流行的方法是对专家驾驶数据集进行大规模模仿学习，旨在泛化不同的现实场景。对于在线轨迹生成，此类方法必须以实时速率运行。扩散模型在推理时需要数百个去噪步骤，导致高延迟。一致性模型缓解了这个问题，但依赖于仔细调整的噪声计划来捕获自动驾驶中常见的多模式动作分布。调整时间表通常需要昂贵的再培训。为了解决这些限制，我们提出了一个基于条件流匹配的框架，该框架共同预测周围智能体的未来运动并实时规划自我轨迹。我们训练一个轻量级方差估计器，它在线选择推理步骤的数量，从而无需重新训练来平衡运行时和模仿学习性能。为了进一步提高乘坐质量，我们引入了轨迹后处理步骤，将其转换为凸二次程序，计算开销可以忽略不计。该框架在 Waymo 开放运动数据集上进行训练，可以执行变道、巡航控制和导航无保护左转等操作，无需针对特定场景进行调整。我们的方法在 NVIDIA RTX 3070 GPU 上保持 20 Hz 的更新率，使其适合在线部署。与变压器、扩散和一致性模型基线相比，我们实现了改进的轨迹平滑度和更好地遵守动态约束。实验视频和代码实现可以在 https://flow-matching-self-driven.github.io/ 找到。

</details>

---

## 202. Decoupled MPPI-Based Multi-Arm Motion Planning

**中文标题**: 基于 MPPI 的解耦多臂运动规划

**Date**: 2026-02-10 | **arXiv**: [2602.10114v1](http://arxiv.org/abs/2602.10114v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10114v1)

<details><summary><b>Abstract</b></summary>

Recent advances in sampling-based motion planning algorithms for high DOF arms leverage GPUs to provide SOTA performance. These algorithms can be used to control multiple arms jointly, but this approach scales poorly. To address this, we extend STORM, a sampling-based model-predictive-control (MPC) motion planning algorithm, to handle multiple robots in a distributed fashion. First, we modify STORM to handle dynamic obstacles. Then, we let each arm compute its own motion plan prefix, which it shares with the other arms, which treat it as a dynamic obstacle. Finally, we add a dynamic priority scheme. The new algorithm, MR-STORM, demonstrates clear empirical advantages over SOTA algorithms when operating with both static and dynamic obstacles.

</details>

<details><summary><b>中文摘要</b></summary>

高自由度臂基于采样的运动规划算法的最新进展利用 GPU 提供 SOTA 性能。这些算法可用于联合控制多个手臂，但这种方法的扩展性很差。为了解决这个问题，我们扩展了 STORM，一种基于采样的模型预测控制 (MPC) 运动规划算法，以分布式方式处理多个机器人。首先，我们修改 STORM 以处理动态障碍。然后，我们让每个手臂计算自己的运动计划前缀，并与其他手臂共享该前缀，其他手臂将其视为动态障碍物。最后，我们添加一个动态优先级方案。新算法 MR-STORM 在处理静态和动态障碍物时表现出明显优于 SOTA 算法的经验优势。

</details>

---

## 203. ST4VLA: Spatially Guided Training for Vision-Language-Action Models

**中文标题**: ST4VLA：视觉-语言-动作模型的空间引导训练

**Date**: 2026-02-10 | **arXiv**: [2602.10109v1](http://arxiv.org/abs/2602.10109v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10109v1)

<details><summary><b>Abstract</b></summary>

Large vision-language models (VLMs) excel at multimodal understanding but fall short when extended to embodied tasks, where instructions must be transformed into low-level motor actions. We introduce ST4VLA, a dual-system Vision-Language-Action framework that leverages Spatial Guided Training to align action learning with spatial priors in VLMs. ST4VLA includes two stages: (i) spatial grounding pre-training, which equips the VLM with transferable priors via scalable point, box, and trajectory prediction from both web-scale and robot-specific data, and (ii) spatially guided action post-training, which encourages the model to produce richer spatial priors to guide action generation via spatial prompting. This design preserves spatial grounding during policy learning and promotes consistent optimization across spatial and action objectives. Empirically, ST4VLA achieves substantial improvements over vanilla VLA, with performance increasing from 66.1 -> 84.6 on Google Robot and from 54.7 -> 73.2 on WidowX Robot, establishing new state-of-the-art results on SimplerEnv. It also demonstrates stronger generalization to unseen objects and paraphrased instructions, as well as robustness to long-horizon perturbations in real-world settings. These results highlight scalable spatially guided training as a promising direction for robust, generalizable robot learning. Source code, data and models are released at https://internrobotics.github.io/internvla-m1.github.io/

</details>

<details><summary><b>中文摘要</b></summary>

大型视觉语言模型（VLM）擅长多模态理解，但在扩展到具体任务时却表现不佳，在具体任务中指令必须转换为低级运动动作。我们引入了 ST4VLA，这是一种双系统视觉-语言-动作框架，它利用空间引导训练将动作学习与 VLM 中的空间先验保持一致。 ST4VLA 包括两个阶段：(i) 空间基础预训练，通过来自网络规模和机器人特定数据的可扩展点、框和轨迹预测，为 VLM 配备可转移的先验；(ii) 空间引导动作后训练，鼓励模型产生更丰富的空间先验，以通过空间提示指导动作生成。这种设计在政策学习期间保留了空间基础，并促进空间和行动目标的一致优化。根据经验，ST4VLA 比普通 VLA 取得了实质性改进，Google Robot 上的性能从 66.1 -> 84.6 增加，WidowX Robot 上的性能从 54.7 -> 73.2 增加，在 SimplerEnv 上建立了新的最先进结果。它还展示了对看不见的物体和释义指令的更强的泛化能力，以及对现实世界环境中的长视野扰动的鲁棒性。这些结果凸显了可扩展的空间引导训练是稳健、可推广的机器人学习的一个有前途的方向。源代码、数据和模型发布于 https://internrobotics.github.io/internvla-m1.github.io/

</details>

---

## 204. EgoHumanoid: Unlocking In-the-Wild Loco-Manipulation with Robot-Free Egocentric Demonstration

**中文标题**: EgoHumanoid：通过无机器人的自我中心演示解锁野外局部操作

**Date**: 2026-02-10 | **arXiv**: [2602.10106v1](http://arxiv.org/abs/2602.10106v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10106v1)

<details><summary><b>Abstract</b></summary>

Human demonstrations offer rich environmental diversity and scale naturally, making them an appealing alternative to robot teleoperation. While this paradigm has advanced robot-arm manipulation, its potential for the more challenging, data-hungry problem of humanoid loco-manipulation remains largely unexplored. We present EgoHumanoid, the first framework to co-train a vision-language-action policy using abundant egocentric human demonstrations together with a limited amount of robot data, enabling humanoids to perform loco-manipulation across diverse real-world environments. To bridge the embodiment gap between humans and robots, including discrepancies in physical morphology and viewpoint, we introduce a systematic alignment pipeline spanning from hardware design to data processing. A portable system for scalable human data collection is developed, and we establish practical collection protocols to improve transferability. At the core of our human-to-humanoid alignment pipeline lies two key components. The view alignment reduces visual domain discrepancies caused by camera height and perspective variation. The action alignment maps human motions into a unified, kinematically feasible action space for humanoid control. Extensive real-world experiments demonstrate that incorporating robot-free egocentric data significantly outperforms robot-only baselines by 51\%, particularly in unseen environments. Our analysis further reveals which behaviors transfer effectively and the potential for scaling human data.

</details>

<details><summary><b>中文摘要</b></summary>

人类演示自然地提供了丰富的环境多样性和规模，使其成为机器人远程操作的有吸引力的替代方案。虽然这种范例具有先进的机器人手臂操纵，但其解决更具挑战性、需要数据的人形机器人操纵问题的潜力在很大程度上仍未得到探索。我们提出了 EgoHumanoid，这是第一个使用丰富的以自我为中心的人类演示和有限的机器人数据来共同训练视觉-语言-动作策略的框架，使类人机器人能够在不同的现实世界环境中执行局部操作。为了弥合人类和机器人之间的体现差距，包括物理形态和观点的差异，我们引入了从硬件设计到数据处理的系统对准管道。开发了一种用于可扩展人类数据收集的便携式系统，并且我们建立了实用的收集协议以提高可转移性。我们的人与人之间的对齐流程的核心是两个关键组件。视图对齐减少了由相机高度和透视变化引起的视域差异。动作对齐将人体运动映射到一个统一的、运动学上可行的动作空间中，用于人形控制。广泛的现实世界实验表明，合并无机器人的自我中心数据显着优于仅机器人的基线 51%，特别是在看不见的环境中。我们的分析进一步揭示了哪些行为可以有效转移以及扩展人类数据的潜力。

</details>

---

## 205. DexImit: Learning Bimanual Dexterous Manipulation from Monocular Human Videos

**中文标题**: DexImit：从单眼人类视频中学习双手灵巧操作

**Date**: 2026-02-10 | **arXiv**: [2602.10105v1](http://arxiv.org/abs/2602.10105v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10105v1)

<details><summary><b>Abstract</b></summary>

Data scarcity fundamentally limits the generalization of bimanual dexterous manipulation, as real-world data collection for dexterous hands is expensive and labor-intensive. Human manipulation videos, as a direct carrier of manipulation knowledge, offer significant potential for scaling up robot learning. However, the substantial embodiment gap between human hands and robotic dexterous hands makes direct pretraining from human videos extremely challenging. To bridge this gap and unleash the potential of large-scale human manipulation video data, we propose DexImit, an automated framework that converts monocular human manipulation videos into physically plausible robot data, without any additional information. DexImit employs a four-stage generation pipeline: (1) reconstructing hand-object interactions from arbitrary viewpoints with near-metric scale; (2) performing subtask decomposition and bimanual scheduling; (3) synthesizing robot trajectories consistent with the demonstrated interactions; (4) comprehensive data augmentation for zero-shot real-world deployment. Building on these designs, DexImit can generate large-scale robot data based on human videos, either from the Internet or video generation models. DexImit is capable of handling diverse manipulation tasks, including tool use (e.g., cutting an apple), long-horizon tasks (e.g., making a beverage), and fine-grained manipulations (e.g., stacking cups).

</details>

<details><summary><b>中文摘要</b></summary>

数据稀缺从根本上限制了双手灵巧操作的普及，因为灵巧手的现实世界数据收集成本高昂且劳动密集型。人类操作视频作为操作知识的直接载体，为扩大机器人学习提供了巨大的潜力。然而，人手和机器人灵巧手之间的巨大体现差距使得从人类视频直接进行预训练极具挑战性。为了弥补这一差距并释放大规模人类操纵视频数据的潜力，我们提出了 DexImit，这是一种自动化框架，可以将单眼人类操纵视频转换为物理上合理的机器人数据，而无需任何附加信息。 DexImit 采用四阶段生成流程：（1）从任意角度以接近公制的尺度重建手部与物体的交互； (2)进行子任务分解和双手调度； (3) 合成与所演示的交互一致的机器人轨迹； (4) 全面的数据增强，用于零样本的现实世界部署。基于这些设计，DexImit 可以根据来自互联网或视频生成模型的人类视频生成大规模机器人数据。 DexImit 能够处理各种操作任务，包括工具使用（例如切苹果）、长期任务（例如制作饮料）和细粒度操作（例如堆叠杯子）。

</details>

---

## 206. Robo3R: Enhancing Robotic Manipulation with Accurate Feed-Forward 3D Reconstruction

**中文标题**: Robo3R：通过精确的前馈 3D 重建增强机器人操作

**Date**: 2026-02-10 | **arXiv**: [2602.10101v1](http://arxiv.org/abs/2602.10101v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10101v1)

<details><summary><b>Abstract</b></summary>

3D spatial perception is fundamental to generalizable robotic manipulation, yet obtaining reliable, high-quality 3D geometry remains challenging. Depth sensors suffer from noise and material sensitivity, while existing reconstruction models lack the precision and metric consistency required for physical interaction. We introduce Robo3R, a feed-forward, manipulation-ready 3D reconstruction model that predicts accurate, metric-scale scene geometry directly from RGB images and robot states in real time. Robo3R jointly infers scale-invariant local geometry and relative camera poses, which are unified into the scene representation in the canonical robot frame via a learned global similarity transformation. To meet the precision demands of manipulation, Robo3R employs a masked point head for sharp, fine-grained point clouds, and a keypoint-based Perspective-n-Point (PnP) formulation to refine camera extrinsics and global alignment. Trained on Robo3R-4M, a curated large-scale synthetic dataset with four million high-fidelity annotated frames, Robo3R consistently outperforms state-of-the-art reconstruction methods and depth sensors. Across downstream tasks including imitation learning, sim-to-real transfer, grasp synthesis, and collision-free motion planning, we observe consistent gains in performance, suggesting the promise of this alternative 3D sensing module for robotic manipulation.

</details>

<details><summary><b>中文摘要</b></summary>

3D 空间感知是通用机器人操作的基础，但获得可靠、高质量的 3D 几何形状仍然具有挑战性。深度传感器受到噪声和材料敏感性的影响，而现有的重建模型缺乏物理交互所需的精度和度量一致性。我们推出了 Robo3R，这是一种前馈、可操作的 3D 重建模型，可直接根据 RGB 图像和机器人状态实时预测准确的公制尺度场景几何形状。 Robo3R 联合推断尺度不变的局部几何形状和相对相机姿态，通过学习的全局相似性变换将其统一到规范机器人框架中的场景表示中。为了满足操纵的精度要求，Robo3R 采用蒙版点头来实现清晰、细粒度的点云，并采用基于关键点的透视 n 点 (PnP) 公式来细化相机外参和全局对齐。 Robo3R-4M 是一个精心策划的大型合成数据集，具有 400 万个高保真注释帧，经过训练后，Robo3R 的性能始终优于最先进的重建方法和深度传感器。在模仿学习、模拟到真实迁移、抓取合成和无碰撞运动规划等下游任务中，我们观察到性能的持续提升，表明这种替代 3D 传感模块在机器人操作方面的前景。

</details>

---

## 207. UniVTAC: A Unified Simulation Platform for Visuo-Tactile Manipulation Data Generation, Learning, and Benchmarking

**中文标题**: UniVTAC：用于视觉触觉操作数据生成、学习和基准测试的统一仿真平台

**Date**: 2026-02-10 | **arXiv**: [2602.10093v1](http://arxiv.org/abs/2602.10093v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10093v1)

<details><summary><b>Abstract</b></summary>

Robotic manipulation has seen rapid progress with vision-language-action (VLA) policies. However, visuo-tactile perception is critical for contact-rich manipulation, as tasks such as insertion are difficult to complete robustly using vision alone. At the same time, acquiring large-scale and reliable tactile data in the physical world remains costly and challenging, and the lack of a unified evaluation platform further limits policy learning and systematic analysis. To address these challenges, we propose UniVTAC, a simulation-based visuo-tactile data synthesis platform that supports three commonly used visuo-tactile sensors and enables scalable and controllable generation of informative contact interactions. Based on this platform, we introduce the UniVTAC Encoder, a visuo-tactile encoder trained on large-scale simulation-synthesized data with designed supervisory signals, providing tactile-centric visuo-tactile representations for downstream manipulation tasks. In addition, we present the UniVTAC Benchmark, which consists of eight representative visuo-tactile manipulation tasks for evaluating tactile-driven policies. Experimental results show that integrating the UniVTAC Encoder improves average success rates by 17.1% on the UniVTAC Benchmark, while real-world robotic experiments further demonstrate a 25% improvement in task success. Our webpage is available at https://univtac.github.io/.

</details>

<details><summary><b>中文摘要</b></summary>

通过视觉-语言-动作（VLA）政策，机器人操作取得了快速进展。然而，视觉触觉感知对于富含接触的操作至关重要，因为仅使用视觉很难稳健地完成诸如插入之类的任务。与此同时，在物理世界中获取大规模且可靠的触觉数据仍然成本高昂且具有挑战性，而且缺乏统一的评估平台进一步限制了政策学习和系统分析。为了应对这些挑战，我们提出了 UniVTAC，这是一种基于模拟的视觉触觉数据合成平台，支持三种常用的视觉触觉传感器，并能够生成可扩展且可控的信息接触交互。基于该平台，我们推出了 UniVTAC 编码器，这是一种视觉触觉编码器，使用设计的监控信号在大规模模拟合成数据上进行训练，为下游操作任务提供以触觉为中心的视觉触觉表示。此外，我们还提出了 UniVTAC 基准，它由八个代表性的视觉触觉操作任务组成，用于评估触觉驱动的策略。实验结果表明，集成 UniVTAC 编码器在 UniVTAC 基准上将平均成功率提高了 17.1%，而现实世界的机器人实验进一步证明任务成功率提高了 25%。我们的网页位于 https://univtac.github.io/。

</details>

---

## 208. RoboInter: A Holistic Intermediate Representation Suite Towards Robotic Manipulation

**中文标题**: RoboInter：面向机器人操作的整体中间表示套件

**Date**: 2026-02-10 | **arXiv**: [2602.09973v1](http://arxiv.org/abs/2602.09973v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09973v1)

<details><summary><b>Abstract</b></summary>

Advances in large vision-language models (VLMs) have stimulated growing interest in vision-language-action (VLA) systems for robot manipulation. However, existing manipulation datasets remain costly to curate, highly embodiment-specific, and insufficient in coverage and diversity, thereby hindering the generalization of VLA models. Recent approaches attempt to mitigate these limitations via a plan-then-execute paradigm, where high-level plans (e.g., subtasks, trace) are first generated and subsequently translated into low-level actions, but they critically rely on extra intermediate supervision, which is largely absent from existing datasets. To bridge this gap, we introduce the RoboInter Manipulation Suite, a unified resource including data, benchmarks, and models of intermediate representations for manipulation. It comprises RoboInter-Tool, a lightweight GUI that enables semi-automatic annotation of diverse representations, and RoboInter-Data, a large-scale dataset containing over 230k episodes across 571 diverse scenes, which provides dense per-frame annotations over more than 10 categories of intermediate representations, substantially exceeding prior work in scale and annotation quality. Building upon this foundation, RoboInter-VQA introduces 9 spatial and 20 temporal embodied VQA categories to systematically benchmark and enhance the embodied reasoning capabilities of VLMs. Meanwhile, RoboInter-VLA offers an integrated plan-then-execute framework, supporting modular and end-to-end VLA variants that bridge high-level planning with low-level execution via intermediate supervision. In total, RoboInter establishes a practical foundation for advancing robust and generalizable robotic learning via fine-grained and diverse intermediate representations.

</details>

<details><summary><b>中文摘要</b></summary>

大型视觉语言模型 (VLM) 的进步激发了人们对用于机器人操作的视觉语言动作 (VLA) 系统日益增长的兴趣。然而，现有的操作数据集的管理成本仍然很高，高度特定于实施例，并且覆盖范围和多样性不足，从而阻碍了 VLA 模型的泛化。最近的方法试图通过先计划后执行的范例来减轻这些限制，其中首先生成高级计划（例如子任务、跟踪），然后将其转换为低级操作，但它们严重依赖于额外的中间监督，而现有数据集中基本上不存在这种监督。为了弥补这一差距，我们引入了 RoboInter Manipulation Suite，这是一个统一的资源，包括数据、基准测试和操作中间表示模型。它由 RoboInter-Tool 和 RoboInter-Data 组成，RoboInter-Tool 是一个轻量级 GUI，可对不同表示进行半自动注释；RoboInter-Data 是一个大型数据集，包含 571 个不同场景的 23 万多个片段，可在 10 多个类别的中间表示上提供密集的每帧注释，在规模和注释质量方面大大超过了之前的工作。在此基础上，RoboInter-VQA 引入了 9 个空间和 20 个时间的体现 VQA 类别，以系统地基准测试和增强 VLM 的体现推理能力。同时，RoboInter-VLA 提供了一个集成的计划然后执行框架，支持模块化和端到端的 VLA 变体，通过中间监督将高层规划与低层执行联系起来。总的来说，RoboInter 为通过细粒度和多样化的中间表示推进稳健和通用的机器人学习奠定了实践基础。

</details>

---

## 209. Hydra-Nav: Object Navigation via Adaptive Dual-Process Reasoning

**中文标题**: Hydra-Nav：通过自适应双进程推理进行对象导航

**Date**: 2026-02-10 | **arXiv**: [2602.09972v1](http://arxiv.org/abs/2602.09972v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09972v1)

<details><summary><b>Abstract</b></summary>

While large vision-language models (VLMs) show promise for object goal navigation, current methods still struggle with low success rates and inefficient localization of unseen objects--failures primarily attributed to weak temporal-spatial reasoning. Meanwhile, recent attempts to inject reasoning into VLM-based agents improve success rates but incur substantial computational overhead. To address both the ineffectiveness and inefficiency of existing approaches, we introduce Hydra-Nav, a unified VLM architecture that adaptively switches between a deliberative slow system for analyzing exploration history and formulating high-level plans, and a reactive fast system for efficient execution. We train Hydra-Nav through a three-stage curriculum: (i) spatial-action alignment to strengthen trajectory planning, (ii) memory-reasoning integration to enhance temporal-spatial reasoning over long-horizon exploration, and (iii) iterative rejection fine-tuning to enable selective reasoning at critical decision points. Extensive experiments demonstrate that Hydra-Nav achieves state-of-the-art performance on the HM3D, MP3D, and OVON benchmarks, outperforming the second-best methods by 11.1%, 17.4%, and 21.2%, respectively. Furthermore, we introduce SOT (Success weighted by Operation Time), a new metric to measure search efficiency across VLMs with varying reasoning intensity. Results show that adaptive reasoning significantly enhances search efficiency over fixed-frequency baselines.

</details>

<details><summary><b>中文摘要</b></summary>

虽然大型视觉语言模型（VLM）显示出物体目标导航的希望，但当前的方法仍然面临成功率低和看不见的物体定位效率低的问题——失败主要归因于时空推理能力弱。与此同时，最近尝试将推理注入基于 VLM 的代理中，提高了成功率，但会产生大量的计算开销。为了解决现有方法的低效和低效问题，我们引入了 Hydra-Nav，这是一种统一的 VLM 架构，可以在用于分析勘探历史和制定高级计划的深思熟虑的慢系统和用于高效执行的反应快速系统之间自适应地切换。我们通过三阶段课程来训练 Hydra-Nav：（i）空间动作对齐以加强轨迹规划，（ii）记忆推理整合以增强长视野探索中的时空推理，以及（iii）迭代拒绝微调以在关键决策点实现选择性推理。大量实验表明，Hydra-Nav 在 HM3D、MP3D 和 OVON 基准测试中实现了最先进的性能，分别比第二好的方法高出 11.1%、17.4% 和 21.2%。此外，我们还引入了 SOT（按操作时间加权的成功），这是一种新指标，用于衡量具有不同推理强度的 VLM 的搜索效率。结果表明，自适应推理比固定频率基线显着提高了搜索效率。

</details>

---

## 210. TriPilot-FF: Coordinated Whole-Body Teleoperation with Force Feedback

**中文标题**: TriPilot-FF：具有力反馈的协调全身远程操作

**Date**: 2026-02-10 | **arXiv**: [2602.09888v1](http://arxiv.org/abs/2602.09888v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09888v1)

<details><summary><b>Abstract</b></summary>

Mobile manipulators broaden the operational envelope for robot manipulation. However, the whole-body teleoperation of such robots remains a problem: operators must coordinate a wheeled base and two arms while reasoning about obstacles and contact. Existing interfaces are predominantly hand-centric (e.g., VR controllers and joysticks), leaving foot-operated channels underexplored for continuous base control. We present TriPilot-FF, an open-source whole-body teleoperation system for a custom bimanual mobile manipulator that introduces a foot-operated pedal with lidar-driven pedal haptics, coupled with upper-body bimanual leader-follower teleoperation. Using only a low-cost base-mounted lidar, TriPilot-FF renders a resistive pedal cue from proximity-to-obstacle signals in the commanded direction, shaping operator commands toward collision-averse behaviour without an explicit collision-avoidance controller. The system also supports arm-side force reflection for contact awareness and provides real-time force and visual guidance of bimanual manipulability to prompt mobile base repositioning, thereby improving reach. We demonstrate the capability of TriPilot-FF to effectively ``co-pilot'' the human operator over long time-horizons and tasks requiring precise mobile base movement and coordination. Finally, we incorporate teleoperation feedback signals into an Action Chunking with Transformers (ACT) policy and demonstrate improved performance when the additional information is available. We release the pedal device design, full software stack, and conduct extensive real-world evaluations on a bimanual wheeled platform. The project page of TriPilot-FF is http://bit.ly/46H3ZJT.

</details>

<details><summary><b>中文摘要</b></summary>

移动机械手拓宽了机器人操纵的操作范围。然而，此类机器人的全身远程操作仍然是一个问题：操作员必须协调轮式底座和两个手臂，同时推理障碍物和接触。现有的界面主要以手动为中心（例如 VR 控制器和操纵杆），而对于连续基础控制而言，脚踏操作通道尚未得到充分探索。我们推出了 TriPilot-FF，这是一种用于定制双手移动机械手的开源全身远程操作系统，该系统引入了带有激光雷达驱动踏板触觉的脚踏踏板，并结合了上身双手领导者-跟随者远程操作。 TriPilot-FF 仅使用低成本底座安装的激光雷达，根据指令方向上接近障碍物的信号呈现电阻踏板提示，从而在没有明确的防撞控制器的情况下将操作员命令塑造为防碰撞行为。该系统还支持手臂侧力反射以实现接触感知，并提供双手可操作性的实时力和视觉引导，以提示移动底座重新定位，从而提高覆盖范围。我们展示了 TriPilot-FF 能够在长时间范围内和需要精确的移动基地移动和协调的任务中有效地“副驾驶”人类操作员。最后，我们将远程操作反馈信号合并到 Transformers 的 Action Chunking (ACT) 策略中，并在附加信息可用时展示了改进的性能。我们发布了踏板设备设计、完整的软件堆栈，并在双手轮式平台上进行了广泛的实际评估。 TriPilot-FF的项目页面为http://bit.ly/46H3ZJT。

</details>

---

## 211. BagelVLA: Enhancing Long-Horizon Manipulation via Interleaved Vision-Language-Action Generation

**中文标题**: BagelVLA：通过交错的视觉-语言-动作生成增强长视野操作

**Date**: 2026-02-10 | **arXiv**: [2602.09849v2](http://arxiv.org/abs/2602.09849v2) | **PDF**: [Link](http://arxiv.org/pdf/2602.09849v2)

<details><summary><b>Abstract</b></summary>

Equipping embodied agents with the ability to reason about tasks, foresee physical outcomes, and generate precise actions is essential for general-purpose manipulation. While recent Vision-Language-Action (VLA) models have leveraged pre-trained foundation models, they typically focus on either linguistic planning or visual forecasting in isolation. These methods rarely integrate both capabilities simultaneously to guide action generation, leading to suboptimal performance in complex, long-horizon manipulation tasks. To bridge this gap, we propose BagelVLA, a unified model that integrates linguistic planning, visual forecasting, and action generation within a single framework. Initialized from a pretrained unified understanding and generative model, BagelVLA is trained to interleave textual reasoning and visual prediction directly into the action execution loop. To efficiently couple these modalities, we introduce Residual Flow Guidance (RFG), which initializes from current observation and leverages single-step denoising to extract predictive visual features, guiding action generation with minimal latency. Extensive experiments demonstrate that BagelVLA outperforms existing baselines by a significant margin on multiple simulated and real-world benchmarks, particularly in tasks requiring multi-stage reasoning.

</details>

<details><summary><b>中文摘要</b></summary>

为实体智能体配备推理任务、预见物理结果和生成精确动作的能力对于通用操纵至关重要。虽然最近的视觉-语言-动作（VLA）模型利用了预先训练的基础模型，但它们通常单独关注语言规划或视觉预测。这些方法很少同时集成这两种功能来指导动作生成，从而导致在复杂的长视野操作任务中表现不佳。为了弥补这一差距，我们提出了 BagelVLA，这是一种将语言规划、视觉预测和动作生成集成在单一框架内的统一模型。 BagelVLA 从预训练的统一理解和生成模型初始化，经过训练可将文本推理和视觉预测直接插入到动作执行循环中。为了有效地耦合这些模式，我们引入了残差流引导（RFG），它从当前观察中初始化，并利用单步去噪来提取预测视觉特征，以最小的延迟指导动作生成。大量实验表明，BagelVLA 在多个模拟和现实世界基准上明显优于现有基准，特别是在需要多阶段推理的任务中。

</details>

---

## 212. Diverse Skill Discovery for Quadruped Robots via Unsupervised Learning

**中文标题**: 通过无监督学习发现四足机器人的多样化技能

**Date**: 2026-02-10 | **arXiv**: [2602.09767v1](http://arxiv.org/abs/2602.09767v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09767v1)

<details><summary><b>Abstract</b></summary>

Reinforcement learning necessitates meticulous reward shaping by specialists to elicit target behaviors, while imitation learning relies on costly task-specific data. In contrast, unsupervised skill discovery can potentially reduce these burdens by learning a diverse repertoire of useful skills driven by intrinsic motivation. However, existing methods exhibit two key limitations: they typically rely on a single policy to master a versatile repertoire of behaviors without modeling the shared structure or distinctions among them, which results in low learning efficiency; moreover, they are susceptible to reward hacking, where the reward signal increases and converges rapidly while the learned skills display insufficient actual diversity. In this work, we introduce an Orthogonal Mixture-of-Experts (OMoE) architecture that prevents diverse behaviors from collapsing into overlapping representations, enabling a single policy to master a wide spectrum of locomotion skills. In addition, we design a multi-discriminator framework in which different discriminators operate on distinct observation spaces, effectively mitigating reward hacking. We evaluated our method on the 12-DOF Unitree A1 quadruped robot, demonstrating a diverse set of locomotion skills. Our experiments demonstrate that the proposed framework boosts training efficiency and yields an 18.3\% expansion in state-space coverage compared to the baseline.

</details>

<details><summary><b>中文摘要</b></summary>

强化学习需要专家精心设计奖励来引发目标行为，而模仿学习则依赖于昂贵的特定任务数据。相比之下，无监督的技能发现可以通过学习由内在动机驱动的各种有用技能来潜在地减轻这些负担。然而，现有方法存在两个关键局限性：它们通常依赖于单一策略来掌握多种行为，而不对它们之间的共享结构或区别进行建模，这导致学习效率低下；此外，它们很容易受到奖励黑客攻击，即奖励信号迅速增加和收敛，而所学技能的实际多样性却不足。在这项工作中，我们引入了一种正交专家混合（OMoE）架构，该架构可以防止不同的行为陷入重叠的表示，从而使单个策略能够掌握广泛的运动技能。此外，我们设计了一个多鉴别器框架，其中不同的鉴别器在不同的观察空间上运行，有效地减轻了奖励黑客行为。我们在 12 自由度 Unitree A1 四足机器人上评估了我们的方法，展示了多种运动技能。我们的实验表明，所提出的框架提高了训练效率，并且与基线相比，状态空间覆盖范围扩大了 18.3%。

</details>

---

## 213. NavDreamer: Video Models as Zero-Shot 3D Navigators

**中文标题**: NavDreamer：作为零镜头 3D 导航器的视频模型

**Date**: 2026-02-10 | **arXiv**: [2602.09765v1](http://arxiv.org/abs/2602.09765v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09765v1)

<details><summary><b>Abstract</b></summary>

Previous Vision-Language-Action models face critical limitations in navigation: scarce, diverse data from labor-intensive collection and static representations that fail to capture temporal dynamics and physical laws. We propose NavDreamer, a video-based framework for 3D navigation that leverages generative video models as a universal interface between language instructions and navigation trajectories. Our main hypothesis is that video's ability to encode spatiotemporal information and physical dynamics, combined with internet-scale availability, enables strong zero-shot generalization in navigation. To mitigate the stochasticity of generative predictions, we introduce a sampling-based optimization method that utilizes a VLM for trajectory scoring and selection. An inverse dynamics model is employed to decode executable waypoints from generated video plans for navigation. To systematically evaluate this paradigm in several video model backbones, we introduce a comprehensive benchmark covering object navigation, precise navigation, spatial grounding, language control, and scene reasoning. Extensive experiments demonstrate robust generalization across novel objects and unseen environments, with ablation studies revealing that navigation's high-level decision-making nature makes it particularly suited for video-based planning.

</details>

<details><summary><b>中文摘要</b></summary>

以前的视觉-语言-动作模型在导航方面面临着严重的局限性：来自劳动密集型收集的稀缺且多样化的数据以及无法捕捉时间动态和物理定律的静态表示。我们提出了 NavDreamer，一种基于视频的 3D 导航框架，利用生成视频模型作为语言指令和导航轨迹之间的通用接口。我们的主要假设是，视频编码时空信息和物理动力学的能力，与互联网规模的可用性相结合，可以在导航中实现强大的零样本泛化。为了减轻生成预测的随机性，我们引入了一种基于采样的优化方法，该方法利用 VLM 进行轨迹评分和选择。采用逆动态模型从生成的导航视频计划中解码可执行航路点。为了系统地评估几个视频模型主干中的这种范式，我们引入了一个涵盖对象导航、精确导航、空间基础、语言控制和场景推理的综合基准。大量的实验证明了对新物体和看不见的环境的强大泛化能力，消融研究表明导航的高级决策性质使其特别适合基于视频的规划。

</details>

---

## 214. Rethinking Visual-Language-Action Model Scaling: Alignment, Mixture, and Regularization

**中文标题**: 重新思考视觉语言动作模型缩放：对齐、混合和正则化

**Date**: 2026-02-10 | **arXiv**: [2602.09722v1](http://arxiv.org/abs/2602.09722v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09722v1)

<details><summary><b>Abstract</b></summary>

While Vision-Language-Action (VLA) models show strong promise for generalist robot control, it remains unclear whether -- and under what conditions -- the standard "scale data" recipe translates to robotics, where training data is inherently heterogeneous across embodiments, sensors, and action spaces. We present a systematic, controlled study of VLA scaling that revisits core training choices for pretraining across diverse robots. Using a representative VLA framework that combines a vision-language backbone with flow-matching, we ablate key design decisions under matched conditions and evaluate in extensive simulation and real-robot experiments. To improve the reliability of real-world results, we introduce a Grouped Blind Ensemble protocol that blinds operators to model identity and separates policy execution from outcome judgment, reducing experimenter bias. Our analysis targets three dimensions of VLA scaling. (1) Physical alignment: we show that a unified end-effector (EEF)-relative action representation is critical for robust cross-embodiment transfer. (2) Embodiment mixture: we find that naively pooling heterogeneous robot datasets often induces negative transfer rather than gains, underscoring the fragility of indiscriminate data scaling. (3) Training regularization: we observe that intuitive strategies, such as sensory dropout and multi-stage fine-tuning, do not consistently improve performance at scale. Together, this study challenge some common assumptions about embodied scaling and provide practical guidance for training large-scale VLA policies from diverse robotic data. Project website: https://research.beingbeyond.com/rethink_vla

</details>

<details><summary><b>中文摘要</b></summary>

虽然视觉-语言-动作（VLA）模型在通用机器人控制方面显示出强大的前景，但仍不清楚标准的“规模数据”配方是否以及在什么条件下可以转化为机器人技术，其中训练数据在实施例、传感器和动作空间之间本质上是异构的。我们提出了一项关于 VLA 缩放的系统性、受控研究，重新审视了不同机器人预训练的核心训练选择。使用将视觉语言主干与流程匹配相结合的代表性 VLA 框架，我们在匹配条件下消除了关键设计决策，并在广泛的模拟和真实机器人实验中进行评估。为了提高现实世界结果的可靠性，我们引入了分组盲集成协议，该协议使操作员无法对身份进行建模，并将策略执行与结果判断分开，从而减少实验者的偏见。我们的分析针对 VLA 缩放的三个维度。 （1）物理对齐：我们表明，统一的末端执行器（EEF）相关动作表示对于稳健的跨实体迁移至关重要。 (2) 实施例混合：我们发现，天真地汇集异构机器人数据集通常会引起负迁移而不是增益，这凸显了不加区别的数据扩展的脆弱性。 (3) 训练正则化：我们观察到直觉策略，例如感觉丢弃和多阶段微调，并不能持续大规模地提高性能。总之，这项研究挑战了有关体现扩展的一些常见假设，并为从不同的机器人数据中训练大规模 VLA 策略提供了实用指导。项目网站：https://research.beingbeyond.com/rethink_vla

</details>

---

## 215. Fast Motion Planning for Non-Holonomic Mobile Robots via a Rectangular Corridor Representation of Structured Environments

**中文标题**: 通过结构化环境的矩形走廊表示的非完整移动机器人的快速运动规划

**Date**: 2026-02-10 | **arXiv**: [2602.09714v1](http://arxiv.org/abs/2602.09714v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09714v1)

<details><summary><b>Abstract</b></summary>

We present a complete framework for fast motion planning of non-holonomic autonomous mobile robots in highly complex but structured environments. Conventional grid-based planners struggle with scalability, while many kinematically-feasible planners impose a significant computational burden due to their search space complexity. To overcome these limitations, our approach introduces a deterministic free-space decomposition that creates a compact graph of overlapping rectangular corridors. This method enables a significant reduction in the search space, without sacrificing path resolution. The framework then performs online motion planning by finding a sequence of rectangles and generating a near-time-optimal, kinematically-feasible trajectory using an analytical planner. The result is a highly efficient solution for large-scale navigation. We validate our framework through extensive simulations and on a physical robot. The implementation is publicly available as open-source software.

</details>

<details><summary><b>中文摘要</b></summary>

我们提出了一个完整的框架，用于在高度复杂但结构化的环境中非完整自主移动机器人的快速运动规划。传统的基于网格的规划器在可扩展性方面遇到了困难，而许多运动学上可行的规划器由于其搜索空间的复杂性而带来了巨大的计算负担。为了克服这些限制，我们的方法引入了确定性自由空间分解，创建了重叠矩形走廊的紧凑图。该方法可以显着减少搜索空间，而不牺牲路径分辨率。然后，该框架通过查找一系列矩形并使用分析规划器生成近乎时间最优的、运动学上可行的轨迹来执行在线运动规划。其结果是大规模导航的高效解决方案。我们通过广泛的模拟和在物理机器人上验证我们的框架。该实现作为开源软件公开可用。

</details>

---

## 216. RANT: Ant-Inspired Multi-Robot Rainforest Exploration Using Particle Filter Localisation and Virtual Pheromone Coordination

**中文标题**: RANT：使用粒子过滤器定位和虚拟信息素协调的受蚂蚁启发的多机器人雨林探索

**Date**: 2026-02-10 | **arXiv**: [2602.09661v1](http://arxiv.org/abs/2602.09661v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09661v1)

<details><summary><b>Abstract</b></summary>

This paper presents RANT, an ant-inspired multi-robot exploration framework for noisy, uncertain environments. A team of differential-drive robots navigates a 10 x 10 m terrain, collects noisy probe measurements of a hidden richness field, and builds local probabilistic maps while the supervisor maintains a global evaluation. RANT combines particle-filter localisation, a behaviour-based controller with gradient-driven hotspot exploitation, and a lightweight no-revisit coordination mechanism based on virtual pheromone blocking. We experimentally analyse how team size, localisation fidelity, and coordination influence coverage, hotspot recall, and redundancy. Results show that particle filtering is essential for reliable hotspot engagement, coordination substantially reduces overlap, and increasing team size improves coverage but yields diminishing returns due to interference.

</details>

<details><summary><b>中文摘要</b></summary>

本文提出了 RANT，一种受蚂蚁启发的多机器人探索框架，适用于嘈杂、不确定的环境。一组差动驱动机器人在 10 x 10 m 的地形中导航，收集隐藏丰富度场的噪声探针测量值，并构建局部概率图，同时监督员维护全局评估。 RANT 结合了粒子过滤器定位、基于行为的控制器和梯度驱动的热点开发，以及基于虚拟信息素阻塞的轻量级免重访协调机制。我们通过实验分析团队规模、本地化保真度和协调如何影响覆盖范围、热点召回和冗余。结果表明，粒子过滤对于可靠的热点参与至关重要，协调可显着减少重叠，增加团队规模可提高覆盖范围，但会因干扰而产生收益递减。

</details>

---

## 217. AutoFly: Vision-Language-Action Model for UAV Autonomous Navigation in the Wild

**中文标题**: AutoFly：无人机野外自主导航的视觉-语言-动作模型

**Date**: 2026-02-10 | **arXiv**: [2602.09657v1](http://arxiv.org/abs/2602.09657v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09657v1)

<details><summary><b>Abstract</b></summary>

Vision-language navigation (VLN) requires intelligent agents to navigate environments by interpreting linguistic instructions alongside visual observations, serving as a cornerstone task in Embodied AI. Current VLN research for unmanned aerial vehicles (UAVs) relies on detailed, pre-specified instructions to guide the UAV along predetermined routes. However, real-world outdoor exploration typically occurs in unknown environments where detailed navigation instructions are unavailable. Instead, only coarse-grained positional or directional guidance can be provided, requiring UAVs to autonomously navigate through continuous planning and obstacle avoidance. To bridge this gap, we propose AutoFly, an end-to-end Vision-Language-Action (VLA) model for autonomous UAV navigation. AutoFly incorporates a pseudo-depth encoder that derives depth-aware features from RGB inputs to enhance spatial reasoning, coupled with a progressive two-stage training strategy that effectively aligns visual, depth, and linguistic representations with action policies. Moreover, existing VLN datasets have fundamental limitations for real-world autonomous navigation, stemming from their heavy reliance on explicit instruction-following over autonomous decision-making and insufficient real-world data. To address these issues, we construct a novel autonomous navigation dataset that shifts the paradigm from instruction-following to autonomous behavior modeling through: (1) trajectory collection emphasizing continuous obstacle avoidance, autonomous planning, and recognition workflows; (2) comprehensive real-world data integration. Experimental results demonstrate that AutoFly achieves a 3.9% higher success rate compared to state-of-the-art VLA baselines, with consistent performance across simulated and real environments.

</details>

<details><summary><b>中文摘要</b></summary>

视觉语言导航（VLN）需要智能代理通过解释语言指令和视觉观察来导航环境，这是嵌入式人工智能的基石任务。目前针对无人机 (UAV) 的 VLN 研究依赖于详细的、预先指定的指令来引导无人机沿预定路线行驶。然而，现实世界的户外探索通常发生在无法获得详细导航说明的未知环境中。相反，只能提供粗粒度的位置或方向引导，要求无人机通过连续规划和避障来自主导航。为了弥补这一差距，我们提出了 AutoFly，一种用于自主无人机导航的端到端视觉-语言-动作（VLA）模型。 AutoFly 采用了伪深度编码器，可从 RGB 输入中派生深度感知特征以增强空间推理，再加上渐进式两阶段训练策略，可有效地将视觉、深度和语言表示与动作策略保持一致。此外，现有的 VLN 数据集对于现实世界的自主导航存在根本性的限制，因为它们严重依赖于自主决策的明确指令跟踪以及现实世界数据的不足。为了解决这些问题，我们构建了一个新颖的自主导航数据集，通过以下方式将范式从遵循指令转变为自主行为建模：（1）轨迹收集，强调连续避障、自主规划和识别工作流程； (2)全面的现实世界数据集成。实验结果表明，与最先进的 VLA 基线相比，AutoFly 的成功率提高了 3.9%，并且在模拟和真实环境中具有一致的性能。

</details>

---

## 218. TeleGate: Whole-Body Humanoid Teleoperation via Gated Expert Selection with Motion Prior

**中文标题**: TeleGate：通过门控专家选择和运动先验进行全身人形远程操作

**Date**: 2026-02-10 | **arXiv**: [2602.09628v1](http://arxiv.org/abs/2602.09628v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09628v1)

<details><summary><b>Abstract</b></summary>

Real-time whole-body teleoperation is a critical method for humanoid robots to perform complex tasks in unstructured environments. However, developing a unified controller that robustly supports diverse human motions remains a significant challenge. Existing methods typically distill multiple expert policies into a single general policy, which often inevitably leads to performance degradation, particularly on highly dynamic motions. This paper presents TeleGate, a unified whole-body teleoperation framework for humanoid robots that achieves high-precision tracking across various motions while avoiding the performance loss inherent in knowledge distillation. Our key idea is to preserve the full capability of domain-specific expert policies by training a lightweight gating network, which dynamically activates experts in real-time based on proprioceptive states and reference trajectories. Furthermore, to compensate for the absence of future reference trajectories in real-time teleoperation, we introduce a VAE-based motion prior module that extracts implicit future motion intent from historical observations, enabling anticipatory control for motions requiring prediction such as jumping and standing up. We conducted empirical evaluations in simulation and also deployed our technique on the Unitree G1 humanoid robot. Using only 2.5 hours of motion capture data for training, our TeleGate achieves high-precision real-time teleoperation across diverse dynamic motions (e.g., running, fall recovery, and jumping), significantly outperforming the baseline methods in both tracking accuracy and success rate.

</details>

<details><summary><b>中文摘要</b></summary>

实时全身远程操作是仿人机器人在非结构化环境中执行复杂任务的关键方法。然而，开发一个能够强有力地支持不同人体运动的统一控制器仍然是一个重大挑战。现有方法通常将多个专家策略提炼为单个通用策略，这通常不可避免地导致性能下降，特别是在高度动态的运动中。本文提出了 TeleGate，这是一种用于人形机器人的统一全身远程操作框架，可实现各种运动的高精度跟踪，同时避免知识蒸馏中固有的性能损失。我们的关键思想是通过训练轻量级门控网络来保留特定领域专家策略的全部功能，该网络根据本体感受状态和参考轨迹实时动态激活专家。此外，为了弥补实时遥操作中未来参考轨迹的缺失，我们引入了基于 VAE 的运动先验模块，该模块从历史观察中提取隐式的未来运动意图，从而能够对需要预测的运动（例如跳跃和站立）进行预期控制。我们在模拟中进行了实证评估，并将我们的技术部署在 Unitree G1 人形机器人上。我们的 TeleGate 仅使用 2.5 小时的动作捕捉数据进行训练，就实现了各种动态动作（例如跑步、跌倒恢复和跳跃）的高精度实时遥操作，在跟踪精度和成功率方面均显着优于基线方法。

</details>

---

## 219. Preference Aligned Visuomotor Diffusion Policies for Deformable Object Manipulation

**中文标题**: 用于可变形物体操纵的偏好对齐视觉运动扩散策略

**Date**: 2026-02-10 | **arXiv**: [2602.09583v1](http://arxiv.org/abs/2602.09583v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09583v1)

<details><summary><b>Abstract</b></summary>

Humans naturally develop preferences for how manipulation tasks should be performed, which are often subtle, personal, and difficult to articulate. Although it is important for robots to account for these preferences to increase personalization and user satisfaction, they remain largely underexplored in robotic manipulation, particularly in the context of deformable objects like garments and fabrics. In this work, we study how to adapt pretrained visuomotor diffusion policies to reflect preferred behaviors using limited demonstrations. We introduce RKO, a novel preference-alignment method that combines the benefits of two recent frameworks: RPO and KTO. We evaluate RKO against common preference learning frameworks, including these two, as well as a baseline vanilla diffusion policy, on real-world cloth-folding tasks spanning multiple garments and preference settings. We show that preference-aligned policies (particularly RKO) achieve superior performance and sample efficiency compared to standard diffusion policy fine-tuning. These results highlight the importance and feasibility of structured preference learning for scaling personalized robot behavior in complex deformable object manipulation tasks.

</details>

<details><summary><b>中文摘要</b></summary>

人类自然会对如何执行操作任务产生偏好，这些偏好通常是微妙的、个人的且难以清晰表达。尽管对于机器人来说，考虑这些偏好对于提高个性化和用户满意度非常重要，但它们在机器人操作方面仍然很大程度上未被充分探索，特别是在服装和织物等可变形物体的背景下。在这项工作中，我们研究如何使用有限的演示来调整预训练的视觉运动扩散策略以反映偏好的行为。我们介绍 RKO，这是一种新颖的偏好调整方法，它结合了两个最新框架的优点：RPO 和 KTO。我们根据常见的偏好学习框架（包括这两个框架）以及基线香草扩散策略，针对跨越多种服装和偏好设置的现实世界布料折叠任务来评估 RKO。我们表明，与标准扩散策略微调相比，偏好一致策略（特别是 RKO）实现了卓越的性能和样本效率。这些结果凸显了结构化偏好学习对于在复杂的可变形物体操纵任务中扩展个性化机器人行为的重要性和可行性。

</details>

---

## 220. Optimal Control of Microswimmers for Trajectory Tracking Using Bayesian Optimization

**中文标题**: 使用贝叶斯优化对微型游泳器进行轨迹跟踪优化控制

**Date**: 2026-02-10 | **arXiv**: [2602.09563v1](http://arxiv.org/abs/2602.09563v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09563v1)

<details><summary><b>Abstract</b></summary>

Trajectory tracking for microswimmers remains a key challenge in microrobotics, where low-Reynolds-number dynamics make control design particularly complex. In this work, we formulate the trajectory tracking problem as an optimal control problem and solve it using a combination of B-spline parametrization with Bayesian optimization, allowing the treatment of high computational costs without requiring complex gradient computations. Applied to a flagellated magnetic swimmer, the proposed method reproduces a variety of target trajectories, including biologically inspired paths observed in experimental studies. We further evaluate the approach on a three-sphere swimmer model, demonstrating that it can adapt to and partially compensate for wall-induced hydrodynamic effects. The proposed optimization strategy can be applied consistently across models of different fidelity, from low-dimensional ODE-based models to high-fidelity PDE-based simulations, showing its robustness and generality. These results highlight the potential of Bayesian optimization as a versatile tool for optimal control strategies in microscale locomotion under complex fluid-structure interactions.

</details>

<details><summary><b>中文摘要</b></summary>

微型游泳者的轨迹跟踪仍然是微型机器人领域的一个关键挑战，其中低雷诺数动力学使得控制设计特别复杂。在这项工作中，我们将轨迹跟踪问题表述为最优控制问题，并使用 B 样条参数化与贝叶斯优化相结合来解决它，从而无需复杂的梯度计算即可处理高计算成​​本。应用于有鞭毛的磁性游泳者时，所提出的方法再现了各种目标轨迹，包括在实验研究中观察到的受生物学启发的路径。我们进一步在三球游泳者模型上评估该方法，证明它可以适应并部分补偿壁引起的水动力效应。所提出的优化策略可以一致地应用于不同保真度的模型，从基于低维 ODE 的模型到基于 PDE 的高保真模拟，显示出其鲁棒性和通用性。这些结果凸显了贝叶斯优化作为复杂流固相互作用下微尺度运动最优控制策略的多功能工具的潜力。

</details>

---

## 221. Sci-VLA: Agentic VLA Inference Plugin for Long-Horizon Tasks in Scientific Experiments

**中文标题**: Sci-VLA：用于科学实验中长期任务的代理 VLA 推理插件

**Date**: 2026-02-10 | **arXiv**: [2602.09430v1](http://arxiv.org/abs/2602.09430v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09430v1)

<details><summary><b>Abstract</b></summary>

Robotic laboratories play a critical role in autonomous scientific discovery by enabling scalable, continuous experimental execution. Recent vision-language-action (VLA) models offer a promising foundation for robotic laboratories. However, scientific experiments typically involve long-horizon tasks composed of multiple atomic tasks, posing a fundamental challenge to existing VLA models. While VLA models fine-tuned for scientific tasks can reliably execute atomic experimental actions seen during training, they often fail to perform composite tasks formed by reordering and composing these known atomic actions. This limitation arises from a distributional mismatch between training-time atomic tasks and inference-time composite tasks, which prevents VLA models from executing necessary transitional operations between atomic tasks. To address this challenge, we propose an Agentic VLA Inference Plugin for Long-Horizon Tasks in Scientific Experiments. It introduces an LLM-based agentic inference mechanism that intervenes when executing sequential manipulation tasks. By performing explicit transition inference and generating transitional robotic action code, the proposed plugin guides VLA models through missing transitional steps, enabling reliable execution of composite scientific workflows without any additional training. This inference-only intervention makes our method computationally efficient, data-efficient, and well-suited for open-ended and long-horizon robotic laboratory tasks. We build 3D assets of scientific instruments and common scientific operating scenes within an existing simulation environment. In these scenes, we have verified that our method increases the average success rate per atomic task by 42\% during inference. Furthermore, we show that our method can be easily transferred from the simulation to real scientific laboratories.

</details>

<details><summary><b>中文摘要</b></summary>

机器人实验室通过实现可扩展、连续的实验执行，在自主科学发现中发挥着关键作用。最近的视觉-语言-动作（VLA）模型为机器人实验室提供了有前途的基础。然而，科学实验通常涉及由多个原子任务组成的长视野任务，这对现有的VLA模型提出了根本性的挑战。虽然针对科学任务进行微调的 VLA 模型可以可靠地执行训练期间看到的原子实验动作，但它们通常无法执行通过重新排序和组合这些已知原子动作而形成的复合任务。此限制是由于训练时原子任务和推理时复合任务之间的分布不匹配而引起的，这会阻止 VLA 模型在原子任务之间执行必要的转换操作。为了应对这一挑战，我们提出了一个用于科学实验中长期任务的 Agentic VLA 推理插件。它引入了一种基于 LLM 的代理推理机制，可以在执行顺序操作任务时进行干预。通过执行显式转换推理并生成转换机器人动作代码，所提出的插件可引导 VLA 模型完成缺失的转换步骤，从而无需任何额外训练即可可靠地执行复合科学工作流程。这种仅推理的干预使我们的方法计算效率高、数据效率高，并且非常适合开放式和长视野的机器人实验室任务。我们在现有的模拟环境中构建科学仪器的 3D 资产和常见的科学操作场景。在这些场景中，我们已经验证我们的方法在推理过程中将每个原子任务的平均成功率提高了 42%。此外，我们表明我们的方法可以轻松地从模拟转移到真实的科学实验室。

</details>

---

## 222. Finite-time Stable Pose Estimation on TSE(3) using Point Cloud and Velocity Sensors

**中文标题**: 使用点云和速度传感器对 TSE(3) 进行有限时间稳定姿态估计

**Date**: 2026-02-10 | **arXiv**: [2602.09414v1](http://arxiv.org/abs/2602.09414v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09414v1)

<details><summary><b>Abstract</b></summary>

This work presents a finite-time stable pose estimator (FTS-PE) for rigid bodies undergoing rotational and translational motion in three dimensions, using measurements from onboard sensors that provide position vectors to inertially-fixed points and body velocities. The FTS-PE is a full-state observer for the pose (position and orientation) and velocities and is obtained through a Lyapunov analysis that shows its stability in finite time and its robustness to bounded measurement noise. Further, this observer is designed directly on the state space, the tangent bundle of the Lie group of rigid body motions, SE(3), without using local coordinates or (dual) quaternion representations. Therefore, it can estimate arbitrary rigid body motions without encountering singularities or the unwinding phenomenon and be readily applied to autonomous vehicles. A version of this observer that does not need translational velocity measurements and uses only point clouds and angular velocity measurements from rate gyros, is also obtained. It is discretized using the framework of geometric mechanics for numerical and experimental implementations. The numerical simulations compare the FTS-PE with a dual-quaternion extended Kalman filter and our previously developed variational pose estimator (VPE). The experimental results are obtained using point cloud images and rate gyro measurements obtained from a Zed 2i stereo depth camera sensor. These results validate the stability and robustness of the FTS-PE.

</details>

<details><summary><b>中文摘要</b></summary>

这项工作提出了一种有限时间稳定姿态估计器（FTS-PE），用于在三个维度上进行旋转和平移运动的刚体，使用板载传感器的测量值，这些传感器为惯性固定点和车身速度提供位置矢量。 FTS-PE 是位姿（位置和方向）和速度的全状态观测器，通过 Lyapunov 分析获得，显示了其在有限时间内的稳定性及其对有界测量噪声的鲁棒性。此外，该观测器直接在状态空间、刚体运动李群 SE(3) 的切丛上设计，而不使用局部坐标或（对偶）四元数表示。因此，它可以估计任意刚体运动，而不会遇到奇点或展开现象，并且很容易应用于自动驾驶车辆。还获得了该观测器的一个版本，它不需要平移速度测量，并且仅使用来自速率陀螺仪的​​点云和角速度测量。它使用几何力学框架进行离散化，以进行数值和实验实现。数值模拟将 FTS-PE 与双四元数扩展卡尔曼滤波器和我们之前开发的变分姿态估计器 (VPE) 进行了比较。实验结果是使用点云图像和从 Zed 2i 立体深度相机传感器获得的速率陀螺仪测量值获得的。这些结果验证了 FTS-PE 的稳定性和鲁棒性。

</details>

---

## 223. Phase-Aware Policy Learning for Skateboard Riding of Quadruped Robots via Feature-wise Linear Modulation

**中文标题**: 通过特征线性调制进行四足机器人滑板运动的阶段感知策略学习

**Date**: 2026-02-10 | **arXiv**: [2602.09370v1](http://arxiv.org/abs/2602.09370v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09370v1)

<details><summary><b>Abstract</b></summary>

Skateboards offer a compact and efficient means of transportation as a type of personal mobility device. However, controlling them with legged robots poses several challenges for policy learning due to perception-driven interactions and multi-modal control objectives across distinct skateboarding phases. To address these challenges, we introduce Phase-Aware Policy Learning (PAPL), a reinforcement-learning framework tailored for skateboarding with quadruped robots. PAPL leverages the cyclic nature of skateboarding by integrating phase-conditioned Feature-wise Linear Modulation layers into actor and critic networks, enabling a unified policy that captures phase-dependent behaviors while sharing robot-specific knowledge across phases. Our evaluations in simulation validate command-tracking accuracy and conduct ablation studies quantifying each component's contribution. We also compare locomotion efficiency against leg and wheel-leg baselines and show real-world transferability.

</details>

<details><summary><b>中文摘要</b></summary>

滑板作为一种个人移动设备提供了一种紧凑而高效的交通方式。然而，由于感知驱动的交互和不同滑板阶段的多模态控制目标，用腿机器人控制它们给政策学习带来了一些挑战。为了应对这些挑战，我们引入了阶段感知策略学习（PAPL），这是一种专为四足机器人滑板而设计的强化学习框架。 PAPL 通过将相位条件特征线性调制层集成到参与者和批评者网络中，利用滑板的循环性质，实现统一的策略，捕获相位相关的行为，同时跨阶段共享机器人特定的知识。我们的模拟评估验证了命令跟踪的准确性，并进行消融研究，量化每个组件的贡献。我们还将运动效率与腿和轮腿基线进行比较，并展示现实世界的可转移性。

</details>

---

## 224. CAPER: Constrained and Procedural Reasoning for Robotic Scientific Experiments

**中文标题**: CAPER：机器人科学实验的约束和程序推理

**Date**: 2026-02-10 | **arXiv**: [2602.09367v1](http://arxiv.org/abs/2602.09367v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09367v1)

<details><summary><b>Abstract</b></summary>

Robotic assistance in scientific laboratories requires procedurally correct long-horizon manipulation, reliable execution under limited supervision, and robustness in low-demonstration regimes. Such conditions greatly challenge end-to-end vision-language-action (VLA) models, whose assumptions of recoverable errors and data-driven policy learning often break down in protocol-sensitive experiments. We propose CAPER, a framework for Constrained And ProcEdural Reasoning for robotic scientific experiments, which explicitly restricts where learning and reasoning occur in the planning and control pipeline. Rather than strengthening end-to-end policies, CAPER enforces a responsibility-separated structure: task-level reasoning generates procedurally valid action sequences under explicit constraints, mid-level multimodal grounding realizes subtasks without delegating spatial decision-making to large language models, and low-level control adapts to physical uncertainty via reinforcement learning with minimal demonstrations. By encoding procedural commitments through interpretable intermediate representations, CAPER prevents execution-time violations of experimental logic, improving controllability, robustness, and data efficiency. Experiments on a scientific workflow benchmark and a public long-horizon manipulation dataset demonstrate consistent improvements in success rate and procedural correctness, particularly in low-data and long-horizon settings.

</details>

<details><summary><b>中文摘要</b></summary>

科学实验室中的机器人协助需要程序上正确的长视野操作、有限监督下的可靠执行以及低示范制度的稳健性。这种情况极大地挑战了端到端视觉语言动作（VLA）模型，其可恢复错误和数据驱动策略学习的假设在协议敏感的实验中经常被打破。我们提出了 CAPER，一个用于机器人科学实验的约束和过程推理框架，它明确限制了学习和推理在规划和控制管道中发生的位置。 CAPER 没有加强端到端策略，而是实施了责任分离的结构：任务级推理在明确的约束下生成程序上有效的动作序列，中级多模态基础实现子任务，而不将空间决策委托给大型语言模型，低级控制通过强化学习以最少的演示来适应物理不确定性。通过可解释的中间表示对程序承诺进行编码，CAPER 可以防止执行时违反实验逻辑，从而提高可控性、鲁棒性和数据效率。对科学工作流程基准和公共长期操作数据集的实验证明了成功率和程序正确性的持续改进，特别是在低数据和长期设置中。

</details>

---

## 225. Hardware Co-Design Scaling Laws via Roofline Modelling for On-Device LLMs

**中文标题**: 通过设备上 LLM 的 Roofline 建模实现硬件协同设计扩展法则

**Date**: 2026-02-10 | **arXiv**: [2602.10377v1](http://arxiv.org/abs/2602.10377v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10377v1)

<details><summary><b>Abstract</b></summary>

Vision-Language-Action Models (VLAs) have emerged as a key paradigm of Physical AI and are increasingly deployed in autonomous vehicles, robots, and smart spaces. In these resource-constrained on-device settings, selecting an appropriate large language model (LLM) backbone is a critical challenge: models must balance accuracy with strict inference latency and hardware efficiency constraints. This makes hardware-software co-design a game-changing requirement for on-device LLM deployment, where each hardware platform demands a tailored architectural solution. We propose a hardware co-design law that jointly captures model accuracy and inference performance. Specifically, we model training loss as an explicit function of architectural hyperparameters and characterise inference latency via roofline modelling. We empirically evaluate 1,942 candidate architectures on NVIDIA Jetson Orin, training 170 selected models for 10B tokens each to fit a scaling law relating architecture to training loss. By coupling this scaling law with latency modelling, we establish a direct accuracy-latency correspondence and identify the Pareto frontier for hardware co-designed LLMs. We further formulate architecture search as a joint optimisation over precision and performance, deriving feasible design regions under industrial hardware and application budgets. Our approach reduces architecture selection from months to days. At the same latency as Qwen2.5-0.5B on the target hardware, our co-designed architecture achieves 19.42% lower perplexity on WikiText-2. To our knowledge, this is the first principled and operational framework for hardware co-design scaling laws in on-device LLM deployment. We will make the code and related checkpoints publicly available.

</details>

<details><summary><b>中文摘要</b></summary>

视觉-语言-动作模型（VLA）已成为物理人工智能的关键范例，并越来越多地部署在自动驾驶汽车、机器人和智能空间中。在这些资源受限的设备上设置中，选择合适的大型语言模型 (LLM) 主干是一项关键挑战：模型必须在准确性与严格的推理延迟和硬件效率约束之间取得平衡。这使得硬件-软件协同设计成为设备上 LLM 部署的颠覆性要求，其中每个硬件平台都需要量身定制的架构解决方案。我们提出了一种硬件协同设计法则，可以共同捕获模型准确性和推理性能。具体来说，我们将训练损失建模为架构超参数的显式函数，并通过屋顶线建模来表征推理延迟。我们在 NVIDIA Jetson Orin 上根据经验评估了 1,942 个候选架构，为每个 10B 令牌训练了 170 个选定模型，以适应将架构与训练损失相关的缩放法则。通过将这种缩放定律与延迟建模相结合，我们建立了直接的准确性-延迟对应关系，并确定了硬件联合设计的 LLM 的帕累托前沿。我们进一步将架构搜索制定为精度和性能的联合优化，在工业硬件和应用预算下得出可行的设计区域。我们的方法将架构选择从几个月缩短到几天。在目标硬件上与 Qwen2.5-0.5B 相同的延迟下，我们共同设计的架构在 WikiText-2 上实现了 19.42% 的困惑度降低。据我们所知，这是设备上 LLM 部署中硬件协同设计扩展法则的第一个原则性和可操作框架。我们将公开代码和相关检查点。

</details>

---

## 226. Simple LLM Baselines are Competitive for Model Diffing

**中文标题**: 简单的 LLM 基线对于模型比较来说具有竞争力

**Date**: 2026-02-10 | **arXiv**: [2602.10371v1](http://arxiv.org/abs/2602.10371v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10371v1)

<details><summary><b>Abstract</b></summary>

Standard LLM evaluations only test capabilities or dispositions that evaluators designed them for, missing unexpected differences such as behavioral shifts between model revisions or emergent misaligned tendencies. Model diffing addresses this limitation by automatically surfacing systematic behavioral differences. Recent approaches include LLM-based methods that generate natural language descriptions and sparse autoencoder (SAE)-based methods that identify interpretable features. However, no systematic comparison of these approaches exists nor are there established evaluation criteria. We address this gap by proposing evaluation metrics for key desiderata (generalization, interestingness, and abstraction level) and use these to compare existing methods. Our results show that an improved LLM-based baseline performs comparably to the SAE-based method while typically surfacing more abstract behavioral differences.

</details>

<details><summary><b>中文摘要</b></summary>

标准法学硕士评估仅测试评估者设计的能力或性格，忽略了意想不到的差异，例如模型修订之间的行为转变或出现的不一致倾向。模型差异通过自动呈现系统行为差异来解决此限制。最近的方法包括生成自然语言描述的基于 LLM 的方法和识别可解释特征的基于稀疏自动编码器 (SAE) 的方法。然而，这些方法不存在系统比较，也没有既定的评估标准。我们通过提出关键需求（泛化性、趣味性和抽象水平）的评估指标来解决这一差距，并使用这些指标来比较现有方法。我们的结果表明，改进的基于 LLM 的基线与基于 SAE 的方法的性能相当，同时通常会表现出更抽象的行为差异。

</details>

---

## 227. Efficient reduction of stellar contamination and noise in planetary transmission spectra using neural networks

**中文标题**: 使用神经网络有效减少行星传输光谱中的恒星污染和噪声

**Date**: 2026-02-10 | **arXiv**: [2602.10330v1](http://arxiv.org/abs/2602.10330v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10330v1)

<details><summary><b>Abstract</b></summary>

Context: JWST has enabled transmission spectroscopy at unprecedented precision, but stellar heterogeneities (spots and faculae) remain a dominant contamination source that can bias atmospheric retrievals if uncorrected. Aims: We present a fast, unsupervised methodology to reduce stellar contamination and instrument-specific noise in exoplanet transmission spectra using denoising autoencoders, improving the reliability of retrieved atmospheric parameters. Methods: We design and train denoising autoencoder architectures on large synthetic datasets of terrestrial (TRAPPIST-1e analogues) and sub-Neptune (K2-18b analogues) planets. Reconstruction quality is evaluated with the $χ^2$ statistic over a wide range of signal-to-noise ratios, and atmospheric retrieval experiments on contaminated spectra are used to compare against standard correction approaches in accuracy and computational cost. Results: The autoencoders reconstruct uncontaminated spectra while preserving key molecular features, even at low S/N. In retrieval tests, pre-processing with denoising autoencoders reduces bias in inferred abundances relative to uncorrected baselines and matches the accuracy of simultaneous stellar-contamination fitting while reducing computational time by a factor of three to six. Conclusions: Denoising autoencoders provide an efficient alternative to conventional correction strategies and are promising components of future atmospheric characterization pipelines for both rocky and gaseous exoplanets.

</details>

<details><summary><b>中文摘要</b></summary>

背景：JWST 使透射光谱达到了前所未有的精度，但恒星异质性（斑点和光斑）仍然是主要的污染源，如果不加以纠正，可能会导致大气反演出现偏差。目标：我们提出了一种快速、无监督的方法，使用去噪自动编码器来减少系外行星传输光谱中的恒星污染和仪器特定噪声，从而提高检索大气参数的可靠性。方法：我们在类地行星（TRAPPIST-1e 类似物）和亚海王星行星（K2-18b 类似物）的大型合成数据集上设计和训练去噪自动编码器架构。重建质量使用 $χ^2$ 统计量在广泛的信噪比范围内进行评估，并且使用污染光谱的大气反演实验来与标准校正方法的准确性和计算成本进行比较。结果：自动编码器重建未受污染的光谱，同时保留关键分子特征，即使在低信噪比的情况下也是如此。在检索测试中，使用去噪自动编码器进行预处理可以减少推断丰度相对于未校正基线的偏差，并与同时恒星污染拟合的准确性相匹配，同时将计算时间减少三到六倍。结论：去噪自动编码器提供了传统校正策略的有效替代方案，并且是未来岩石和气态系外行星大气特征管道的有前途的组成部分。

</details>

---

## 228. R2RAG-Flood: A reasoning-reinforced training-free retrieval augmentation generation framework for flood damage nowcasting

**中文标题**: R2RAG-Flood：用于洪灾临近预报的推理强化免训练检索增强生成框架

**Date**: 2026-02-10 | **arXiv**: [2602.10312v1](http://arxiv.org/abs/2602.10312v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10312v1)

<details><summary><b>Abstract</b></summary>

R2RAG-Flood is a reasoning-reinforced, training-free retrieval-augmented generation framework for post-storm property damage nowcasting. Building on an existing supervised tabular predictor, the framework constructs a reasoning-centric knowledge base composed of labeled tabular records, where each sample includes structured predictors, a compact natural language text-mode summary, and a model-generated reasoning trajectory. During inference, R2RAG-Flood issues context-augmented prompts that retrieve and condition on relevant reasoning trajectories from nearby geospatial neighbors and canonical class prototypes, enabling the large language model backbone to emulate and adapt prior reasoning rather than learn new task-specific parameters. Predictions follow a two-stage procedure that first determines property damage occurrence and then refines severity within a three-level Property Damage Extent categorization, with a conditional downgrade step to correct over-predicted severity. In a case study of Harris County, Texas at the 12-digit Hydrologic Unit Code scale, the supervised tabular baseline trained directly on structured predictors achieves 0.714 overall accuracy and 0.859 damage class accuracy for medium and high damage classes. Across seven large language model backbones, R2RAG-Flood attains 0.613 to 0.668 overall accuracy and 0.757 to 0.896 damage class accuracy, approaching the supervised baseline while additionally producing a structured rationale for each prediction. Using a severity-per-cost efficiency metric derived from API pricing and GPU instance costs, lightweight R2RAG-Flood variants demonstrate substantially higher efficiency than both the supervised tabular baseline and larger language models, while requiring no task-specific training or fine-tuning.

</details>

<details><summary><b>中文摘要</b></summary>

R2RAG-Flood 是一种推理强化、免训练检索增强生成框架，用于风暴后财产损失临近预报。该框架以现有的监督表格预测器为基础，构建了一个由标记表格记录组成的以推理为中心的知识库，其中每个样本都包含结构化预测器、紧凑的自然语言文本模式摘要和模型生成的推理轨迹。在推理过程中，R2RAG-Flood 发出上下文增强提示，从附近的地理空间邻居和规范类原型检索相关推理轨迹并进行条件调节，使大型语言模型骨干能够模拟和适应先前的推理，而不是学习新的特定于任务的参数。预测遵循两阶段程序，首先确定财产损失的发生情况，然后在三级财产损失范围分类中细化严重性，并通过有条件的降级步骤来纠正过高预测的严重性。在德克萨斯州哈里斯县的 12 位水文单位代码规模的案例研究中，直接在结构化预测器上训练的监督表格基线实现了 0.714 的总体准确度和 0.859 的中等和高损害类别的损害类别准确度。在七个大型语言模型主干中，R2RAG-Flood 获得了 0.613 至 0.668 的整体准确度和 0.757 至 0.896 的损害类别准确度，接近监督基线，同时还为每个预测生成了结构化的基本原理。使用从 API 定价和 GPU 实例成本得出的按成本严重性效率指标，轻量级 R2RAG-Flood 变体表现出比受监督表格基线和更大语言模型高得多的效率，同时不需要特定于任务的训练或微调。

</details>

---

## 229. Temper-Then-Tilt: Principled Unlearning for Generative Models through Tempering and Classifier Guidance

**中文标题**: Temper-Then-Tilt：通过训练和分类器指导对生成模型进行原则性的忘却

**Date**: 2026-02-10 | **arXiv**: [2602.10217v1](http://arxiv.org/abs/2602.10217v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10217v1)

<details><summary><b>Abstract</b></summary>

We study machine unlearning in large generative models by framing the task as density ratio estimation to a target distribution rather than supervised fine-tuning. While classifier guidance is a standard approach for approximating this ratio and can succeed in general, we show it can fail to faithfully unlearn with finite samples when the forget set represents a sharp, concentrated data distribution. To address this, we introduce Temper-Then-Tilt Unlearning (T3-Unlearning), which freezes the base model and applies a two-step inference procedure: (i) tempering the base distribution to flatten high-confidence spikes, and (ii) tilting the tempered distribution using a lightweight classifier trained to distinguish retain from forget samples. Our theoretical analysis provides finite-sample guarantees linking the surrogate classifier's risk to unlearning error, proving that tempering is necessary to successfully unlearn for concentrated distributions. Empirical evaluations on the TOFU benchmark show that T3-Unlearning improves forget quality and generative utility over existing baselines, while training only a fraction of the parameters with a minimal runtime.

</details>

<details><summary><b>中文摘要</b></summary>

我们通过将任务框架为目标分布的密度比估计而不是监督微调来研究大型生成模型中的机器遗忘。虽然分类器指导是近似该比率的标准方法并且通常可以成功，但我们表明，当遗忘集代表尖锐、集中的数据分布时，它可能无法忠实地忘记有限样本。为了解决这个问题，我们引入了Temper-Then-Tilt Unlearning（T3-Unlearning），它冻结基础模型并应用两步推理过程：（i）调整基础分布以压平高置信度尖峰，以及（ii）使用经过训练以区分保留样本和遗忘样本的轻量级分类器倾斜调整分布。我们的理论分析提供了有限样本保证，将代理分类器的风险与遗忘错误联系起来，证明调节对于成功遗忘集中分布是必要的。对 TOFU 基准的实证评估表明，T3-Unlearning 比现有基线提高了遗忘质量和生成效用，同时以最短的运行时间仅训练一小部分参数。

</details>

---

## 230. ELROND: Exploring and decomposing intrinsic capabilities of diffusion models

**中文标题**: ELROND：探索和分解扩散模型的内在能力

**Date**: 2026-02-10 | **arXiv**: [2602.10216v1](http://arxiv.org/abs/2602.10216v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10216v1)

<details><summary><b>Abstract</b></summary>

A single text prompt passed to a diffusion model often yields a wide range of visual outputs determined solely by stochastic process, leaving users with no direct control over which specific semantic variations appear in the image. While existing unsupervised methods attempt to analyze these variations via output features, they omit the underlying generative process. In this work, we propose a framework to disentangle these semantic directions directly within the input embedding space. To that end, we collect a set of gradients obtained by backpropagating the differences between stochastic realizations of a fixed prompt that we later decompose into meaningful steering directions with either Principal Components Analysis or Sparse Autoencoder. Our approach yields three key contributions: (1) it isolates interpretable, steerable directions for precise, fine-grained control over a single concept; (2) it effectively mitigates mode collapse in distilled models by reintroducing lost diversity; and (3) it establishes a novel estimator for concept complexity under a specific model, based on the dimensionality of the discovered subspace.

</details>

<details><summary><b>中文摘要</b></summary>

传递到扩散模型的单个文本提示通常会产生仅由随机过程决定的各种视觉输出，使用户无法直接控制图像中出现的特定语义变化。虽然现有的无监督方法试图通过输出特征来分析这些变化，但它们忽略了底层的生成过程。在这项工作中，我们提出了一个框架来直接在输入嵌入空间中解开这些语义方向。为此，我们收集了一组梯度，这些梯度是通过反向传播固定提示的随机实现之间的差异而获得的，随后我们使用主成分分析或稀疏自动编码器将其分解为有意义的转向方向。我们的方法产生了三个关键贡献：（1）它隔离了可解释、可操纵的方向，以对单个概念进行精确、细粒度的控制； （2）通过重新引入丢失的多样性，有效缓解蒸馏模型中的模式崩溃； (3)基于所发现的子空间的维数，在特定模型下建立了一种新颖的概念复杂性估计器。

</details>

---

## 231. Features as Rewards: Scalable Supervision for Open-Ended Tasks via Interpretability

**中文标题**: 作为奖励的功能：通过可解释性对开放式任务进行可扩展的监督

**Date**: 2026-02-10 | **arXiv**: [2602.10067v1](http://arxiv.org/abs/2602.10067v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10067v1)

<details><summary><b>Abstract</b></summary>

Language models trained on large-scale datasets have been shown to learn features that encode abstract concepts such as factuality or intent. Such features are traditionally used for test-time monitoring or steering. We present an alternative affordance: features as scalable supervision for open-ended tasks. We consider the case of hallucination-reduction as a desirable, yet open-ended behavior and design a reinforcement learning (RL) pipeline, titled RLFR (Reinforcement Learning from Feature Rewards), that uses features as reward functions. Grounded in a novel probing framework that identifies candidate hallucinated claims, our pipeline teaches a model to intervene and correct its completions when it is uncertain of their factuality. Furthermore, the pipeline enables scalable test-time compute, guided once more by our reward features. This end-to-end process operationalized on Gemma-3-12B-IT results in a policy that is 58% less likely to hallucinate compared to the original model, while preserving performance on standard benchmarks. Taken together, by grounding supervision in the language of features, this paper introduces a novel paradigm in the use of interpretability for learning open-ended tasks.

</details>

<details><summary><b>中文摘要</b></summary>

在大规模数据集上训练的语言模型已被证明可以学习编码抽象概念（例如事实或意图）的特征。这些功能传统上用于测试时间监控或指导。我们提出了另一种可供选择的功能：对开放式任务进行可扩展的监督。我们认为减少幻觉的情况是一种理想的、但开放式的行为，并设计了一个强化学习（RL）管道，名为 RLFR（特征奖励强化学习），它使用特征作为奖励函数。我们的流程基于一种新颖的探测框架，可以识别候选人的幻觉主张，并教导模型在不确定其真实性时进行干预和纠正其完成情况。此外，该管道还可以在我们的奖励功能的指导下实现可扩展的测试时计算。与原始模型相比，在 Gemma-3-12B-IT 上实施的这一端到端流程可降低 58% 的策略产生幻觉的可能性，同时保持标准基准的性能。总而言之，通过以特征语言为基础的监督，本文引入了一种使用可解释性学习开放式任务的新颖范式。

</details>

---

## 232. Evaluating Disentangled Representations for Controllable Music Generation

**中文标题**: 评估可控音乐生成的解缠结表示

**Date**: 2026-02-10 | **arXiv**: [2602.10058v1](http://arxiv.org/abs/2602.10058v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10058v1)

<details><summary><b>Abstract</b></summary>

Recent approaches in music generation rely on disentangled representations, often labeled as structure and timbre or local and global, to enable controllable synthesis. Yet the underlying properties of these embeddings remain underexplored. In this work, we evaluate such disentangled representations in a set of music audio models for controllable generation using a probing-based framework that goes beyond standard downstream tasks. The selected models reflect diverse unsupervised disentanglement strategies, including inductive biases, data augmentations, adversarial objectives, and staged training procedures. We further isolate specific strategies to analyze their effect. Our analysis spans four key axes: informativeness, equivariance, invariance, and disentanglement, which are assessed across datasets, tasks, and controlled transformations. Our findings reveal inconsistencies between intended and actual semantics of the embeddings, suggesting that current strategies fall short of producing truly disentangled representations, and prompting a re-examination of how controllability is approached in music generation.

</details>

<details><summary><b>中文摘要</b></summary>

最近的音乐生成方法依赖于解开的表示，通常标记为结构和音色或局部和全局，以实现可控合成。然而，这些嵌入的基本属性仍未得到充分探索。在这项工作中，我们使用超越标准下游任务的基于探测的框架来评估一组音乐音频模型中的这种解开的表示，以实现可控生成。所选模型反映了多种无监督解缠策略，包括归纳偏差、数据增强、对抗性目标和分阶段训练程序。我们进一步分离出具体策略来分析其效果。我们的分析跨越四个关键轴：信息性、等方差、不变性和解缠结，这些轴是跨数据集、任务和受控转换进行评估的。我们的研究结果揭示了嵌入的预期语义和实际语义之间的不一致，这表明当前的策略无法产生真正解开的表示，并促使人们重新审视音乐生成中如何实现可控性。

</details>

---

## 233. Answer First, Reason Later: Aligning Search Relevance via Mode-Balanced Reinforcement Learning

**中文标题**: 先回答，后推理：通过模式平衡强化学习调整搜索相关性

**Date**: 2026-02-10 | **arXiv**: [2602.10006v1](http://arxiv.org/abs/2602.10006v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10006v1)

<details><summary><b>Abstract</b></summary>

Building a search relevance model that achieves both low latency and high performance is a long-standing challenge in the search industry. To satisfy the millisecond-level response requirements of online systems while retaining the interpretable reasoning traces of Large Language Models (LLMs), we propose a novel \textbf{Answer-First, Reason Later (AFRL)} paradigm. This paradigm requires the model to output the definitive relevance score in the very first token, followed by a structured logical explanation. Inspired by the success of reasoning models, we adopt a "Supervised Fine-Tuning (SFT) + Reinforcement Learning (RL)" pipeline to achieve AFRL. However, directly applying existing RL training often leads to \textbf{mode collapse} in the search relevance task, where the model forgets complex long-tail rules in pursuit of high rewards. From an information theory perspective: RL inherently minimizes the \textbf{Reverse KL divergence}, which tends to seek probability peaks (mode-seeking) and is prone to "reward hacking." On the other hand, SFT minimizes the \textbf{Forward KL divergence}, forcing the model to cover the data distribution (mode-covering) and effectively anchoring expert rules. Based on this insight, we propose a \textbf{Mode-Balanced Optimization} strategy, incorporating an SFT auxiliary loss into Stepwise-GRPO training to balance these two properties. Furthermore, we construct an automated instruction evolution system and a multi-stage curriculum to ensure expert-level data quality. Extensive experiments demonstrate that our 32B teacher model achieves state-of-the-art performance. Moreover, the AFRL architecture enables efficient knowledge distillation, successfully transferring expert-level logic to a 0.6B model, thereby reconciling reasoning depth with deployment latency.

</details>

<details><summary><b>中文摘要</b></summary>

构建同时实现低延迟和高性能的搜索相关性模型是搜索行业长期面临的挑战。为了满足在线系统的毫秒级响应要求，同时保留大型语言模型（LLM）的可解释推理痕迹，我们提出了一种新颖的 \textbf{先回答，后推理（AFRL）}范式。这种范例要求模型在第一个标记中输出明确的相关性分数，然后是结构化的逻辑解释。受到推理模型成功的启发，我们采用“监督微调（SFT）+强化学习（RL）”流程来实现 AFRL。然而，直接应用现有的强化学习训练通常会导致搜索相关性任务中的模式崩溃，即模型为了追求高奖励而忘记复杂的长尾规则。从信息论的角度来看：RL 本质上最小化了 \textbf{Reverse KL divergence}，它倾向于寻求概率峰值（模式寻求）并且容易出现“奖励黑客”。另一方面，SFT最小化\textbf{Forward KL divergence}，迫使模型覆盖数据分布（模式覆盖）并有效锚定专家规则。基于这一见解，我们提出了一种 \textbf{模式平衡优化} 策略，将 SFT 辅助损失纳入 Stepwise-GRPO 训练中以平衡这两个属性。此外，我们构建了自动化指令进化系统和多阶段课程，以确保专家级的数据质量。大量实验表明，我们的 32B 教师模型实现了最先进的性能。此外，AFRL架构能够实现高效的知识蒸馏，成功地将专家级逻辑转移到0.6B模型，从而协调推理深度和部署延迟。

</details>

---

## 234. Rethinking Global Text Conditioning in Diffusion Transformers

**中文标题**: 重新思考扩散变压器中的全局文本调节

**Date**: 2026-02-09 | **arXiv**: [2602.09268v1](http://arxiv.org/abs/2602.09268v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09268v1)

<details><summary><b>Abstract</b></summary>

Diffusion transformers typically incorporate textual information via attention layers and a modulation mechanism using a pooled text embedding. Nevertheless, recent approaches discard modulation-based text conditioning and rely exclusively on attention. In this paper, we address whether modulation-based text conditioning is necessary and whether it can provide any performance advantage. Our analysis shows that, in its conventional usage, the pooled embedding contributes little to overall performance, suggesting that attention alone is generally sufficient for faithfully propagating prompt information. However, we reveal that the pooled embedding can provide significant gains when used from a different perspective-serving as guidance and enabling controllable shifts toward more desirable properties. This approach is training-free, simple to implement, incurs negligible runtime overhead, and can be applied to various diffusion models, bringing improvements across diverse tasks, including text-to-image/video generation and image editing.

</details>

<details><summary><b>中文摘要</b></summary>

扩散变压器通常通过注意力层和使用池文本嵌入的调制机制合并文本信息。然而，最近的方法放弃了基于调制的文本调节并完全依赖于注意力。在本文中，我们讨论基于调制的文本调节是否必要以及它是否可以提供任何性能优势。我们的分析表明，在常规用法中，池化嵌入对整体性能贡献不大，这表明仅注意通常足以忠实地传播提示信息。然而，我们发现，从不同的角度使用时，池化嵌入可以提供显着的收益——作为指导并实现向更理想的属性的可控转变。这种方法无需培训，易于实现，运行时开销可以忽略不计，并且可以应用于各种扩散模型，从而改进各种任务，包括文本到图像/视频生成和图像编辑。

</details>

---

## 235. VLM-Guided Iterative Refinement for Surgical Image Segmentation with Foundation Models

**中文标题**: VLM 引导的基于基础模型的手术图像分割迭代细化

**Date**: 2026-02-09 | **arXiv**: [2602.09252v1](http://arxiv.org/abs/2602.09252v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09252v1)

<details><summary><b>Abstract</b></summary>

Surgical image segmentation is essential for robot-assisted surgery and intraoperative guidance. However, existing methods are constrained to predefined categories, produce one-shot predictions without adaptive refinement, and lack mechanisms for clinician interaction. We propose IR-SIS, an iterative refinement system for surgical image segmentation that accepts natural language descriptions. IR-SIS leverages a fine-tuned SAM3 for initial segmentation, employs a Vision-Language Model to detect instruments and assess segmentation quality, and applies an agentic workflow that adaptively selects refinement strategies. The system supports clinician-in-the-loop interaction through natural language feedback. We also construct a multi-granularity language-annotated dataset from EndoVis2017 and EndoVis2018 benchmarks. Experiments demonstrate state-of-the-art performance on both in-domain and out-of-distribution data, with clinician interaction providing additional improvements. Our work establishes the first language-based surgical segmentation framework with adaptive self-refinement capabilities.

</details>

<details><summary><b>中文摘要</b></summary>

手术图像分割对于机器人辅助手术和术中指导至关重要。然而，现有的方法仅限于预定义的类别，产生没有自适应细化的一次性预测，并且缺乏临床医生交互的机制。我们提出了 IR-SIS，这是一种接受自然语言描述的外科图像分割迭代细化系统。 IR-SIS 利用微调的 SAM3 进行初始分割，采用视觉语言模型来检测仪器并评估分割质量，并应用自适应选择细化策略的代理工作流程。该系统通过自然语言反馈支持临床医生在循环中的交互。我们还根据 EndoVis2017 和 EndoVis2018 基准构建了多粒度语言注释数据集。实验证明了域内和分布外数据的最先进性能，临床医生的互动提供了额外的改进。我们的工作建立了第一个基于语言的具有自适应自我完善功能的手术分割框架。

</details>

---

## 236. A Systematic Review on Data-Driven Brain Deformation Modeling for Image-Guided Neurosurgery

**中文标题**: 图像引导神经外科数据驱动脑变形建模的系统综述

**Date**: 2026-02-09 | **arXiv**: [2602.10155v1](http://arxiv.org/abs/2602.10155v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10155v1)

<details><summary><b>Abstract</b></summary>

Accurate compensation of brain deformation is a critical challenge for reliable image-guided neurosurgery, as surgical manipulation and tumor resection induce tissue motion that misaligns preoperative planning images with intraoperative anatomy and longitudinal studies. In this systematic review, we synthesize recent AI-driven approaches developed between January 2020 and April 2025 for modeling and correcting brain deformation. A comprehensive literature search was conducted in PubMed, IEEE Xplore, Scopus, and Web of Science, with predefined inclusion and exclusion criteria focused on computational methods applied to brain deformation compensation for neurosurgical imaging, resulting in 41 studies meeting these criteria. We provide a unified analysis of methodological strategies, including deep learning-based image registration, direct deformation field regression, synthesis-driven multimodal alignment, resection-aware architectures addressing missing correspondences, and hybrid models that integrate biomechanical priors. We also examine dataset utilization, reported evaluation metrics, validation protocols, and how uncertainty and generalization have been assessed across studies. While AI-based deformation models demonstrate promising performance and computational efficiency, current approaches exhibit limitations in out-of-distribution robustness, standardized benchmarking, interpretability, and readiness for clinical deployment. Our review highlights these gaps and outlines opportunities for future research aimed at achieving more robust, generalizable, and clinically translatable deformation compensation solutions for neurosurgical guidance. By organizing recent advances and critically evaluating evaluation practices, this work provides a comprehensive foundation for researchers and clinicians engaged in developing and applying AI-based brain deformation methods.

</details>

<details><summary><b>中文摘要</b></summary>

大脑变形的准确补偿是可靠的图像引导神经外科手术的一个关键挑战，因为手术操作和肿瘤切除会引起组织运动，使术前计划图像与术中解剖和纵向研究不一致。在这篇系统综述中，我们综合了 2020 年 1 月至 2025 年 4 月期间开发的最新人工智能驱动方法，用于建模和纠正大脑变形。在 PubMed、IEEE Xplore、Scopus 和 Web of Science 上进行了全面的文献检索，预定义的纳入和排除标准侧重于应用于神经外科成像脑变形补偿的计算方法，结果有 41 项研究符合这些标准。我们提供方法策略的统一分析，包括基于深度学习的图像配准、直接变形场回归、合成驱动的多模态对齐、解决缺失对应关系的切除感知架构以及集成生物力学先验的混合模型。我们还检查数据集利用率、报告的评估指标、验证协议以及如何评估研究中的不确定性和概括性。虽然基于人工智能的变形模型表现出良好的性能和计算效率，但当前的方法在分布外稳健性、标准化基准测试、可解释性和临床部署准备方面表现出局限性。我们的综述强调了这些差距，并概述了未来研究的机会，旨在为神经外科指导实现更稳健、可推广和临床可转化的变形补偿解决方案。通过整理最新进展并严格评估评估实践，这项工作为从事开发和应用基于人工智能的大脑变形方法的研究人员和临床医生提供了全面的基础。

</details>

---

## 237. VLM-UQBench: A Benchmark for Modality-Specific and Cross-Modality Uncertainties in Vision Language Models

**中文标题**: VLM-UQBench：视觉语言模型中特定模态和跨模态不确定性的基准

**Date**: 2026-02-09 | **arXiv**: [2602.09214v1](http://arxiv.org/abs/2602.09214v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09214v1)

<details><summary><b>Abstract</b></summary>

Uncertainty quantification (UQ) is vital for ensuring that vision-language models (VLMs) behave safely and reliably. A central challenge is to localize uncertainty to its source, determining whether it arises from the image, the text, or misalignment between the two. We introduce VLM-UQBench, a benchmark for modality-specific and cross-modal data uncertainty in VLMs, It consists of 600 real-world samples drawn from the VizWiz dataset, curated into clean, image-, text-, and cross-modal uncertainty subsets, and a scalable perturbation pipeline with 8 visual, 5 textual, and 3 cross-modal perturbations. We further propose two simple metrics that quantify the sensitivity of UQ scores to these perturbations and their correlation with hallucinations, and use them to evaluate a range of UQ methods across four VLMs and three datasets. Empirically, we find that: (i) existing UQ methods exhibit strong modality-specific specialization and substantial dependence on the underlying VLM, (ii) modality-specific uncertainty frequently co-occurs with hallucinations while current UQ scores provide only weak and inconsistent risk signals, and (iii) although UQ methods can rival reasoning-based chain-of-thought baselines on overt, group-level ambiguity, they largely fail to detect the subtle, instance-level ambiguity introduced by our perturbation pipeline. These results highlight a significant gap between current UQ practices and the fine-grained, modality-aware uncertainty required for reliable VLM deployment.

</details>

<details><summary><b>中文摘要</b></summary>

不确定性量化 (UQ) 对于确保视觉语言模型 (VLM) 安全可靠地运行至关重要。一个核心挑战是定位不确定性的来源，确定它是由图像、文本还是两者之间的错位引起的。我们引入了 VLM-UQBench，它是 VLM 中特定模态和跨模态数据不确定性的基准，它由从 VizWiz 数据集提取的 600 个真实世界样本组成，整理为干净的图像、文本和跨模态不确定性子集，以及具有 8 个视觉扰动、5 个文本扰动和 3 个跨模态扰动的可扩展扰动管道。我们进一步提出了两个简单的指标来量化 UQ 分数对这些扰动的敏感性及其与幻觉的相关性，并使用它们来评估跨四个 VLM 和三个数据集的一系列 UQ 方法。根据经验，我们发现：（i）现有的昆士兰大学方法表现出强烈的特定于模态的专业化和对底层 VLM 的实质性依赖，（ii）特定于模态的不确定性经常与幻觉同时出现，而当前的 UQ 分数仅提供微弱且不一致的风险信号，以及（iii）尽管 UQ 方法可以与基于推理的思维链基线在明显的群体级模糊性上相媲美，但它们在很大程度上无法检测到我们引入的微妙的实例级模糊性。扰动管道。这些结果凸显了昆士兰大学当前的实践与可靠的 VLM 部署所需的细粒度、模态感知的不确定性之间存在显着差距。

</details>

---

## 238. Wearable environmental sensing to forecast how legged systems will interact with upcoming terrain

**中文标题**: 可穿戴环境传感可预测腿式系统如何与即将到来的地形相互作用

**Date**: 2026-02-09 | **arXiv**: [2602.09209v1](http://arxiv.org/abs/2602.09209v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09209v1)

<details><summary><b>Abstract</b></summary>

Computer-vision (CV) has been used for environmental classification during gait and is often used to inform control in assistive systems; however, the ability to predict how the foot will contact a changing environment is underexplored. We evaluated the feasibility of forecasting the anterior-posterior (AP) foot center-of-pressure (COP) and time-of-impact (TOI) prior to foot-strike on a level-ground to stair-ascent transition. Eight subjects wore an RGB-D camera on their right shank and instrumented insoles while performing the task of stepping onto the stairs. We trained a CNN-RNN to forecast the COP and TOI continuously within a 250ms window prior to foot-strike, termed the forecast horizon (FH). The COP mean-absolute-error (MAE) at 150, 100, and 50ms FH was 29.42mm, 26.82, and 23.72mm respectively. The TOI MAE was 21.14, 20.08, and 17.73ms for 150, 100, and 50ms respectively. While torso velocity had no effect on the error in either task, faster toe-swing speeds prior to foot-strike were found to improve the prediction accuracy in the COP case, however, was insignificant in the TOI case. Further, more anterior foot-strikes were found to reduce COP prediction accuracy but did not affect the TOI prediction accuracy. We also found that our lightweight model was capable at running at 60 FPS on either a consumer grade laptop or an edge computing device. This study demonstrates that forecasting COP and TOI from visual data was feasible using a lightweight model, which may have important implications for anticipatory control in assistive systems.

</details>

<details><summary><b>中文摘要</b></summary>

计算机视觉（CV）已用于步态期间的环境分类，并且通常用于通知辅助系统中的控制；然而，预测足部如何接触不断变化的环境的能力尚未得到充分探索。我们评估了在平地到爬楼梯过渡时预测足部触地前的前后 (​​AP) 足部压力中心 (COP) 和冲击时间 (TOI) 的可行性。八名受试者在执行上楼梯任务时，右腿上佩戴有 RGB-D 相机，鞋垫上装有仪器。我们训练了一个 CNN-RNN，在步行之前的 250 毫秒窗口内连续预测 COP 和 TOI，称为预测范围 (FH)。 150、100 和 50ms FH 时的 COP 平均绝对误差 (MAE) 分别为 29.42mm、26.82 和 23.72mm。 150、100 和 50 毫秒时，TOI MAE 分别为 21.14、20.08 和 17.73 毫秒。虽然躯干速度对这两项任务的误差没有影响，但在脚着地之前更快的脚趾摆动速度被发现可以提高 COP 情况下的预测准确性，然而，在 TOI 情况下却微不足道。此外，更多的前脚着地会降低 COP 预测的准确性，但不会影响 TOI 预测的准确性。我们还发现，我们的轻量级模型能够在消费级笔记本电脑或边缘计算设备上以 60 FPS 的速度运行。这项研究表明，使用轻量级模型从视觉数据预测 COP 和 TOI 是可行的，这可能对辅助系统的预期控制产生重要影响。

</details>

---

## 239. All-in-One Conditioning for Text-to-Image Synthesis

**中文标题**: 用于文本到图像合成的多合一调节

**Date**: 2026-02-09 | **arXiv**: [2602.09165v1](http://arxiv.org/abs/2602.09165v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09165v1)

<details><summary><b>Abstract</b></summary>

Accurate interpretation and visual representation of complex prompts involving multiple objects, attributes, and spatial relationships is a critical challenge in text-to-image synthesis. Despite recent advancements in generating photorealistic outputs, current models often struggle with maintaining semantic fidelity and structural coherence when processing intricate textual inputs. We propose a novel approach that grounds text-to-image synthesis within the framework of scene graph structures, aiming to enhance the compositional abilities of existing models. Eventhough, prior approaches have attempted to address this by using pre-defined layout maps derived from prompts, such rigid constraints often limit compositional flexibility and diversity. In contrast, we introduce a zero-shot, scene graph-based conditioning mechanism that generates soft visual guidance during inference. At the core of our method is the Attribute-Size-Quantity-Location (ASQL) Conditioner, which produces visual conditions via a lightweight language model and guides diffusion-based generation through inference-time optimization. This enables the model to maintain text-image alignment while supporting lightweight, coherent, and diverse image synthesis.

</details>

<details><summary><b>中文摘要</b></summary>

涉及多个对象、属性和空间关系的复杂提示的准确解释和视觉表示是文本到图像合成的关键挑战。尽管最近在生成逼真输出方面取得了进展，但当前模型在处理复杂的文本输入时常常难以维持语义保真度和结构连贯性。我们提出了一种新颖的方法，将文本到图像的合成建立在场景图结构的框架内，旨在增强现有模型的组合能力。尽管先前的方法已经尝试通过使用从提示导出的预定义布局图来解决这个问题，但是这种严格的约束通常限制了构图的灵活性和多样性。相比之下，我们引入了一种零样本、基于场景图的条件机制，可以在推理过程中生成软视觉指导。我们方法的核心是属性-大小-数量-位置 (ASQL) 条件器，它通过轻量级语言模型生成视觉条件，并通过推理时间优化指导基于扩散的生成。这使得模型能够保持文本图像对齐，同时支持轻量级、连贯且多样化的图像合成。

</details>

---

## 240. SemanticMoments: Training-Free Motion Similarity via Third Moment Features

**中文标题**: SemanticMoments：通过第三矩特征进行免训练运动相似性

**Date**: 2026-02-09 | **arXiv**: [2602.09146v1](http://arxiv.org/abs/2602.09146v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09146v1)

<details><summary><b>Abstract</b></summary>

Retrieving videos based on semantic motion is a fundamental, yet unsolved, problem. Existing video representation approaches overly rely on static appearance and scene context rather than motion dynamics, a bias inherited from their training data and objectives. Conversely, traditional motion-centric inputs like optical flow lack the semantic grounding needed to understand high-level motion. To demonstrate this inherent bias, we introduce the SimMotion benchmarks, combining controlled synthetic data with a new human-annotated real-world dataset. We show that existing models perform poorly on these benchmarks, often failing to disentangle motion from appearance. To address this gap, we propose SemanticMoments, a simple, training-free method that computes temporal statistics (specifically, higher-order moments) over features from pre-trained semantic models. Across our benchmarks, SemanticMoments consistently outperforms existing RGB, flow, and text-supervised methods. This demonstrates that temporal statistics in a semantic feature space provide a scalable and perceptually grounded foundation for motion-centric video understanding.

</details>

<details><summary><b>中文摘要</b></summary>

基于语义运动检索视频是一个基本但尚未解决的问题。现有的视频表示方法过度依赖静态外观和场景上下文，而不是运动动态，这是从其训练数据和目标继承的偏见。相反，传统的以运动为中心的输入（例如光流）缺乏理解高级运动所需的语义基础。为了证明这种固有偏差，我们引入了 SimMotion 基准，将受控合成数据与新的人工注释的真实世界数据集相结合。我们表明，现有模型在这些基准测试中表现不佳，通常无法将运动与外观分开。为了解决这一差距，我们提出了 SemanticMoments，这是一种简单的、免训练的方法，可以根据预先训练的语义模型的特征计算时间统计数据（特别是高阶矩）。在我们的基准测试中，SemanticMoments 始终优于现有的 RGB、流和文本监督方法。这表明语义特征空间中的时间统计为以运动为中心的视频理解提供了可扩展且基于感知的基础。

</details>

---

## 241. Autoregressive Image Generation with Masked Bit Modeling

**中文标题**: 使用掩蔽位建模的自回归图像生成

**Date**: 2026-02-09 | **arXiv**: [2602.09024v1](http://arxiv.org/abs/2602.09024v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09024v1)

<details><summary><b>Abstract</b></summary>

This paper challenges the dominance of continuous pipelines in visual generation. We systematically investigate the performance gap between discrete and continuous methods. Contrary to the belief that discrete tokenizers are intrinsically inferior, we demonstrate that the disparity arises primarily from the total number of bits allocated in the latent space (i.e., the compression ratio). We show that scaling up the codebook size effectively bridges this gap, allowing discrete tokenizers to match or surpass their continuous counterparts. However, existing discrete generation methods struggle to capitalize on this insight, suffering from performance degradation or prohibitive training costs with scaled codebook. To address this, we propose masked Bit AutoRegressive modeling (BAR), a scalable framework that supports arbitrary codebook sizes. By equipping an autoregressive transformer with a masked bit modeling head, BAR predicts discrete tokens through progressively generating their constituent bits. BAR achieves a new state-of-the-art gFID of 0.99 on ImageNet-256, outperforming leading methods across both continuous and discrete paradigms, while significantly reducing sampling costs and converging faster than prior continuous approaches. Project page is available at https://bar-gen.github.io/

</details>

<details><summary><b>中文摘要</b></summary>

本文挑战了连续管道在视觉生成中的主导地位。我们系统地研究离散方法和连续方法之间的性能差距。与离散分词器本质上较差的观点相反，我们证明这种差异主要源于潜在空间中分配的位数（即压缩比）。我们证明，扩大码本大小可以有效地弥补这一差距，使离散分词器能够匹配或超越其连续分词器。然而，现有的离散生成方法很难利用这种洞察力，因为性能下降或缩放码本的训练成本过高。为了解决这个问题，我们提出了屏蔽位自回归建模（BAR），这是一种支持任意码本大小的可扩展框架。通过为自回归变压器配备掩码位建模头，BAR 通过逐步生成离散标记的组成位来预测离散标记。 BAR 在 ImageNet-256 上实现了最先进的 gFID 0.99，在连续和离散范式上都优于领先方法，同时显着降低了采样成本，并且比之前的连续方法收敛得更快。项目页面位于 https://bar-gen.github.io/

</details>

---

## 242. WorldCompass: Reinforcement Learning for Long-Horizon World Models

**中文标题**: WorldCompass：长期世界模型的强化学习

**Date**: 2026-02-09 | **arXiv**: [2602.09022v1](http://arxiv.org/abs/2602.09022v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09022v1)

<details><summary><b>Abstract</b></summary>

This work presents WorldCompass, a novel Reinforcement Learning (RL) post-training framework for the long-horizon, interactive video-based world models, enabling them to explore the world more accurately and consistently based on interaction signals. To effectively "steer" the world model's exploration, we introduce three core innovations tailored to the autoregressive video generation paradigm: 1) Clip-level rollout Strategy: We generate and evaluate multiple samples at a single target clip, which significantly boosts rollout efficiency and provides fine-grained reward signals. 2) Complementary Reward Functions: We design reward functions for both interaction-following accuracy and visual quality, which provide direct supervision and effectively suppress reward-hacking behaviors. 3) Efficient RL Algorithm: We employ the negative-aware fine-tuning strategy coupled with various efficiency optimizations to efficiently and effectively enhance model capacity. Evaluations on the SoTA open-source world model, WorldPlay, demonstrate that WorldCompass significantly improves interaction accuracy and visual fidelity across various scenarios.

</details>

<details><summary><b>中文摘要</b></summary>

这项工作提出了 WorldCompass，这是一种新颖的强化学习 (RL) 后训练框架，适用于长视野、基于交互式视频的世界模型，使他们能够根据交互信号更准确、一致地探索世界。为了有效地“引导”世界模型的探索，我们引入了针对自回归视频生成范式量身定制的三项核心创新：1）剪辑级推出策略：我们在单个目标剪辑上生成并评估多个样本，这显着提高了推出效率并提供细粒度的奖励信号。 2）补充奖励函数：我们设计了针对交互跟踪准确性和视觉质量的奖励函数，提供直接监督并有效抑制奖励黑客行为。 3）高效的强化学习算法：我们采用负感知微调策略结合各种效率优化来高效且有效地增强模型容量。对SoTA开源世界模型WorldPlay的评估表明，WorldCompass显着提高了各种场景下的交互准确性和视觉保真度。

</details>

---

## 243. $χ_{0}$: Resource-Aware Robust Manipulation via Taming Distributional Inconsistencies

**中文标题**: $χ_{0}$：通过驯服分布不一致进行资源感知的鲁棒操作

**Date**: 2026-02-09 | **arXiv**: [2602.09021v1](http://arxiv.org/abs/2602.09021v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09021v1)

<details><summary><b>Abstract</b></summary>

High-reliability long-horizon robotic manipulation has traditionally relied on large-scale data and compute to understand complex real-world dynamics. However, we identify that the primary bottleneck to real-world robustness is not resource scale alone, but the distributional shift among the human demonstration distribution, the inductive bias learned by the policy, and the test-time execution distribution -- a systematic inconsistency that causes compounding errors in multi-stage tasks. To mitigate these inconsistencies, we propose $χ_{0}$, a resource-efficient framework with effective modules designated to achieve production-level robustness in robotic manipulation. Our approach builds off three technical pillars: (i) Model Arithmetic, a weight-space merging strategy that efficiently soaks up diverse distributions of different demonstrations, varying from object appearance to state variations; (ii) Stage Advantage, a stage-aware advantage estimator that provides stable, dense progress signals, overcoming the numerical instability of prior non-stage approaches; and (iii) Train-Deploy Alignment, which bridges the distribution gap via spatio-temporal augmentation, heuristic DAgger corrections, and temporal chunk-wise smoothing. $χ_{0}$ enables two sets of dual-arm robots to collaboratively orchestrate long-horizon garment manipulation, spanning tasks from flattening, folding, to hanging different clothes. Our method exhibits high-reliability autonomy; we are able to run the system from arbitrary initial state for consecutive 24 hours non-stop. Experiments validate that $χ_{0}$ surpasses the state-of-the-art $π_{0.5}$ in success rate by nearly 250%, with only 20-hour data and 8 A100 GPUs. Code, data and models will be released to facilitate the community.

</details>

<details><summary><b>中文摘要</b></summary>

高可靠性长视距机器人操纵传统上依赖大规模数据和计算来理解复杂的现实世界动态。然而，我们发现现实世界鲁棒性的主要瓶颈不仅仅是资源规模，而是人类示范分布、策略学习到的归纳偏差和测试时执行分布之间的分布变化——这是一种系统不一致，会导致多阶段任务中的复合错误。为了缓解这些不一致问题，我们提出了 $χ_{0}$，这是一个资源高效的框架，具有有效的模块，旨在实现机器人操作的生产级鲁棒性。我们的方法建立在三个技术支柱之上：（i）模型算术，一种权重空间合并策略，可以有效地吸收不同演示的不同分布，从对象外观到状态变化； (ii) Stage Advantage，一种阶段感知优势估计器，可提供稳定、密集的进度信号，克服先前非阶段方法的数值不稳定性； (iii) 训练部署对齐，通过时空增强、启发式 DAgger 校正和时间块平滑来弥合分布差距。 $χ_{0}$ 使两组双臂机器人能够协作编排长期服装操作，涵盖从展平、折叠到悬挂不同衣服的任务。我们的方法表现出高可靠性的自主性；我们能够从任意初始状态连续24小时不间断地运行系统。实验验证，仅用 20 小时的数据和 8 个 A100 GPU，$χ_{0}$ 的成功率就超过了最先进的 $π_{0.5}$ 近 250%。代码、数据和模型将被发布以方便社区。

</details>

---

## 244. Robustness Is a Function, Not a Number: A Factorized Comprehensive Study of OOD Robustness in Vision-Based Driving

**中文标题**: 鲁棒性是一个函数，而不是一个数字：基于视觉的驾驶中 OOD 鲁棒性的分解综合研究

**Date**: 2026-02-09 | **arXiv**: [2602.09018v1](http://arxiv.org/abs/2602.09018v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09018v1)

<details><summary><b>Abstract</b></summary>

Out of distribution (OOD) robustness in autonomous driving is often reduced to a single number, hiding what breaks a policy. We decompose environments along five axes: scene (rural/urban), season, weather, time (day/night), and agent mix; and measure performance under controlled $k$-factor perturbations ($k \in \{0,1,2,3\}$). Using closed loop control in VISTA, we benchmark FC, CNN, and ViT policies, train compact ViT heads on frozen foundation-model (FM) features, and vary ID support in scale, diversity, and temporal context. (1) ViT policies are markedly more OOD-robust than comparably sized CNN/FC, and FM features yield state-of-the-art success at a latency cost. (2) Naive temporal inputs (multi-frame) do not beat the best single-frame baseline. (3) The largest single factor drops are rural $\rightarrow$ urban and day $\rightarrow$ night ($\sim 31\%$ each); actor swaps $\sim 10\%$, moderate rain $\sim 7\%$; season shifts can be drastic, and combining a time flip with other changes further degrades performance. (4) FM-feature policies stay above $85\%$ under three simultaneous changes; non-FM single-frame policies take a large first-shift hit, and all no-FM models fall below $50\%$ by three changes. (5) Interactions are non-additive: some pairings partially offset, whereas season-time combinations are especially harmful. (6) Training on winter/snow is most robust to single-factor shifts, while a rural+summer baseline gives the best overall OOD performance. (7) Scaling traces/views improves robustness ($+11.8$ points from $5$ to $14$ traces), yet targeted exposure to hard conditions can substitute for scale. (8) Using multiple ID environments broadens coverage and strengthens weak cases (urban OOD $60.6\% \rightarrow 70.1\%$) with a small ID drop; single-ID preserves peak performance but in a narrow domain. These results yield actionable design rules for OOD-robust driving policies.

</details>

<details><summary><b>中文摘要</b></summary>

自动驾驶中的分布外 (OOD) 鲁棒性通常会简化为一个数字，从而隐藏了违反策略的内容。我们沿着五个轴分解环境：场景（农村/城市）、季节、天气、时间（白天/夜晚）和代理组合；并测量受控 $k$ 因子扰动下的性能 ($k \in \{0,1,2,3\}$)。使用 VISTA 中的闭环控制，我们对 FC、CNN 和 ViT 策略进行基准测试，在冻结的基础模型 (FM) 特征上训练紧凑的 ViT 头，并在规模、多样性和时间上下文中改变 ID 支持。 (1) ViT 策略明显比同等规模的 CNN/FC 更具有 OOD 鲁棒性，并且 FM 功能以延迟成本取得了最先进的成功。 (2) 朴素时间输入（多帧）无法击败最佳单帧基线。 （3）单因素下降最大的是农村$\rightarrow$城市和白天$\rightarrow$夜间（各$\sim 31\%$）；演员交换$\sim 10\%$，中雨$\sim 7\%$；季节变化可能会很剧烈，并且将时间翻转与其他变化结合起来会进一步降低性能。 (4) FM特色保单在三项同时变化下保持在$85\%$之上；非 FM 单帧策略受到较大的第一轮打击，所有非 FM 模型均通过三个变化跌至 50\%$ 以下。 (5) 相互作用是非累加性的：一些配对会部分抵消，而季节组合尤其有害。 (6) 冬季/雪地训练对于单因素变化最为稳健，而乡村+夏季基线则提供最佳的整体 OOD 性能。 (7) 缩放轨迹/视图可提高鲁棒性（从 5 美元到 14 美元轨迹，$+11.8 点），但有针对性地暴露在恶劣条件下可以替代缩放。 （8）使用多个ID环境扩大了覆盖范围并加强了弱案例（城市OOD $60.6\% \rightarrow 70.1\%$），ID下降幅度较小；单 ID 可以保持峰值性能，但范围很窄。这些结果为 OOD 稳健的驾驶策略提供了可行的设计规则。

</details>

---

## 245. ArcFlow: Unleashing 2-Step Text-to-Image Generation via High-Precision Non-Linear Flow Distillation

**中文标题**: ArcFlow：通过高精度非线性流动蒸馏实现两步文本到图像生成

**Date**: 2026-02-09 | **arXiv**: [2602.09014v1](http://arxiv.org/abs/2602.09014v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09014v1)

<details><summary><b>Abstract</b></summary>

Diffusion models have achieved remarkable generation quality, but they suffer from significant inference cost due to their reliance on multiple sequential denoising steps, motivating recent efforts to distill this inference process into a few-step regime. However, existing distillation methods typically approximate the teacher trajectory by using linear shortcuts, which makes it difficult to match its constantly changing tangent directions as velocities evolve across timesteps, thereby leading to quality degradation. To address this limitation, we propose ArcFlow, a few-step distillation framework that explicitly employs non-linear flow trajectories to approximate pre-trained teacher trajectories. Concretely, ArcFlow parameterizes the velocity field underlying the inference trajectory as a mixture of continuous momentum processes. This enables ArcFlow to capture velocity evolution and extrapolate coherent velocities to form a continuous non-linear trajectory within each denoising step. Importantly, this parameterization admits an analytical integration of this non-linear trajectory, which circumvents numerical discretization errors and results in high-precision approximation of the teacher trajectory. To train this parameterization into a few-step generator, we implement ArcFlow via trajectory distillation on pre-trained teacher models using lightweight adapters. This strategy ensures fast, stable convergence while preserving generative diversity and quality. Built on large-scale models (Qwen-Image-20B and FLUX.1-dev), ArcFlow only fine-tunes on less than 5% of original parameters and achieves a 40x speedup with 2 NFEs over the original multi-step teachers without significant quality degradation. Experiments on benchmarks show the effectiveness of ArcFlow both qualitatively and quantitatively.

</details>

<details><summary><b>中文摘要</b></summary>

扩散模型已经实现了卓越的生成质量，但由于依赖多个连续的去噪步骤，它们的推理成本很高，这促使人们最近努力将这种推理过程提炼为几个步骤。然而，现有的蒸馏方法通常使用线性捷径来近似教师轨迹，这使得随着速度跨时间步长的变化而难以匹配其不断变化的切线方向，从而导致质量下降。为了解决这个限制，我们提出了 ArcFlow，这是一种分步蒸馏框架，它明确地采用非线性流动轨迹来近似预先训练的教师轨迹。具体来说，ArcFlow 将推理轨迹下的速度场参数化为连续动量过程的混合。这使得 ArcFlow 能够捕获速度演化并推断相干速度，以在每个去噪步骤内形成连续的非线性轨迹。重要的是，这种参数化允许对非线性轨迹进行分析积分，从而避免数值离散误差并导致教师轨迹的高精度近似。为了将这种参数化训练成几步生成器，我们使用轻量级适配器在预先训练的教师模型上通过轨迹蒸馏来实现 ArcFlow。该策略确保快速、稳定的收敛，同时保持生成多样性和质量。 ArcFlow 基于大型模型（Qwen-Image-20B 和 FLUX.1-dev）构建，仅对不到 5% 的原始参数进行微调，与原始多步教师相比，通过 2 个 NFE 实现了 40 倍的加速，而质量没有显着下降。基准实验从定性和定量两个方面证明了 ArcFlow 的有效性。

</details>

---

## 246. Dexterous Manipulation Policies from RGB Human Videos via 4D Hand-Object Trajectory Reconstruction

**中文标题**: 通过 4D 手部物体轨迹重建从 RGB 人类视频中获得灵巧操纵策略

**Date**: 2026-02-09 | **arXiv**: [2602.09013v1](http://arxiv.org/abs/2602.09013v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09013v1)

<details><summary><b>Abstract</b></summary>

Multi-finger robotic hand manipulation and grasping are challenging due to the high-dimensional action space and the difficulty of acquiring large-scale training data. Existing approaches largely rely on human teleoperation with wearable devices or specialized sensing equipment to capture hand-object interactions, which limits scalability. In this work, we propose VIDEOMANIP, a device-free framework that learns dexterous manipulation directly from RGB human videos. Leveraging recent advances in computer vision, VIDEOMANIP reconstructs explicit 4D robot-object trajectories from monocular videos by estimating human hand poses, object meshes, and retargets the reconstructed human motions to robotic hands for manipulation learning. To make the reconstructed robot data suitable for dexterous manipulation training, we introduce hand-object contact optimization with interaction-centric grasp modeling, as well as a demonstration synthesis strategy that generates diverse training trajectories from a single video, enabling generalizable policy learning without additional robot demonstrations. In simulation, the learned grasping model achieves a 70.25% success rate across 20 diverse objects using the Inspire Hand. In the real world, manipulation policies trained from RGB videos achieve an average 62.86% success rate across seven tasks using the LEAP Hand, outperforming retargeting-based methods by 15.87%. Project videos are available at videomanip.github.io.

</details>

<details><summary><b>中文摘要</b></summary>

由于高维动作空间和获取大规模训练数据的困难，多指机器人手的操纵和抓取具有挑战性。现有方法很大程度上依赖于人类通过可穿戴设备或专用传感设备进行远程操作来捕获手部物体交互，这限制了可扩展性。在这项工作中，我们提出了 VIDEOMANIP，这是一种无需设备的框架，可以直接从 RGB 人类视频中学习灵巧的操作。利用计算机视觉的最新进展，VIDEOMANIP 通过估计人类手部姿势、物体网格，从单目视频中重建明确的 4D 机器人物体轨迹，并将重建的人类运动重新定位到机器人手以进行操作学习。为了使重建的机器人数据适合灵巧操作训练，我们引入了以交互为中心的抓取建模的手部物体接触优化，以及从单个视频生成不同训练轨迹的演示综合策略，无需额外的机器人演示即可实现可推广的策略学习。在模拟中，学习抓取模型使用 Inspire Hand 在 20 个不同物体上实现了 70.25% 的成功率。在现实世界中，使用 LEAP Hand 从 RGB 视频训练的操纵策略在七项任务中平均成功率为 62.86%，比基于重定向的方法高出 15.87%。项目视频可在 videomanip.github.io 上获取。

</details>

---

## 247. GEBench: Benchmarking Image Generation Models as GUI Environments

**中文标题**: GEBench：将图像生成模型作为 GUI 环境进行基准测试

**Date**: 2026-02-09 | **arXiv**: [2602.09007v2](http://arxiv.org/abs/2602.09007v2) | **PDF**: [Link](http://arxiv.org/pdf/2602.09007v2)

**Code**: https://github.com/stepfun-ai/GEBench.

<details><summary><b>Abstract</b></summary>

Recent advancements in image generation models have enabled the prediction of future Graphical User Interface (GUI) states based on user instructions. However, existing benchmarks primarily focus on general domain visual fidelity, leaving the evaluation of state transitions and temporal coherence in GUI-specific contexts underexplored. To address this gap, we introduce GEBench, a comprehensive benchmark for evaluating dynamic interaction and temporal coherence in GUI generation. GEBench comprises 700 carefully curated samples spanning five task categories, covering both single-step interactions and multi-step trajectories across real-world and fictional scenarios, as well as grounding point localization. To support systematic evaluation, we propose GE-Score, a novel five-dimensional metric that assesses Goal Achievement, Interaction Logic, Content Consistency, UI Plausibility, and Visual Quality. Extensive evaluations on current models indicate that while they perform well on single-step transitions, they struggle significantly with maintaining temporal coherence and spatial grounding over longer interaction sequences. Our findings identify icon interpretation, text rendering, and localization precision as critical bottlenecks. This work provides a foundation for systematic assessment and suggests promising directions for future research toward building high-fidelity generative GUI environments. The code is available at: https://github.com/stepfun-ai/GEBench.

</details>

<details><summary><b>中文摘要</b></summary>

图像生成模型的最新进展使得能够根据用户指令预测未来的图形用户界面（GUI）状态。然而，现有的基准主要关注一般领域的视觉保真度，而对特定于 GUI 的上下文中的状态转换和时间一致性的评估尚未得到充分探索。为了解决这一差距，我们引入了 GEBench，这是一个用于评估 GUI 生成中的动态交互和时间一致性的综合基准。 GEBench 包含 700 个精心策划的样本，涵盖五个任务类别，涵盖现实世界和虚构场景中的单步交互和多步轨迹，以及接地点定位。为了支持系统评估，我们提出了 GE-Score，这是一种新颖的五维指标，用于评估目标实现、交互逻辑、内容一致性、UI 合理性和视觉质量。对当前模型的广泛评估表明，虽然它们在单步转换上表现良好，但在较长交互序列上维持时间连贯性和空间基础方面存在很大困难。我们的研究结果表明图标解释、文本渲染和定位精度是关键瓶颈。这项工作为系统评估奠定了基础，并为构建高保真生成 GUI 环境的未来研究提出了有希望的方向。代码位于：https://github.com/stepfun-ai/GEBench。

</details>

---

## 248. WorldArena: A Unified Benchmark for Evaluating Perception and Functional Utility of Embodied World Models

**中文标题**: WorldArena：评估具体世界模型的感知和功能效用的统一基准

**Date**: 2026-02-09 | **arXiv**: [2602.08971v2](http://arxiv.org/abs/2602.08971v2) | **PDF**: [Link](http://arxiv.org/pdf/2602.08971v2)

<details><summary><b>Abstract</b></summary>

While world models have emerged as a cornerstone of embodied intelligence by enabling agents to reason about environmental dynamics through action-conditioned prediction, their evaluation remains fragmented. Current evaluation of embodied world models has largely focused on perceptual fidelity (e.g., video generation quality), overlooking the functional utility of these models in downstream decision-making tasks. In this work, we introduce WorldArena, a unified benchmark designed to systematically evaluate embodied world models across both perceptual and functional dimensions. WorldArena assesses models through three dimensions: video perception quality, measured with 16 metrics across six sub-dimensions; embodied task functionality, which evaluates world models as data engines, policy evaluators, and action planners integrating with subjective human evaluation. Furthermore, we propose EWMScore, a holistic metric integrating multi-dimensional performance into a single interpretable index. Through extensive experiments on 14 representative models, we reveal a significant perception-functionality gap, showing that high visual quality does not necessarily translate into strong embodied task capability. WorldArena benchmark with the public leaderboard is released at https://world-arena.ai, providing a framework for tracking progress toward truly functional world models in embodied AI.

</details>

<details><summary><b>中文摘要</b></summary>

虽然世界模型已成为体现智能的基石，使智能体能够通过行动条件预测来推理环境动态，但它们的评估仍然支离破碎。目前对具体世界模型的评估主要集中在感知保真度（例如视频生成质量），而忽视了这些模型在下游决策任务中的功能效用。在这项工作中，我们介绍了 WorldArena，这是一个统一的基准，旨在跨感知和功能维度系统地评估具体世界模型。 WorldArena 通过三个维度评估模型：视频感知质量，通过 6 个子维度的 16 个指标进行衡量；体现任务功能，将世界模型评估为数据引擎、政策评估者和与主观人类评估相结合的行动规划者。此外，我们提出了 EWMScore，这是一种将多维性能集成到单个可解释指数中的整体指标。通过对 14 个代表性模型的广泛实验，我们揭示了显着的感知功能差距，表明高视觉质量并不一定转化为强大的具体任务能力。 WorldArena 基准测试和公共排行榜在 https://world-arena.ai 上发布，提供了一个框架，用于跟踪具体人工智能中真正功能性世界模型的进展。

</details>

---

## 249. Modeling 3D Pedestrian-Vehicle Interactions for Vehicle-Conditioned Pose Forecasting

**中文标题**: 对 3D 行人-车辆交互建模以进行车辆条件姿态预测

**Date**: 2026-02-09 | **arXiv**: [2602.08962v1](http://arxiv.org/abs/2602.08962v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.08962v1)

**Code**: https://github.com/GuangxunZhu/VehCondPose3D

<details><summary><b>Abstract</b></summary>

Accurately predicting pedestrian motion is crucial for safe and reliable autonomous driving in complex urban environments. In this work, we present a 3D vehicle-conditioned pedestrian pose forecasting framework that explicitly incorporates surrounding vehicle information. To support this, we enhance the Waymo-3DSkelMo dataset with aligned 3D vehicle bounding boxes, enabling realistic modeling of multi-agent pedestrian-vehicle interactions. We introduce a sampling scheme to categorize scenes by pedestrian and vehicle count, facilitating training across varying interaction complexities. Our proposed network adapts the TBIFormer architecture with a dedicated vehicle encoder and pedestrian-vehicle interaction cross-attention module to fuse pedestrian and vehicle features, allowing predictions to be conditioned on both historical pedestrian motion and surrounding vehicles. Extensive experiments demonstrate substantial improvements in forecasting accuracy and validate different approaches for modeling pedestrian-vehicle interactions, highlighting the importance of vehicle-aware 3D pose prediction for autonomous driving. Code is available at: https://github.com/GuangxunZhu/VehCondPose3D

</details>

<details><summary><b>中文摘要</b></summary>

准确预测行人运动对于复杂城市环境中安全可靠的自动驾驶至关重要。在这项工作中，我们提出了一个 3D 车辆调节行人姿势预测框架，该框架明确地结合了周围车辆信息。为了支持这一点，我们使用对齐的 3D 车辆边界框增强了 Waymo-3DSkelMo 数据集，从而实现了多智能体行人-车辆交互的真实建模。我们引入了一种采样方案，根据行人和车辆数量对场景进行分类，从而促进不同交互复杂性的训练。我们提出的网络采用专用车辆编码器和行人车辆交互交叉注意模块来适应 TBIFormer 架构，以融合行人和车辆特征，从而允许根据历史行人运动和周围车辆进行预测。大量实验证明了预测准确性的显着提高，并验证了行人-车辆交互建模的不同方法，凸显了车辆感知 3D 姿态预测对于自动驾驶的重要性。代码可见：https://github.com/GuangxunZhu/VehCondPose3D

</details>

---

## 250. MotionCrafter: Dense Geometry and Motion Reconstruction with a 4D VAE

**中文标题**: MotionCrafter：使用 4D VAE 进行密集几何和运动重建

**Date**: 2026-02-09 | **arXiv**: [2602.08961v1](http://arxiv.org/abs/2602.08961v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.08961v1)

**Project**: https://ruijiezhu94.github.io/MotionCrafter_Page  <details><summary><b>Abstract</b></summary>

We introduce MotionCrafter, a video diffusion-based framework that jointly reconstructs 4D geometry and estimates dense motion from a monocular video. The core of our method is a novel joint representation of dense 3D point maps and 3D scene flows in a shared coordinate system, and a novel 4D VAE to effectively learn this representation. Unlike prior work that forces the 3D value and latents to align strictly with RGB VAE latents-despite their fundamentally different distributions-we show that such alignment is unnecessary and leads to suboptimal performance. Instead, we introduce a new data normalization and VAE training strategy that better transfers diffusion priors and greatly improves reconstruction quality. Extensive experiments across multiple datasets demonstrate that MotionCrafter achieves state-of-the-art performance in both geometry reconstruction and dense scene flow estimation, delivering 38.64% and 25.0% improvements in geometry and motion reconstruction, respectively, all without any post-optimization. Project page: https://ruijiezhu94.github.io/MotionCrafter_Page

</details>

<details><summary><b>中文摘要</b></summary>

我们引入了 MotionCrafter，这是一种基于视频扩散的框架，可以联合重建 4D 几何结构并估计单目视频中的密集运动。我们方法的核心是共享坐标系中密集 3D 点图和 3D 场景流的新颖联合表示，以及有效学习这种表示的新颖 4D VAE。与之前强制 3D 值和潜在变量与 RGB VAE 潜在变量严格对齐的工作不同（尽管它们的分布根本不同），我们表明这种对齐是不必要的，并且会导致性能不佳。相反，我们引入了一种新的数据归一化和 VAE 训练策略，可以更好地传输扩散先验并大大提高重建质量。跨多个数据集的大量实验表明，MotionCrafter 在几何重建和密集场景流估计方面均实现了最先进的性能，在几何和运动重建方面分别实现了 38.64% 和 25.0% 的改进，并且全部无需任何后期优化。项目页面：https://ruijiezhu94.github.io/MotionCrafter_Page

</details>

---

## 251. Grow with the Flow: 4D Reconstruction of Growing Plants with Gaussian Flow Fields

**中文标题**: 随流生长：利用高斯流场 4D 重建正在生长的植物

**Date**: 2026-02-09 | **arXiv**: [2602.08958v2](http://arxiv.org/abs/2602.08958v2) | **PDF**: [Link](http://arxiv.org/pdf/2602.08958v2)

<details><summary><b>Abstract</b></summary>

Modeling the time-varying 3D appearance of plants during their growth poses unique challenges: unlike many dynamic scenes, plants generate new geometry over time as they expand, branch, and differentiate. Recent motion modeling techniques are ill-suited to this problem setting. For example, deformation fields cannot introduce new geometry, and 4D Gaussian splatting constrains motion to a linear trajectory in space and time and cannot track the same set of Gaussians over time. Here, we introduce a 3D Gaussian flow field representation that models plant growth as a time-varying derivative over Gaussian parameters -- position, scale, orientation, color, and opacity -- enabling nonlinear and continuous-time growth dynamics. To initialize a sufficient set of Gaussian primitives, we reconstruct the mature plant and learn a process of reverse growth, effectively simulating the plant's developmental history in reverse. Our approach achieves superior image quality and geometric accuracy compared to prior methods on multi-view timelapse datasets of plant growth, providing a new approach for appearance modeling of growing 3D structures.

</details>

<details><summary><b>中文摘要</b></summary>

对植物生长过程中随时间变化的 3D 外观进行建模提出了独特的挑战：与许多动态场景不同，植物随着时间的推移，在扩展、分支和分化时会生成新的几何形状。最近的运动建模技术不适合这个问题设置。例如，变形场无法引入新的几何形状，4D 高斯喷射将运动限制为空间和时间中的线性轨迹，并且无法随时间跟踪同一组高斯。在这里，我们引入了 3D 高斯流场表示，将植物生长建模为高斯参数（位置、尺度、方向、颜色和不透明度）的时变导数，从而实现非线性和连续时间生长动态。为了初始化一组足够的高斯原语，我们重建了成熟的植物并学习了反向生长的过程，有效地反向模拟了植物的发育历史。与植物生长多视图延时数据集上的先前方法相比，我们的方法实现了卓越的图像质量和几何精度，为生长 3D 结构的外观建模提供了一种新方法。

</details>

---

## 252. PRISM-XR: Empowering Privacy-Aware XR Collaboration with Multimodal Large Language Models

**中文标题**: PRISM-XR：通过多模式大语言模型增强隐私意识 XR 协作

**Date**: 2026-02-09 | **arXiv**: [2602.10154v1](http://arxiv.org/abs/2602.10154v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10154v1)

<details><summary><b>Abstract</b></summary>

Multimodal Large Language Models (MLLMs) enhance collaboration in Extended Reality (XR) environments by enabling flexible object and animation creation through the combination of natural language and visual inputs. However, visual data captured by XR headsets includes real-world backgrounds that may contain irrelevant or sensitive user information, such as credit cards left on the table or facial identities of other users. Uploading those frames to cloud-based MLLMs poses serious privacy risks, particularly when such data is processed without explicit user consent. Additionally, existing colocation and synchronization mechanisms in commercial XR APIs rely on time-consuming, privacy-invasive environment scanning and struggle to adapt to the highly dynamic nature of MLLM-integrated XR environments. In this paper, we propose PRISM-XR, a novel framework that facilitates multi-user collaboration in XR by providing privacy-aware MLLM integration. PRISM-XR employs intelligent frame preprocessing on the edge server to filter sensitive data and remove irrelevant context before communicating with cloud generative AI models. Additionally, we introduce a lightweight registration process and a fully customizable content-sharing mechanism to enable efficient, accurate, and privacy-preserving content synchronization among users. Our numerical evaluation results indicate that the proposed platform achieves nearly 90% accuracy in fulfilling user requests and less than 0.27 seconds registration time while maintaining spatial inconsistencies of less than 3.5 cm. Furthermore, we conducted an IRB-approved user study with 28 participants, demonstrating that our system could automatically filter highly sensitive objects in over 90% of scenarios while maintaining strong overall usability.

</details>

<details><summary><b>中文摘要</b></summary>

多模态大语言模型 (MLLM) 通过结合自然语言和视觉输入来实现灵活的对象和动画创建，从而增强扩展现实 (XR) 环境中的协作。然而，XR 耳机捕获的视觉数据包括现实世界的背景，其中可能包含不相关或敏感的用户信息，例如留在桌子上的信用卡或其他用户的面部身份。将这些帧上传到基于云的 MLLM 会带来严重的隐私风险，特别是在未经用户明确同意的情况下处理此类数据时。此外，商业 XR API 中现有的托管和同步机制依赖于耗时、侵犯隐私的环境扫描，并且难以适应 MLLM 集成 XR 环境的高度动态特性。在本文中，我们提出了 PRISM-XR，这是一种新颖的框架，通过提供隐私感知的 MLLM 集成来促进 XR 中的多用户协作。 PRISM-XR 在边缘服务器上采用智能帧预处理，在与云生成人工智能模型通信之前过滤敏感数据并删除不相关的上下文。此外，我们引入了轻量级注册流程和完全可定制的内容共享机制，以实现用户之间高效、准确且保护隐私的内容同步。我们的数值评估结果表明，所提出的平台在满足用户请求方面实现了近 90% 的准确度，注册时间小于 0.27 秒，同时保持空间不一致性小于 3.5 厘米。此外，我们还对 28 名参与者进行了 IRB 批准的用户研究，证明我们的系统可以在超过 90% 的场景中自动过滤高度敏感的对象，同时保持强大的整体可用性。

</details>

---

## 253. GOT-Edit: Geometry-Aware Generic Object Tracking via Online Model Editing

**中文标题**: GOT-Edit：通过在线模型编辑进行几何感知通用对象跟踪

**Date**: 2026-02-09 | **arXiv**: [2602.08550v1](http://arxiv.org/abs/2602.08550v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.08550v1)

<details><summary><b>Abstract</b></summary>

Human perception for effective object tracking in a 2D video stream arises from the implicit use of prior 3D knowledge combined with semantic reasoning. In contrast, most generic object tracking (GOT) methods primarily rely on 2D features of the target and its surroundings while neglecting 3D geometric cues, which makes them susceptible to partial occlusion, distractors, and variations in geometry and appearance. To address this limitation, we introduce GOT-Edit, an online cross-modality model editing approach that integrates geometry-aware cues into a generic object tracker from a 2D video stream. Our approach leverages features from a pre-trained Visual Geometry Grounded Transformer to enable geometric cue inference from only a few 2D images. To tackle the challenge of seamlessly combining geometry and semantics, GOT-Edit performs online model editing with null-space constrained updates that incorporate geometric information while preserving semantic discrimination, yielding consistently better performance across diverse scenarios. Extensive experiments on multiple GOT benchmarks demonstrate that GOT-Edit achieves superior robustness and accuracy, particularly under occlusion and clutter, establishing a new paradigm for combining 2D semantics with 3D geometric reasoning for generic object tracking.

</details>

<details><summary><b>中文摘要</b></summary>

人类对 2D 视频流中有效对象跟踪的感知源自对先验 3D 知识与语义推理相结合的隐式使用。相比之下，大多数通用对象跟踪 (GOT) 方法主要依赖于目标及其周围环境的 2D 特征，而忽略 3D 几何线索，这使得它们容易受到部分遮挡、干扰以及几何和外观变化的影响。为了解决这个限制，我们引入了 GOT-Edit，这是一种在线跨模态模型编辑方法，它将几何感知线索集成到来自 2D 视频流的通用对象跟踪器中。我们的方法利用预先训练的 Visual Geometry Grounded Transformer 的功能，仅从少量 2D 图像即可进行几何线索推断。为了应对无缝结合几何和语义的挑战，GOT-Edit 通过零空间约束更新执行在线模型编辑，在保留语义区分的同时合并几何信息，从而在不同场景中始终获得更好的性能。对多个 GOT 基准的大量实验表明，GOT-Edit 实现了卓越的鲁棒性和准确性，特别是在遮挡和杂乱的情况下，建立了将 2D 语义与 3D 几何推理相结合以进行通用对象跟踪的新范例。

</details>

---

## 254. T2VTree: User-Centered Visual Analytics for Agent-Assisted Thought-to-Video Authoring

**中文标题**: T2VTree：以用户为中心的可视化分析，用于代理辅助的思想到视频创作

**Date**: 2026-02-09 | **arXiv**: [2602.08368v1](http://arxiv.org/abs/2602.08368v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.08368v1)

**Code**: https://github.com/tezuka0210/T2VTree.

<details><summary><b>Abstract</b></summary>

Generative models have substantially expanded video generation capabilities, yet practical thought-to-video creation remains a multi-stage, multi-modal, and decision-intensive process. However, existing tools either hide intermediate decisions behind repeated reruns or expose operator-level workflows that make exploration traces difficult to manage, compare, and reuse. We present T2VTree, a user-centered visual analytics approach for agent-assisted thought-to-video authoring. T2VTree represents the authoring process as a tree visualization. Each node in the tree binds an editable specification (intent, referenced inputs, workflow choice, prompts, and parameters) with the resulting multimodal outputs, making refinement, branching, and provenance inspection directly operable. To reduce the burden of deciding what to do next, a set of collaborating agents translates step-level intent into an executable plan that remains visible and user-editable before execution. We further implement a visual analytics system that integrates branching authoring with in-place preview and stitching for convergent assembly, enabling end-to-end multi-scene creation without leaving the authoring context. We demonstrate T2VTreeVA through two multi-scene case studies and a comparative user study, showing how the T2VTree visualization and editable agent planning support reliable refinement, localized comparison, and practical reuse in real authoring workflows. T2VTree is available at: https://github.com/tezuka0210/T2VTree.

</details>

<details><summary><b>中文摘要</b></summary>

生成模型大大扩展了视频生成功能，但实际的思想到视频创作仍然是一个多阶段、多模式和决策密集型的过程。然而，现有工具要么隐藏重复重新运行背后的中间决策，要么暴露操作员级别的工作流程，这使得探索跟踪难以管理、比较和重用。我们提出了 T2VTree，一种以用户为中心的可视化分析方法，用于代理辅助的思想到视频创作。 T2VTree 将创作过程表示为树可视化。树中的每个节点都将可编辑的规范（意图、引用的输入、工作流选择、提示和参数）与生成的多模式输出绑定在一起，从而使细化、分支和来源检查可直接操作。为了减轻决定下一步做什么的负担，一组协作代理将步骤级意图转换为可执行计划，该计划在执行前保持可见且用户可编辑。我们进一步实现了一个可视化分析系统，该系统将分支创作与就地预览和拼接集成在一起以进行聚合组装，从而无需离开创作上下文即可实现端到端的多场景创建。我们通过两个多场景案例研究和比较用户研究来演示 T2VTreeVA，展示 T2VTree 可视化和可编辑代理规划如何支持真实创作工作流程中的可靠细化、本地化比较和实际重用。 T2VTree 位于：https://github.com/tezuka0210/T2VTree。

</details>

---

## 255. Data-centric Design of Learning-based Surgical Gaze Perception Models in Multi-Task Simulation

**中文标题**: 多任务模拟中基于学习的手术注视感知模型的以数据为中心的设计

**Date**: 2026-02-09 | **arXiv**: [2602.09259v1](http://arxiv.org/abs/2602.09259v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09259v1)

<details><summary><b>Abstract</b></summary>

In robot-assisted minimally invasive surgery (RMIS), reduced haptic feedback and depth cues increase reliance on expert visual perception, motivating gaze-guided training and learning-based surgical perception models. However, operative expert gaze is costly to collect, and it remains unclear how the source of gaze supervision, both expertise level (intermediate vs. novice) and perceptual modality (active execution vs. passive viewing), shapes what attention models learn. We introduce a paired active-passive, multi-task surgical gaze dataset collected on the da Vinci SimNow simulator across four drills. Active gaze was recorded during task execution using a VR headset with eye tracking, and the corresponding videos were reused as stimuli to collect passive gaze from observers, enabling controlled same-video comparisons. We quantify skill- and modality-dependent differences in gaze organization and evaluate the substitutability of passive gaze for operative supervision using fixation density overlap analyses and single-frame saliency modeling. Across settings, MSI-Net produced stable, interpretable predictions, whereas SalGAN was unstable and often poorly aligned with human fixations. Models trained on passive gaze recovered a substantial portion of intermediate active attention, but with predictable degradation, and transfer was asymmetric between active and passive targets. Notably, novice passive labels approximated intermediate-passive targets with limited loss on higher-quality demonstrations, suggesting a practical path for scalable, crowd-sourced gaze supervision in surgical coaching and perception modeling.

</details>

<details><summary><b>中文摘要</b></summary>

在机器人辅助微创手术（RMIS）中，触觉反馈和深度提示的减少增加了对专家视觉感知的依赖，激发了凝视引导训练和基于学习的手术感知模型。然而，操作专家凝视的收集成本很高，而且目前还不清楚凝视监督的来源，包括专业水平（中级与新手）和感知方式（主动执行与被动观看）如何塑造注意力模型学习的内容。我们介绍了在达芬奇 SimNow 模拟器上通过四次演习收集的配对主动-被动、多任务手术注视数据集。在任务执行过程中，使用具有眼动追踪功能的 VR 耳机记录主动凝视，并将相应的视频重新用作刺激，以收集观察者的被动凝视，从而实现受控的相同视频比较。我们量化注视组织中依赖于技能和模态的差异，并使用注视密度重叠分析和单帧显着性模型评估被动注视对操作监督的可替代性。在不同的设置中，MSI-Net 产生稳定、可解释的预测，而 SalGAN 则不稳定，并且通常与人类注视点不一致。在被动凝视上训练的模型恢复了大部分中间主动注意力，但会出现可预测的退化，并且主动目标和被动目标之间的转移是不对称的。值得注意的是，新手被动标签近似于中被动目标，在高质量演示中损失有限，这为手术指导和感知建模中可扩展的、众包的注视监督提供了一条实用途径。

</details>

---

## 256. STaR: Scalable Task-Conditioned Retrieval for Long-Horizon Multimodal Robot Memory

**中文标题**: STaR：长视野多模态机器人内存的可扩展任务条件检索

**Date**: 2026-02-09 | **arXiv**: [2602.09255v1](http://arxiv.org/abs/2602.09255v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09255v1)

<details><summary><b>Abstract</b></summary>

Mobile robots are often deployed over long durations in diverse open, dynamic scenes, including indoor setting such as warehouses and manufacturing facilities, and outdoor settings such as agricultural and roadway operations. A core challenge is to build a scalable long-horizon memory that supports an agentic workflow for planning, retrieval, and reasoning over open-ended instructions at variable granularity, while producing precise, actionable answers for navigation. We present STaR, an agentic reasoning framework that (i) constructs a task-agnostic, multimodal long-term memory that generalizes to unseen queries while preserving fine-grained environmental semantics (object attributes, spatial relations, and dynamic events), and (ii) introduces a Scalable TaskConditioned Retrieval algorithm based on the Information Bottleneck principle to extract from long-term memory a compact, non-redundant, information-rich set of candidate memories for contextual reasoning. We evaluate STaR on NaVQA (mixed indoor/outdoor campus scenes) and WH-VQA, a customized warehouse benchmark with many visually similar objects built with Isaac Sim, emphasizing contextual reasoning. Across the two datasets, STaR consistently outperforms strong baselines, achieving higher success rates and markedly lower spatial error. We further deploy STaR on a real Husky wheeled robot in both indoor and outdoor environments, demonstrating robust longhorizon reasoning, scalability, and practical utility.

</details>

<details><summary><b>中文摘要</b></summary>

移动机器人通常长时间部署在各种开放、动态的场景中，包括仓库和制造设施等室内环境，以及农业和道路作业等室外环境。核心挑战是构建一个可扩展的长视野内存，支持代理工作流程，以可变粒度对开放式指令进行规划、检索和推理，同时生成精确的、可操作的导航答案。我们提出了 STaR，一种代理推理框架，它（i）构建了一个与任务无关的多模态长期记忆，可泛化到未见过的查询，同时保留细粒度的环境语义（对象属性、空间关系和动态事件），以及（ii）引入基于信息瓶颈原理的可扩展任务条件检索算法，从长期记忆中提取紧凑、非冗余、信息丰富的候选记忆集，用于上下文推理。我们在 NaVQA（室内/室外混合校园场景）和 WH-VQA 上评估 STaR，WH-VQA 是一个定制的仓库基准，具有许多用 Isaac Sim 构建的视觉相似的对象，强调上下文推理。在这两个数据集中，STARR 始终优于强大的基线，实现了更高的成功率和显着更低的空间误差。我们进一步在室内和室外环境中的真实 Husky 轮式机器人上部署 STaR，展示了强大的长视野推理、可扩展性和实用性。

</details>

---

## 257. From Legible to Inscrutable Trajectories: (Il)legible Motion Planning Accounting for Multiple Observers

**中文标题**: 从清晰的轨迹到难以理解的轨迹：（不）清晰的多个观察者的运动规划说明

**Date**: 2026-02-09 | **arXiv**: [2602.09227v1](http://arxiv.org/abs/2602.09227v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09227v1)

<details><summary><b>Abstract</b></summary>

In cooperative environments, such as in factories or assistive scenarios, it is important for a robot to communicate its intentions to observers, who could be either other humans or robots. A legible trajectory allows an observer to quickly and accurately predict an agent's intention. In adversarial environments, such as in military operations or games, it is important for a robot to not communicate its intentions to observers. An illegible trajectory leads an observer to incorrectly predict the agent's intention or delays when an observer is able to make a correct prediction about the agent's intention. However, in some environments there are multiple observers, each of whom may be able to see only part of the environment, and each of whom may have different motives. In this work, we introduce the Mixed-Motive Limited-Observability Legible Motion Planning (MMLO-LMP) problem, which requires a motion planner to generate a trajectory that is legible to observers with positive motives and illegible to observers with negative motives while also considering the visibility limitations of each observer. We highlight multiple strategies an agent can take while still achieving the problem objective. We also present DUBIOUS, a trajectory optimizer that solves MMLO-LMP. Our results show that DUBIOUS can generate trajectories that balance legibility with the motives and limited visibility regions of the observers. Future work includes many variations of MMLO-LMP, including moving observers and observer teaming.

</details>

<details><summary><b>中文摘要</b></summary>

在合作环境中，例如在工厂或辅助场景中，机器人将其意图传达给观察者（可以是其他人类或机器人）非常重要。清晰的轨迹使观察者能够快速准确地预测特工的意图。在敌对环境中，例如在军事行动或游戏中，机器人不要向观察者传达其意图，这一点很重要。难以辨认的轨迹会导致观察者错误地预测智能体的意图，或者在观察者能够对智能体的意图做出正确预测时出现延迟。然而，在某些环境中存在多个观察者，每个观察者可能只能看到环境的一部分，并且每个观察者可能有不同的动机。在这项工作中，我们引入了混合动机有限可观察性清晰运动规划（MMLO-LMP）问题，该问题要求运动规划器生成一条轨迹，该轨迹对于具有积极动机的观察者来说是清晰的，对于具有消极动机的观察者来说是难以辨认的，同时还考虑到每个观察者的可见性限制。我们强调了智能体在实现问题目标的同时可以采取的多种策略。我们还推出了 DUBIOUS，一种求解 MMLO-LMP 的轨迹优化器。我们的结果表明，DUBIOUS 可以生成平衡易读性与观察者的动机和有限可见区域的轨迹。未来的工作包括 MMLO-LMP 的许多变体，包括移动观察者和观察者分组。

</details>

---

## 258. Risk-Aware Obstacle Avoidance Algorithm for Real-Time Applications

**中文标题**: 实时应用的风险感知避障算法

**Date**: 2026-02-09 | **arXiv**: [2602.09204v1](http://arxiv.org/abs/2602.09204v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09204v1)

<details><summary><b>Abstract</b></summary>

Robust navigation in changing marine environments requires autonomous systems capable of perceiving, reasoning, and acting under uncertainty. This study introduces a hybrid risk-aware navigation architecture that integrates probabilistic modeling of obstacles along the vehicle path with smooth trajectory optimization for autonomous surface vessels. The system constructs probabilistic risk maps that capture both obstacle proximity and the behavior of dynamic objects. A risk-biased Rapidly Exploring Random Tree (RRT) planner leverages these maps to generate collision-free paths, which are subsequently refined using B-spline algorithms to ensure trajectory continuity. Three distinct RRT* rewiring modes are implemented based on the cost function: minimizing the path length, minimizing risk, and optimizing a combination of the path length and total risk. The framework is evaluated in experimental scenarios containing both static and dynamic obstacles. The results demonstrate the system's ability to navigate safely, maintain smooth trajectories, and dynamically adapt to changing environmental risks. Compared with conventional LIDAR or vision-only navigation approaches, the proposed method shows improvements in operational safety and autonomy, establishing it as a promising solution for risk-aware autonomous vehicle missions in uncertain and dynamic environments.

</details>

<details><summary><b>中文摘要</b></summary>

在不断变化的海洋环境中实现稳健的导航需要能够在不确定性下感知、推理和行动的自主系统。本研究引入了一种混合风险感知导航架构，该架构将车辆路径沿线障碍物的概率建模与自主水面船舶的平滑轨迹优化相结合。该系统构建概率风险图，捕捉障碍物接近度和动态物体的行为。有风险的快速探索随机树 (RRT) 规划器利用这些地图生成无碰撞路径，随后使用 B 样条算法对其进行细化，以确保轨迹连续性。基于成本函数实现了三种不同的 RRT* 重布线模式：最小化路径长度、最小化风险以及优化路径长度和总风险的组合。该框架在包含静态和动态障碍物的实验场景中进行评估。结果证明了该系统能够安全导航、保持平稳轨迹并动态适应不断变化的环境风险。与传统的激光雷达或仅视觉导航方法相比，所提出的方法显示了操作安全性和自主性方面的改进，使其成为不确定和动态环境中具有风险意识的自动驾驶车辆任务的有前景的解决方案。

</details>

---

## 259. Elements of Robot Morphology: Supporting Designers in Robot Form Exploration

**中文标题**: 机器人形态学的要素：支持设计师探索机器人形态

**Date**: 2026-02-09 | **arXiv**: [2602.09203v1](http://arxiv.org/abs/2602.09203v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09203v1)

<details><summary><b>Abstract</b></summary>

Robot morphology, the form, shape, and structure of robots, is a key design space in human-robot interaction (HRI), shaping how robots function, express themselves, and interact with people. Yet, despite its importance, little is known about how design frameworks can guide systematic form exploration. To address this gap, we introduce Elements of Robot Morphology, a framework that identifies five fundamental elements: perception, articulation, end effectors, locomotion, and structure. Derived from an analysis of existing robots, the framework supports structured exploration of diverse robot forms. To operationalize the framework, we developed Morphology Exploration Blocks (MEB), a set of tangible blocks that enable hands-on, collaborative experimentation with robot morphologies. We evaluate the framework and toolkit through a case study and design workshops, showing how they support analysis, ideation, reflection, and collaborative robot design.

</details>

<details><summary><b>中文摘要</b></summary>

机器人形态，即机器人的形式、形状和结构，是人机交互（HRI）中的关键设计空间，决定着机器人如何发挥作用、表达自己以及与人互动。然而，尽管设计框架很重要，但人们对如何指导系统形式探索却知之甚少。为了解决这一差距，我们引入了机器人形态学的元素，该框架确定了五个基本元素：感知、关节、末端执行器、运动和结构。该框架源自对现有机器人的分析，支持对不同机器人形式的结构化探索。为了实施该框架，我们开发了形态探索模块（MEB），这是一组有形的模块，可以对机器人形态进行动手、协作实验。我们通过案例研究和设计研讨会评估框架和工具包，展示它们如何支持分析、构思、反思和协作机器人设计。

</details>

---

## 260. Agile asymmetric multi-legged locomotion: contact planning via geometric mechanics and spin model duality

**中文标题**: 敏捷的不对称多足运动：通过几何力学和旋转模型对偶性进行接触规划

**Date**: 2026-02-09 | **arXiv**: [2602.09123v1](http://arxiv.org/abs/2602.09123v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09123v1)

<details><summary><b>Abstract</b></summary>

Legged robot research is presently focused on bipedal or quadrupedal robots, despite capabilities to build robots with many more legs to potentially improve locomotion performance. This imbalance is not necessarily due to hardware limitations, but rather to the absence of principled control frameworks that explain when and how additional legs improve locomotion performance. In multi-legged systems, coordinating many simultaneous contacts introduces a severe curse of dimensionality that challenges existing modeling and control approaches. As an alternative, multi-legged robots are typically controlled using low-dimensional gaits originally developed for bipeds or quadrupeds. These strategies fail to exploit the new symmetries and control opportunities that emerge in higher-dimensional systems. In this work, we develop a principled framework for discovering new control structures in multi-legged locomotion. We use geometric mechanics to reduce contact-rich locomotion planning to a graph optimization problem, and propose a spin model duality framework from statistical mechanics to exploit symmetry breaking and guide optimal gait reorganization. Using this approach, we identify an asymmetric locomotion strategy for a hexapod robot that achieves a forward speed of 0.61 body lengths per cycle (a 50% improvement over conventional gaits). The resulting asymmetry appears at both the control and hardware levels. At the control level, the body orientation oscillates asymmetrically between fast clockwise and slow counterclockwise turning phases for forward locomotion. At the hardware level, two legs on the same side remain unactuated and can be replaced with rigid parts without degrading performance. Numerical simulations and robophysical experiments validate the framework and reveal novel locomotion behaviors that emerge from symmetry reforming in high-dimensional embodied systems.

</details>

<details><summary><b>中文摘要</b></summary>

腿式机器人研究目前主要集中在双足或四足机器人，尽管有能力制造具有更多腿的机器人以潜在地提高运动性能。这种不平衡不一定是由于硬件限制，而是由于缺乏原则性的控制框架来解释额外的腿何时以及如何提高运动性能。在多足系统中，协调许多同时接触会带来严重的维数灾难，这对现有的建模和控制方法提出了挑战。作为替代方案，多足机器人通常使用最初为两足动物或四足动物开发的低维步态进行控制。这些策略未能利用高维系统中出现的新对称性和控制机会。在这项工作中，我们开发了一个原则框架，用于发现多足运动中的新控制结构。我们使用几何力学将富含接触的运动规划简化为图优化问题，并提出了统计力学的自旋模型对偶框架，以利用对称性破缺并指导最佳步态重组。使用这种方法，我们确定了六足机器人的不对称运动策略，该策略实现了每个周期 0.61 个身体长度的前进速度（比传统步态提高了 50%）。由此产生的不对称性同时出现在控制和硬件级别。在控制层面，身体方向在快速顺时针转动阶段和缓慢逆时针转动阶段之间不对称振荡，以实现向前运动。在硬件层面，同一侧的两条腿保持未驱动状态，可以用刚性部件替换，而不会降低性能。数值模拟和机器人物理实验验证了该框架，并揭示了高维体现系统中对称性重组所产生的新颖运动行为。

</details>

---

## 261. TwinRL-VLA: Digital Twin-Driven Reinforcement Learning for Real-World Robotic Manipulation

**中文标题**: TwinRL-VLA：用于现实世界机器人操作的数字孪生驱动强化学习

**Date**: 2026-02-09 | **arXiv**: [2602.09023v1](http://arxiv.org/abs/2602.09023v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09023v1)

<details><summary><b>Abstract</b></summary>

Despite strong generalization capabilities, Vision-Language-Action (VLA) models remain constrained by the high cost of expert demonstrations and insufficient real-world interaction. While online reinforcement learning (RL) has shown promise in improving general foundation models, applying RL to VLA manipulation in real-world settings is still hindered by low exploration efficiency and a restricted exploration space. Through systematic real-world experiments, we observe that the effective exploration space of online RL is closely tied to the data distribution of supervised fine-tuning (SFT). Motivated by this observation, we propose TwinRL, a digital twin-real-world collaborative RL framework designed to scale and guide exploration for VLA models. First, a high-fidelity digital twin is efficiently reconstructed from smartphone-captured scenes, enabling realistic bidirectional transfer between real and simulated environments. During the SFT warm-up stage, we introduce an exploration space expansion strategy using digital twins to broaden the support of the data trajectory distribution. Building on this enhanced initialization, we propose a sim-to-real guided exploration strategy to further accelerate online RL. Specifically, TwinRL performs efficient and parallel online RL in the digital twin prior to deployment, effectively bridging the gap between offline and online training stages. Subsequently, we exploit efficient digital twin sampling to identify failure-prone yet informative configurations, which are used to guide targeted human-in-the-loop rollouts on the real robot. In our experiments, TwinRL approaches 100% success in both in-distribution regions covered by real-world demonstrations and out-of-distribution regions, delivering at least a 30% speedup over prior real-world RL methods and requiring only about 20 minutes on average across four tasks.

</details>

<details><summary><b>中文摘要</b></summary>

尽管泛化能力很强，但视觉-语言-动作（VLA）模型仍然受到专家演示成本高昂和现实世界交互不足的限制。虽然在线强化学习 (RL) 在改进通用基础模型方面表现出了良好的前景，但在现实环境中将 RL 应用于 VLA 操作仍然受到探索效率低和探索空间有限的阻碍。通过系统的现实世界实验，我们观察到在线强化学习的有效探索空间与监督微调（SFT）的数据分布密切相关。受这一观察的启发，我们提出了 TwinRL，这是一种数字孪生现实世界协作 RL 框架，旨在扩展和指导 VLA 模型的探索。首先，从智能手机捕获的场景中有效地重建高保真数字孪生，从而实现真实环境和模拟环境之间的真实双向传输。在SFT预热阶段，我们引入了使用数字孪生的探索空间扩展策略，以拓宽数据轨迹分布的支持。基于这种增强的初始化，我们提出了一种模拟到真实的引导探索策略，以进一步加速在线强化学习。具体来说，TwinRL 在部署之前在数字孪生中执行高效且并行的在线强化学习，有效地弥合了离线和在线训练阶段之间的差距。随后，我们利用高效的数字孪生采样来识别容易发生故障但信息丰富的配置，这些配置用于指导在真实机器人上进行有针对性的人机交互。在我们的实验中，TwinRL 在现实世界演示覆盖的分布内区域和分布外区域均取得了 100% 的成功，比之前的现实世界 RL 方法至少提高了 30% 的速度，并且四项任务平均只需要大约 20 分钟。

</details>

---

## 262. From Obstacles to Etiquette: Robot Social Navigation with VLM-Informed Path Selection

**中文标题**: 从障碍到礼节：具有 VLM 通知路径选择的机器人社交导航

**Date**: 2026-02-09 | **arXiv**: [2602.09002v1](http://arxiv.org/abs/2602.09002v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09002v1)

<details><summary><b>Abstract</b></summary>

Navigating socially in human environments requires more than satisfying geometric constraints, as collision-free paths may still interfere with ongoing activities or conflict with social norms. Addressing this challenge calls for analyzing interactions between agents and incorporating common-sense reasoning into planning. This paper presents a social robot navigation framework that integrates geometric planning with contextual social reasoning. The system first extracts obstacles and human dynamics to generate geometrically feasible candidate paths, then leverages a fine-tuned vision-language model (VLM) to evaluate these paths, informed by contextually grounded social expectations, selecting a socially optimized path for the controller. This task-specific VLM distills social reasoning from large foundation models into a smaller and efficient model, allowing the framework to perform real-time adaptation in diverse human-robot interaction contexts. Experiments in four social navigation contexts demonstrate that our method achieves the best overall performance with the lowest personal space violation duration, the minimal pedestrian-facing time, and no social zone intrusions. Project page: https://path-etiquette.github.io

</details>

<details><summary><b>中文摘要</b></summary>

在人类环境中进行社交导航需要的不仅仅是满足几何约束，因为无碰撞路径仍然可能干扰正在进行的活动或与社会规范发生冲突。应对这一挑战需要分析代理之间的交互并将常识推理纳入规划中。本文提出了一种将几何规划与情境社交推理相结合的社交机器人导航框架。该系统首先提取障碍物和人体动态，以生成几何上可行的候选路径，然后利用微调的视觉语言模型（VLM）来评估这些路径，并根据基于上下文的社会期望来评估这些路径，为控制器选择一条社会优化路径。这种特定于任务的 VLM 将大型基础模型中的社会推理提炼为更小且高效的模型，使框架能够在不同的人机交互环境中执行实时适应。在四种社交导航环境中的实验表明，我们的方法实现了最佳的整体性能，具有最低的个人空间侵犯持续时间、最短的行人面对时间并且没有社交区域入侵。项目页面：https://path-etiquette.github.io

</details>

---

## 263. CLUE: Crossmodal disambiguation via Language-vision Understanding with attEntion

**中文标题**: 线索：通过语言视觉理解和注意进行跨模态消歧

**Date**: 2026-02-09 | **arXiv**: [2602.08999v1](http://arxiv.org/abs/2602.08999v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.08999v1)

<details><summary><b>Abstract</b></summary>

With the increasing integration of robots into daily life, human-robot interaction has become more complex and multifaceted. A critical component of this interaction is Interactive Visual Grounding (IVG), through which robots must interpret human intentions and resolve ambiguity. Existing IVG models generally lack a mechanism to determine when to ask clarification questions, as they implicitly rely on their learned representations. CLUE addresses this gap by converting the VLM's cross-modal attention into an explicit, spatially grounded signal for deciding when to ask. We extract text to image attention maps and pass them to a lightweight CNN to detect referential ambiguity, while a LoRA fine-tuned decoder conducts the dialog and emits grounding location tokens. We train on a real-world interactive dataset for IVG, and a mixed ambiguity set for the detector. With InViG-only supervision, our model surpasses a state-of-the-art method while using parameter-efficient fine-tuning. Similarly, the ambiguity detector outperforms prior baselines. Overall, CLUE turns the internal cross-modal attention of a VLM into an explicit, spatially grounded signal for deciding when to ask. The data and code are publicly available at: mouadabrini.github.io/clue

</details>

<details><summary><b>中文摘要</b></summary>

随着机器人越来越融入日常生活，人机交互变得更加复杂和多层面。这种交互的一个关键组成部分是交互式视觉基础（IVG），机器人必须通过它解释人类的意图并解决歧义。现有的 IVG 模型通常缺乏确定何时提出澄清问题的机制，因为它们隐含地依赖于其学习到的表示。 CLUE 通过将 VLM 的跨模式注意力转换为明确的、基于空间的信号来决定何时询问，从而解决了这一差距。我们将文本提取到图像注意力图，并将它们传递给轻量级 CNN 来检测引用歧义，而 LoRA 微调解码器则进行对话并发出接地位置标记。我们在 IVG 的真实交互数据集和检测器的混合模糊度集上进行训练。通过仅 InViG 的监督，我们的模型超越了最先进的方法，同时使用了参数高效的微调。同样，歧义检测器的性能优于先前的基线。总体而言，CLUE 将 VLM 的内部跨模态注意力转化为明确的、基于空间的信号，用于决定何时提问。数据和代码可公开获取：mouadabrini.github.io/clue

</details>

---

## 264. Legs Over Arms: On the Predictive Value of Lower-Body Pose for Human Trajectory Prediction from Egocentric Robot Perception

**中文标题**: 双腿放在手臂上：论下半身姿势对基于自我中心机器人感知的人体轨迹预测的预测价值

**Date**: 2026-02-09 | **arXiv**: [2602.09076v1](http://arxiv.org/abs/2602.09076v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.09076v1)

<details><summary><b>Abstract</b></summary>

Predicting human trajectory is crucial for social robot navigation in crowded environments. While most existing approaches treat human as point mass, we present a study on multi-agent trajectory prediction that leverages different human skeletal features for improved forecast accuracy. In particular, we systematically evaluate the predictive utility of 2D and 3D skeletal keypoints and derived biomechanical cues as additional inputs. Through a comprehensive study on the JRDB dataset and another new dataset for social navigation with 360-degree panoramic videos, we find that focusing on lower-body 3D keypoints yields a 13% reduction in Average Displacement Error and augmenting 3D keypoint inputs with corresponding biomechanical cues provides a further 1-4% improvement. Notably, the performance gain persists when using 2D keypoint inputs extracted from equirectangular panoramic images, indicating that monocular surround vision can capture informative cues for motion forecasting. Our finding that robots can forecast human movement efficiently by watching their legs provides actionable insights for designing sensing capabilities for social robot navigation.

</details>

<details><summary><b>中文摘要</b></summary>

预测人类轨迹对于社交机器人在拥挤环境中的导航至关重要。虽然大多数现有方法将人类视为质点，但我们提出了一项关于多智能体轨迹预测的研究，该研究利用不同的人类骨骼特征来提高预测准确性。特别是，我们系统地评估 2D 和 3D 骨骼关键点的预测效用以及派生的生物力学线索作为额外输入。通过对 JRDB 数据集和另一个用于 360 度全景视频社交导航的新数据集的综合研究，我们发现，关注下半身 3D 关键点可使平均位移误差减少 13%，而通过相应的生物力学线索增强 3D 关键点输入可进一步提高 1-4%。值得注意的是，当使用从等距柱状全景图像提取的 2D 关键点输入时，性能增益仍然存在，这表明单目环绕视觉可以捕获用于运动预测的信息线索。我们发现机器人可以通过观察人类的腿部来有效预测人类的运动，这为设计社交机器人导航的传感功能提供了可行的见解。

</details>

---

## 265. Multi-Staged Framework for Safety Analysis of Offloaded Services in Distributed Intelligent Transportation Systems

**中文标题**: 分布式智能交通系统卸载服务安全分析的多阶段框架

**Date**: 2026-02-09 | **arXiv**: [2602.08821v1](http://arxiv.org/abs/2602.08821v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.08821v1)

<details><summary><b>Abstract</b></summary>

The integration of service-oriented architectures (SOA) with function offloading for distributed, intelligent transportation systems (ITS) offers the opportunity for connected autonomous vehicles (CAVs) to extend their locally available services. One major goal of offloading a subset of functions in the processing chain of a CAV to remote devices is to reduce the overall computational complexity on the CAV. The extension of using remote services, however, requires careful safety analysis, since the remotely created data are corrupted more easily, e.g., through an attacker on the remote device or by intercepting the wireless transmission. To tackle this problem, we first analyze the concept of SOA for distributed environments. From this, we derive a safety framework that validates the reliability of remote services and the data received locally. Since it is possible for the autonomous driving task to offload multiple different services, we propose a specific multi-staged framework for safety analysis dependent on the service composition of local and remote services. For efficiency reasons, we directly include the multi-staged framework for safety analysis in our service-oriented function offloading framework (SOFOF) that we have proposed in earlier work. The evaluation compares the performance of the extended framework considering computational complexity, with energy savings being a major motivation for function offloading, and its capability to detect data from corrupted remote services.

</details>

<details><summary><b>中文摘要</b></summary>

面向服务的架构 (SOA) 与分布式智能交通系统 (ITS) 功能卸载的集成为联网自动驾驶车辆 (CAV) 提供了扩展其本地可用服务的机会。将 CAV 处理链中的功能子集卸载到远程设备的一个主要目标是降低 CAV 的整体计算复杂性。然而，使用远程服务的扩展需要仔细的安全分析，因为远程创建的数据更容易被破坏，例如，通过远程设备上的攻击者或通过拦截无线传输。为了解决这个问题，我们首先分析分布式环境的 SOA 概念。由此，我们推导出一个安全框架，用于验证远程服务和本地接收的数据的可靠性。由于自动驾驶任务可以卸载多个不同的服务，因此我们提出了一个具体的多阶段框架，用于依赖于本地和远程服务的服务组合进行安全分析。出于效率原因，我们直接将多阶段安全分析框架包含在我们在早期工作中提出的面向服务的功能卸载框架（SOFOF）中。该评估比较了扩展框架的性能，考虑到计算复杂性，节能是功能卸载的主要动机，以及从损坏的远程服务中检测数据的能力。

</details>

---

## 266. A Generic Service-Oriented Function Offloading Framework for Connected Automated Vehicles

**中文标题**: 适用于互联自动驾驶汽车的通用面向服务的功能卸载框架

**Date**: 2026-02-09 | **arXiv**: [2602.08799v1](http://arxiv.org/abs/2602.08799v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.08799v1)

<details><summary><b>Abstract</b></summary>

Function offloading is a promising solution to address limitations concerning computational capacity and available energy of Connected Automated Vehicles~(CAVs) or other autonomous robots by distributing computational tasks between local and remote computing devices in form of distributed services. This paper presents a generic function offloading framework that can be used to offload an arbitrary set of computational tasks with a focus on autonomous driving. To provide flexibility, the function offloading framework is designed to incorporate different offloading decision making algorithms and quality of service~(QoS) requirements that can be adjusted to different scenarios or the objectives of the CAVs. With a focus on the applicability, we propose an efficient location-based approach, where the decision whether tasks are processed locally or remotely depends on the location of the CAV. We apply the proposed framework on the use case of service-oriented trajectory planning, where we offload the trajectory planning task of CAVs to a Multi-Access Edge Computing~(MEC) server. The evaluation is conducted in both simulation and real-world application. It demonstrates the potential of the function offloading framework to guarantee the QoS for trajectory planning while improving the computational efficiency of the CAVs. Moreover, the simulation results also show the adaptability of the framework to diverse scenarios involving simultaneous offloading requests from multiple CAVs.

</details>

<details><summary><b>中文摘要</b></summary>

功能卸载是一种很有前途的解决方案，可以通过以分布式服务的形式在本地和远程计算设备之间分配计算任务来解决联网自动驾驶车辆（CAV）或其他自主机器人的计算能力和可用能量的限制。本文提出了一种通用功能卸载框架，可用于卸载任意一组计算任务，重点关注自动驾驶。为了提供灵活性，功能卸载框架被设计为合并不同的卸载决策算法和服务质量（QoS）要求，可以根据不同的场景或 CAV 的目标进行调整。着眼于适用性，我们提出了一种有效的基于位置的方法，其中任务是在本地还是远程处理的决定取决于 CAV 的位置。我们将所提出的框架应用于面向服务的轨迹规划用例，其中我们将 CAV 的轨迹规划任务卸载到多访问边缘计算（MEC）服务器。评估是在模拟和实际应用中进行的。它展示了功能卸载框架在保证轨迹规划的 QoS 的同时提高 CAV 的计算效率的潜力。此外，模拟结果还显示了该框架对涉及多个 CAV 同时卸载请求的不同场景的适应性。

</details>

---

## 267. GaussianCaR: Gaussian Splatting for Efficient Camera-Radar Fusion

**中文标题**: GaussianCaR：用于高效相机雷达融合的高斯泼溅

**Date**: 2026-02-09 | **arXiv**: [2602.08784v1](http://arxiv.org/abs/2602.08784v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.08784v1)

<details><summary><b>Abstract</b></summary>

Robust and accurate perception of dynamic objects and map elements is crucial for autonomous vehicles performing safe navigation in complex traffic scenarios. While vision-only methods have become the de facto standard due to their technical advances, they can benefit from effective and cost-efficient fusion with radar measurements. In this work, we advance fusion methods by repurposing Gaussian Splatting as an efficient universal view transformer that bridges the view disparity gap, mapping both image pixels and radar points into a common Bird's-Eye View (BEV) representation. Our main contribution is GaussianCaR, an end-to-end network for BEV segmentation that, unlike prior BEV fusion methods, leverages Gaussian Splatting to map raw sensor information into latent features for efficient camera-radar fusion. Our architecture combines multi-scale fusion with a transformer decoder to efficiently extract BEV features. Experimental results demonstrate that our approach achieves performance on par with, or even surpassing, the state of the art on BEV segmentation tasks (57.3%, 82.9%, and 50.1% IoU for vehicles, roads, and lane dividers) on the nuScenes dataset, while maintaining a 3.2x faster inference runtime. Code and project page are available online.

</details>

<details><summary><b>中文摘要</b></summary>

对动态物体和地图元素的鲁棒而准确的感知对于自动驾驶汽车在复杂交通场景中执行安全导航至关重要。虽然仅视觉方法因其技术进步而已成为事实上的标准，但它们可以受益于与雷达测量的有效且经济高效的融合。在这项工作中，我们通过将高斯泼溅重新利用为一种有效的通用视图变换器来改进融合方法，该变换器可以弥合视图视差间隙，将图像像素和雷达点映射到通用鸟瞰图（BEV）表示中。我们的主要贡献是 GaussianCaR，这是一种用于 BEV 分割的端到端网络，与之前的 BEV 融合方法不同，它利用 Gaussian Splatting 将原始传感器信息映射到潜在特征中，以实现高效的相机雷达融合。我们的架构将多尺度融合与变压器解码器相结合，以有效提取 BEV 特征。实验结果表明，我们的方法在 nuScenes 数据集上的 BEV 分割任务（车辆、道路和车道分隔线的 IoU 分别为 57.3%、82.9% 和 50.1%）上实现了与现有技术相当甚至超越的性能，同时保持了 3.2 倍更快的推理运行时间。代码和项目页面可在线获取。

</details>

---

## 268. Mind the Gap: Learning Implicit Impedance in Visuomotor Policies via Intent-Execution Mismatch

**中文标题**: 注意差距：通过意图执行不匹配学习视觉运动策略中的隐式阻抗

**Date**: 2026-02-09 | **arXiv**: [2602.08776v1](http://arxiv.org/abs/2602.08776v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.08776v1)

**Project**: https://xucj98.github.io/mind-the-gap-page/  <details><summary><b>Abstract</b></summary>

Teleoperation inherently relies on the human operator acting as a closed-loop controller to actively compensate for hardware imperfections, including latency, mechanical friction, and lack of explicit force feedback. Standard Behavior Cloning (BC), by mimicking the robot's executed trajectory, fundamentally ignores this compensatory mechanism. In this work, we propose a Dual-State Conditioning framework that shifts the learning objective to "Intent Cloning" (master command). We posit that the Intent-Execution Mismatch, the discrepancy between master command and slave response, is not noise, but a critical signal that physically encodes implicit interaction forces and algorithmically reveals the operator's strategy for overcoming system dynamics. By predicting the master intent, our policy learns to generate a "virtual equilibrium point", effectively realizing implicit impedance control. Furthermore, by explicitly conditioning on the history of this mismatch, the model performs implicit system identification, perceiving tracking errors as external forces to close the control loop. To bridge the temporal gap caused by inference latency, we further formulate the policy as a trajectory inpainter to ensure continuous control. We validate our approach on a sensorless, low-cost bi-manual setup. Empirical results across tasks requiring contact-rich manipulation and dynamic tracking reveal a decisive gap: while standard execution-cloning fails due to the inability to overcome contact stiffness and tracking lag, our mismatch-aware approach achieves robust success. This presents a minimalist behavior cloning framework for low-cost hardware, enabling force perception and dynamic compensation without relying on explicit force sensing. Videos are available on the \href{https://xucj98.github.io/mind-the-gap-page/}{project page}.

</details>

<details><summary><b>中文摘要</b></summary>

远程操作本质上依赖于人类操作员充当闭环控制器来主动补偿硬件缺陷，包括延迟、机械摩擦和缺乏明确的力反馈。标准行为克隆（BC）通过模仿机器人的执行轨迹，从根本上忽略了这种补偿机制。在这项工作中，我们提出了一个双状态调节框架，将学习目标转变为“意图克隆”（主命令）。我们假设意图执行不匹配（主命令和从响应之间的差异）不是噪声，而是一个关键信号，它对隐式交互力进行物理编码，并在算法上揭示操作员克服系统动态的策略。通过预测主意图，我们的策略学会生成“虚拟平衡点”，有效地实现隐式阻抗控制。此外，通过明确地调节这种不匹配的历史，该模型执行隐式系统识别，将跟踪误差视为关闭控制环路的外力。为了弥补推理延迟造成的时间差距，我们进一步将该策略制定为轨迹修复器，以确保连续控制。我们在无传感器、低成本的双手动设置上验证了我们的方法。需要大量接触操作和动态跟踪的任务的经验结果揭示了决定性的差距：虽然标准执行克隆由于无法克服接触刚度和跟踪滞后而失败，但我们的失配感知方法取得了巨大的成功。这为低成本硬件提供了一个极简行为克隆框架，无需依赖显式力传感即可实现力感知和动态补偿。视频可在 \href{https://xucj98.github.io/mind-the-gap-page/}{项目页面} 上找到。

</details>

---

## 269. High-Speed Vision-Based Flight in Clutter with Safety-Shielded Reinforcement Learning

**中文标题**: 利用安全防护强化学习在杂波中实现基于视觉的高速飞行

**Date**: 2026-02-09 | **arXiv**: [2602.08653v1](http://arxiv.org/abs/2602.08653v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.08653v1)

<details><summary><b>Abstract</b></summary>

Quadrotor unmanned aerial vehicles (UAVs) are increasingly deployed in complex missions that demand reliable autonomous navigation and robust obstacle avoidance. However, traditional modular pipelines often incur cumulative latency, whereas purely reinforcement learning (RL) approaches typically provide limited formal safety guarantees. To bridge this gap, we propose an end-to-end RL framework augmented with model-based safety mechanisms. We incorporate physical priors in both training and deployment. During training, we design a physics-informed reward structure that provides global navigational guidance. During deployment, we integrate a real-time safety filter that projects the policy outputs onto a provably safe set to enforce strict collision-avoidance constraints. This hybrid architecture reconciles high-speed flight with robust safety assurances. Benchmark evaluations demonstrate that our method outperforms both traditional planners and recent end-to-end obstacle avoidance approaches based on differentiable physics. Extensive experiments demonstrate strong generalization, enabling reliable high-speed navigation in dense clutter and challenging outdoor forest environments at velocities up to 7.5m/s.

</details>

<details><summary><b>中文摘要</b></summary>

四旋翼无人机 (UAV) 越来越多地部署在需要可靠自主导航和强大避障功能的复杂任务中。然而，传统的模块化管道经常会产生累积延迟，而纯粹的强化学习（RL）方法通常提供有限的形式安全保证。为了弥补这一差距，我们提出了一个端到端的强化学习框架，并增强了基于模型的安全机制。我们将物理先验纳入训练和部署中。在训练过程中，我们设计了一个基于物理的奖励结构，提供全球导航指导。在部署过程中，我们集成了一个实时安全过滤器，将策略输出投影到可证明安全的集合上，以强制执行严格的防碰撞约束。这种混合架构将高速飞行与强大的安全保证融为一体。基准评估表明，我们的方法优于传统规划器和最近基于可微物理的端到端避障方法。大量实验证明了其强大的泛化能力，能够在密集杂波和具有挑战性的室外森林环境中以高达 7.5m/s 的速度实现可靠的高速导航。

</details>

---

## 270. Mimic Intent, Not Just Trajectories

**中文标题**: 模仿意图，而不仅仅是轨迹

**Date**: 2026-02-09 | **arXiv**: [2602.08602v1](http://arxiv.org/abs/2602.08602v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.08602v1)

<details><summary><b>Abstract</b></summary>

While imitation learning (IL) has achieved impressive success in dexterous manipulation through generative modeling and pretraining, state-of-the-art approaches like Vision-Language-Action (VLA) models still struggle with adaptation to environmental changes and skill transfer. We argue this stems from mimicking raw trajectories without understanding the underlying intent. To address this, we propose explicitly disentangling behavior intent from execution details in end-2-end IL: \textit{``Mimic Intent, Not just Trajectories'' (MINT)}. We achieve this via \textit{multi-scale frequency-space tokenization}, which enforces a spectral decomposition of action chunk representation. We learn action tokens with a multi-scale coarse-to-fine structure, and force the coarsest token to capture low-frequency global structure and finer tokens to encode high-frequency details. This yields an abstract \textit{Intent token} that facilitates planning and transfer, and multi-scale \textit{Execution tokens} that enable precise adaptation to environmental dynamics. Building on this hierarchy, our policy generates trajectories through \textit{next-scale autoregression}, performing progressive \textit{intent-to-execution reasoning}, thus boosting learning efficiency and generalization. Crucially, this disentanglement enables \textit{one-shot transfer} of skills, by simply injecting the Intent token from a demonstration into the autoregressive generation process. Experiments on several manipulation benchmarks and on a real robot demonstrate state-of-the-art success rates, superior inference efficiency, robust generalization against disturbances, and effective one-shot transfer.

</details>

<details><summary><b>中文摘要</b></summary>

虽然模仿学习（IL）通过生成建模和预训练在灵巧操作方面取得了令人印象深刻的成功，但视觉-语言-动作（VLA）模型等最先进的方法仍然难以适应环境变化和技能转移。我们认为这源于模仿原始轨迹而不理解潜在的意图。为了解决这个问题，我们建议明确地将行为意图与 end-2-end IL 中的执行细节分开：\textit{``模仿意图，不仅仅是轨迹''（MINT）}。我们通过 \textit{多尺度频率空间标记化} 来实现这一点，它强制执行动作块表示的频谱分解。我们学习具有多尺度从粗到细结构的动作标记，并强制最粗糙的标记捕获低频全局结构，并强制更精细的标记编码高频细节。这产生了一个抽象的\textit{意图令牌}，有助于规划和传输，以及多尺度的\textit{执行令牌}，可以精确适应环境动态。在此层次结构的基础上，我们的策略通过 \textit{next-scale autoregression} 生成轨迹，执行渐进的 \textit{意图执行推理}，从而提高学习效率和泛化能力。至关重要的是，这种解开可以通过简单地将演示中的意图令牌注入自回归生成过程来实现技能的 \textit{一次性迁移}。在多个操纵基准和真实机器人上进行的实验证明了最先进的成功率、卓越的推理效率、针对干扰的鲁棒泛化以及有效的一次性迁移。

</details>

---

## 271. A Precise Real-Time Force-Aware Grasping System for Robust Aerial Manipulation

**中文标题**: 用于稳健空中操纵的精确实时力感知抓取系统

**Date**: 2026-02-09 | **arXiv**: [2602.08599v1](http://arxiv.org/abs/2602.08599v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.08599v1)

<details><summary><b>Abstract</b></summary>

Aerial manipulation requires force-aware capabilities to enable safe and effective grasping and physical interaction. Previous works often rely on heavy, expensive force sensors unsuitable for typical quadrotor platforms, or perform grasping without force feedback, risking damage to fragile objects. To address these limitations, we propose a novel force-aware grasping framework incorporating six low-cost, sensitive skin-like tactile sensors. We introduce a magnetic-based tactile sensing module that provides high-precision three-dimensional force measurements. We eliminate geomagnetic interference through a reference Hall sensor and simplify the calibration process compared to previous work. The proposed framework enables precise force-aware grasping control, allowing safe manipulation of fragile objects and real-time weight measurement of grasped items. The system is validated through comprehensive real-world experiments, including balloon grasping, dynamic load variation tests, and ablation studies, demonstrating its effectiveness in various aerial manipulation scenarios. Our approach achieves fully onboard operation without external motion capture systems, significantly enhancing the practicality of force-sensitive aerial manipulation. The supplementary video is available at: https://www.youtube.com/watch?v=mbcZkrJEf1I.

</details>

<details><summary><b>中文摘要</b></summary>

空中操纵需要力感知能力，以实现安全有效的抓取和物理交互。以前的工作通常依赖于笨重、昂贵的力传感器，不适合典型的四旋翼平台，或者在没有力反馈的情况下进行抓取，从而存在损坏易碎物体的风险。为了解决这些限制，我们提出了一种新颖的力感知抓取框架，该框架包含六个低成本、敏感的类皮肤触觉传感器。我们推出了一种基于磁性的触觉传感模块，可提供高精度的三维力测量。与之前的工作相比，我们通过参考霍尔传感器消除了地磁干扰并简化了校准过程。所提出的框架可以实现精确的力感知抓取控制，从而可以安全地操纵易碎物体并实时测量抓取的物品的重量。该系统通过全面的真实实验进行了验证，包括气球抓取、动态负载变化测试和烧蚀研究，证明了其在各种空中操纵场景中的有效性。我们的方法无需外部动作捕捉系统即可实现完全机载操作，显着增强了力敏感空中操纵的实用性。补充视频可在以下网址获取：https://www.youtube.com/watch?v=mbcZkrJEf1I。

</details>

---

## 272. MOSAIC: Bridging the Sim-to-Real Gap in Generalist Humanoid Motion Tracking and Teleoperation with Rapid Residual Adaptation

**中文标题**: MOSAIC：通过快速残差适应来弥合通用人形运动跟踪和远程操作中的模拟与真实差距

**Date**: 2026-02-09 | **arXiv**: [2602.08594v1](http://arxiv.org/abs/2602.08594v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.08594v1)

<details><summary><b>Abstract</b></summary>

Generalist humanoid motion trackers have recently achieved strong simulation metrics by scaling data and training, yet often remain brittle on hardware during sustained teleoperation due to interface- and dynamics-induced errors. We present MOSAIC, an open-source, full-stack system for humanoid motion tracking and whole-body teleoperation across multiple interfaces. MOSAIC first learns a teleoperation-oriented general motion tracker via RL on a multi-source motion bank with adaptive resampling and rewards that emphasize world-frame motion consistency, which is critical for mobile teleoperation. To bridge the sim-to-real interface gap without sacrificing generality, MOSAIC then performs rapid residual adaptation: an interface-specific policy is trained using minimal interface-specific data, and then distilled into the general tracker through an additive residual module, outperforming naive fine-tuning or continual learning. We validate MOSAIC with systematic ablations, out-of-distribution benchmarking, and real-robot experiments demonstrating robust offline motion replay and online long-horizon teleoperation under realistic latency and noise.

</details>

<details><summary><b>中文摘要</b></summary>

通用类人运动跟踪器最近通过扩展数据和训练实现了强大的模拟指标，但由于接口和动力学引起的错误，在持续远程操作期间，硬件通常仍然脆弱。我们推出 MOSAIC，这是一种开源全栈系统，用于跨多个界面的人形运动跟踪和全身远程操作。 MOSAIC 首先通过 RL 在多源运动库上学习面向远程操作的通用运动跟踪器，具有自适应重采样和奖励，强调世界框架运动一致性，这对于移动远程操作至关重要。为了在不牺牲通用性的情况下弥合模拟与真实接口之间的差距，MOSAIC 然后执行快速残差适应：使用最少的特定于接口的数据来训练特定于接口的策略，然后通过附加残差模块将其提炼到通用跟踪器中，从而优于朴素的微调或持续学习。我们通过系统消融、分布外基准测试和真实机器人实验来验证 MOSAIC，这些实验展示了在真实延迟和噪声下强大的离线运动重放和在线长视距远程操作。

</details>

---

## 273. Head-to-Head autonomous racing at the limits of handling in the A2RL challenge

**中文标题**: 在 A2RL 挑战赛中挑战操控极限的头对头自动驾驶赛车

**Date**: 2026-02-09 | **arXiv**: [2602.08571v1](http://arxiv.org/abs/2602.08571v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.08571v1)

<details><summary><b>Abstract</b></summary>

Autonomous racing presents a complex challenge involving multi-agent interactions between vehicles operating at the limit of performance and dynamics. As such, it provides a valuable research and testing environment for advancing autonomous driving technology and improving road safety. This article presents the algorithms and deployment strategies developed by the TUM Autonomous Motorsport team for the inaugural Abu Dhabi Autonomous Racing League (A2RL). We showcase how our software emulates human driving behavior, pushing the limits of vehicle handling and multi-vehicle interactions to win the A2RL. Finally, we highlight the key enablers of our success and share our most significant learnings.

</details>

<details><summary><b>中文摘要</b></summary>

自动驾驶赛车提出了一个复杂的挑战，涉及在性能和动态极限下运行的车辆之间的多智能体交互。因此，它为推进自动驾驶技术和提高道路安全提供了宝贵的研究和测试环境。本文介绍了慕尼黑工业大学自动驾驶赛车运动团队为首届阿布扎比自动驾驶赛车联盟 (A2RL) 开发的算法和部署策略。我们展示我们的软件如何模拟人类驾驶行为，突破车辆操控和多车辆交互的极限，从而赢得 A2RL。最后，我们强调了我们成功的关键推动因素，并分享了我们最重要的经验教训。

</details>

---

## 274. Constrained Sampling to Guide Universal Manipulation RL

**中文标题**: 约束采样指导通用操纵强化学习

**Date**: 2026-02-09 | **arXiv**: [2602.08557v1](http://arxiv.org/abs/2602.08557v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.08557v1)

<details><summary><b>Abstract</b></summary>

We consider how model-based solvers can be leveraged to guide training of a universal policy to control from any feasible start state to any feasible goal in a contact-rich manipulation setting. While Reinforcement Learning (RL) has demonstrated its strength in such settings, it may struggle to sufficiently explore and discover complex manipulation strategies, especially in sparse-reward settings. Our approach is based on the idea of a lower-dimensional manifold of feasible, likely-visited states during such manipulation and to guide RL with a sampler from this manifold. We propose Sample-Guided RL, which uses model-based constraint solvers to efficiently sample feasible configurations (satisfying differentiable collision, contact, and force constraints) and leverage them to guide RL for universal (goal-conditioned) manipulation policies. We study using this data directly to bias state visitation, as well as using black-box optimization of open-loop trajectories between random configurations to impose a state bias and optionally add a behavior cloning loss. In a minimalistic double sphere manipulation setting, Sample-Guided RL discovers complex manipulation strategies and achieves high success rates in reaching any statically stable state. In a more challenging panda arm setting, our approach achieves a significant success rate over a near-zero baseline, and demonstrates a breadth of complex whole-body-contact manipulation strategies.

</details>

<details><summary><b>中文摘要</b></summary>

我们考虑如何利用基于模型的求解器来指导通用策略的训练，以在接触丰富的操纵设置中控制从任何可行的起始状态到任何可行的目标。虽然强化学习 (RL) 在此类环境中展示了其优势，但它可能很难充分探索和发现复杂的操纵策略，尤其是在稀疏奖励环境中。我们的方法基于这样的操作过程中可行的、可能访问的状态的低维流形的想法，并使用来自该流形的采样器来指导强化学习。我们提出了 Sample-Guided RL，它使用基于模型的约束求解器来有效地采样可行的配置（满足可微的碰撞、接触和力约束），并利用它们来指导 RL 实现通用（目标条件）操纵策略。我们研究直接使用这些数据来偏置状态访问，以及使用随机配置之间的开环轨迹的黑盒优化来施加状态偏差并可选择添加行为克隆损失。在简约的双球操纵设置中，样本引导强化学习发现了复杂的操纵策略，并在达到任何静态稳定状态方面取得了很高的成功率。在更具挑战性的熊猫手臂环境中，我们的方法在接近零的基线上实现了显着的成功率，并展示了广泛的复杂的全身接触操纵策略。

</details>

---

## 275. UniPlan: Vision-Language Task Planning for Mobile Manipulation with Unified PDDL Formulation

**中文标题**: UniPlan：具有统一 PDDL 公式的移动操作视觉语言任务规划

**Date**: 2026-02-09 | **arXiv**: [2602.08537v1](http://arxiv.org/abs/2602.08537v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.08537v1)

<details><summary><b>Abstract</b></summary>

Integration of VLM reasoning with symbolic planning has proven to be a promising approach to real-world robot task planning. Existing work like UniDomain effectively learns symbolic manipulation domains from real-world demonstrations, described in Planning Domain Definition Language (PDDL), and has successfully applied them to real-world tasks. These domains, however, are restricted to tabletop manipulation. We propose UniPlan, a vision-language task planning system for long-horizon mobile-manipulation in large-scale indoor environments, that unifies scene topology, visuals, and robot capabilities into a holistic PDDL representation. UniPlan programmatically extends learned tabletop domains from UniDomain to support navigation, door traversal, and bimanual coordination. It operates on a visual-topological map, comprising navigation landmarks anchored with scene images. Given a language instruction, UniPlan retrieves task-relevant nodes from the map and uses a VLM to ground the anchored image into task-relevant objects and their PDDL states; next, it reconnects these nodes to a compressed, densely-connected topological map, also represented in PDDL, with connectivity and costs derived from the original map; Finally, a mobile-manipulation plan is generated using off-the-shelf PDDL solvers. Evaluated on human-raised tasks in a large-scale map with real-world imagery, UniPlan significantly outperforms VLM and LLM+PDDL planning in success rate, plan quality, and computational efficiency.

</details>

<details><summary><b>中文摘要</b></summary>

VLM 推理与符号规划的集成已被证明是现实世界机器人任务规划的一种有前途的方法。像 UniDomain 这样的现有工作可以有效地从现实世界的演示中学习符号操作域，如规划域定义语言 (PDDL) 中所述，并已成功地将它们应用到现实世界的任务中。然而，这些域仅限于桌面操作。我们提出了 UniPlan，这是一种用于大规模室内环境中长视距移动操作的视觉语言任务规划系统，它将场景拓扑、视觉效果和机器人功能统一到整体 PDDL 表示中。 UniPlan 以编程方式扩展从 UniDomain 学习的桌面域，以支持导航、门遍历和双手协调。它在视觉拓扑地图上运行，包括锚定场景图像的导航地标。给定语言指令，UniPlan 从地图中检索与任务相关的节点，并使用 VLM 将锚定图像转化为与任务相关的对象及其 PDDL 状态；接下来，它将这些节点重新连接到压缩的、密集连接的拓扑图，也以 PDDL 表示，连接性和成本来自原始地图；最后，使用现成的 PDDL 求解器生成移动操纵计划。在具有真实世界图像的大规模地图中对人工任务进行评估后，UniPlan 在成功率、计划质量和计算效率方面显着优于 VLM 和 LLM+PDDL 规划。

</details>

---

## 276. Reliability-aware Execution Gating for Near-field and Off-axis Vision-guided Robotic Alignment

**中文标题**: 用于近场和离轴视觉引导机器人对准的可靠性感知执行门控

**Date**: 2026-02-09 | **arXiv**: [2602.08466v1](http://arxiv.org/abs/2602.08466v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.08466v1)

<details><summary><b>Abstract</b></summary>

Vision-guided robotic systems are increasingly deployed in precision alignment tasks that require reliable execution under near-field and off-axis configurations. While recent advances in pose estimation have significantly improved numerical accuracy, practical robotic systems still suffer from frequent execution failures even when pose estimates appear accurate. This gap suggests that pose accuracy alone is insufficient to guarantee execution-level reliability. In this paper, we reveal that such failures arise from a deterministic geometric error amplification mechanism, in which small pose estimation errors are magnified through system structure and motion execution, leading to unstable or failed alignment. Rather than modifying pose estimation algorithms, we propose a Reliability-aware Execution Gating mechanism that operates at the execution level. The proposed approach evaluates geometric consistency and configuration risk before execution, and selectively rejects or scales high-risk pose updates. We validate the proposed method on a real UR5 robotic platform performing single-step visual alignment tasks under varying camera-target distances and off-axis configurations. Experimental results demonstrate that the proposed execution gating significantly improves task success rates, reduces execution variance, and suppresses tail-risk behavior, while leaving average pose accuracy largely unchanged. Importantly, the proposed mechanism is estimator-agnostic and can be readily integrated with both classical geometry-based and learning-based pose estimation pipelines. These results highlight the importance of execution-level reliability modeling and provide a practical solution for improving robustness in near-field vision-guided robotic systems.

</details>

<details><summary><b>中文摘要</b></summary>

视觉引导机器人系统越来越多地部署在需要在近场和离轴配置下可靠执行的精密对准任务中。尽管姿态估计方面的最新进展显着提高了数值精度，但即使姿态估计看起来准确，实际的机器人系统仍然会频繁出现执行失败。这一差距表明，仅靠姿势精度不足以保证执行级别的可靠性。在本文中，我们揭示了此类故障源于确定性几何误差放大机制，其中小的位姿估计误差通过系统结构和运动执行被放大，导致对准不稳定或失败。我们提出了一种在执行级别运行的可靠性感知执行门控机制，而不是修改姿态估计算法。所提出的方法在执行前评估几何一致性和配置风险，并选择性地拒绝或缩放高风险的姿态更新。我们在真实的 UR5 机器人平台上验证了所提出的方法，在不同的相机目标距离和离轴配置下执行单步视觉对准任务。实验结果表明，所提出的执行门控显着提高了任务成功率，减少了执行方差，并抑制了尾部风险行为，同时平均姿态精度基本保持不变。重要的是，所提出的机制与估计器无关，并且可以轻松地与经典的基于几何和基于学习的姿态估计管道集成。这些结果凸显了执行级可靠性建模的重要性，并为提高近场视觉引导机器人系统的鲁棒性提供了实用的解决方案。

</details>

---

## 277. UAV-Supported Maritime Search System: Experience from Valun Bay Field Trials

**中文标题**: 无人机支持的海上搜索系统：瓦伦湾实地试验经验

**Date**: 2026-02-09 | **arXiv**: [2602.08450v1](http://arxiv.org/abs/2602.08450v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.08450v1)

<details><summary><b>Abstract</b></summary>

This paper presents the integration of flow field reconstruction, dynamic probabilistic modeling, search control, and machine vision detection in a system for autonomous maritime search operations. Field experiments conducted in Valun Bay (Cres Island, Croatia) involved real-time drifter data acquisition, surrogate flow model fitting based on computational fluid dynamics and numerical optimization, advanced multi-UAV search control and vision sensing, as well as deep learning-based object detection. The results demonstrate that a tightly coupled approach enables reliable detection of floating targets under realistic uncertainties and complex environmental conditions, providing concrete insights for future autonomous maritime search and rescue applications.

</details>

<details><summary><b>中文摘要</b></summary>

本文介绍了自主海上搜索操作系统中流场重建、动态概率建模、搜索控制和机器视觉检测的集成。在瓦伦湾（克罗地亚克雷斯岛）进行的现场实验涉及实时漂流器数据采集、基于计算流体动力学和数值优化的替代流模型拟合、先进的多无人机搜索控制和视觉传感，以及基于深度学习的目标检测。结果表明，紧密耦合的方法能够在现实的不确定性和复杂的环境条件下可靠地检测浮动目标，为未来的自主海上搜索和救援应用提供具体的见解。

</details>

---

## 278. Post-Collision Trajectory Restoration for a Single-track Ackermann Vehicle using Heuristic Steering and Tractive Force Functions

**中文标题**: 使用启发式转向和牵引力函数恢复单轨阿克曼车辆的碰撞后轨迹

**Date**: 2026-02-09 | **arXiv**: [2602.08444v1](http://arxiv.org/abs/2602.08444v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.08444v1)

<details><summary><b>Abstract</b></summary>

Post-collision trajectory restoration is a safety-critical capability for autonomous vehicles, as impact-induced lateral motion and yaw transients can rapidly drive the vehicle away from the intended path. This paper proposes a structured heuristic recovery control law that jointly commands steering and tractive force for a generalized single-track Ackermann vehicle model. The formulation explicitly accounts for time-varying longitudinal velocity in the lateral-yaw dynamics and retains nonlinear steering-coupled interaction terms that are commonly simplified in the literature. Unlike approaches that assume constant longitudinal speed, the proposed design targets the transient post-impact regime where speed variations and nonlinear coupling significantly influence recovery. The method is evaluated in simulation on the proposed generalized single-track model and a standard 3DOF single-track reference model in MATLAB, demonstrating consistent post-collision restoration behaviour across representative initial post-impact conditions.

</details>

<details><summary><b>中文摘要</b></summary>

碰撞后轨迹恢复对于自动驾驶车辆来说是一项安全关键的功能，因为碰撞引起的横向运动和偏航瞬态可能会迅速使车辆偏离预期路径。本文提出了一种结构化启发式恢复控制律，为广义单轨阿克曼车辆模型联合控制转向和牵引力。该公式明确地考虑了横向偏航动力学中随时间变化的纵向速度，并保留了文献中通常简化的非线性转向耦合相互作用项。与假定纵向速度恒定的方法不同，所提出的设计针对瞬态撞击后状态，其中速度变化和非线性耦合显着影响恢复。该方法在 MATLAB 中对所提出的广义单轨模型和标准 3DOF 单轨参考模型进行了仿真评估，展示了在代表性初始碰撞后条件下一致的碰撞后恢复行为。

</details>

---

## 279. SteerVLA: Steering Vision-Language-Action Models in Long-Tail Driving Scenarios

**中文标题**: SteerVLA：长尾驾驶场景中的转向视觉-语言-动作模型

**Date**: 2026-02-09 | **arXiv**: [2602.08440v1](http://arxiv.org/abs/2602.08440v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.08440v1)

<details><summary><b>Abstract</b></summary>

A fundamental challenge in autonomous driving is the integration of high-level, semantic reasoning for long-tail events with low-level, reactive control for robust driving. While large vision-language models (VLMs) trained on web-scale data offer powerful common-sense reasoning, they lack the grounded experience necessary for safe vehicle control. We posit that an effective autonomous agent should leverage the world knowledge of VLMs to guide a steerable driving policy toward robust control in driving scenarios. To this end, we propose SteerVLA, which leverages the reasoning capabilities of VLMs to produce fine-grained language instructions that steer a vision-language-action (VLA) driving policy. Key to our method is this rich language interface between the high-level VLM and low-level VLA, which allows the high-level policy to more effectively ground its reasoning in the control outputs of the low-level policy. To provide fine-grained language supervision aligned with vehicle control, we leverage a VLM to augment existing driving data with detailed language annotations, which we find to be essential for effective reasoning and steerability. We evaluate SteerVLA on a challenging closed-loop benchmark, where it outperforms state-of-the-art methods by 4.77 points in overall driving score and by 8.04 points on a long-tail subset. The project website is available at: https://steervla.github.io/.

</details>

<details><summary><b>中文摘要</b></summary>

自动驾驶的一个基本挑战是将长尾事件的高级语义推理与稳健驾驶的低级反应控制相集成。虽然基于网络规模数据训练的大型视觉语言模型 (VLM) 提供了强大的常识推理，但它们缺乏安全车辆控制所需的基础经验。我们认为，一个有效的自主代理应该利用 VLM 的世界知识来指导可操纵的驾驶策略，以实现驾驶场景中的稳健控制。为此，我们提出了 SteerVLA，它利用 VLM 的推理能力来生成细粒度的语言指令，以引导视觉-语言-动作 (VLA) 驱动策略。我们方法的关键是高级 VLM 和低级 VLA 之间的丰富语言接口，它允许高级策略更有效地将其推理建立在低级策略的控制输出中。为了提供与车辆控制相一致的细粒度语言监督，我们利用 VLM 通过详细的语言注释来增强现有的驾驶数据，我们发现这对于有效的推理和可操纵性至关重要。我们在具有挑战性的闭环基准上评估了 SteerVLA，它在整体驾驶得分上比最先进的方法高出 4.77 分，在长尾子集上高出 8.04 分。该项目网站位于：https://steervla.github.io/。

</details>

---

## 280. Bi-Adapt: Few-shot Bimanual Adaptation for Novel Categories of 3D Objects via Semantic Correspondence

**中文标题**: Bi-Adapt：通过语义对应对 3D 对象的新类别进行少量双手适应

**Date**: 2026-02-09 | **arXiv**: [2602.08425v2](http://arxiv.org/abs/2602.08425v2) | **PDF**: [Link](http://arxiv.org/pdf/2602.08425v2)

**Project**: https://biadapt-project.github.io/  <details><summary><b>Abstract</b></summary>

Bimanual manipulation is imperative yet challenging for robots to execute complex tasks, requiring coordinated collaboration between two arms. However, existing methods for bimanual manipulation often rely on costly data collection and training, struggling to generalize to unseen objects in novel categories efficiently. In this paper, we present Bi-Adapt, a novel framework designed for efficient generalization for bimanual manipulation via semantic correspondence. Bi-Adapt achieves cross-category affordance mapping by leveraging the strong capability of vision foundation models. Fine-tuning with restricted data on novel categories, Bi-Adapt exhibits notable generalization to out-of-category objects in a zero-shot manner. Extensive experiments conducted in both simulation and real-world environments validate the effectiveness of our approach and demonstrate its high efficiency, achieving a high success rate on different benchmark tasks across novel categories with limited data. Project website: https://biadapt-project.github.io/

</details>

<details><summary><b>中文摘要</b></summary>

对于机器人执行复杂的任务来说，双手操纵是必要的，但也具有挑战性，需要两臂之间的协调协作。然而，现有的双手操作方法通常依赖于昂贵的数据收集和训练，难以有效地推广到新类别中看不见的物体。在本文中，我们提出了 Bi-Adapt，这是一种新颖的框架，旨在通过语义对应来有效泛化双手操作。 Bi-Adapt利用视觉基础模型的强大能力，实现了跨品类可供性映射。 Bi-Adapt 通过对新颖类别的有限数据进行微调，以零样本的方式对类别外对象表现出显着的泛化能力。在模拟和现实环境中进行的大量实验验证了我们方法的有效性，并证明了其高效率，在数据有限的新类别的不同基准任务上取得了很高的成功率。项目网站：https://biadapt-project.github.io/

</details>

---

## 281. Decentralized Intent-Based Multi-Robot Task Planner with LLM Oracles on Hyperledger Fabric

**中文标题**: Hyperledger Fabric 上具有 LLM Oracle 的分散式基于意图的多机器人任务规划器

**Date**: 2026-02-09 | **arXiv**: [2602.08421v1](http://arxiv.org/abs/2602.08421v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.08421v1)

<details><summary><b>Abstract</b></summary>

Large language models (LLMs) have opened new opportunities for transforming natural language user intents into executable actions. This capability enables embodied AI agents to perform complex tasks, without involvement of an expert, making human-robot interaction (HRI) more convenient. However these developments raise significant security and privacy challenges such as self-preferencing, where a single LLM service provider dominates the market and uses this power to promote their own preferences. LLM oracles have been recently proposed as a mechanism to decentralize LLMs by executing multiple LLMs from different vendors and aggregating their outputs to obtain a more reliable and trustworthy final result. However, the accuracy of these approaches highly depends on the aggregation method. The current aggregation methods mostly use semantic similarity between various LLM outputs, not suitable for robotic task planning, where the temporal order of tasks is important. To fill the gap, we propose an LLM oracle with a new aggregation method for robotic task planning. In addition, we propose a decentralized multi-robot infrastructure based on Hyperledger Fabric that can host the proposed oracle. The proposed infrastructure enables users to express their natural language intent to the system, which then can be decomposed into subtasks. These subtasks require coordinating different robots from different vendors, while enforcing fine-grained access control management on the data. To evaluate our methodology, we created the SkillChain-RTD benchmark made it publicly available. Our experimental results demonstrate the feasibility of the proposed architecture, and the proposed aggregation method outperforms other aggregation methods currently in use.

</details>

<details><summary><b>中文摘要</b></summary>

大型语言模型 (LLM) 为将自然语言用户意图转化为可执行操作提供了新的机会。这种能力使具体的人工智能代理能够执行复杂的任务，而无需专家的参与，使人机交互（HRI）更加方便。然而，这些发展带来了重大的安全和隐私挑战，例如自我偏好，单一法学硕士服务提供商主导市场并利用这种权力来促进自己的偏好。 LLM预言机最近被提议作为一种分散LLM的机制，通过执行来自不同供应商的多个LLM并聚合它们的输出以获得更可靠和值得信赖的最终结果。然而，这些方法的准确性很大程度上取决于聚合方法。当前的聚合方法主要使用各种LLM输出之间的语义相似性，不适合机器人任务规划，其中任务的时间顺序很重要。为了填补这一空白，我们提出了一个 LLM 预言机，它具有用于机器人任务规划的新聚合方法。此外，我们提出了一个基于 Hyperledger Fabric 的去中心化多机器人基础设施，可以托管所提出的预言机。所提出的基础设施使用户能够向系统表达他们的自然语言意图，然后可以将其分解为子任务。这些子任务需要协调来自不同供应商的不同机器人，同时对数据实施细粒度的访问控制管理。为了评估我们的方法，我们创建了 SkillChain-RTD 基准并公开发布。我们的实验结果证明了所提出的架构的可行性，并且所提出的聚合方法优于当前使用的其他聚合方法。

</details>

---

## 282. Graph-Loc: Robust Graph-Based LiDAR Pose Tracking with Compact Structural Map Priors under Low Observability and Occlusion

**中文标题**: Graph-Loc：在低可观测性和遮挡下具有紧凑结构地图先验的基于稳健图的 LiDAR 位姿跟踪

**Date**: 2026-02-09 | **arXiv**: [2602.08417v1](http://arxiv.org/abs/2602.08417v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.08417v1)

<details><summary><b>Abstract</b></summary>

Map-based LiDAR pose tracking is essential for long-term autonomous operation, where onboard map priors need be compact for scalable storage and fast retrieval, while online observations are often partial, repetitive, and heavily occluded. We propose Graph-Loc, a graph-based localization framework that tracks the platform pose against compact structural map priors represented as a lightweight point-line graph. Such priors can be constructed from heterogeneous sources commonly available in practice, including polygon outlines vectorized from occupancy/grid maps and CAD/model/floor-plan layouts. For each incoming LiDAR scan, Graph-Loc extracts sparse point and line primitives to form an observation graph, retrieves a pose-conditioned visible subgraph via LiDAR ray simulation, and performs scan-to-map association through unbalanced optimal transport with a local graph-context regularizer. The unbalanced formulation relaxes mass conservation, improving robustness to missing, spurious, and fragmented structures under occlusion. To enhance stability in low-observability segments, we estimate information anisotropy from the refinement normal matrix and defer updates along weakly constrained directions until sufficient constraints reappear. Experiments on public benchmarks, controlled stress tests, and real-world deployments demonstrate accurate and stable tracking with KB-level priors from heterogeneous map sources, including under geometrically degenerate and sustained occlusion and in the presence of gradual scene changes.

</details>

<details><summary><b>中文摘要</b></summary>

基于地图的 LiDAR 位姿跟踪对于长期自主操作至关重要，其中机载地图先验需要紧凑，以便可扩展存储和快速检索，而在线观察通常是部分的、重复的和严重遮挡的。我们提出了 Graph-Loc，这是一种基于图的定位框架，可以根据表示为轻量级点线图的紧凑结构图先验来跟踪平台姿态。此类先验可以从实践中常见的异构源构建，包括从占用/网格地图和 CAD/模型/平面图布局矢量化的多边形轮廓。对于每次传入的 LiDAR 扫描，Graph-Loc 提取稀疏点和线基元以形成观察图，通过 LiDAR 射线模拟检索姿势条件可见子图，并通过局部图上下文正则化器通过不平衡最佳传输执行扫描到地图关联。不平衡的公式放松了质量守恒，提高了遮挡下缺失、虚假和碎片结构的鲁棒性。为了增强低可观测性段的稳定性，我们从细化法线矩阵估计信息各向异性，并推迟沿弱约束方向的更新，直到重新出现足够的约束。公共基准测试、受控压力测试和现实世界部署的实验证明了来自异构地图源的 KB 级先验的准确和稳定的跟踪，包括在几何退化和持续遮挡以及场景逐渐变化的情况下。

</details>

---

## 283. BiManiBench: A Hierarchical Benchmark for Evaluating Bimanual Coordination of Multimodal Large Language Models

**中文标题**: BiManiBench：评估多模态大语言模型双手协调的分层基准

**Date**: 2026-02-09 | **arXiv**: [2602.08392v1](http://arxiv.org/abs/2602.08392v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.08392v1)

<details><summary><b>Abstract</b></summary>

Multimodal Large Language Models (MLLMs) have significantly advanced embodied AI, and using them to benchmark robotic intelligence has become a pivotal trend. However, existing frameworks remain predominantly confined to single-arm manipulation, failing to capture the spatio-temporal coordination required for bimanual tasks like lifting a heavy pot. To address this, we introduce BiManiBench, a hierarchical benchmark evaluating MLLMs across three tiers: fundamental spatial reasoning, high-level action planning, and low-level end-effector control. Our framework isolates unique bimanual challenges, such as arm reachability and kinematic constraints, thereby distinguishing perceptual hallucinations from planning failures. Analysis of over 30 state-of-the-art models reveals that despite high-level reasoning proficiency, MLLMs struggle with dual-arm spatial grounding and control, frequently resulting in mutual interference and sequencing errors. These findings suggest the current paradigm lacks a deep understanding of mutual kinematic constraints, highlighting the need for future research to focus on inter-arm collision-avoidance and fine-grained temporal sequencing.

</details>

<details><summary><b>中文摘要</b></summary>

多模态大型语言模型 (MLLM) 显着先进了具体人工智能，使用它们来衡量机器人智能已成为一个关键趋势。然而，现有的框架仍然主要局限于单臂操作，无法捕捉双手任务（例如举重锅）所需的时空协调。为了解决这个问题，我们引入了 BiManiBench，这是一个跨三个层次评估 MLLM 的分层基准：基本空间推理、高级行动规划和低级末端执行器控制。我们的框架隔离了独特的双手挑战，例如手臂可达性和运动学限制，从而区分知觉幻觉和计划失败。对 30 多个最先进模型的分析表明，尽管 MLLM 具有高水平的推理能力，但它仍难以应对双臂空间接地和控制，经常导致相互干扰和排序错误。这些发现表明，当前的范式缺乏对相互运动学约束的深入理解，强调未来研究需要关注臂间碰撞避免和细粒度时间排序。

</details>

---

## 284. Learning Human-Like Badminton Skills for Humanoid Robots

**中文标题**: 仿人机器人学习类人羽毛球技能

**Date**: 2026-02-09 | **arXiv**: [2602.08370v1](http://arxiv.org/abs/2602.08370v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.08370v1)

<details><summary><b>Abstract</b></summary>

Realizing versatile and human-like performance in high-demand sports like badminton remains a formidable challenge for humanoid robotics. Unlike standard locomotion or static manipulation, this task demands a seamless integration of explosive whole-body coordination and precise, timing-critical interception. While recent advances have achieved lifelike motion mimicry, bridging the gap between kinematic imitation and functional, physics-aware striking without compromising stylistic naturalness is non-trivial. To address this, we propose Imitation-to-Interaction, a progressive reinforcement learning framework designed to evolve a robot from a "mimic" to a capable "striker." Our approach establishes a robust motor prior from human data, distills it into a compact, model-based state representation, and stabilizes dynamics via adversarial priors. Crucially, to overcome the sparsity of expert demonstrations, we introduce a manifold expansion strategy that generalizes discrete strike points into a dense interaction volume. We validate our framework through the mastery of diverse skills, including lifts and drop shots, in simulation. Furthermore, we demonstrate the first zero-shot sim-to-real transfer of anthropomorphic badminton skills to a humanoid robot, successfully replicating the kinetic elegance and functional precision of human athletes in the physical world.

</details>

<details><summary><b>中文摘要</b></summary>

对于人形机器人来说，在羽毛球等高要求运动中实现多功能和类人的表现仍然是一个艰巨的挑战。与标准的运动或静态操纵不同，这项任务需要爆炸性全身协调和精确、时间关键的拦截的无缝集成。虽然最近的进展已经实现了逼真的运动模仿，但在不影响风格自然性的情况下弥合运动学模仿和功能性物理感知打击之间的差距并非易事。为了解决这个问题，我们提出了模仿到交互，这是一种渐进式强化学习框架，旨在将机器人从“模仿者”进化为有能力的“前锋”。我们的方法根据人类数据建立了强大的运动先验，将其提炼成紧凑的、基于模型的状态表示，并通过对抗性先验稳定动态。至关重要的是，为了克服专家演示的稀疏性，我们引入了一种流形扩展策略，将离散的打击点概括为密集的交互体积。我们通过在模拟中掌握各种技能（包括举起球和吊球）来验证我们的框架。此外，我们还展示了首次将拟人羽毛球技能零镜头模拟到真实地转移到人形机器人上，成功地复制了人类运动员在现实世界中的运动优雅和功能精确度。

</details>

---

## 285. Controlled Flight of an Insect-Scale Flapping-Wing Robot via Integrated Onboard Sensing and Computation

**中文标题**: 通过集成机载传感和计算控制昆虫规模扑翼机器人的飞行

**Date**: 2026-02-09 | **arXiv**: [2602.08328v1](http://arxiv.org/abs/2602.08328v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.08328v1)

<details><summary><b>Abstract</b></summary>

Aerial insects can effortlessly navigate dense vegetation, whereas similarly sized aerial robots typically depend on offboard sensors and computation to maintain stable flight. This disparity restricts insect-scale robots to operation within motion capture environments, substantially limiting their applicability to tasks such as search-and-rescue and precision agriculture. In this work, we present a 1.29-gram aerial robot capable of hovering and tracking trajectories with solely onboard sensing and computation. The combination of a sensor suite, estimators, and a low-level controller achieved centimeter-scale positional flight accuracy. Additionally, we developed a hierarchical controller in which a human operator provides high-level commands to direct the robot's motion. In a 30-second flight experiment conducted outside a motion capture system, the robot avoided obstacles and ultimately landed on a sunflower. This level of sensing and computational autonomy represents a significant advancement for the aerial microrobotics community, further opening opportunities to explore onboard planning and power autonomy.

</details>

<details><summary><b>中文摘要</b></summary>

空中昆虫可以毫不费力地在茂密的植被中导航，而类似大小的空中机器人通常依靠机外传感器和计算来保持稳定的飞行。这种差异限制了昆虫级机器人只能在动作捕捉环境中运行，从而极大地限制了它们在搜索救援和精准农业等任务中的适用性。在这项工作中，我们展示了一款 1.29 克重的空中机器人，能够仅通过机载传感和计算来悬停和跟踪轨迹。传感器套件、估计器和低级控制器的组合实现了厘米级的位置飞行精度。此外，我们开发了一种分层控制器，其中人类操作员提供高级命令来指导机器人的运动。在动作捕捉系统外进行的 30 秒飞行实验中，机器人避开了障碍物，最终降落在向日葵上。这种水平的传感和计算自主性代表了航空微型机器人社区的重大进步，进一步为探索机载规划和动力自主性提供了机会。

</details>

---

## 286. ReefFlex: A Generative Design Framework for Soft Robotic Grasping of Organic and Fragile objects

**中文标题**: ReefFlex：用于软机器人抓取有机和易碎物体的生成设计框架

**Date**: 2026-02-09 | **arXiv**: [2602.08285v1](http://arxiv.org/abs/2602.08285v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.08285v1)

<details><summary><b>Abstract</b></summary>

Climate change, invasive species and human activities are currently damaging the world's coral reefs at unprecedented rates, threatening their vast biodiversity and fisheries, and reducing coastal protection. Solving this vast challenge requires scalable coral regeneration technologies that can breed climate-resilient species and accelerate the natural regrowth processes; actions that are impeded by the absence of safe and robust tools to handle the fragile coral. We investigate ReefFlex, a generative soft finger design methodology that explores a diverse space of soft fingers to produce a set of candidates capable of safely grasping fragile and geometrically heterogeneous coral in a cluttered environment. Our key insight is encoding heterogeneous grasping into a reduced set of motion primitives, creating a simplified, tractable multi-objective optimisation problem. To evaluate the method, we design a soft robot for reef rehabilitation, which grows and manipulates coral in onshore aquaculture facilities for future reef out-planting. We demonstrate ReefFlex increases both grasp success and grasp quality (disturbance resistance, positioning accuracy) and reduces in adverse events encountered during coral manipulation compared to reference designs. ReefFlex, offers a generalisable method to design soft end-effectors for complex handling and paves a pathway towards automation in previously unachievable domains like coral handling for restoration.

</details>

<details><summary><b>中文摘要</b></summary>

气候变化、入侵物种和人类活动目前正以前所未有的速度破坏世界珊瑚礁，威胁其丰富的生物多样性和渔业，并减少沿海保护。解决这一巨大挑战需要可扩展的珊瑚再生技术，这些技术可以培育适应气候变化的物种并加速自然再生过程；由于缺乏安全和强大的工具来处理脆弱的珊瑚而阻碍的行动。我们研究了 ReefFlex，这是一种生成软手指设计方法，该方法探索不同的软手指空间，以产生一组能够在杂乱的环境中安全地抓住脆弱且几何异质珊瑚的候选珊瑚。我们的主要见解是将异构抓取编码为一组减少的运动原语，创建一个简化的、易于处理的多目标优化问题。为了评估该方法，我们设计了一种用于珊瑚礁修复的软机器人，它可以在陆上水产养殖设施中生长和操纵珊瑚，以便将来进行珊瑚礁外植。我们证明，与参考设计相比，ReefFlex 提高了抓取成功率和抓取质量（抗干扰性、定位精度），并减少了珊瑚操作过程中遇到的不良事件。 ReefFlex 提供了一种通用的方法来设计用于复杂处理的软末端执行器，并为以前无法​​实现的领域（例如用于修复的珊瑚处理）的自动化铺平了道路。

</details>

---

## 287. Aerial Manipulation with Contact-Aware Onboard Perception and Hybrid Control

**中文标题**: 具有接触感知机载感知和混合控制的空中操纵

**Date**: 2026-02-09 | **arXiv**: [2602.08251v1](http://arxiv.org/abs/2602.08251v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.08251v1)

<details><summary><b>Abstract</b></summary>

Aerial manipulation (AM) promises to move Unmanned Aerial Vehicles (UAVs) beyond passive inspection to contact-rich tasks such as grasping, assembly, and in-situ maintenance. Most prior AM demonstrations rely on external motion capture (MoCap) and emphasize position control for coarse interactions, limiting deployability. We present a fully onboard perception-control pipeline for contact-rich AM that achieves accurate motion tracking and regulated contact wrenches without MoCap. The main components are (1) an augmented visual-inertial odometry (VIO) estimator with contact-consistency factors that activate only during interaction, tightening uncertainty around the contact frame and reducing drift, and (2) image-based visual servoing (IBVS) to mitigate perception-control coupling, together with a hybrid force-motion controller that regulates contact wrenches and lateral motion for stable contact. Experiments show that our approach closes the perception-to-wrench loop using only onboard sensing, yielding an velocity estimation improvement of 66.01% at contact, reliable target approach, and stable force holding-pointing toward deployable, in-the-wild aerial manipulation.

</details>

<details><summary><b>中文摘要</b></summary>

空中操纵 (AM) 有望使无人机 (UAV) 超越被动检查，转向执行抓取、组装和现场维护等接触丰富的任务。大多数先前的增材制造演示都依赖于外部动作捕捉 (MoCap)，并强调粗略交互的位置控制，从而限制了可部署性。我们为接触丰富的增材​​制造提供了一个完全板载的感知控制管道，可以在没有MoCap的情况下实现精确的运动跟踪和调节接触扳手。主要组件是（1）增强视觉惯性里程计（VIO）估计器，具有仅在交互过程中激活的接触一致性因素，收紧接触框架周围的不确定性并减少漂移；（2）基于图像的视觉伺服（IBVS）以减轻感知控制耦合，以及混合力运动控制器，用于调节接触扳手和横向运动以实现稳定接触。实验表明，我们的方法仅使用机载传感来闭合感知到扳手环路，接触时的速度估计提高了 66.01%，可靠的目标接近，以及稳定的力保持指向可部署的野外空中操纵。

</details>

---

## 288. STEP: Warm-Started Visuomotor Policies with Spatiotemporal Consistency Prediction

**中文标题**: 步骤：具有时空一致性预测的热启动视觉运动策略

**Date**: 2026-02-09 | **arXiv**: [2602.08245v1](http://arxiv.org/abs/2602.08245v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.08245v1)

<details><summary><b>Abstract</b></summary>

Diffusion policies have recently emerged as a powerful paradigm for visuomotor control in robotic manipulation due to their ability to model the distribution of action sequences and capture multimodality. However, iterative denoising leads to substantial inference latency, limiting control frequency in real-time closed-loop systems. Existing acceleration methods either reduce sampling steps, bypass diffusion through direct prediction, or reuse past actions, but often struggle to jointly preserve action quality and achieve consistently low latency. In this work, we propose STEP, a lightweight spatiotemporal consistency prediction mechanism to construct high-quality warm-start actions that are both distributionally close to the target action and temporally consistent, without compromising the generative capability of the original diffusion policy. Then, we propose a velocity-aware perturbation injection mechanism that adaptively modulates actuation excitation based on temporal action variation to prevent execution stall especially for real-world tasks. We further provide a theoretical analysis showing that the proposed prediction induces a locally contractive mapping, ensuring convergence of action errors during diffusion refinement. We conduct extensive evaluations on nine simulated benchmarks and two real-world tasks. Notably, STEP with 2 steps can achieve an average 21.6% and 27.5% higher success rate than BRIDGER and DDIM on the RoboMimic benchmark and real-world tasks, respectively. These results demonstrate that STEP consistently advances the Pareto frontier of inference latency and success rate over existing methods.

</details>

<details><summary><b>中文摘要</b></summary>

扩散策略最近已成为机器人操作中视觉运动控制的强大范例，因为它们能够对动作序列的分布进行建模并捕获多模态。然而，迭代去噪会导致大量的推理延迟，从而限制了实时闭环系统中的控制频率。现有的加速方法要么减少采样步骤，通过直接预测绕过扩散，要么重用过去的动作，但通常很难共同保持动作质量并实现持续的低延迟。在这项工作中，我们提出了STEP，一种轻量级的时空一致性预测机制，用于构建高质量的热启动动作，该动作在分布上接近目标动作并且在时间上一致，而不损害原始扩散策略的生成能力。然后，我们提出了一种速度感知扰动注入机制，该机制根据时间动作变化自适应地调制驱动激励，以防止执行停顿，特别是对于现实世界的任务。我们进一步提供了理论分析，表明所提出的预测会产生局部收缩映射，确保扩散细化期间动作误差的收敛。我们对九个模拟基准和两个实际任务进行了广泛的评估。值得注意的是，在 RoboMimic 基准测试和实际任务中，2 个步骤的 STEP 的成功率比 BRIDGER 和 DDIM 平均高出 21.6% 和 27.5%。这些结果表明，STEP 始终超越现有方法的推理延迟和成功率的帕累托前沿。

</details>

---

