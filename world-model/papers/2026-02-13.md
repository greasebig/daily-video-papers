# arXiv World Model Papers - 2026-02-13

**Paper Count**: 7

---

## 1. The Observer Effect in World Models: Invasive Adaptation Corrupts Latent Physics / 世界模型中的观察者效应：侵入性适应破坏了潜在的物理学

**Date**: 2026-02-12 | **arXiv**: [2602.12218v1](http://arxiv.org/abs/2602.12218v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.12218v1)

**Categories**: cs.LG, cs.AI

<details><summary><b>Abstract / 摘要</b></summary>

Determining whether neural models internalize physical laws as world models, rather than exploiting statistical shortcuts, remains challenging, especially under out-of-distribution (OOD) shifts. Standard evaluations often test latent capability via downstream adaptation (e.g., fine-tuning or high-capacity probes), but such interventions can change the representations being measured and thus confound what was learned during self-supervised learning (SSL). We propose a non-invasive evaluation protocol, PhyIP. We test whether physical quantities are linearly decodable from frozen representations, motivated by the linear representation hypothesis. Across fluid dynamics and orbital mechanics, we find that when SSL achieves low error, latent structure becomes linearly accessible. PhyIP recovers internal energy and Newtonian inverse-square scaling on OOD tests (e.g., $ρ> 0.90$). In contrast, adaptation-based evaluations can collapse this structure ($ρ\approx 0.05$). These findings suggest that adaptation-based evaluation can obscure latent structures and that low-capacity probes offer a more accurate evaluation of physical world models.

确定神经模型是否将物理定律内化为世界模型，而不是利用统计捷径，仍然具有挑战性，特别是在分布外（OOD）变化的情况下。标准评估通常通过下游适应（例如微调或高容量探测）来测试潜在能力，但此类干预可能会改变正在测量的表示，从而混淆自监督学习（SSL）期间学到的内容。我们提出了一种非侵入性评估协议 PhyIP。在线性表示假设的推动下，我们测试物理量是否可以从冻结表示中线性解码。在流体动力学和轨道力学中，我们发现当 SSL 实现低误差时，潜在结构变得可线性访问。 PhyIP 在 OOD 测试中恢复内能和牛顿平方反比缩放（例如 $ρ> 0.90$）。相反，基于适应的评估可以破坏这种结构（$ρ\approx 0.05$）。这些发现表明，基于适应的评估可以掩盖潜在结构，并且低容量探针可以对物理世界模型提供更准确的评估。

</details>

---

## 2. Accelerating Robotic Reinforcement Learning with Agent Guidance / 通过代理指导加速机器人强化学习

**Date**: 2026-02-12 | **arXiv**: [2602.11978v1](http://arxiv.org/abs/2602.11978v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.11978v1)

**Categories**: cs.RO, cs.AI

<details><summary><b>Abstract / 摘要</b></summary>

Reinforcement Learning (RL) offers a powerful paradigm for autonomous robots to master generalist manipulation skills through trial-and-error. However, its real-world application is stifled by severe sample inefficiency. Recent Human-in-the-Loop (HIL) methods accelerate training by using human corrections, yet this approach faces a scalability barrier. Reliance on human supervisors imposes a 1:1 supervision ratio that limits fleet expansion, suffers from operator fatigue over extended sessions, and introduces high variance due to inconsistent human proficiency. We present Agent-guided Policy Search (AGPS), a framework that automates the training pipeline by replacing human supervisors with a multimodal agent. Our key insight is that the agent can be viewed as a semantic world model, injecting intrinsic value priors to structure physical exploration. By using executable tools, the agent provides precise guidance via corrective waypoints and spatial constraints for exploration pruning. We validate our approach on two tasks, ranging from precision insertion to deformable object manipulation. Results demonstrate that AGPS outperforms HIL methods in sample efficiency. This automates the supervision pipeline, unlocking the path to labor-free and scalable robot learning. Project website: https://agps-rl.github.io/agps.

强化学习 (RL) 为自主机器人提供了一个强大的范例，让其通过反复试验掌握通用操作技能。然而，其实际应用却因严重的样本效率低下而受到抑制。最近的人在环（HIL）方法通过使用人工修正来加速训练，但这种方法面临可扩展性障碍。对人类监督员的依赖强制实行 1:1 的监督比例，这限制了车队的扩张，操作员在长时间的工作中会感到疲劳，并且由于人员熟练程度不一致而带来很大的差异。我们提出了代理引导策略搜索（AGPS），这是一个通过用多模式代理取代人类监督员来自动化训练流程的框架。我们的主要见解是，代理可以被视为语义世界模型，在结构物理探索之前注入内在价值。通过使用可执行工具，代理通过修正路径点和空间约束提供精确的指导，以进行探索修剪。我们在两项任务上验证了我们的方法，从精确插入到可变形对象操作。结果表明，AGPS 在样本效率方面优于 HIL 方法。这实现了监督管道的自动化，开启了免劳动力且可扩展的机器人学习之路。项目网站：https://agps-rl.github.io/agps。

</details>

---

## 3. Where Bits Matter in World Model Planning: A Paired Mixed-Bit Study for Efficient Spatial Reasoning / 比特在世界模型规划中的作用：高效空间推理的配对混合比特研究

**Date**: 2026-02-12 | **arXiv**: [2602.11882v1](http://arxiv.org/abs/2602.11882v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.11882v1)

**Categories**: cs.LG, cs.AI, cs.CV, cs.RO

**Code**: https://github.com/suraj-ranganath/DINO-MBQuant.

<details><summary><b>Abstract / 摘要</b></summary>

Efficient spatial reasoning requires world models that remain reliable under tight precision budgets. We study whether low-bit planning behavior is determined mostly by total bitwidth or by where bits are allocated across modules. Using DINO-WM on the Wall planning task, we run a paired-goal mixed-bit evaluation across uniform, mixed, asymmetric, and layerwise variants under two planner budgets. We observe a consistent three-regime pattern: 8-bit and 6-bit settings remain close to FP16, 3-bit settings collapse, and 4-bit settings are allocation-sensitive. In that transition region, preserving encoder precision improves planning relative to uniform quantization, and near-size asymmetric variants show the same encoder-side direction. In a later strict 22-cell replication with smaller per-cell episode count, the mixed-versus-uniform INT4 sign becomes budget-conditioned, which further highlights the sensitivity of this transition regime. These findings motivate module-aware, budget-aware quantization policies as a broader research direction for efficient spatial reasoning. Code and run artifacts are available at https://github.com/suraj-ranganath/DINO-MBQuant.

高效的空间推理需要世界模型在严格的精度预算下保持可靠。我们研究低位规划行为是否主要由总位宽或位在模块之间分配的位置决定。在 Wall 规划任务上使用 DINO-WM，我们在两个规划器预算下对均匀、混合、不对称和分层变体进行配对目标混合位评估。我们观察到一致的三机制模式：8 位和 6 位设置保持接近 FP16，3 位设置崩溃，4 位设置对分配敏感。在该过渡区域中，保持编码器精度相对于均匀量化改进了规划，并且接近尺寸的不对称变体显示了相同的编码器侧方向。在后来的严格 22 细胞复制中，每个细胞的情节数更小，混合与均匀的 INT4 符号变得受预算限制，这进一步凸显了这种过渡机制的敏感性。这些发现激发了模块感知、预算感知的量化策略作为高效空间推理的更广泛的研究方向。代码和运行工件可在 https://github.com/suraj-ranganath/DINO-MBQuant 获取。

</details>

---

## 4. Budget-Constrained Agentic Large Language Models: Intention-Based Planning for Costly Tool Use / 预算受限的代理大型语言模型：基于意图的昂贵工具使用规划

**Date**: 2026-02-12 | **arXiv**: [2602.11541v1](http://arxiv.org/abs/2602.11541v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.11541v1)

**Categories**: cs.AI, cs.LG

<details><summary><b>Abstract / 摘要</b></summary>

We study budget-constrained tool-augmented agents, where a large language model must solve multi-step tasks by invoking external tools under a strict monetary budget. We formalize this setting as sequential decision making in context space with priced and stochastic tool executions, making direct planning intractable due to massive state-action spaces, high variance of outcomes and prohibitive exploration cost. To address these challenges, we propose INTENT, an inference-time planning framework that leverages an intention-aware hierarchical world model to anticipate future tool usage, risk-calibrated cost, and guide decisions online. Across cost-augmented StableToolBench, INTENT strictly enforces hard budget feasibility while substantially improving task success over baselines, and remains robust under dynamic market shifts such as tool price changes and varying budgets.

我们研究预算受限的工具增强代理，其中大型语言模型必须在严格的货币预算下通过调用外部工具来解决多步骤任务。我们将这种设置形式化为上下文空间中具有定价和随机工具执行的顺序决策，由于巨大的状态动作空间、结果的高方差和令人望而却步的探索成本，使得直接规划变得棘手。为了应对这些挑战，我们提出了 INTENT，这是一种推理时间规划框架，它利用意图感知的分层世界模型来预测未来的工具使用、风险校准成本并指导在线决策。在成本增加的 StableToolBench 中，INTENT 严格执行硬预算可行性，同时大幅提高任务成功率（较基准），并在工具价格变化和预算变化等动态市场变化下保持稳健。

</details>

---

## 5. Causal-JEPA: Learning World Models through Object-Level Latent Interventions / 因果-JEPA：通过对象级潜在干预学习世界模型

**Date**: 2026-02-11 | **arXiv**: [2602.11389v1](http://arxiv.org/abs/2602.11389v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.11389v1)

**Categories**: cs.AI

**Code**: https://github.com/galilai-group/cjepa.

<details><summary><b>Abstract / 摘要</b></summary>

World models require robust relational understanding to support prediction, reasoning, and control. While object-centric representations provide a useful abstraction, they are not sufficient to capture interaction-dependent dynamics. We therefore propose C-JEPA, a simple and flexible object-centric world model that extends masked joint embedding prediction from image patches to object-centric representations. By applying object-level masking that requires an object's state to be inferred from other objects, C-JEPA induces latent interventions with counterfactual-like effects and prevents shortcut solutions, making interaction reasoning essential. Empirically, C-JEPA leads to consistent gains in visual question answering, with an absolute improvement of about 20\% in counterfactual reasoning compared to the same architecture without object-level masking. On agent control tasks, C-JEPA enables substantially more efficient planning by using only 1\% of the total latent input features required by patch-based world models, while achieving comparable performance. Finally, we provide a formal analysis demonstrating that object-level masking induces a causal inductive bias via latent interventions. Our code is available at https://github.com/galilai-group/cjepa.

世界模型需要强大的关系理解来支持预测、推理和控制。虽然以对象为中心的表示提供了有用的抽象，但它们不足以捕获依赖于交互的动态。因此，我们提出了 C-JEPA，这是一种简单而灵活的以对象为中心的世界模型，它将蒙版联合嵌入预测从图像块扩展到以对象为中心的表示。通过应用需要从其他对象推断对象状态的对象级屏蔽，C-JEPA 会引发具有类似反事实效果的潜在干预，并阻止捷径解决方案，从而使交互推理变得至关重要。根据经验，C-JEPA 在视觉问答方面带来了持续的收益，与没有对象级屏蔽的相同架构相比，反事实推理绝对提高了约 20%。在代理控制任务上，C-JEPA 仅使用基于补丁的世界模型所需的总潜在输入特征的 1%，从而实现了更高效的规划，同时实现了可比的性能。最后，我们提供了正式的分析，证明对象级掩蔽通过潜在干预诱发了因果归纳偏差。我们的代码可在 https://github.com/galilai-group/cjepa 获取。

</details>

---

## 6. Neuro-Symbolic Synergy for Interactive World Modeling / 交互式世界建模的神经符号协同作用

**Date**: 2026-02-11 | **arXiv**: [2602.10480v2](http://arxiv.org/abs/2602.10480v2) | **PDF**: [Link](http://arxiv.org/pdf/2602.10480v2)

**Categories**: cs.CL

<details><summary><b>Abstract / 摘要</b></summary>

Large language models (LLMs) exhibit strong general-purpose reasoning capabilities, yet they frequently hallucinate when used as world models (WMs), where strict compliance with deterministic transition rules--particularly in corner cases--is essential. In contrast, Symbolic WMs provide logical consistency but lack semantic expressivity. To bridge this gap, we propose Neuro-Symbolic Synergy (NeSyS), a framework that integrates the probabilistic semantic priors of LLMs with executable symbolic rules to achieve both expressivity and robustness. NeSyS alternates training between the two models using trajectories inadequately explained by the other. Unlike rule-based prompting, the symbolic WM directly constrains the LLM by modifying its output probability distribution. The neural WM is fine-tuned only on trajectories not covered by symbolic rules, reducing training data by 50% without loss of accuracy. Extensive experiments on three distinct interactive environments, i.e., ScienceWorld, Webshop, and Plancraft, demonstrate NeSyS's consistent advantages over baselines in both WM prediction accuracy and data efficiency.

大型语言模型 (LLM) 表现出强大的通用推理能力，但在用作世界模型 (WM) 时，它们经常产生幻觉，在这种情况下，严格遵守确定性转换规则（尤其是在极端情况下）至关重要。相比之下，符号 WM 提供逻辑一致性，但缺乏语义表达能力。为了弥补这一差距，我们提出了神经符号协同（NeSyS），这是一个将法学硕士的概率语义先验与可执行符号规则相结合的框架，以实现表达性和鲁棒性。 NeSyS 使用另一个模型无法充分解释的轨迹在两个模型之间交替训练。与基于规则的提示不同，符号WM通过修改其输出概率分布来直接约束LLM。神经 WM 仅对符号规则未涵盖的轨迹进行微调，从而在不损失准确性的情况下减少 50% 的训练数据。在三个不同的交互环境（即 ScienceWorld、Webshop 和 Plancraft）上进行的大量实验证明了 NeSyS 在 WM 预测准确性和数据效率方面相对于基线具有一致的优势。

</details>

---

## 7. On Emergent Social World Models -- Evidence for Functional Integration of Theory of Mind and Pragmatic Reasoning in Language Models / 论新兴的社会世界模型——心灵理论和语用推理在语言模型中功能整合的证据

**Date**: 2026-02-10 | **arXiv**: [2602.10298v1](http://arxiv.org/abs/2602.10298v1) | **PDF**: [Link](http://arxiv.org/pdf/2602.10298v1)

**Categories**: cs.CL

<details><summary><b>Abstract / 摘要</b></summary>

This paper investigates whether LMs recruit shared computational mechanisms for general Theory of Mind (ToM) and language-specific pragmatic reasoning in order to contribute to the general question of whether LMs may be said to have emergent "social world models", i.e., representations of mental states that are repurposed across tasks (the functional integration hypothesis). Using behavioral evaluations and causal-mechanistic experiments via functional localization methods inspired by cognitive neuroscience, we analyze LMs' performance across seven subcategories of ToM abilities (Beaudoin et al., 2020) on a substantially larger localizer dataset than used in prior like-minded work. Results from stringent hypothesis-driven statistical testing offer suggestive evidence for the functional integration hypothesis, indicating that LMs may develop interconnected "social world models" rather than isolated competencies. This work contributes novel ToM localizer data, methodological refinements to functional localization techniques, and empirical insights into the emergence of social cognition in artificial systems.

本文研究了 LM 是否为一般心智理论 (ToM) 和特定于语言的语用推理引入共享计算机制，以便回答 LM 是否可以说具有新兴的“社会世界模型”这一普遍问题，即跨任务重新调整用途的心理状态的表示（功能整合假设）。通过受认知神经科学启发的功能定位方法进行行为评估和因果机制实验，我们在比之前志同道合的工作中使用的定位器数据集大得多的定位器数据集上分析了 LM 在 ToM 能力的七个子类别中的表现（Beaudoin 等人，2020）。严格的假设驱动的统计测试的结果为功能整合假设提供了暗示性证据，表明 LM 可能会开发相互关联的“社会世界模型”，而不是孤立的能力。这项工作贡献了新颖的 ToM 定位器数据、功能定位技术的方法改进以及对人工系统中社会认知的出现的实证见解。

</details>

---

